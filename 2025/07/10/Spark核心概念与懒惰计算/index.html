<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>Spark核心概念与懒惰计算[未修订完] | 凌霄的博客</title><meta name="keywords" content="Spark,分布式计算,RDD"><meta name="author" content="XR"><meta name="copyright" content="XR"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="Spark核心概念与懒惰计算[未修订完]"><meta name="application-name" content="Spark核心概念与懒惰计算[未修订完]"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="Spark核心概念与懒惰计算[未修订完]"><meta property="og:url" content="http://example.com/2025/07/10/Spark%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97/index.html"><meta property="og:site_name" content="凌霄的博客"><meta property="og:description" content="Spark核心概念与懒惰计算[未修订完]1. Spark核心数据结构：RDD与共享变量在深入探讨算子之前，我们必须首先理解Spark工作的基本单元：弹性分布式数据集（RDD） 和 共享变量。它们是构建所有Spark应用的基础。 1.1 核心抽象：弹性分布式数据集（RDD）RDD (Resilient"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg"><meta property="article:author" content="XR"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg"><meta name="description" content="Spark核心概念与懒惰计算[未修订完]1. Spark核心数据结构：RDD与共享变量在深入探讨算子之前，我们必须首先理解Spark工作的基本单元：弹性分布式数据集（RDD） 和 共享变量。它们是构建所有Spark应用的基础。 1.1 核心抽象：弹性分布式数据集（RDD）RDD (Resilient"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://example.com/2025/07/10/Spark%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走！再看看嘛！","backTitle":"♪(^∇^*)欢迎肥来！"},
  LA51: undefined,
  greetingBox: undefined,
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  music_page_default: "nav_music",
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🧱 团队小组发动机"]},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: XR","link":"链接: ","source":"来源: 凌霄的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '凌霄的博客',
  title: 'Spark核心概念与懒惰计算[未修订完]',
  postAI: '',
  pageFillDescription: 'Spark核心概念与懒惰计算[未修订完], 1. Spark核心数据结构：RDD与共享变量, 1.1 核心抽象：弹性分布式数据集（RDD）, 创建RDD, 1.2 优化工具：共享变量, 1.2.1 广播变量 (Broadcast Variables), 1.2.2 累加器 (Accumulators), 2. Spark算子的分类与特性, 2.1 按功能划分：转换（Transformation）与行动（Action）, 2.2 按依赖关系划分：窄依赖（Narrow）与宽依赖（Wide）, 3. 算子执行的内存与磁盘管理, 3.1 统一内存管理模型, 3.2 内存与磁盘的交互：溢写 (Spill) 与合并 (Merge), 4. 数据序列化与网络传输, 5. 为什么理解算子原理如此重要？, 6. RDD懒惰计算机制深度剖析, 6.1 核心概念：懒惰计算 vs 急切计算, 6.2 为什么Spark要采用懒惰计算？, 6.3 懒惰计算工作原理：详细示例分析, 6.4 执行流程详解, 7. 数据本地性原理深度解析, 7.1 数据本地性的层次结构核心概念与懒惰计算未修订完核心数据结构与共享变量在深入探讨算子之前我们必须首先理解工作的基本单元弹性分布式数据集和共享变量它们是构建所有应用的基础核心抽象弹性分布式数据集是最核心的抽象可以将其理解为一个不可变的可分区的包含可并行计算元素的大型集合想象一下你有一本超大的书你的海量数据这本书太厚了一个人根本读不完于是你想了个办法分布式你把书撕成很多小册子分片分给一群朋友集群中的计算机每人读一部分数据集这本书就是你的数据集合可以是数字文字用户信息等等弹性突然有个朋友把咖啡洒在小册子上机器故障没关系因为你记得这本书是怎么撕开的血统你可以重新复印那几页重新计算整个阅读工作不会因此停止这个就是的设计特点弹性通过其血缘关系天生支持容错如果某个分区的数据丢失可以根据血缘关系重新计算出该分区而无需从头再来分布式的数据被分成多个分区存储在集群的不同节点上这使得数据可以被并行处理数据集它是一个只读的数据集合可以存储任何类型的或对象不可变一旦创建就不能被修改对的任何操作转换都会生成一个新的这种设计简化了并发和容错惰性计算在中对的转换操作如等不会立即执行而是记录下操作形成血缘关系图只有当遇到一个行动操作如等时才会触发实际的计算为什么重要不怕故障机器坏了数据能恢复高效并行任务可以分给很多机器同时做灵活处理适合各种复杂的数据处理任务内存计算数据可以放在内存中处理比读硬盘快得多创建在中创建主要有两种方式并行化一个已有的集合使用的方法将程序中的一个普通集合如转换为一个分布式这主要用于学习和测试读取外部数据源从本地文件系统等外部存储系统加载数据这是生产环境中最常见的方式优化工具共享变量通常情况下当我们在端定义的函数闭包被发送到上执行时函数中引用的所有变量都会被复制一份每个任务都拥有一份独立的副本但有时我们需要在所有任务间共享数据或者将结果聚合回端为此提供了两种特殊的共享变量广播变量问题当一个较大的只读变量例如一个查找表或配置对象被多个任务使用时如果直接在闭包中引用它这个变量会被序列化并随每个任务一起发送到造成巨大的网络开销解决方案使用广播变量广播变量只会被发送到每个一次然后该上的所有任务都可以共享这份数据这极大地减少了网络传输和的负载有一个较大的只读查找表将其广播出去在算子中通过方法访问广播变量累加器问题任务在上执行时是相互隔离的我们无法在算子内部安全地修改一个外部变量例如用一个计数器来统计符合某个条件的记录数解决方案使用累加器累加器是一种只支持累加操作的变量它可以在所有任务中被安全地并行更新最终由端统一读取结果原生支持数值型和集合类型的累加器创建一个长整型累加器初始值为在算子中通过方法累加在端通过获取最终结果偶数的数量是输出理解了广播变量和累加器之后我们就可以开始学习如何使用算子来操作这些数据结构了算子的分类与特性算子是构建分布式数据处理应用的基础指令理解其分类是掌握编程模型的第一步算子可以从两个核心维度进行分类按功能划分和按依赖关系划分这两个维度共同决定了算子的行为执行时机和性能特征按功能划分转换与行动这个维度决定了算子的执行时机是理解核心特性懒惰计算的关键转换核心思想只定义计算逻辑不立即执行特点懒惰计算调用时并不会立即执行计算而是将该操作记录下来形成一个计算的有向无环图的一部分这就像是制定一份详细的作战计划但并不开火返回值一个新的代表了应用该转换后的结果数据集代表算子等行动核心思想触发计算获取结果特点立即计算调用时会触发一个作业的提交和执行会根据之前构建的将计算任务分发到集群执行这是开火的信号返回值一个非类型的值如或无返回值例如将结果写入外部存储代表算子等按依赖关系划分窄依赖与宽依赖这个维度决定了数据的物理流转方式是理解性能瓶颈的关键窄依赖算子定义子的每个分区只依赖父的一个或少数几个固定的分区这意味着计算可以在单个节点上独立完成无需等待其他节点的数据特点数据不需要跨节点传输计算可以在单个节点上以流水线方式高效执行性能极高代表算子等宽依赖算子定义子的每个分区依赖父的所有或多个分区这意味着一个子分区的计算需要从父的多个分区拉取数据特点需要进行操作数据必须在网络间进行大规模传输和重分区是中最昂贵的操作之一是性能优化的重点和难点代表算子等算子执行的内存与磁盘管理在分布式计算中内存与磁盘的管理是决定性能和稳定性的核心要素通过一个精巧的统一内存管理模型以及高效的溢写机制在执行效率数据缓存和大规模数据处理能力之间取得了动态平衡统一内存管理模型通过一个精巧的统一内存管理模型在执行效率和数据缓存之间取得了动态平衡在版本之前执行内存和存储内存是静态划分的利用率不高而统一内存管理模型允许这两部分内存在运行时动态地相互借用从而极大地提升了内存使用效率其核心思想是计算优先在不影响计算的前提下尽可能多地利用内存进行数据缓存内存区域划分总内存保留内存固定存储内部对象用户内存存储用户代码创建的对象内存统一内存管理区域执行内存算子执行存储内存缓存数据广播变量的内存被划分为几个关键区域保留内存系统保留内存固定为用于存储内部对象和元数据防止用户内存用户代码使用的内存区域例如在算子函数中创建的自定义对象数据结构等这部分内存不受管理如果使用不当是的主要来源之一内存框架自身管理的内存是优化的核心区域它进一步动态地分为执行内存执行算子如时所需的内存这部分内存用于存储中间数据例如时的缓冲区它是保障计算任务顺利执行的关键存储内存用于缓存广播变量等数据的内存通过将常用数据缓存在此可以避免重复计算提升性能当执行内存不足时会强制驱逐存储内存中缓存的数据块为计算任务腾出空间核心机制执行内存和存储内存共享区域动态抢占执行任务可抢占存储内存若存储内存未用完存储内存只能被动回收策略不能抢占执行内存内存与磁盘的交互溢写与合并统一内存管理模型解释了内存的内部划分与动态调整但当执行内存本身也不足以容纳所有计算所需的数据时会发生什么这时会启动溢写机制将部分数据临时写入磁盘以释放内存供当前计算任务继续使用溢写触发时机在执行需要大量内存的算子时如这些算子通常使用基于哈希的聚合器或外部排序器当这些内存中的数据结构例如一个巨大的哈希表的大小超过了可用的执行内存时溢写就会被触发过程将内存中的数据例如哈希表的部分内容进行排序如果需要然后序列化成字节流写入本地磁盘上的一个临时文件之后清空内存中的这部分数据结构以继续处理后续数据一个任务可能会因为数据量巨大而产生多个溢写文件合并触发时机当一个任务处理完其所有的输入数据后它可能已经在磁盘上留下了多个溢写文件同时内存里可能还剩余一部分数据过程为了形成该任务的最终输出例如为的下一阶段准备数据会启动一个合并流程它使用归并排序的策略同时从所有溢写文件和内存中读取数据将它们合并成一个单一的通常是排序好的输出文件这个最终文件才是阶段网络传输的源文件这个内存溢写合并的流程是能够处理远超内存容量的大规模数据的关键它以磁盘的开销为代价换取了计算的稳定性和对海量数据的处理能力数据序列化与网络传输在分布式系统中数据需要在不同节点间通过网络传输而网络传输的数据必须是二进制格式序列化就是将内存中的对象包含数据和结构转换为二进制字节流的过程而反序列化则是相反的过程序列化是中一个基础但极其重要的性能影响点它的效率直接决定了网络传输和磁盘的开销在多个场景下都会触发序列化操作序列化触发场景序列化将从发送到任务包含代码依赖分区信息场景解读当你在端编写的算子函数闭包需要被发送到上执行时整个任务包括代码和其引用的外部变量都会被序列化如果闭包引用了庞大且不可序列化的对象会导致任务提交失败或性能低下序列化数据在节点间传输序列化序列化场景解读这是序列化最影响性能的环节在过程中大量数据需要在节点间流动高效的序列化格式如可以显著减少网络传输的数据量和消耗缓存序列化持久化到内存磁盘将数据序列化后存储场景解读当你调用等包含的缓存级别时数据会以序列化的形式存储这样做的好处是节省内存空间但代价是每次访问缓存数据时都需要进行反序列化增加了开销为什么理解算子原理如此重要在开发中实现同一个业务需求往往有多种算子组合然而不同的实现方式可能导致百倍甚至千倍的性能差异这种差异的根源就在于每个算子背后的数据处理和流转机制完全不同性能差异的根本原因不同算子的性能差异主要源于它们在以下几个方面的不同选择依赖关系是需要的宽依赖还是无需的窄依赖这是最核心的区别数据局部性计算是在数据所在的节点本地执行还是必须通过网络拉取远程数据内存使用模式算子是一次性将整个分区加载到内存还是以流式方式逐条处理这决定了内存消耗的峰值利用率算子的计算逻辑是否复杂是否能被的优化器如进行优化下面的例子直观地展示了和的巨大性能差异尽管它们都能实现分组聚合的功能场景处理数据统计每个用户的订单数量方案使用性能差宽依赖所有数据执行时间约秒数据量方案使用性能好本地预聚合减少数据执行时间约秒数据量约假设有万用户优化思路的本质因此理解算子原理并非炫技而是进行性能优化的基石它能让你在开发时就具备性能思维从而能够选择合适的算子主动避免不必要的例如用替代设计合理的数据流通过等技巧将密集型的操作优化为本地计算利用数据局部性合理设计分区策略让计算尽可能在数据所在的节点发生合理配置资源预估算子的内存消耗为作业分配合理的内存和资源避免和性能瓶颈为什么有些算子执行很快有些却很慢答案就藏在算子的实现原理和数据流转机制中只有深入理解这些才能真正驾驭懒惰计算机制深度剖析懒惰计算是最核心最巧妙的设计之一是其实现高效容错的分布式计算的基石简单来说懒惰计算就是非到万不得已绝不执行计算核心概念懒惰计算急切计算懒惰计算指的是在遇到转换操作时并不会立即执行计算并生成新的它只是记录下这个操作以及它依赖的父即构建了一个逻辑执行计划或称为真正的计算数据读取转换处理会被推迟到遇到行动操作时才触发执行急切计算传统编程或某些数据处理框架如集合的某些操作是急切计算的当你调用一个函数它会立即执行并返回结果例如在中会立即计算并返回对比示例急切计算传统集合立即执行立即执行立即返回结果懒惰计算仅记录操作不执行仅记录操作不执行此时还没有任何实际计算发生这里才开始真正计算为什么要采用懒惰计算这种谋定而后动的设计哲学为带来了几个在分布式环境下至关重要的优势优化执行计划这是懒惰计算最大的优势因为所有转换操作都只是记录在中直到行动操作被调用前都拥有了计算的全景图这使得的优化器如和可以从全局视角对整个计算流程进行优化流水线化在急切计算中会执行两次全量数据扫描但在懒惰计算中会将和这两个操作合并成一个任务数据在分区内以流式的方式被处理一条数据处理完后立刻进行无需将中间结果写入内存或磁盘极大地提升了效率谓词下推如果数据源如支持会将操作下推到数据读取层这样在数据加载到内存之前就能过滤掉大量无关数据从源头上减少了和内存的消耗减少优化器可以分析整个识别出可以避免或优化的操作例如在多个操作中选择最优的执行顺序懒惰计算的优化示例定义一系列转换操作全部是懒惰的过滤操作转换操作再次过滤截取操作只有在调用时才开始优化和执行的优化策略流水线化将所有和操作合并为单个执行谓词下推如果数据源支持将下推到读取层减少中间结果不需要物化每个中间减少不必要的计算懒惰计算使得可以只计算任务真正需要的数据对于一些只需要部分结果的行动操作这个特性可以节省大量的计算资源当你调用时知道只需要获取条记录它会启动任务一旦某个分区计算得到了足够的条记录其他正在运行的或尚未开始的任务就可以被终止避免了对整个数据集的无效扫描类似地只会计算第一个分区直到找到第一条记录为止节省内存和存储由于转换操作不会立即物化中间结果因此极大地节省了内存和磁盘空间在一个长长的转换链中数据以流的方式在算子间传递处理完即被回收内存中只需保留当前正在处理的数据即可这与那些每一步都生成完整中间结果的系统形成了鲜明对比内存效率示例定义长转换链全部懒惰关键点这些中间不会真的存储在内存中它们只是包含信息的对象实际数据在时才计算只有在触发时数据才流式处理无需存储中间结果对比如果是急切计算每个都会产生完整的中间数据集这会消耗倍的内存容错性的天然支持懒惰计算与的容错机制紧密相关因为记录了完整的血缘关系即每个是如何通过转换操作从其父派生而来的这个就像一份详细的数据重建指南当集群中某个节点故障导致其上的数据分区丢失时可以根据这份指南精确地只重新计算丢失的那个分区而无需重跑整个作业懒惰计算使得记录这份指南成为其执行模型的自然组成部分懒惰计算工作原理详细示例分析让我们通过一个完整的例子来理解懒惰计算的工作流程定义惰性只记录来源创建无计算发生只记录数据源转换操作惰性只记录转换逻辑创建无计算发生只记录操作创建无计算发生只记录操作创建无计算发生只记录操作创建无计算发生只记录操作此时的状态行动操作触发计算调用开始真正的计算计算完成结果信息依赖链数据源转换转换转换转换此时只有逻辑执行计划没有实际数据执行流程详解阶段定义和转换阶段到构建过程的内部机制当执行每个转换操作时内部的工作操作内部创建对象记录数据源路径分区策略基于块依赖关系无叶子节点操作内部创建对象记录父转换函数和依赖类型窄依赖操作内部创建对象记录父过滤函数判断依赖类型窄依赖操作内部创建对象记录父聚合函数依赖类型宽依赖分区器构建的图结构分界点阶段触发执行分析从的目标开始回溯链识别依赖关系发现可流水线执行确定需要单独宽依赖边界划分输出按分区的对输入的输出输出结果任务生成根据输入分区数个块生成个根据分区数默认生成个任务调度将任务分发到优先考虑数据本地性数据所在节点严格执行顺序完成才能开始任务执行任务读取文件块流水线执行按哈希分区执行任务从多个节点拉取数据按聚合执行生成最终结果结果收集所有的将结果发送回汇总所有结果返回给用户的懒惰计算机制是实现高效容错的大规模分布式数据处理的核心智慧它将昂贵的计算推迟到最后并利用这段时间窗口进行全局优化极大地提升了处理能力和资源利用率理解这一机制对于编写高效的应用程序至关重要数据本地性原理深度解析移动计算而非移动数据是大数据处理的基本原则数据本地性正是这一原则在中的具体体现由于网络传输的开销远大于内存读取的调度器会尽可能地将计算任务分配到存储着其所需数据的节点上执行以最大限度地减少网络提升性能数据本地性的层次结构定义了从优到劣的多个本地性级别任务调度器会按照这个顺序在一定的时间等待阈值内为任务寻找最近的可用资源本地性级别的详细定义任务和数据在同一个的进程中这是最理想的级别数据无需任何网络传输可以直接在内存中访问任务和数据在同一个物理节点上但可能在不同的进程中数据需要通过节点内部的进程间通信或共享内存来传输任务和数据在同一个机架的不同节点上数据需要通过机架内的交换机进行网络传输任务和数据在集群的任何地方通常意味着需要跨机架进行网络传输这是开销最大的情况数据本地性级别枚举进程本地数据在同一进程中节点本地数据在同一物理节点上机架本地数据在同一机架内任意位置可以在任何地方执行本地性感知的任务调度算法的任务调度并非死等最佳的本地性级别它采用了一种延迟调度策略在效率和时间之间进行权衡调度器首先尝试以级别在数据所在的上启动任务如果在设定的等待时间默认为秒由配置内该没有空闲资源调度器会将本地性级别降级到尝试在该节点的其他上启动任务如果又等待了一个周期后仍然没有资源级别会继续降级到最后到这种策略既追求了最佳的数据本地性又避免了因等待某个繁忙节点而导致整个作业被阻塞本地性感知调度器本地性等待时间配置秒秒秒立即执行',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-07-11 15:21:29',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://npm.elemecdn.com/anzhiyu-blog-static@1.0.4/img/avatar.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/" accesskey="h"><div class="title">凌霄的博客</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Argon2/" style="font-size: 1.05rem;">Argon2<sup>1</sup></a><a href="/tags/DNS/" style="font-size: 1.05rem;">DNS<sup>2</sup></a><a href="/tags/HBase/" style="font-size: 1.05rem;">HBase<sup>1</sup></a><a href="/tags/HDFS/" style="font-size: 1.05rem;">HDFS<sup>3</sup></a><a href="/tags/HTTP/" style="font-size: 1.05rem;">HTTP<sup>1</sup></a><a href="/tags/Hadoop/" style="font-size: 1.05rem;">Hadoop<sup>1</sup></a><a href="/tags/Hive/" style="font-size: 1.05rem;">Hive<sup>1</sup></a><a href="/tags/Java/" style="font-size: 1.05rem;">Java<sup>8</sup></a><a href="/tags/Kubernetes/" style="font-size: 1.05rem;">Kubernetes<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 1.05rem;">Linux<sup>4</sup></a><a href="/tags/Maven/" style="font-size: 1.05rem;">Maven<sup>1</sup></a><a href="/tags/MinIO/" style="font-size: 1.05rem;">MinIO<sup>1</sup></a><a href="/tags/NAT/" style="font-size: 1.05rem;">NAT<sup>1</sup></a><a href="/tags/RDD/" style="font-size: 1.05rem;">RDD<sup>2</sup></a><a href="/tags/SGX/" style="font-size: 1.05rem;">SGX<sup>2</sup></a><a href="/tags/Shuffle%E6%9C%BA%E5%88%B6/" style="font-size: 1.05rem;">Shuffle机制<sup>1</sup></a><a href="/tags/Spark/" style="font-size: 1.05rem;">Spark<sup>6</sup></a><a href="/tags/Spring/" style="font-size: 1.05rem;">Spring<sup>3</sup></a><a href="/tags/TDX/" style="font-size: 1.05rem;">TDX<sup>2</sup></a><a href="/tags/TEE/" style="font-size: 1.05rem;">TEE<sup>3</sup></a><a href="/tags/TME/" style="font-size: 1.05rem;">TME<sup>2</sup></a><a href="/tags/YARN/" style="font-size: 1.05rem;">YARN<sup>1</sup></a><a href="/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/" style="font-size: 1.05rem;">云原生<sup>1</sup></a><a href="/tags/%E4%BB%A3%E7%90%86/" style="font-size: 1.05rem;">代理<sup>1</sup></a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/" style="font-size: 1.05rem;">分布式存储<sup>2</sup></a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/" style="font-size: 1.05rem;">分布式计算<sup>3</sup></a><a href="/tags/%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E9%99%90%E5%88%B6/" style="font-size: 1.05rem;">地理位置限制<sup>1</sup></a><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size: 1.05rem;">大数据<sup>4</sup></a><a href="/tags/%E5%AE%89%E5%85%A8/" style="font-size: 1.05rem;">安全<sup>2</sup></a><a href="/tags/%E5%AF%86%E7%A0%81%E5%93%88%E5%B8%8C/" style="font-size: 1.05rem;">密码哈希<sup>1</sup></a><a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 1.05rem;">密码学<sup>1</sup></a><a href="/tags/%E5%B9%B6%E5%8F%91/" style="font-size: 1.05rem;">并发<sup>2</sup></a><a href="/tags/%E6%8A%80%E6%9C%AF%E4%B8%93%E6%A0%8F/" style="font-size: 1.05rem;">技术专栏<sup>1</sup></a><a href="/tags/%E6%B5%81%E5%AA%92%E4%BD%93%E8%A7%A3%E9%94%81/" style="font-size: 1.05rem;">流媒体解锁<sup>1</sup></a><a href="/tags/%E7%B3%BB%E7%BB%9F/" style="font-size: 1.05rem;">系统<sup>2</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C/" style="font-size: 1.05rem;">网络<sup>4</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90/" style="font-size: 1.05rem;">网络分析<sup>1</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" style="font-size: 1.05rem;">网络安全<sup>1</sup></a><a href="/tags/%E9%98%B2%E7%81%AB%E5%A2%99/" style="font-size: 1.05rem;">防火墙<sup>2</sup></a><a href="/tags/%E9%9A%90%E7%A7%81%E8%AE%A1%E7%AE%97/" style="font-size: 1.05rem;">隐私计算<sup>2</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/07/"><span class="card-archive-list-date">七月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">9</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/06/"><span class="card-archive-list-date">六月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">32</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/01/"><span class="card-archive-list-date">一月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url">大数据</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/Spark/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Spark</span></a><a class="article-meta__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>分布式计算</span></a><a class="article-meta__tags" href="/tags/RDD/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>RDD</span></a></span></div></div><h1 class="post-title" itemprop="name headline">Spark核心概念与懒惰计算[未修订完]</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2025-07-10T03:00:00.000Z" title="发表于 2025-07-10 11:00:00">2025-07-10</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2025-07-11T07:21:29.560Z" title="更新于 2025-07-11 15:21:29">2025-07-11</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="Spark核心概念与懒惰计算[未修订完]"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为杭州"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>杭州</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src=""></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="http://example.com/2025/07/10/Spark%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97/"><header><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url">大数据</a><a href="/tags/Spark/" tabindex="-1" itemprop="url">Spark</a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/" tabindex="-1" itemprop="url">分布式计算</a><a href="/tags/RDD/" tabindex="-1" itemprop="url">RDD</a><h1 id="CrawlerTitle" itemprop="name headline">Spark核心概念与懒惰计算[未修订完]</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">XR</span><time itemprop="dateCreated datePublished" datetime="2025-07-10T03:00:00.000Z" title="发表于 2025-07-10 11:00:00">2025-07-10</time><time itemprop="dateCreated datePublished" datetime="2025-07-11T07:21:29.560Z" title="更新于 2025-07-11 15:21:29">2025-07-11</time></header><h1 id="Spark核心概念与懒惰计算-未修订完"><a href="#Spark核心概念与懒惰计算-未修订完" class="headerlink" title="Spark核心概念与懒惰计算[未修订完]"></a>Spark核心概念与懒惰计算[未修订完]</h1><h2 id="1-Spark核心数据结构：RDD与共享变量"><a href="#1-Spark核心数据结构：RDD与共享变量" class="headerlink" title="1. Spark核心数据结构：RDD与共享变量"></a>1. Spark核心数据结构：RDD与共享变量</h2><p>在深入探讨算子之前，我们必须首先理解Spark工作的基本单元：<strong>弹性分布式数据集（RDD）</strong> 和 <strong>共享变量</strong>。它们是构建所有Spark应用的基础。</p>
<h3 id="1-1-核心抽象：弹性分布式数据集（RDD）"><a href="#1-1-核心抽象：弹性分布式数据集（RDD）" class="headerlink" title="1.1 核心抽象：弹性分布式数据集（RDD）"></a>1.1 核心抽象：弹性分布式数据集（RDD）</h3><p><strong>RDD (Resilient Distributed Dataset)</strong> 是Spark最核心的抽象。可以将其理解为一个<strong>不可变的、可分区的、包含可并行计算元素的大型集合</strong>。</p>
<p>想象一下，你有一本超大的书（你的海量数据），这本书太厚了，一个人根本读不完。于是你想了个办法：</p>
<ol>
<li><strong>分布式（Distributed）</strong>：<ul>
<li>你把书撕成很多小册子（分片）</li>
<li>分给一群朋友（集群中的计算机）每人读一部分</li>
</ul>
</li>
<li><strong>数据集（Dataset）</strong>：<ul>
<li>这本”书”就是你的数据集合</li>
<li>可以是数字、文字、用户信息等等</li>
</ul>
</li>
<li><strong>弹性（Resilient）</strong>：<ul>
<li>突然有个朋友把咖啡洒在小册子上（机器故障）</li>
<li>没关系！因为你记得这本书是怎么撕开的（血统）</li>
<li>你可以重新复印那几页（重新计算）</li>
<li>整个阅读工作不会因此停止</li>
</ul>
</li>
</ol>
<p>这个就是RDD的设计特点：</p>
<ul>
<li>**弹性 (Resilient)**：RDD通过其“血缘关系（Lineage）”天生支持容错。如果某个分区的数据丢失，Spark可以根据血缘关系重新计算出该分区，而无需从头再来。</li>
<li>**分布式 (Distributed)**：RDD的数据被分成多个分区（Partition），存储在集群的不同节点上。这使得数据可以被并行处理。</li>
<li>**数据集 (Dataset)**：它是一个只读的数据集合，可以存储任何类型的Java或Python对象。</li>
<li>**不可变 (Immutable)*<em>：一旦创建，RDD就不能被修改。对RDD的任何操作（转换）都会生成一个</em>新的*RDD。这种设计简化了并发和容错。</li>
<li>**惰性计算 (Lazy Evaluation)**：在Spark中，对RDD的转换操作（如map、filter、join等）不会立即执行，而是记录下操作（形成血缘关系图）。只有当遇到一个行动操作（如count、collect、save等）时，才会触发实际的计算。</li>
</ul>
<p><strong>为什么RDD重要？</strong></p>
<ul>
<li><strong>不怕故障</strong>：机器坏了数据能恢复</li>
<li><strong>高效并行</strong>：任务可以分给很多机器同时做</li>
<li><strong>灵活处理</strong>：适合各种复杂的数据处理任务</li>
<li><strong>内存计算</strong>：数据可以放在内存中处理，比读硬盘快得多</li>
</ul>
<h4 id="创建RDD"><a href="#创建RDD" class="headerlink" title="创建RDD"></a>创建RDD</h4><p>在Spark中，创建RDD主要有两种方式：</p>
<ol>
<li><p><strong>并行化一个已有的集合</strong>：使用<code>SparkContext</code>的<code>parallelize</code>方法，将Driver程序中的一个普通集合（如List）转换为一个分布式RDD。这主要用于学习和测试。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">List&lt;Integer&gt; data = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; distData = sc.parallelize(data);</span><br></pre></td></tr></table></figure>
</li>
<li><p><strong>读取外部数据源</strong>：从HDFS、S3、本地文件系统等外部存储系统加载数据。这是生产环境中最常见的方式。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; distFile = sc.textFile(<span class="string">&quot;data.txt&quot;</span>);</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="1-2-优化工具：共享变量"><a href="#1-2-优化工具：共享变量" class="headerlink" title="1.2 优化工具：共享变量"></a>1.2 优化工具：共享变量</h3><p>通常情况下，当我们在Driver端定义的函数（闭包）被发送到Executor上执行时，函数中引用的所有变量都会被复制一份，每个任务都拥有一份独立的副本。但有时，我们需要在所有任务间共享数据，或者将结果聚合回Driver端。为此，Spark提供了两种特殊的共享变量。</p>
<h4 id="1-2-1-广播变量-Broadcast-Variables"><a href="#1-2-1-广播变量-Broadcast-Variables" class="headerlink" title="1.2.1 广播变量 (Broadcast Variables)"></a>1.2.1 广播变量 (Broadcast Variables)</h4><p><strong>问题</strong>：当一个较大的只读变量（例如，一个查找表或配置对象）被多个任务使用时，如果直接在闭包中引用它，这个变量会被序列化并随每个任务一起发送到Executor，造成巨大的网络开销。</p>
<p><strong>解决方案</strong>：使用广播变量。广播变量只会被发送到每个Executor一次，然后该Executor上的所有任务都可以共享这份数据。这极大地减少了网络传输和Driver的负载。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 有一个较大的只读查找表</span></span><br><span class="line">Map&lt;String, String&gt; lookupTable = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();</span><br><span class="line">lookupTable.put(<span class="string">&quot;A&quot;</span>, <span class="string">&quot;Apple&quot;</span>);</span><br><span class="line">lookupTable.put(<span class="string">&quot;B&quot;</span>, <span class="string">&quot;Ball&quot;</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 将其广播出去</span></span><br><span class="line">Broadcast&lt;Map&lt;String, String&gt;&gt; broadcastTable = sc.broadcast(lookupTable);</span><br><span class="line"></span><br><span class="line">JavaRDD&lt;String&gt; rdd = sc.parallelize(Arrays.asList(<span class="string">&quot;A&quot;</span>, <span class="string">&quot;B&quot;</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在算子中通过.value()方法访问广播变量</span></span><br><span class="line">rdd.map(key -&gt; &#123;</span><br><span class="line">    Map&lt;String, String&gt; localTable = broadcastTable.value();</span><br><span class="line">    <span class="keyword">return</span> localTable.get(key);</span><br><span class="line">&#125;).collect();</span><br></pre></td></tr></table></figure>

<h4 id="1-2-2-累加器-Accumulators"><a href="#1-2-2-累加器-Accumulators" class="headerlink" title="1.2.2 累加器 (Accumulators)"></a>1.2.2 累加器 (Accumulators)</h4><p><strong>问题</strong>：任务在Executor上执行时是相互隔离的，我们无法在算子内部安全地修改一个外部变量（例如，用一个计数器来统计符合某个条件的记录数）。</p>
<p><strong>解决方案</strong>：使用累加器。累加器是一种只支持“累加”操作的变量，它可以在所有任务中被安全地并行更新，最终由Driver端统一读取结果。Spark原生支持数值型和集合类型的累加器。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建一个长整型累加器，初始值为0</span></span><br><span class="line"><span class="type">LongAccumulator</span> <span class="variable">counter</span> <span class="operator">=</span> sc.sc().longAccumulator(<span class="string">&quot;MyCounter&quot;</span>);</span><br><span class="line"></span><br><span class="line">JavaRDD&lt;Integer&gt; numbers = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在算子中通过.add()方法累加</span></span><br><span class="line">numbers.foreach(x -&gt; &#123;</span><br><span class="line">    <span class="keyword">if</span> (x % <span class="number">2</span> == <span class="number">0</span>) &#123;</span><br><span class="line">        counter.add(<span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 在Driver端通过.value()获取最终结果</span></span><br><span class="line">System.out.println(<span class="string">&quot;偶数的数量是: &quot;</span> + counter.value()); <span class="comment">// 输出: 2</span></span><br></pre></td></tr></table></figure>

<p>理解了RDD、广播变量和累加器之后，我们就可以开始学习如何使用<strong>算子</strong>来操作这些数据结构了。</p>
<h2 id="2-Spark算子的分类与特性"><a href="#2-Spark算子的分类与特性" class="headerlink" title="2. Spark算子的分类与特性"></a>2. Spark算子的分类与特性</h2><p>Spark算子是构建分布式数据处理应用的基础指令，理解其分类是掌握Spark编程模型的第一步。算子可以从两个核心维度进行分类：<strong>按功能划分</strong>和<strong>按依赖关系划分</strong>。这两个维度共同决定了算子的行为、执行时机和性能特征。</p>
<h3 id="2-1-按功能划分：转换（Transformation）与行动（Action）"><a href="#2-1-按功能划分：转换（Transformation）与行动（Action）" class="headerlink" title="2.1 按功能划分：转换（Transformation）与行动（Action）"></a>2.1 按功能划分：转换（Transformation）与行动（Action）</h3><p>这个维度决定了算子的执行时机，是理解Spark核心特性——<strong>懒惰计算</strong>——的关键。</p>
<p><strong>转换（Transformation）</strong></p>
<ul>
<li><strong>核心思想</strong>：只定义计算逻辑，不立即执行。</li>
<li><strong>特点</strong>：<strong>懒惰计算（Lazy Evaluation）</strong>。调用时，Spark并不会立即执行计算，而是将该操作记录下来，形成一个计算的有向无环图（DAG）的一部分。这就像是制定一份详细的作战计划，但并不开火。</li>
<li><strong>返回值</strong>：一个新的RDD，代表了应用该转换后的结果数据集。</li>
<li><strong>代表算子</strong>：<code>map</code>, <code>filter</code>, <code>flatMap</code>, <code>groupByKey</code>, <code>reduceByKey</code>, <code>join</code>, <code>repartition</code>等。</li>
</ul>
<p><strong>行动（Action）</strong></p>
<ul>
<li><strong>核心思想</strong>：触发计算，获取结果。</li>
<li><strong>特点</strong>：<strong>立即计算（Eager Evaluation）</strong>。调用时，会触发一个Spark作业（Job）的提交和执行。Spark会根据之前构建的DAG，将计算任务分发到集群执行，这是“开火”的信号。</li>
<li><strong>返回值</strong>：一个非RDD类型的值（如<code>Int</code>, <code>List</code>）或无返回值（例如，将结果写入外部存储）。</li>
<li><strong>代表算子</strong>：<code>count</code>, <code>collect</code>, <code>first</code>, <code>take</code>, <code>reduce</code>, <code>foreach</code>, <code>saveAsTextFile</code>等。</li>
</ul>
<h3 id="2-2-按依赖关系划分：窄依赖（Narrow）与宽依赖（Wide）"><a href="#2-2-按依赖关系划分：窄依赖（Narrow）与宽依赖（Wide）" class="headerlink" title="2.2 按依赖关系划分：窄依赖（Narrow）与宽依赖（Wide）"></a>2.2 按依赖关系划分：窄依赖（Narrow）与宽依赖（Wide）</h3><p>这个维度决定了数据的物理流转方式，是理解Spark性能瓶颈——<strong>Shuffle</strong>——的关键。</p>
<p><strong>窄依赖算子（Narrow Dependency）：</strong></p>
<ul>
<li><strong>定义</strong>：子RDD的每个分区只依赖父RDD的一个或少数几个固定的分区。这意味着计算可以在单个节点上独立完成，无需等待其他节点的数据。</li>
<li><strong>特点</strong>：数据不需要跨节点传输（No Shuffle），计算可以在单个节点上以流水线（Pipeline）方式高效执行，性能极高。</li>
<li><strong>代表算子</strong>：<code>map</code>, <code>filter</code>, <code>flatMap</code>, <code>union</code>等。</li>
</ul>
<p><strong>宽依赖算子（Wide Dependency）：</strong></p>
<ul>
<li><strong>定义</strong>：子RDD的每个分区依赖父RDD的所有或多个分区。这意味着一个子分区的计算需要从父RDD的多个分区拉取数据。</li>
<li><strong>特点</strong>：需要进行Shuffle操作，数据必须在网络间进行大规模传输和重分区。Shuffle是Spark中最昂贵的操作之一，是性能优化的重点和难点。</li>
<li><strong>代表算子</strong>：<code>groupByKey</code>, <code>reduceByKey</code>, <code>join</code>, <code>distinct</code>, <code>repartition</code>等。</li>
</ul>
<h2 id="3-算子执行的内存与磁盘管理"><a href="#3-算子执行的内存与磁盘管理" class="headerlink" title="3. 算子执行的内存与磁盘管理"></a>3. 算子执行的内存与磁盘管理</h2><p>在分布式计算中，内存与磁盘的管理是决定性能和稳定性的核心要素。Spark通过一个精巧的<strong>统一内存管理（Unified Memory Management）</strong>模型以及高效的<strong>溢写（Spill）</strong>机制，在执行效率、数据缓存和大规模数据处理能力之间取得了动态平衡。</p>
<h3 id="3-1-统一内存管理模型"><a href="#3-1-统一内存管理模型" class="headerlink" title="3.1 统一内存管理模型"></a>3.1 统一内存管理模型</h3><p>Spark通过一个精巧的<strong>统一内存管理（Unified Memory Management）</strong>模型，在执行效率和数据缓存之间取得了动态平衡。</p>
<p>在Spark 1.6版本之前，执行内存和存储内存是静态划分的，利用率不高。而统一内存管理模型允许这两部分内存在运行时动态地相互借用，从而极大地提升了内存使用效率。其核心思想是：<strong>计算优先，在不影响计算的前提下，尽可能多地利用内存进行数据缓存。</strong></p>
<p><strong>内存区域划分：</strong></p>
<pre class="mermaid">graph TD
    A["Executor 总内存"]
    A --> B["保留内存 (Reserved Memory)<br/>固定300MB, 存储Spark内部对象"]
    A --> C["用户内存 (User Memory)<br/>存储用户代码创建的对象"]
    A --> D["Spark 内存 (Spark Memory)<br/>统一内存管理区域"]
    D --> E["执行内存 (Execution Memory)<br/>算子执行<br/>(Shuffle/Join/Sort)"]
    D --> F["存储内存 (Storage Memory)<br/>缓存数据<br/>(RDD/广播变量)"]
    E <--> F</pre>

<p>Spark Executor的内存被划分为几个关键区域：</p>
<ol>
<li>**保留内存 (Reserved Memory)**：系统保留内存，固定为300MB，用于存储Spark内部对象和元数据，防止OOM。</li>
<li>**用户内存 (User Memory)**：用户代码使用的内存区域，例如，在算子函数中创建的自定义对象、数据结构等。这部分内存不受Spark管理，如果使用不当，是OOM的主要来源之一。</li>
<li>**Spark内存 (Spark Memory)**：Spark框架自身管理的内存，是优化的核心区域。它进一步动态地分为：<ul>
<li>**执行内存 (Execution Memory)**：执行算子（如Shuffle、Join、Sort、Aggregate）时所需的内存。这部分内存用于存储中间数据，例如Shuffle时的缓冲区。它是保障计算任务顺利执行的关键。</li>
<li>**存储内存 (Storage Memory)**：用于缓存RDD、广播变量等数据的内存。通过将常用数据缓存在此，可以避免重复计算，提升性能。当执行内存不足时，Spark会强制驱逐（Evict）存储内存中缓存的数据块，为计算任务腾出空间。</li>
</ul>
</li>
</ol>
<p>🔥 <strong>核心机制</strong>：执行内存和存储内存共享 <strong>Unified Memory</strong> 区域（动态抢占）：</p>
<ul>
<li>执行任务可抢占存储内存（若存储内存未用完）</li>
<li>存储内存只能被动回收（LRU 策略），<strong>不能抢占</strong>执行内存</li>
</ul>
<h3 id="3-2-内存与磁盘的交互：溢写-Spill-与合并-Merge"><a href="#3-2-内存与磁盘的交互：溢写-Spill-与合并-Merge" class="headerlink" title="3.2 内存与磁盘的交互：溢写 (Spill) 与合并 (Merge)"></a>3.2 内存与磁盘的交互：溢写 (Spill) 与合并 (Merge)</h3><p>统一内存管理模型解释了内存的内部划分与动态调整，但当执行内存本身也不足以容纳所有计算所需的数据时会发生什么？这时，Spark会启动<strong>溢写（Spill）</strong>机制，将部分数据临时写入磁盘，以释放内存供当前计算任务继续使用。</p>
<p><strong>溢写（Spill）</strong></p>
<ul>
<li><strong>触发时机</strong>：在执行需要大量内存的算子时（如 <code>reduceByKey</code>, <code>groupByKey</code>, <code>sortByKey</code>, <code>join</code>），这些算子通常使用基于哈希的聚合器或外部排序器。当这些内存中的数据结构（例如，一个巨大的哈希表）的大小超过了可用的执行内存时，溢写就会被触发。</li>
<li><strong>过程</strong>：Spark将内存中的数据（例如哈希表的部分内容）进行排序（如果需要），然后序列化成字节流，写入本地磁盘上的一个临时文件。之后，清空内存中的这部分数据结构，以继续处理后续数据。一个任务可能会因为数据量巨大而产生多个溢写文件。</li>
</ul>
<p><strong>合并（Merge）</strong></p>
<ul>
<li><strong>触发时机</strong>：当一个任务处理完其所有的输入数据后，它可能已经在磁盘上留下了多个溢写文件，同时内存里可能还剩余一部分数据。</li>
<li><strong>过程</strong>：为了形成该任务的最终输出（例如，为Shuffle的下一阶段准备数据），Spark会启动一个合并流程。它使用归并排序的策略，同时从所有溢写文件和内存中读取数据，将它们合并成一个单一的、通常是排序好的输出文件。这个最终文件才是Shuffle阶段网络传输的源文件。</li>
</ul>
<p>这个 <strong>内存-溢写-合并</strong> 的流程是Spark能够处理远超内存容量的大规模数据的关键。它以磁盘I&#x2F;O的开销为代价，换取了计算的稳定性和对海量数据的处理能力。</p>
<h2 id="4-数据序列化与网络传输"><a href="#4-数据序列化与网络传输" class="headerlink" title="4. 数据序列化与网络传输"></a>4. 数据序列化与网络传输</h2><p>在分布式系统中，数据需要在不同节点间通过网络传输，而网络传输的数据必须是二进制格式。<strong>序列化</strong>就是将内存中的Java对象（包含数据和结构）转换为二进制字节流的过程，而<strong>反序列化</strong>则是相反的过程。序列化是Spark中一个基础但极其重要的性能影响点，它的效率直接决定了网络传输和磁盘IO的开销。</p>
<p>Spark在多个场景下都会触发序列化操作：</p>
<p><strong>序列化触发场景：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. Task序列化：将Task从Driver发送到Executor</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">TaskSerialization</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="type">byte</span>[] serializeTask(Task&lt;?&gt; task) &#123;</span><br><span class="line">        <span class="comment">// 任务包含：代码、依赖、分区信息</span></span><br><span class="line">        <span class="keyword">return</span> serializer.serialize(task);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>场景解读</strong>：当你在Driver端编写的算子函数（闭包）需要被发送到Executor上执行时，整个任务（包括代码和其引用的外部变量）都会被序列化。如果闭包引用了庞大且不可序列化的对象，会导致任务提交失败或性能低下。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 2. Shuffle序列化：数据在节点间传输</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ShuffleDataSerialization</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">writeShuffleData</span><span class="params">(Iterator&lt;Product2&lt;K, V&gt;&gt; records)</span> &#123;</span><br><span class="line">        <span class="type">SerializationStream</span> <span class="variable">stream</span> <span class="operator">=</span> serializer.serializeStream(outputStream);</span><br><span class="line">        <span class="keyword">while</span> (records.hasNext()) &#123;</span><br><span class="line">            Product2&lt;K, V&gt; record = records.next();</span><br><span class="line">            stream.writeKey(record._1);    <span class="comment">// 序列化key</span></span><br><span class="line">            stream.writeValue(record._2);  <span class="comment">// 序列化value</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>场景解读</strong>：这是序列化最影响性能的环节。在Shuffle过程中，大量数据需要在节点间流动，高效的序列化格式（如Kryo）可以显著减少网络传输的数据量和CPU消耗。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 3. 缓存序列化：RDD持久化到内存/磁盘</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CacheSerialization</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">cacheRDD</span><span class="params">(RDD&lt;?&gt; rdd, StorageLevel level)</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (level.useSerialization()) &#123;</span><br><span class="line">            <span class="comment">// 将RDD数据序列化后存储</span></span><br><span class="line">            <span class="type">byte</span>[] serializedData = serializer.serialize(rdd.collect());</span><br><span class="line">            blockManager.putBytes(blockId, serializedData, level);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><strong>场景解读</strong>：当你调用<code>rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)</code>等包含<code>_SER</code>的缓存级别时，数据会以序列化的形式存储。这样做的好处是节省内存空间，但代价是每次访问缓存数据时都需要进行反序列化，增加了CPU开销。</li>
</ul>
<h2 id="5-为什么理解算子原理如此重要？"><a href="#5-为什么理解算子原理如此重要？" class="headerlink" title="5. 为什么理解算子原理如此重要？"></a>5. 为什么理解算子原理如此重要？</h2><p>在Spark开发中，实现同一个业务需求往往有多种算子组合。然而，不同的实现方式可能导致百倍甚至千倍的性能差异。这种差异的根源，就在于每个算子背后的数据处理和流转机制完全不同。</p>
<p><strong>性能差异的根本原因：</strong></p>
<p>不同算子的性能差异主要源于它们在以下几个方面的不同选择：</p>
<ol>
<li><strong>依赖关系</strong>：是需要Shuffle的宽依赖，还是无需Shuffle的窄依赖？这是最核心的区别。</li>
<li><strong>数据局部性</strong>：计算是在数据所在的节点本地执行，还是必须通过网络拉取远程数据？</li>
<li><strong>内存使用模式</strong>：算子是一次性将整个分区加载到内存，还是以流式（Streaming）方式逐条处理？这决定了内存消耗的峰值。</li>
<li><strong>CPU利用率</strong>：算子的计算逻辑是否复杂，是否能被Spark的优化器（如Tungsten）进行优化？</li>
</ol>
<p>下面的例子直观地展示了<code>groupByKey</code>和<code>reduceByKey</code>的巨大性能差异，尽管它们都能实现分组聚合的功能。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 场景：处理1GB数据，统计每个用户的订单数量</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 方案1：使用groupByKey - 性能差</span></span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; result1 = orders</span><br><span class="line">    .mapToPair(order -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(order.getUserId(), <span class="number">1</span>))</span><br><span class="line">    .groupByKey()  <span class="comment">// 宽依赖，Shuffle所有数据</span></span><br><span class="line">    .mapValues(values -&gt; &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">count</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (Integer v : values) count += v;</span><br><span class="line">        <span class="keyword">return</span> count;</span><br><span class="line">    &#125;);</span><br><span class="line"><span class="comment">// 执行时间：约45秒，Shuffle数据量：1GB</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 方案2：使用reduceByKey - 性能好</span></span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; result2 = orders</span><br><span class="line">    .mapToPair(order -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(order.getUserId(), <span class="number">1</span>))</span><br><span class="line">    .reduceByKey((a, b) -&gt; a + b);  <span class="comment">// 本地预聚合，减少Shuffle数据</span></span><br><span class="line"><span class="comment">// 执行时间：约15秒，Shuffle数据量：约100MB（假设有10万用户）</span></span><br></pre></td></tr></table></figure>

<p><strong>优化思路的本质：</strong><br>因此，理解算子原理并非炫技，而是进行性能优化的基石。它能让你在开发时就具备“性能思维”，从而能够：</p>
<ul>
<li><strong>选择合适的算子</strong>：主动避免不必要的Shuffle，例如用<code>reduceByKey</code>替代<code>groupByKey</code>。</li>
<li><strong>设计合理的数据流</strong>：通过<code>broadcast</code>等技巧，将Shuffle密集型的<code>join</code>操作优化为本地计算。</li>
<li><strong>利用数据局部性</strong>：合理设计分区策略，让计算尽可能在数据所在的节点发生。</li>
<li><strong>合理配置资源</strong>：预估算子的内存消耗，为作业分配合理的内存和CPU资源，避免OOM和性能瓶颈。</li>
</ul>
<p>为什么有些算子执行很快，有些却很慢？答案就藏在算子的实现原理和数据流转机制中。只有深入理解这些，才能真正驾驭Spark。</p>
<h2 id="6-RDD懒惰计算机制深度剖析"><a href="#6-RDD懒惰计算机制深度剖析" class="headerlink" title="6. RDD懒惰计算机制深度剖析"></a>6. RDD懒惰计算机制深度剖析</h2><p>懒惰计算（Lazy Evaluation）是Spark最核心、最巧妙的设计之一，是其实现高效、容错的分布式计算的基石。简单来说，懒惰计算就是<strong>“非到万不得已，绝不执行计算”</strong>。</p>
<h3 id="6-1-核心概念：懒惰计算-vs-急切计算"><a href="#6-1-核心概念：懒惰计算-vs-急切计算" class="headerlink" title="6.1 核心概念：懒惰计算 vs 急切计算"></a>6.1 核心概念：懒惰计算 vs 急切计算</h3><p><strong>懒惰计算（Lazy Evaluation）</strong>：</p>
<ul>
<li>指的是Spark在遇到<strong>转换操作（Transformations）</strong>时，并不会立即执行计算并生成新的RDD</li>
<li>它只是记录下这个操作以及它依赖的父RDD（即：构建了一个逻辑执行计划或称为Lineage）</li>
<li>真正的计算（数据读取、转换处理）会被推迟到遇到<strong>行动操作（Actions）</strong>时才触发执行</li>
</ul>
<p><strong>急切计算（Eager Evaluation）</strong>：</p>
<ul>
<li>传统编程或某些数据处理框架（如Scala集合的某些操作）是急切计算的</li>
<li>当你调用一个函数，它会立即执行并返回结果</li>
<li>例如，在Scala中<code>List(1,2,3).map(_ * 2)</code>会立即计算并返回<code>List(2,4,6)</code></li>
</ul>
<p><strong>对比示例：</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 急切计算 - 传统Java集合</span></span><br><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">List&lt;Integer&gt; doubled = numbers.stream()</span><br><span class="line">    .map(x -&gt; x * <span class="number">2</span>)     <span class="comment">// 立即执行</span></span><br><span class="line">    .filter(x -&gt; x &gt; <span class="number">5</span>)  <span class="comment">// 立即执行</span></span><br><span class="line">    .collect(Collectors.toList()); <span class="comment">// 立即返回结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 懒惰计算 - Spark RDD</span></span><br><span class="line">JavaRDD&lt;Integer&gt; numbersRDD = sc.parallelize(Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>));</span><br><span class="line">JavaRDD&lt;Integer&gt; transformedRDD = numbersRDD</span><br><span class="line">    .map(x -&gt; x * <span class="number">2</span>)     <span class="comment">// 仅记录操作，不执行</span></span><br><span class="line">    .filter(x -&gt; x &gt; <span class="number">5</span>); <span class="comment">// 仅记录操作，不执行</span></span><br><span class="line"><span class="comment">// 此时还没有任何实际计算发生！</span></span><br><span class="line"></span><br><span class="line">List&lt;Integer&gt; result = transformedRDD.collect(); <span class="comment">// 这里才开始真正计算</span></span><br></pre></td></tr></table></figure>

<h3 id="6-2-为什么Spark要采用懒惰计算？"><a href="#6-2-为什么Spark要采用懒惰计算？" class="headerlink" title="6.2 为什么Spark要采用懒惰计算？"></a>6.2 为什么Spark要采用懒惰计算？</h3><p>这种“谋定而后动”的设计哲学，为Spark带来了几个在分布式环境下至关重要的优势：</p>
<p><strong>1. 优化执行计划（Optimization）</strong></p>
<p>这是懒惰计算最大的优势。因为所有转换操作都只是记录在DAG中，直到行动操作被调用前，Spark都拥有了计算的全景图。这使得Spark的优化器（如DAGScheduler和Catalyst）可以从全局视角对整个计算流程进行优化。</p>
<ul>
<li><strong>流水线化（Pipelining）</strong>：在急切计算中，<code>rdd.map(...).filter(...)</code>会执行两次全量数据扫描。但在懒惰计算中，Spark会将<code>map</code>和<code>filter</code>这两个操作合并（fuse）成一个任务。数据在分区内以流式的方式被处理，一条数据处理完<code>map</code>后立刻进行<code>filter</code>，无需将中间结果写入内存或磁盘，极大地提升了效率。</li>
<li><strong>谓词下推（Predicate Pushdown）</strong>：如果数据源（如Parquet、ORC）支持，Spark会将<code>filter</code>操作下推到数据读取层。这样，在数据加载到内存之前，就能过滤掉大量无关数据，从源头上减少了IO和内存的消耗。</li>
<li><strong>减少Shuffle</strong>：优化器可以分析整个DAG，识别出可以避免或优化的Shuffle操作，例如在多个<code>join</code>操作中选择最优的执行顺序。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 懒惰计算的优化示例</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LazyEvaluationOptimizer</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">demonstrateOptimizations</span><span class="params">()</span> &#123;</span><br><span class="line">        JavaRDD&lt;String&gt; textRDD = sc.textFile(<span class="string">&quot;large_file.txt&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 定义一系列转换操作（全部是懒惰的）</span></span><br><span class="line">        JavaRDD&lt;String&gt; result = textRDD</span><br><span class="line">            .filter(line -&gt; line.contains(<span class="string">&quot;ERROR&quot;</span>))      <span class="comment">// 过滤操作</span></span><br><span class="line">            .map(line -&gt; line.toUpperCase())             <span class="comment">// 转换操作</span></span><br><span class="line">            .filter(line -&gt; line.length() &gt; <span class="number">50</span>)          <span class="comment">// 再次过滤</span></span><br><span class="line">            .map(line -&gt; line.substring(<span class="number">0</span>, <span class="number">100</span>));        <span class="comment">// 截取操作</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 只有在调用Action时，Spark才开始优化和执行</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">count</span> <span class="operator">=</span> result.count();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// Spark的优化策略：</span></span><br><span class="line">        <span class="comment">// 1. 流水线化：将所有map和filter操作合并为单个Task执行</span></span><br><span class="line">        <span class="comment">// 2. 谓词下推：如果数据源支持，将filter下推到读取层</span></span><br><span class="line">        <span class="comment">// 3. 减少中间结果：不需要物化每个中间RDD</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>2. 减少不必要的计算（Reduced Computation）</strong></p>
<p>懒惰计算使得Spark可以只计算任务真正需要的数据。对于一些只需要部分结果的行动操作，这个特性可以节省大量的计算资源。</p>
<ul>
<li>当你调用<code>rdd.take(5)</code>时，Spark知道只需要获取5条记录。它会启动任务，一旦某个分区计算得到了足够的5条记录，其他正在运行的或尚未开始的任务就可以被终止，避免了对整个数据集的无效扫描。</li>
<li>类似地，<code>rdd.first()</code>只会计算第一个分区，直到找到第一条记录为止。</li>
</ul>
<p><strong>3. 节省内存和存储（Memory&#x2F;Storage Efficiency）</strong></p>
<p>由于转换操作不会立即物化（materialize）中间结果RDD，因此极大地节省了内存和磁盘空间。在一个长长的转换链中，数据以流的方式在算子间传递，处理完即被回收，内存中只需保留当前正在处理的数据即可。这与那些每一步都生成完整中间结果的系统形成了鲜明对比。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 内存效率示例</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MemoryEfficiency</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">demonstrateMemoryEfficiency</span><span class="params">()</span> &#123;</span><br><span class="line">        JavaRDD&lt;String&gt; data = sc.textFile(<span class="string">&quot;input.txt&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 定义长转换链（全部懒惰）</span></span><br><span class="line">        JavaRDD&lt;String&gt; step1 = data.map(line -&gt; processStep1(line));</span><br><span class="line">        JavaRDD&lt;String&gt; step2 = step1.filter(line -&gt; line.length() &gt; <span class="number">10</span>);</span><br><span class="line">        JavaRDD&lt;String&gt; step3 = step2.map(line -&gt; processStep2(line));</span><br><span class="line">        JavaRDD&lt;String&gt; step4 = step3.filter(line -&gt; line.contains(<span class="string">&quot;important&quot;</span>));</span><br><span class="line">        JavaRDD&lt;String&gt; finalResult = step4.map(line -&gt; processStep3(line));</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 关键点：这些中间RDD（step1-step4）不会真的存储在内存中！</span></span><br><span class="line">        <span class="comment">// 它们只是包含Lineage信息的对象，实际数据在Action时才计算</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 只有在Action触发时，数据才流式处理，无需存储中间结果</span></span><br><span class="line">        <span class="type">long</span> <span class="variable">count</span> <span class="operator">=</span> finalResult.count();</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 对比：如果是急切计算，每个step都会产生完整的中间数据集</span></span><br><span class="line">        <span class="comment">// 这会消耗5倍的内存！</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>4. 容错性（Fault Tolerance）的天然支持</strong></p>
<p>懒惰计算与Spark的容错机制紧密相关。因为Spark记录了完整的RDD血缘关系（Lineage），即每个RDD是如何通过转换操作从其父RDD派生而来的。这个Lineage就像一份详细的“数据重建指南”。当集群中某个节点故障，导致其上的数据分区丢失时，Spark可以根据这份指南，精确地只重新计算丢失的那个分区，而无需重跑整个作业。懒惰计算使得记录这份“指南”成为其执行模型的自然组成部分。</p>
<h3 id="6-3-懒惰计算工作原理：详细示例分析"><a href="#6-3-懒惰计算工作原理：详细示例分析" class="headerlink" title="6.3 懒惰计算工作原理：详细示例分析"></a>6.3 懒惰计算工作原理：详细示例分析</h3><p>让我们通过一个完整的例子来理解懒惰计算的工作流程：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LazyEvaluationWorkflow</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">completeExample</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 1. 定义RDD（惰性：只记录来源）</span></span><br><span class="line">        JavaRDD&lt;String&gt; textRDD = sc.textFile(<span class="string">&quot;hdfs://path/to/largefile.txt&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;Step 1: 创建textRDD - 无计算发生，只记录数据源&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 2. 转换操作（惰性：只记录转换逻辑）</span></span><br><span class="line">        JavaRDD&lt;String&gt; wordsRDD = textRDD.flatMap(line -&gt; </span><br><span class="line">            Arrays.asList(line.split(<span class="string">&quot; &quot;</span>)).iterator());</span><br><span class="line">        System.out.println(<span class="string">&quot;Step 2: 创建wordsRDD - 无计算发生，只记录flatMap操作&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        JavaRDD&lt;String&gt; filteredRDD = wordsRDD.filter(word -&gt; </span><br><span class="line">            word.startsWith(<span class="string">&quot;error&quot;</span>));</span><br><span class="line">        System.out.println(<span class="string">&quot;Step 3: 创建filteredRDD - 无计算发生，只记录filter操作&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; mappedRDD = filteredRDD.mapToPair(word -&gt; </span><br><span class="line">            <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(word, <span class="number">1</span>));</span><br><span class="line">        System.out.println(<span class="string">&quot;Step 4: 创建mappedRDD - 无计算发生，只记录mapToPair操作&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; errorCountRDD = mappedRDD.reduceByKey((a, b) -&gt; a + b);</span><br><span class="line">        System.out.println(<span class="string">&quot;Step 5: 创建errorCountRDD - 无计算发生，只记录reduceByKey操作&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 此时的状态：</span></span><br><span class="line">        printRDDLineage(errorCountRDD);</span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 3. 行动操作（触发计算！）</span></span><br><span class="line">        System.out.println(<span class="string">&quot;Step 6: 调用collect() - 开始真正的计算！&quot;</span>);</span><br><span class="line">        List&lt;Tuple2&lt;String, Integer&gt;&gt; result = errorCountRDD.collect();</span><br><span class="line">        </span><br><span class="line">        System.out.println(<span class="string">&quot;计算完成，结果: &quot;</span> + result);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">void</span> <span class="title function_">printRDDLineage</span><span class="params">(JavaPairRDD&lt;String, Integer&gt; rdd)</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;=== RDD Lineage 信息 ===&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;errorCountRDD 依赖链：&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  textRDD (HadoopRDD) &lt;- 数据源&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  -&gt; wordsRDD (FlatMappedRDD) &lt;- flatMap转换&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  -&gt; filteredRDD (FilteredRDD) &lt;- filter转换&quot;</span>); </span><br><span class="line">        System.out.println(<span class="string">&quot;  -&gt; mappedRDD (MapPartitionsRDD) &lt;- mapToPair转换&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  -&gt; errorCountRDD (ShuffledRDD) &lt;- reduceByKey转换&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;此时只有逻辑执行计划，没有实际数据！&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="6-4-执行流程详解"><a href="#6-4-执行流程详解" class="headerlink" title="6.4 执行流程详解"></a>6.4 执行流程详解</h3><p><strong>阶段1：定义和转换阶段（textFile 到 reduceByKey）</strong></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DAG构建过程的内部机制</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">DAGBuildingProcess</span> &#123;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">demonstrateDAGBuilding</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 当执行每个转换操作时，Spark内部的工作：</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 1. textFile操作</span></span><br><span class="line">        JavaRDD&lt;String&gt; textRDD = sc.textFile(<span class="string">&quot;input.txt&quot;</span>);</span><br><span class="line">        <span class="comment">// 内部：创建HadoopRDD对象，记录：</span></span><br><span class="line">        <span class="comment">// - 数据源路径</span></span><br><span class="line">        <span class="comment">// - 分区策略（基于HDFS块）</span></span><br><span class="line">        <span class="comment">// - 依赖关系：无（叶子节点）</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 2. flatMap操作</span></span><br><span class="line">        JavaRDD&lt;String&gt; wordsRDD = textRDD.flatMap(line -&gt; </span><br><span class="line">            Arrays.asList(line.split(<span class="string">&quot; &quot;</span>)).iterator());</span><br><span class="line">        <span class="comment">// 内部：创建FlatMappedRDD对象，记录：</span></span><br><span class="line">        <span class="comment">// - 父RDD：textRDD</span></span><br><span class="line">        <span class="comment">// - 转换函数：split和iterator</span></span><br><span class="line">        <span class="comment">// - 依赖类型：窄依赖（OneToOneDependency）</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 3. filter操作</span></span><br><span class="line">        JavaRDD&lt;String&gt; filteredRDD = wordsRDD.filter(word -&gt; word.startsWith(<span class="string">&quot;error&quot;</span>));</span><br><span class="line">        <span class="comment">// 内部：创建FilteredRDD对象，记录：</span></span><br><span class="line">        <span class="comment">// - 父RDD：wordsRDD</span></span><br><span class="line">        <span class="comment">// - 过滤函数：startsWith判断</span></span><br><span class="line">        <span class="comment">// - 依赖类型：窄依赖</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 4. reduceByKey操作</span></span><br><span class="line">        JavaPairRDD&lt;String, Integer&gt; countRDD = </span><br><span class="line">            filteredRDD.mapToPair(w -&gt; <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;&gt;(w, <span class="number">1</span>)).reduceByKey((a, b) -&gt; a + b);</span><br><span class="line">        <span class="comment">// 内部：创建ShuffledRDD对象，记录：</span></span><br><span class="line">        <span class="comment">// - 父RDD：mappedRDD</span></span><br><span class="line">        <span class="comment">// - 聚合函数：addition</span></span><br><span class="line">        <span class="comment">// - 依赖类型：宽依赖（ShuffleDependency）</span></span><br><span class="line">        <span class="comment">// - 分区器：HashPartitioner</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">// 构建的DAG图：</span></span><br><span class="line">        System.out.println(<span class="string">&quot;DAG结构：&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;HadoopRDD -&gt; FlatMappedRDD -&gt; FilteredRDD -&gt; MappedRDD -&gt; ShuffledRDD&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;    |            |              |            |           |&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;  textFile    flatMap        filter    mapToPair   reduceByKey&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;                                                        |&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;                                             Stage分界点（Shuffle）&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>阶段2：Action触发执行</strong></p>
<p><strong>1. DAGScheduler分析</strong>：</p>
<ul>
<li>从collect()的目标RDD(ShuffledRDD)开始回溯Lineage链</li>
<li>识别依赖关系：发现flatMap+filter+mapToPair可流水线执行</li>
<li>确定reduceByKey需要单独Stage（宽依赖边界）</li>
</ul>
<p><strong>2. Stage划分</strong>：</p>
<ul>
<li>Stage 0：textFile → flatMap → filter → mapToPair<ul>
<li>输出：按key分区的(word, 1)对</li>
</ul>
</li>
<li>Stage 1：reduceByKey<ul>
<li>输入：Stage 0的Shuffle输出</li>
<li>输出：(word, count)结果</li>
</ul>
</li>
</ul>
<p><strong>3. 任务生成</strong>：</p>
<ul>
<li>Stage 0：根据输入分区数（4个HDFS块）生成4个ShuffleMapTask</li>
<li>Stage 1：根据Shuffle分区数（默认200）生成200个ResultTask</li>
</ul>
<p><strong>4. 任务调度</strong>：</p>
<ul>
<li>TaskScheduler将任务分发到Executor</li>
<li>优先考虑数据本地性（数据所在节点）</li>
<li>严格执行Stage顺序：Stage 0完成才能开始Stage 1</li>
</ul>
<p><strong>5. 任务执行</strong>：</p>
<ul>
<li>Stage 0任务：<ol>
<li>读取HDFS文件块</li>
<li>流水线执行：split → filter → mapToPair</li>
<li>按key哈希分区，执行Shuffle Write</li>
</ol>
</li>
<li>Stage 1任务：<ol>
<li>从多个节点拉取数据（Shuffle Read）</li>
<li>按key聚合执行reduceByKey</li>
<li>生成最终(word, count)结果</li>
</ol>
</li>
</ul>
<p><strong>6. 结果收集</strong>：</p>
<ul>
<li>所有Stage 1的ResultTask将结果发送回Driver</li>
<li>Driver汇总所有结果返回给用户</li>
</ul>
<p>RDD的懒惰计算机制是Spark实现高效、容错的大规模分布式数据处理的核心智慧。它将昂贵的计算推迟到最后，并利用这段时间窗口进行全局优化，极大地提升了处理能力和资源利用率。理解这一机制对于编写高效的Spark应用程序至关重要。</p>
<h2 id="7-数据本地性原理深度解析"><a href="#7-数据本地性原理深度解析" class="headerlink" title="7. 数据本地性原理深度解析"></a>7. 数据本地性原理深度解析</h2><p><strong>“移动计算，而非移动数据”</strong>是大数据处理的基本原则。数据本地性（Data Locality）正是这一原则在Spark中的具体体现。由于网络传输的开销远大于内存读取，Spark的调度器会尽可能地将计算任务分配到存储着其所需数据的节点上执行，以最大限度地减少网络IO，提升性能。</p>
<h3 id="7-1-数据本地性的层次结构"><a href="#7-1-数据本地性的层次结构" class="headerlink" title="7.1 数据本地性的层次结构"></a>7.1 数据本地性的层次结构</h3><p>Spark定义了从优到劣的多个本地性级别，任务调度器会按照这个顺序，在一定的时间等待阈值内，为任务寻找最“近”的可用资源。</p>
<p><strong>本地性级别的详细定义：</strong></p>
<ul>
<li><code>PROCESS_LOCAL</code>: 任务和数据在同一个Executor的JVM进程中。这是最理想的级别，数据无需任何网络传输，可以直接在内存中访问。</li>
<li><code>NODE_LOCAL</code>: 任务和数据在同一个物理节点上，但可能在不同的Executor进程中。数据需要通过节点内部的进程间通信或共享内存来传输。</li>
<li><code>RACK_LOCAL</code>: 任务和数据在同一个机架（Rack）的不同节点上。数据需要通过机架内的交换机进行网络传输。</li>
<li><code>ANY</code>: 任务和数据在集群的任何地方，通常意味着需要跨机架进行网络传输，这是开销最大的情况。</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 数据本地性级别枚举</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">TaskLocality</span> &#123;</span><br><span class="line">    PROCESS_LOCAL(<span class="string">&quot;PROCESS_LOCAL&quot;</span>, <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isAllowed</span><span class="params">(TaskSetManager taskSet, <span class="type">long</span> currentTime)</span> &#123;</span><br><span class="line">            <span class="comment">// 进程本地：数据在同一JVM进程中</span></span><br><span class="line">            <span class="keyword">return</span> taskSet.getAllowedLocalityLevel(currentTime).ordinal() &gt;= ordinal();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    </span><br><span class="line">    NODE_LOCAL(<span class="string">&quot;NODE_LOCAL&quot;</span>, <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isAllowed</span><span class="params">(TaskSetManager taskSet, <span class="type">long</span> currentTime)</span> &#123;</span><br><span class="line">            <span class="comment">// 节点本地：数据在同一物理节点上</span></span><br><span class="line">            <span class="keyword">return</span> taskSet.getAllowedLocalityLevel(currentTime).ordinal() &gt;= ordinal();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    </span><br><span class="line">    RACK_LOCAL(<span class="string">&quot;RACK_LOCAL&quot;</span>, <span class="number">2</span>) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isAllowed</span><span class="params">(TaskSetManager taskSet, <span class="type">long</span> currentTime)</span> &#123;</span><br><span class="line">            <span class="comment">// 机架本地：数据在同一机架内</span></span><br><span class="line">            <span class="keyword">return</span> taskSet.getAllowedLocalityLevel(currentTime).ordinal() &gt;= ordinal();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">    </span><br><span class="line">    ANY(<span class="string">&quot;ANY&quot;</span>, <span class="number">3</span>) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">isAllowed</span><span class="params">(TaskSetManager taskSet, <span class="type">long</span> currentTime)</span> &#123;</span><br><span class="line">            <span class="comment">// 任意位置：可以在任何地方执行</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> String toString;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="type">int</span> id;</span><br><span class="line">    </span><br><span class="line">    TaskLocality(String toString, <span class="type">int</span> id) &#123;</span><br><span class="line">        <span class="built_in">this</span>.toString = toString;</span><br><span class="line">        <span class="built_in">this</span>.id = id;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">abstract</span> <span class="type">boolean</span> <span class="title function_">isAllowed</span><span class="params">(TaskSetManager taskSet, <span class="type">long</span> currentTime)</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>本地性感知的任务调度算法：</strong><br>Spark的任务调度并非“死等”最佳的本地性级别。它采用了一种<strong>延迟调度（Delay Scheduling）</strong>策略，在效率和时间之间进行权衡：</p>
<ol>
<li>调度器首先尝试以<code>PROCESS_LOCAL</code>级别在数据所在的Executor上启动任务。</li>
<li>如果在设定的等待时间（默认为3秒，由<code>spark.locality.wait</code>配置）内，该Executor没有空闲资源，调度器会将本地性级别降级到<code>NODE_LOCAL</code>，尝试在该节点的其他Executor上启动任务。</li>
<li>如果又等待了一个周期后仍然没有资源，级别会继续降级到<code>RACK_LOCAL</code>，最后到<code>ANY</code>。<br>这种策略既追求了最佳的数据本地性，又避免了因等待某个繁忙节点而导致整个作业被阻塞。</li>
</ol>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 本地性感知调度器</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LocalityAwareTaskScheduler</span> &#123;</span><br><span class="line">    <span class="comment">// 本地性等待时间配置</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Map&lt;TaskLocality, Long&gt; localityWaitMap = Map.of(</span><br><span class="line">        TaskLocality.PROCESS_LOCAL, <span class="number">3000L</span>,  <span class="comment">// 3秒</span></span><br><span class="line">        TaskLocality.NODE_LOCAL, <span class="number">3000L</span>,     <span class="comment">// 3秒</span></span><br><span class="line">        TaskLocality.RACK_LOCAL, <span class="number">3000L</span>,     <span class="comment">// 3秒</span></span><br><span class="line">        TaskLocality.ANY, <span class="number">0L</span>                <span class="comment">// 立即执行</span></span><br><span class="line">    );</span><br></pre></td></tr></table></figure></article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">XR</div><div class="post-copyright__author_desc">一片叶、一朵云</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://example.com/2025/07/10/Spark%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('http://example.com/2025/07/10/Spark%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97/')">Spark核心概念与懒惰计算[未修订完]</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://example.com/2025/07/10/Spark%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=Spark核心概念与懒惰计算[未修订完]&amp;url=http://example.com/2025/07/10/Spark%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97/&amp;pic=" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">凌霄的博客</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/Spark/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Spark<span class="tagsPageCount">6</span></a><a class="post-meta__box__tags" href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>分布式计算<span class="tagsPageCount">3</span></a><a class="post-meta__box__tags" href="/tags/RDD/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>RDD<span class="tagsPageCount">2</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250721161224869.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/07/09/Spark3.x%E6%A0%B8%E5%BF%83%E7%AE%97%E5%AD%90%E5%8E%9F%E7%90%86%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E8%BD%AC%E4%B8%8EShuffle%E6%9C%BA%E5%88%B6/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250703143549645.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Spark3.x核心算子原理解析：数据流转与Shuffle机制[后面会拆分]</div></div></a></div><div class="next-post pull-right"><a href="/2025/07/11/%E6%B5%85%E5%B0%9D%20Spring%20AI/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250618094256140.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">浅尝 Spring AI</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2025/07/08/Spark%E4%B8%93%E6%A0%8F%E6%95%B4%E4%BD%93%E6%96%87%E7%AB%A0%E5%A4%A7%E7%BA%B2/" title="Spark专栏整体文章大纲"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-07-08</div><div class="title">Spark专栏整体文章大纲</div></div></a></div><div><a href="/2025/01/15/Spark%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/" title="Spark集群架构与组件详解：从Driver到Executor的深度解析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-01-15</div><div class="title">Spark集群架构与组件详解：从Driver到Executor的深度解析</div></div></a></div><div><a href="/2025/07/15/%E4%BB%8E%20CSV%E6%96%87%E4%BB%B6%E7%9A%84%E5%8A%A0%E8%BD%BD%E3%80%81%E5%88%86%E5%8C%BA%E5%92%8C%E5%A4%84%E7%90%86%20%E6%9D%A5%E7%90%86%E8%A7%A3%20RDD/" title="从 CSV文件的加载、分区和处理 来理解 RDD"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250618094256140.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-07-15</div><div class="title">从 CSV文件的加载、分区和处理 来理解 RDD</div></div></a></div><div><a href="/2025/07/09/Spark3.x%E6%A0%B8%E5%BF%83%E7%AE%97%E5%AD%90%E5%8E%9F%E7%90%86%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%95%B0%E6%8D%AE%E6%B5%81%E8%BD%AC%E4%B8%8EShuffle%E6%9C%BA%E5%88%B6/" title="Spark3.x核心算子原理解析：数据流转与Shuffle机制[后面会拆分]"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250703143549645.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-07-09</div><div class="title">Spark3.x核心算子原理解析：数据流转与Shuffle机制[后面会拆分]</div></div></a></div><div><a href="/2025/06/18/hadoop-ecosystem-explained/" title="Hadoop生态：YARN、HDFS、Hive、Spark、HBase是如何协同工作的？"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250619194740317.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-06-18</div><div class="title">Hadoop生态：YARN、HDFS、Hive、Spark、HBase是如何协同工作的？</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/24/64e6ce9c507bb.png" alt="status"/></div></div><div class="author-info__description"></div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">XR</h1><div class="author-info__desc">一片叶、一朵云</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/kongxiaoran" target="_blank" title="Github"></a></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97-%E6%9C%AA%E4%BF%AE%E8%AE%A2%E5%AE%8C"><span class="toc-number">1.</span> <span class="toc-text">Spark核心概念与懒惰计算[未修订完]</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-Spark%E6%A0%B8%E5%BF%83%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%EF%BC%9ARDD%E4%B8%8E%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F"><span class="toc-number">1.1.</span> <span class="toc-text">1. Spark核心数据结构：RDD与共享变量</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E6%A0%B8%E5%BF%83%E6%8A%BD%E8%B1%A1%EF%BC%9A%E5%BC%B9%E6%80%A7%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%88RDD%EF%BC%89"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 核心抽象：弹性分布式数据集（RDD）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%9B%E5%BB%BARDD"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">创建RDD</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E4%BC%98%E5%8C%96%E5%B7%A5%E5%85%B7%EF%BC%9A%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 优化工具：共享变量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-1-%E5%B9%BF%E6%92%AD%E5%8F%98%E9%87%8F-Broadcast-Variables"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">1.2.1 广播变量 (Broadcast Variables)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-2-%E7%B4%AF%E5%8A%A0%E5%99%A8-Accumulators"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">1.2.2 累加器 (Accumulators)</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-Spark%E7%AE%97%E5%AD%90%E7%9A%84%E5%88%86%E7%B1%BB%E4%B8%8E%E7%89%B9%E6%80%A7"><span class="toc-number">1.2.</span> <span class="toc-text">2. Spark算子的分类与特性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%8C%89%E5%8A%9F%E8%83%BD%E5%88%92%E5%88%86%EF%BC%9A%E8%BD%AC%E6%8D%A2%EF%BC%88Transformation%EF%BC%89%E4%B8%8E%E8%A1%8C%E5%8A%A8%EF%BC%88Action%EF%BC%89"><span class="toc-number">1.2.1.</span> <span class="toc-text">2.1 按功能划分：转换（Transformation）与行动（Action）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%8C%89%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB%E5%88%92%E5%88%86%EF%BC%9A%E7%AA%84%E4%BE%9D%E8%B5%96%EF%BC%88Narrow%EF%BC%89%E4%B8%8E%E5%AE%BD%E4%BE%9D%E8%B5%96%EF%BC%88Wide%EF%BC%89"><span class="toc-number">1.2.2.</span> <span class="toc-text">2.2 按依赖关系划分：窄依赖（Narrow）与宽依赖（Wide）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E7%AE%97%E5%AD%90%E6%89%A7%E8%A1%8C%E7%9A%84%E5%86%85%E5%AD%98%E4%B8%8E%E7%A3%81%E7%9B%98%E7%AE%A1%E7%90%86"><span class="toc-number">1.3.</span> <span class="toc-text">3. 算子执行的内存与磁盘管理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E7%BB%9F%E4%B8%80%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 统一内存管理模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E5%86%85%E5%AD%98%E4%B8%8E%E7%A3%81%E7%9B%98%E7%9A%84%E4%BA%A4%E4%BA%92%EF%BC%9A%E6%BA%A2%E5%86%99-Spill-%E4%B8%8E%E5%90%88%E5%B9%B6-Merge"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 内存与磁盘的交互：溢写 (Spill) 与合并 (Merge)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%95%B0%E6%8D%AE%E5%BA%8F%E5%88%97%E5%8C%96%E4%B8%8E%E7%BD%91%E7%BB%9C%E4%BC%A0%E8%BE%93"><span class="toc-number">1.4.</span> <span class="toc-text">4. 数据序列化与网络传输</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E4%B8%BA%E4%BB%80%E4%B9%88%E7%90%86%E8%A7%A3%E7%AE%97%E5%AD%90%E5%8E%9F%E7%90%86%E5%A6%82%E6%AD%A4%E9%87%8D%E8%A6%81%EF%BC%9F"><span class="toc-number">1.5.</span> <span class="toc-text">5. 为什么理解算子原理如此重要？</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-RDD%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%88%B6%E6%B7%B1%E5%BA%A6%E5%89%96%E6%9E%90"><span class="toc-number">1.6.</span> <span class="toc-text">6. RDD懒惰计算机制深度剖析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%EF%BC%9A%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97-vs-%E6%80%A5%E5%88%87%E8%AE%A1%E7%AE%97"><span class="toc-number">1.6.1.</span> <span class="toc-text">6.1 核心概念：懒惰计算 vs 急切计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E4%B8%BA%E4%BB%80%E4%B9%88Spark%E8%A6%81%E9%87%87%E7%94%A8%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97%EF%BC%9F"><span class="toc-number">1.6.2.</span> <span class="toc-text">6.2 为什么Spark要采用懒惰计算？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-3-%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%EF%BC%9A%E8%AF%A6%E7%BB%86%E7%A4%BA%E4%BE%8B%E5%88%86%E6%9E%90"><span class="toc-number">1.6.3.</span> <span class="toc-text">6.3 懒惰计算工作原理：详细示例分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-4-%E6%89%A7%E8%A1%8C%E6%B5%81%E7%A8%8B%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.6.4.</span> <span class="toc-text">6.4 执行流程详解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E6%95%B0%E6%8D%AE%E6%9C%AC%E5%9C%B0%E6%80%A7%E5%8E%9F%E7%90%86%E6%B7%B1%E5%BA%A6%E8%A7%A3%E6%9E%90"><span class="toc-number">1.7.</span> <span class="toc-text">7. 数据本地性原理深度解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E6%95%B0%E6%8D%AE%E6%9C%AC%E5%9C%B0%E6%80%A7%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84"><span class="toc-number">1.7.1.</span> <span class="toc-text">7.1 数据本地性的层次结构</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/07/21/HyperEnclave%E5%90%AF%E5%8A%A8%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B/" title="HyperEnclave启动和初始化流程"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250721161224869.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HyperEnclave启动和初始化流程"/></a><div class="content"><a class="title" href="/2025/07/21/HyperEnclave%E5%90%AF%E5%8A%A8%E5%92%8C%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B/" title="HyperEnclave启动和初始化流程">HyperEnclave启动和初始化流程</a><time datetime="2025-07-21T11:00:00.000Z" title="发表于 2025-07-21 19:00:00">2025-07-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/07/20/HyperEnclave%E6%9C%BA%E5%AF%86%E8%AE%A1%E7%AE%97%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E3%80%81%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AF%B9%E6%AF%94/" title="HyperEnclave机密计算解析：架构原理、安全机制与技术对比"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250721154750949.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="HyperEnclave机密计算解析：架构原理、安全机制与技术对比"/></a><div class="content"><a class="title" href="/2025/07/20/HyperEnclave%E6%9C%BA%E5%AF%86%E8%AE%A1%E7%AE%97%E8%A7%A3%E6%9E%90%EF%BC%9A%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86%E3%80%81%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6%E4%B8%8E%E6%8A%80%E6%9C%AF%E5%AF%B9%E6%AF%94/" title="HyperEnclave机密计算解析：架构原理、安全机制与技术对比">HyperEnclave机密计算解析：架构原理、安全机制与技术对比</a><time datetime="2025-07-20T14:00:00.000Z" title="发表于 2025-07-20 22:00:00">2025-07-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/07/15/%E4%BB%8E%20CSV%E6%96%87%E4%BB%B6%E7%9A%84%E5%8A%A0%E8%BD%BD%E3%80%81%E5%88%86%E5%8C%BA%E5%92%8C%E5%A4%84%E7%90%86%20%E6%9D%A5%E7%90%86%E8%A7%A3%20RDD/" title="从 CSV文件的加载、分区和处理 来理解 RDD"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250618094256140.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="从 CSV文件的加载、分区和处理 来理解 RDD"/></a><div class="content"><a class="title" href="/2025/07/15/%E4%BB%8E%20CSV%E6%96%87%E4%BB%B6%E7%9A%84%E5%8A%A0%E8%BD%BD%E3%80%81%E5%88%86%E5%8C%BA%E5%92%8C%E5%A4%84%E7%90%86%20%E6%9D%A5%E7%90%86%E8%A7%A3%20RDD/" title="从 CSV文件的加载、分区和处理 来理解 RDD">从 CSV文件的加载、分区和处理 来理解 RDD</a><time datetime="2025-07-15T11:00:00.000Z" title="发表于 2025-07-15 19:00:00">2025-07-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/07/11/%E6%B5%85%E5%B0%9D%20Spring%20AI/" title="浅尝 Spring AI"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250618094256140.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="浅尝 Spring AI"/></a><div class="content"><a class="title" href="/2025/07/11/%E6%B5%85%E5%B0%9D%20Spring%20AI/" title="浅尝 Spring AI">浅尝 Spring AI</a><time datetime="2025-07-11T12:00:00.000Z" title="发表于 2025-07-11 20:00:00">2025-07-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/07/10/Spark%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%8E%E6%87%92%E6%83%B0%E8%AE%A1%E7%AE%97/" title="Spark核心概念与懒惰计算[未修订完]">Spark核心概念与懒惰计算[未修订完]</a><time datetime="2025-07-10T03:00:00.000Z" title="发表于 2025-07-10 11:00:00">2025-07-10</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2024 - 2025 By <a class="footer-bar-link" href="/" title="XR" target="_blank">XR</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">44</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">57</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">5</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://image.anheyu.com/favicon.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Argon2/" style="font-size: 0.88rem;">Argon2<sup>1</sup></a><a href="/tags/DNS/" style="font-size: 0.88rem;">DNS<sup>2</sup></a><a href="/tags/HBase/" style="font-size: 0.88rem;">HBase<sup>1</sup></a><a href="/tags/HDFS/" style="font-size: 0.88rem;">HDFS<sup>3</sup></a><a href="/tags/HTTP/" style="font-size: 0.88rem;">HTTP<sup>1</sup></a><a href="/tags/Hadoop/" style="font-size: 0.88rem;">Hadoop<sup>1</sup></a><a href="/tags/Hive/" style="font-size: 0.88rem;">Hive<sup>1</sup></a><a href="/tags/Java/" style="font-size: 0.88rem;">Java<sup>8</sup></a><a href="/tags/Kubernetes/" style="font-size: 0.88rem;">Kubernetes<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 0.88rem;">Linux<sup>4</sup></a><a href="/tags/Maven/" style="font-size: 0.88rem;">Maven<sup>1</sup></a><a href="/tags/MinIO/" style="font-size: 0.88rem;">MinIO<sup>1</sup></a><a href="/tags/NAT/" style="font-size: 0.88rem;">NAT<sup>1</sup></a><a href="/tags/RDD/" style="font-size: 0.88rem;">RDD<sup>2</sup></a><a href="/tags/SGX/" style="font-size: 0.88rem;">SGX<sup>2</sup></a><a href="/tags/Shuffle%E6%9C%BA%E5%88%B6/" style="font-size: 0.88rem;">Shuffle机制<sup>1</sup></a><a href="/tags/Spark/" style="font-size: 0.88rem;">Spark<sup>6</sup></a><a href="/tags/Spring/" style="font-size: 0.88rem;">Spring<sup>3</sup></a><a href="/tags/TDX/" style="font-size: 0.88rem;">TDX<sup>2</sup></a><a href="/tags/TEE/" style="font-size: 0.88rem;">TEE<sup>3</sup></a><a href="/tags/TME/" style="font-size: 0.88rem;">TME<sup>2</sup></a><a href="/tags/YARN/" style="font-size: 0.88rem;">YARN<sup>1</sup></a><a href="/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/" style="font-size: 0.88rem;">云原生<sup>1</sup></a><a href="/tags/%E4%BB%A3%E7%90%86/" style="font-size: 0.88rem;">代理<sup>1</sup></a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/" style="font-size: 0.88rem;">分布式存储<sup>2</sup></a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/" style="font-size: 0.88rem;">分布式计算<sup>3</sup></a><a href="/tags/%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E9%99%90%E5%88%B6/" style="font-size: 0.88rem;">地理位置限制<sup>1</sup></a><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" style="font-size: 0.88rem;">大数据<sup>4</sup></a><a href="/tags/%E5%AE%89%E5%85%A8/" style="font-size: 0.88rem;">安全<sup>2</sup></a><a href="/tags/%E5%AF%86%E7%A0%81%E5%93%88%E5%B8%8C/" style="font-size: 0.88rem;">密码哈希<sup>1</sup></a><a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 0.88rem;">密码学<sup>1</sup></a><a href="/tags/%E5%B9%B6%E5%8F%91/" style="font-size: 0.88rem;">并发<sup>2</sup></a><a href="/tags/%E6%8A%80%E6%9C%AF%E4%B8%93%E6%A0%8F/" style="font-size: 0.88rem;">技术专栏<sup>1</sup></a><a href="/tags/%E6%B5%81%E5%AA%92%E4%BD%93%E8%A7%A3%E9%94%81/" style="font-size: 0.88rem;">流媒体解锁<sup>1</sup></a><a href="/tags/%E7%B3%BB%E7%BB%9F/" style="font-size: 0.88rem;">系统<sup>2</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C/" style="font-size: 0.88rem;">网络<sup>4</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90/" style="font-size: 0.88rem;">网络分析<sup>1</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" style="font-size: 0.88rem;">网络安全<sup>1</sup></a><a href="/tags/%E9%98%B2%E7%81%AB%E5%A2%99/" style="font-size: 0.88rem;">防火墙<sup>2</sup></a><a href="/tags/%E9%9A%90%E7%A7%81%E8%AE%A1%E7%AE%97/" style="font-size: 0.88rem;">隐私计算<sup>2</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("12/26/2024 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2024 By 安知鱼 V1.6.14",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 XR 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.cbd.int/mermaid@10.2.4/dist/mermaid.min.js').then(runMermaid)
  }

  anzhiyu.addGlobalFn('themeChange', runMermaid, 'mermaid')

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'cbSQtAqs68yENzUQ5wpQK826-MdYXbMMI',
      appKey: 'MR93sqmbPdh7Zm1bZzjXNvlm',
      avatar: 'mp',
      serverURLs: 'https://cbsqtaqs.api.lncldglobal.com',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.cbd.int/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"></div><script src="https://cdn.cbd.int/blueimp-md5@2.19.0/js/md5.min.js"></script><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getIcon = (icon, mail) => {
    if (icon) return icon
    let defaultIcon = '?d=mp'
    let iconUrl = `https://gravatar.loli.net/avatar/${md5(mail.toLowerCase()) + defaultIcon}`
    return iconUrl
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const getComment = () => {
    const serverURL = 'https://cbsqtaqs.api.lncldglobal.com'

    var settings = {
      "method": "GET",
      "headers": {
        "X-LC-Id": 'cbSQtAqs68yENzUQ5wpQK826-MdYXbMMI',
        "X-LC-Key": 'MR93sqmbPdh7Zm1bZzjXNvlm',
        "Content-Type": "application/json"
      },
    }

    fetch(`${serverURL}/1.1/classes/Comment?limit=6&order=-createdAt`,settings)
      .then(response => response.json())
      .then(data => {
        const valineArray = data.results.map(function (e) {
          return {
            'avatar': getIcon(e.QQAvatar, e.mail),
            'content': changeContent(e.comment),
            'nick': e.nick,
            'url': e.url + '#' + e.objectId,
            'date': e.updatedAt,
          }
        })
        saveToLocal.set('valine-newest-comments', JSON.stringify(valineArray), 10/(60*24))
        generateHtml(valineArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      }) 
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('valine-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>