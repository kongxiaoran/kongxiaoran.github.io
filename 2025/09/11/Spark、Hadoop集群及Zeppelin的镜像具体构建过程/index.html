<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>Spark、Hadoop集群及Zeppelin的镜像具体构建过程 | 凌霄的博客</title><meta name="keywords" content="Hadoop,Spark,Zeppelin,Docker,大数据"><meta name="author" content="XR"><meta name="copyright" content="XR"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="Spark、Hadoop集群及Zeppelin的镜像具体构建过程"><meta name="application-name" content="Spark、Hadoop集群及Zeppelin的镜像具体构建过程"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="Spark、Hadoop集群及Zeppelin的镜像具体构建过程"><meta property="og:url" content="http://example.com/2025/09/11/Spark%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E5%8F%8AZeppelin%E7%9A%84%E9%95%9C%E5%83%8F%E5%85%B7%E4%BD%93%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B/index.html"><meta property="og:site_name" content="凌霄的博客"><meta property="og:description" content="本文详细记录了如何构建和部署一个集成了Spark、Hadoop和Zeppelin的Docker化环境，旨在为数据工程师提供一个开箱即用的大数据分析平台。"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250804100847374.png"><meta property="article:author" content="XR"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250804100847374.png"><meta name="description" content="本文详细记录了如何构建和部署一个集成了Spark、Hadoop和Zeppelin的Docker化环境，旨在为数据工程师提供一个开箱即用的大数据分析平台。"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://example.com/2025/09/11/Spark%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E5%8F%8AZeppelin%E7%9A%84%E9%95%9C%E5%83%8F%E5%85%B7%E4%BD%93%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走！再看看嘛！","backTitle":"♪(^∇^*)欢迎肥来！"},
  LA51: undefined,
  greetingBox: undefined,
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  music_page_default: "nav_music",
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🧱 团队小组发动机"]},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: XR","link":"链接: ","source":"来源: 凌霄的博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '凌霄的博客',
  title: 'Spark、Hadoop集群及Zeppelin的镜像具体构建过程',
  postAI: '',
  pageFillDescription: 'Spark、Hadoop集群及Zeppelin的镜像具体构建过程, 1. 概述, 1.1. 核心组件, 1.2. 架构图, 2. 环境准备, 3. 目录结构, 4. 构建Docker镜像, 4.1. Dockerfile制作, 4.2. 构建命令, 5. 配置, 5.1. Hadoop配置, 5.2. Docker Compose配置, 5.2.1. 共享卷, 5.2.2. 环境变量, 6. 部署, 7. 使用, 7.1. 访问服务, 7.2. 在Zeppelin中使用Spark, 7.3. 示例：Word Count, 附录：配置文件内容, A.1 Hadoop 配置, core-site.xml, hadoop-env.sh, hdfs-site.xml, mapred-site.xml, yarn-site.xml, workers, ssh_config, start-cluster.sh集群及的镜像具体构建过程官方文档阿里云镜像站下载地址官方下载本文档详细记录了如何构建和部署一个集成了和的化环境该环境旨在为数据工程师提供一个开箱即用的大数据分析平台如果只是希望能直接部署请直接看本文中内容然后直接如果希望知道这个集成的镜像是怎么构建起来的可以详细看全文概述通过容器化技术将和三个核心组件打包在一起形成一个统一可移植的开发和分析环境主要优势包括环境一致性避免了在不同机器上因环境差异导致的问题快速部署通过可以一键启动整个集群资源隔离每个组件都在独立的容器中运行互不干扰易于扩展可以轻松地增加或减少工作节点核心组件一个快速通用的大数据处理引擎支持批处理流处理机器学习和图计算一个分布式系统基础架构主要使用其分布式文件系统和资源管理器一个基于的笔记本支持交互式数据分析和可视化架构图环境共享卷配置挂载到挂载到库挂载到提交任务环境准备在开始之前请确保您的系统已安装以下软件通常随一同安装下载目录结构用于构建包含和的自定义镜像存放的配置文件自定义的容器入口脚本用于初始化服务用于启动一个基础的和集群的二进制包用于与容器共享文件的本地目录存放与集成的相关文件用于启动包含的完整集群启动集群的便捷脚本构建镜像镜像是整个环境的基础基于镜像并在此基础上添加了制作基础镜像安装依赖安装等运行所需的依赖配置为的和节点之间的免密登录生成密钥安装将复制到容器中并解压设置相关的环境变量如复制配置将目录下的配置文件复制到容器的配置目录中自定义入口点将复制到容器中设置该脚本为容器的以确保在容器启动时首先执行的初始化操作内容使用自定义脚本优雅方案构建命令在项目根目录下执行以下命令来构建镜像配置配置的配置文件位于目录下您可以根据需要修改这些文件例如调整的副本数或的内存分配配置的默认文件系统配置的和配置的和配置作业指定集群中的节点的核心环境变量配置文件它用于设置运行所需的环境变量例如指定安装路径指定安装路径指定配置目录等此外该文件还允许配置守护进程如的选项日志目录用户身份等关键参数客户端配置文件在此项目中文件用于定义连接的默认行为特别是为了实现和集群节点间的无密码登录通过配置和可以避免在节点间首次建立连接时需要手动确认主机密钥的提示从而自动化集群的启动和管理这些配置文件的内容都记录在文章末尾的附录中配置文件定义了整个集群的服务直接将配置目录挂载到共享卷将容器内的库挂载到共享卷使用共享卷中的库挂载配置目录从容器共享持久化数据持久化配置创建一个命名卷来共享配置创建一个命名卷来共享库持久化卷配置持久化卷共享卷为了实现与的无缝集成我们使用了的共享卷在服务中我们将容器内的配置目录挂载到该卷在服务中我们将该卷挂载到从而使能够访问的配置在服务中我们将的库目录挂载到该卷在服务中我们将该卷挂载到从而使能够使用与集群版本一致的库这种设计避免了在容器中重复安装和也无需手动复制配置文件大大简化了架构环境变量在服务中我们设置了以下环境变量以告知如何找到和部署进入目录执行以下脚本即可一键启动整个集群该脚本会执行命令在后台启动所有服务使用访问服务在中使用打开界面创建一个新的笔记本在笔记本的解释器设置中将解释器的属性设置为现在就可以在笔记本中编写代码并将其提交到集群上运行示例在笔记本中运行以下代码体验在上进行单词计数的完整流程写入数据到使用相对路径文件将保存在用户的主目录从读取数据并执行打印结果重要提示权限说明为确保用户拥有必要的操作权限系统在启动时已自动创建目录并将其设置为用户的主目录因此在中读写时请使用相对路径如或以开头的绝对路径以避免权限错误附录配置文件内容配置启动集群的脚本此脚本用于启动整个集群启动集群确保已停止启动集群启动完成自定义脚本优雅的启动方案不修改原始完全自定义启动流程启动服务启动服务设置环境变量启动服务如果未运行启动服务如果未运行为用户创建目录并授权等待完全启动创建用户目录更改目录所有权设置目录权限调用原始传递所有参数',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-09-14 21:07:05',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://npm.elemecdn.com/anzhiyu-blog-static@1.0.4/img/avatar.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/" accesskey="h"><div class="title">凌霄的博客</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Argon2/" style="font-size: 1.05rem;">Argon2<sup>1</sup></a><a href="/tags/DNS/" style="font-size: 1.05rem;">DNS<sup>4</sup></a><a href="/tags/GRUB/" style="font-size: 1.05rem;">GRUB<sup>1</sup></a><a href="/tags/HDFS/" style="font-size: 1.05rem;">HDFS<sup>4</sup></a><a href="/tags/HTTP/" style="font-size: 1.05rem;">HTTP<sup>1</sup></a><a href="/tags/Hadoop/" style="font-size: 1.05rem;">Hadoop<sup>4</sup></a><a href="/tags/HyperEnclave/" style="font-size: 1.05rem;">HyperEnclave<sup>5</sup></a><a href="/tags/Hypervisor/" style="font-size: 1.05rem;">Hypervisor<sup>2</sup></a><a href="/tags/KVM/" style="font-size: 1.05rem;">KVM<sup>2</sup></a><a href="/tags/Kerberos/" style="font-size: 1.05rem;">Kerberos<sup>1</sup></a><a href="/tags/Kubernetes/" style="font-size: 1.05rem;">Kubernetes<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 1.05rem;">Linux<sup>7</sup></a><a href="/tags/Linux%E8%BF%90%E7%BB%B4/" style="font-size: 1.05rem;">Linux运维<sup>1</sup></a><a href="/tags/TEE/" style="font-size: 1.05rem;">TEE<sup>10</sup></a><a href="/tags/TPM/" style="font-size: 1.05rem;">TPM<sup>1</sup></a><a href="/tags/UEFI/" style="font-size: 1.05rem;">UEFI<sup>1</sup></a><a href="/tags/VMware/" style="font-size: 1.05rem;">VMware<sup>1</sup></a><a href="/tags/Xen/" style="font-size: 1.05rem;">Xen<sup>1</sup></a><a href="/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/" style="font-size: 1.05rem;">云原生<sup>1</sup></a><a href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/" style="font-size: 1.05rem;">云计算<sup>1</sup></a><a href="/tags/%E4%BB%A3%E7%90%86/" style="font-size: 1.05rem;">代理<sup>1</sup></a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/" style="font-size: 1.05rem;">分布式存储<sup>2</sup></a><a href="/tags/%E5%8F%AF%E4%BF%A1%E5%90%AF%E5%8A%A8/" style="font-size: 1.05rem;">可信启动<sup>1</sup></a><a href="/tags/%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E9%99%90%E5%88%B6/" style="font-size: 1.05rem;">地理位置限制<sup>1</sup></a><a href="/tags/%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/" style="font-size: 1.05rem;">学习路线<sup>1</sup></a><a href="/tags/%E5%AE%89%E5%85%A8%E5%90%AF%E5%8A%A8/" style="font-size: 1.05rem;">安全启动<sup>1</sup></a><a href="/tags/%E5%AF%86%E7%A0%81%E5%93%88%E5%B8%8C/" style="font-size: 1.05rem;">密码哈希<sup>1</sup></a><a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 1.05rem;">密码学<sup>5</sup></a><a href="/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/" style="font-size: 1.05rem;">故障排查<sup>1</sup></a><a href="/tags/%E6%97%A5%E5%BF%97/" style="font-size: 1.05rem;">日志<sup>1</sup></a><a href="/tags/%E6%9C%BA%E5%AF%86%E8%AE%A1%E7%AE%97/" style="font-size: 1.05rem;">机密计算<sup>2</sup></a><a href="/tags/%E6%B5%81%E5%AA%92%E4%BD%93%E8%A7%A3%E9%94%81/" style="font-size: 1.05rem;">流媒体解锁<sup>1</sup></a><a href="/tags/%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/" style="font-size: 1.05rem;">磁盘空间<sup>1</sup></a><a href="/tags/%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97/" style="font-size: 1.05rem;">系统日志<sup>1</sup></a><a href="/tags/%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93/" style="font-size: 1.05rem;">缓存污染<sup>1</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90/" style="font-size: 1.05rem;">网络分析<sup>1</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" style="font-size: 1.05rem;">网络安全<sup>1</sup></a><a href="/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/" style="font-size: 1.05rem;">虚拟化<sup>5</sup></a><a href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/" style="font-size: 1.05rem;">论文翻译<sup>1</sup></a><a href="/tags/%E9%9A%90%E7%A7%81%E8%AE%A1%E7%AE%97/" style="font-size: 1.05rem;">隐私计算<sup>6</sup></a></div></div><hr/></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/09/"><span class="card-archive-list-date">九月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">11</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/08/"><span class="card-archive-list-date">八月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">6</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/07/"><span class="card-archive-list-date">七月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">17</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/06/"><span class="card-archive-list-date">六月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">32</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/01/"><span class="card-archive-list-date">一月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">1</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url">大数据</a></span><span class="article-meta tags"><a class="article-meta__tags" href="/tags/Hadoop/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Hadoop</span></a><a class="article-meta__tags" href="/tags/Spark/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Spark</span></a><a class="article-meta__tags" href="/tags/Zeppelin/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Zeppelin</span></a><a class="article-meta__tags" href="/tags/Docker/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>Docker</span></a><a class="article-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" tabindex="-1" itemprop="url"> <span> <i class="anzhiyufont anzhiyu-icon-hashtag"></i>大数据</span></a></span></div></div><h1 class="post-title" itemprop="name headline">Spark、Hadoop集群及Zeppelin的镜像具体构建过程</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2025-09-11T06:52:01.000Z" title="发表于 2025-09-11 14:52:01">2025-09-11</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2025-09-14T13:07:05.740Z" title="更新于 2025-09-14 21:07:05">2025-09-14</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="Spark、Hadoop集群及Zeppelin的镜像具体构建过程"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为杭州"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>杭州</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250804100847374.png"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="http://example.com/2025/09/11/Spark%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E5%8F%8AZeppelin%E7%9A%84%E9%95%9C%E5%83%8F%E5%85%B7%E4%BD%93%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B/"><header><a class="post-meta-categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url">大数据</a><a href="/tags/Hadoop/" tabindex="-1" itemprop="url">Hadoop</a><a href="/tags/Spark/" tabindex="-1" itemprop="url">Spark</a><a href="/tags/Zeppelin/" tabindex="-1" itemprop="url">Zeppelin</a><a href="/tags/Docker/" tabindex="-1" itemprop="url">Docker</a><a href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" tabindex="-1" itemprop="url">大数据</a><h1 id="CrawlerTitle" itemprop="name headline">Spark、Hadoop集群及Zeppelin的镜像具体构建过程</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">XR</span><time itemprop="dateCreated datePublished" datetime="2025-09-11T06:52:01.000Z" title="发表于 2025-09-11 14:52:01">2025-09-11</time><time itemprop="dateCreated datePublished" datetime="2025-09-14T13:07:05.740Z" title="更新于 2025-09-14 21:07:05">2025-09-14</time></header><h1 id="Spark、Hadoop集群及Zeppelin的镜像具体构建过程"><a href="#Spark、Hadoop集群及Zeppelin的镜像具体构建过程" class="headerlink" title="Spark、Hadoop集群及Zeppelin的镜像具体构建过程"></a>Spark、Hadoop集群及Zeppelin的镜像具体构建过程</h1><blockquote>
<p>zeppelin官方文档：<a target="_blank" rel="noopener" href="https://zeppelin.apache.org/docs/0.12.0/interpreter/spark.html">https://zeppelin.apache.org/docs/0.12.0/interpreter/spark.html</a><br>阿里云hadoop镜像站：<a target="_blank" rel="noopener" href="https://mirrors.aliyun.com/apache/hadoop/common/?spm=a2c6h.25603864.0.0.25594c98Zq721o">https://mirrors.aliyun.com/apache/hadoop/common/?spm=a2c6h.25603864.0.0.25594c98Zq721o</a><br>spark下载地址：<a target="_blank" rel="noopener" href="https://spark.apache.org/downloads.html">https://spark.apache.org/downloads.html</a><br>hadoop官方下载：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/release/3.4.0.html">https://hadoop.apache.org/release/3.4.0.html</a></p>
</blockquote>
<p>本文档详细记录了如何构建和部署一个集成了Spark、Hadoop和Zeppelin的Docker化环境。该环境旨在为数据工程师提供一个开箱即用的大数据分析平台。</p>
<p>如果只是希望能直接部署，请直接看本文中 docker-compose-with-zeppelin.yml 内容，然后直接 <code>docker-compose -f docker-compose-with-zeppelin.yml up -d</code> 。如果希望知道这个集成的镜像是怎么构建起来的，可以详细看全文。</p>
<h2 id="1-概述"><a href="#1-概述" class="headerlink" title="1. 概述"></a>1. 概述</h2><p>通过Docker容器化技术，将Spark、Hadoop和Zeppelin三个核心组件打包在一起，形成一个统一、可移植的开发和分析环境。主要优势包括：</p>
<ul>
<li><strong>环境一致性</strong>: 避免了在不同机器上因环境差异导致的问题。</li>
<li><strong>快速部署</strong>: 通过Docker Compose可以一键启动整个集群。</li>
<li><strong>资源隔离</strong>: 每个组件都在独立的容器中运行，互不干扰。</li>
<li><strong>易于扩展</strong>: 可以轻松地增加或减少Spark工作节点。</li>
</ul>
<h3 id="1-1-核心组件"><a href="#1-1-核心组件" class="headerlink" title="1.1. 核心组件"></a>1.1. 核心组件</h3><ul>
<li><strong>Spark-3.5.6</strong>: 一个快速、通用的大数据处理引擎，支持批处理、流处理、机器学习和图计算。</li>
<li><strong>Hadoop-3.4.0</strong>: 一个分布式系统基础架构，主要使用其HDFS（分布式文件系统）和YARN（资源管理器）。</li>
<li><strong>Zeppelin-0.12.0</strong>: 一个基于Web的笔记本，支持交互式数据分析和可视化。</li>
</ul>
<h3 id="1-2-架构图"><a href="#1-2-架构图" class="headerlink" title="1.2. 架构图"></a>1.2. 架构图</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>
  graph TD
    subgraph &quot;Docker 环境&quot;
        subgraph &quot;Docker Compose&quot;
            A[Zeppelin] --&gt; B{Spark Master};
            B --&gt; C[Spark Worker 1];
            B --&gt; D[Spark Worker 2];
            B --&gt; E{Hadoop&#x2F;YARN};
            E --&gt; F[HDFS NameNode];
            E --&gt; G[HDFS DataNode];
        end
    end

    subgraph &quot;共享卷&quot;
        H[Hadoop 配置] --挂载到--&gt; A;
        H --挂载到--&gt; B;
        I[Spark 库] --挂载到--&gt; A;
    end

    A --提交任务--&gt; E;
  </pre></div>

<h2 id="2-环境准备"><a href="#2-环境准备" class="headerlink" title="2. 环境准备"></a>2. 环境准备</h2><p>在开始之前，请确保您的系统已安装以下软件：</p>
<ul>
<li><strong>Docker</strong>: <a target="_blank" rel="noopener" href="https://www.docker.com/get-started">https://www.docker.com/get-started</a></li>
<li><strong>Docker Compose</strong>: 通常随Docker一同安装。</li>
<li><strong>下载hadoop-3.4.0.tar.gz</strong>：<a target="_blank" rel="noopener" href="https://hadoop.apache.org/release/3.4.0.html">https://hadoop.apache.org/release/3.4.0.html</a></li>
</ul>
<h2 id="3-目录结构"><a href="#3-目录结构" class="headerlink" title="3. 目录结构"></a>3. 目录结构</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├── Dockerfile</span><br><span class="line">├── config</span><br><span class="line">│   ├── core-site.xml</span><br><span class="line">│   ├── hadoop-env.sh</span><br><span class="line">│   ├── hdfs-site.xml</span><br><span class="line">│   ├── mapred-site.xml</span><br><span class="line">│   ├── ssh_config</span><br><span class="line">│   ├── workers</span><br><span class="line">│   └── yarn-site.xml</span><br><span class="line">├── custom-entrypoint.sh</span><br><span class="line">├── docker-compose.yml</span><br><span class="line">├── hadoop-3.4.0.tar.gz</span><br><span class="line">├── share</span><br><span class="line">│   ├── my_script.py</span><br><span class="line">│   └── words.txt</span><br><span class="line">└── spark-hadoop</span><br><span class="line">    ├── README.md</span><br><span class="line">    ├── docker-compose-with-zeppelin.yml</span><br><span class="line">    ├── docker-compose.yml</span><br><span class="line">    └── start-cluster.sh</span><br></pre></td></tr></table></figure>

<ul>
<li><code>Dockerfile</code>: 用于构建包含Spark和Hadoop的自定义Docker镜像。</li>
<li><code>config/</code>: 存放Hadoop的配置文件。</li>
<li><code>custom-entrypoint.sh</code>: 自定义的容器入口脚本，用于初始化Hadoop服务。</li>
<li><code>docker-compose.yml</code>: 用于启动一个基础的Spark和Hadoop集群。</li>
<li><code>hadoop-3.4.0.tar.gz</code>: Hadoop的二进制包。</li>
<li><code>share/</code>: 用于与容器共享文件的本地目录。</li>
<li><code>spark-hadoop/</code>: 存放与Zeppelin集成的相关文件。<ul>
<li><code>docker-compose-with-zeppelin.yml</code>: 用于启动包含Zeppelin的完整集群。</li>
<li><code>start-cluster.sh</code>: 启动集群的便捷脚本。</li>
</ul>
</li>
</ul>
<h2 id="4-构建Docker镜像"><a href="#4-构建Docker镜像" class="headerlink" title="4. 构建Docker镜像"></a>4. 构建Docker镜像</h2><p>镜像是整个环境的基础。<code>Dockerfile</code>基于<code>bitnami/spark</code>镜像，并在此基础上添加了Hadoop。</p>
<h3 id="4-1-Dockerfile制作"><a href="#4-1-Dockerfile制作" class="headerlink" title="4.1. Dockerfile制作"></a>4.1. Dockerfile制作</h3><ol>
<li><strong>基础镜像</strong>: <code>FROM docker.io/bitnami/spark:3.5.6</code></li>
<li><strong>安装依赖</strong>: 安装<code>openssh-server</code>等Hadoop运行所需的依赖。</li>
<li><strong>配置SSH</strong>: 为Hadoop的Master和Worker节点之间的免密登录生成SSH密钥。</li>
<li><strong>安装Hadoop</strong>:<ul>
<li>将<code>hadoop-3.4.0.tar.gz</code>复制到容器中并解压。</li>
<li>设置Hadoop相关的环境变量，如<code>HADOOP_HOME</code>。</li>
</ul>
</li>
<li><strong>复制Hadoop配置</strong>: 将<code>config/</code>目录下的配置文件复制到容器的Hadoop配置目录中。</li>
<li><strong>自定义入口点</strong>:<ul>
<li>将<code>custom-entrypoint.sh</code>复制到容器中。</li>
<li>设置该脚本为容器的<code>ENTRYPOINT</code>，以确保在容器启动时首先执行Hadoop的初始化操作。</li>
</ul>
</li>
</ol>
<p>Dockerfile内容：</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">FROM</span> <span class="string">docker.io/bitnami/spark:3.5.6</span></span><br><span class="line"><span class="string">LABEL</span> <span class="string">maintainer=&quot;kxr</span> <span class="string">&lt;kongxiaoranx@gmail.com&gt;&quot;</span></span><br><span class="line"><span class="string">LABEL</span> <span class="string">description=&quot;Docker</span> <span class="string">image</span> <span class="string">with</span> <span class="string">Spark</span> <span class="string">(3.5.6)</span> <span class="string">and</span> <span class="string">Hadoop</span> <span class="string">(3.4.0),</span> <span class="string">based</span> <span class="string">on</span> <span class="string">bitnami/spark:3.5.6</span> <span class="string">\</span></span><br><span class="line"><span class="string">For</span> <span class="string">more</span> <span class="string">information,</span> <span class="string">please</span> <span class="string">visit</span> <span class="string">https://github.com/kongxiaoran/spark-hadoop-docker.&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">USER</span> <span class="string">root</span></span><br><span class="line"></span><br><span class="line"><span class="string">ENV</span> <span class="string">HADOOP_HOME=&quot;/opt/hadoop&quot;</span></span><br><span class="line"><span class="string">ENV</span> <span class="string">HADOOP_CONF_DIR=&quot;$HADOOP_HOME/etc/hadoop&quot;</span></span><br><span class="line"><span class="string">ENV</span> <span class="string">HADOOP_LOG_DIR=&quot;/var/log/hadoop&quot;</span></span><br><span class="line"><span class="string">ENV</span> <span class="string">PATH=&quot;$HADOOP_HOME/hadoop/sbin:$HADOOP_HOME/bin:$PATH&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="string">WORKDIR</span> <span class="string">/opt</span></span><br><span class="line"></span><br><span class="line"><span class="string">RUN</span> <span class="string">apt-get</span> <span class="string">update</span> <span class="string">&amp;&amp;</span> <span class="string">apt-get</span> <span class="string">install</span> <span class="string">-y</span> <span class="string">\</span></span><br><span class="line">    <span class="string">openssh-server</span> <span class="string">\</span></span><br><span class="line">    <span class="string">curl</span> <span class="string">\</span></span><br><span class="line">    <span class="string">tar</span> <span class="string">\</span></span><br><span class="line">    <span class="string">gzip</span> <span class="string">\</span></span><br><span class="line">    <span class="string">sudo</span> </span><br><span class="line">			</span><br><span class="line"></span><br><span class="line"><span class="string">RUN</span> <span class="string">ssh-keygen</span> <span class="string">-t</span> <span class="string">rsa</span> <span class="string">-f</span> <span class="string">/root/.ssh/id_rsa</span> <span class="string">-P</span> <span class="string">&#x27;&#x27;</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">cat</span> <span class="string">/root/.ssh/id_rsa.pub</span> <span class="string">&gt;&gt;</span> <span class="string">/root/.ssh/authorized_keys</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="string">COPY</span> <span class="string">./hadoop-3.4.0.tar.gz</span> <span class="string">/opt/</span></span><br><span class="line"></span><br><span class="line"><span class="string">RUN</span> <span class="string">tar</span> <span class="string">-xzvf</span> <span class="string">hadoop-3.4.0.tar.gz</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">  <span class="string">mv</span> <span class="string">hadoop-3.4.0</span> <span class="string">hadoop</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">  <span class="string">rm</span> <span class="string">-rf</span> <span class="string">hadoop-3.4.0.tar.gz</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">  <span class="string">mkdir</span> <span class="string">/var/log/hadoop</span></span><br><span class="line"></span><br><span class="line"><span class="string">RUN</span> <span class="string">mkdir</span> <span class="string">-p</span> <span class="string">/root/hdfs/namenode</span> <span class="string">&amp;&amp;</span> <span class="string">\</span> </span><br><span class="line">    <span class="string">mkdir</span> <span class="string">-p</span> <span class="string">/root/hdfs/datanode</span> </span><br><span class="line"></span><br><span class="line"><span class="string">COPY</span> <span class="string">config/*</span> <span class="string">/tmp/</span></span><br><span class="line"></span><br><span class="line"><span class="string">RUN</span> <span class="string">mv</span> <span class="string">/tmp/ssh_config</span> <span class="string">/root/.ssh/config</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">mv</span> <span class="string">/tmp/hadoop-env.sh</span> <span class="string">$HADOOP_CONF_DIR/hadoop-env.sh</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">mv</span> <span class="string">/tmp/hdfs-site.xml</span> <span class="string">$HADOOP_CONF_DIR/hdfs-site.xml</span> <span class="string">&amp;&amp;</span> <span class="string">\</span> </span><br><span class="line">    <span class="string">mv</span> <span class="string">/tmp/core-site.xml</span> <span class="string">$HADOOP_CONF_DIR/core-site.xml</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">mv</span> <span class="string">/tmp/mapred-site.xml</span> <span class="string">$HADOOP_CONF_DIR/mapred-site.xml</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">mv</span> <span class="string">/tmp/yarn-site.xml</span> <span class="string">$HADOOP_CONF_DIR/yarn-site.xml</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">mv</span> <span class="string">/tmp/workers</span> <span class="string">$HADOOP_CONF_DIR/workers</span></span><br><span class="line"></span><br><span class="line"><span class="string">RUN</span> <span class="string">chmod</span> <span class="string">+x</span> <span class="string">$HADOOP_HOME/sbin/start-dfs.sh</span> <span class="string">&amp;&amp;</span> <span class="string">\</span></span><br><span class="line">    <span class="string">chmod</span> <span class="string">+x</span> <span class="string">$HADOOP_HOME/sbin/start-yarn.sh</span></span><br><span class="line"><span class="comment">#    sed -i &#x27;s/renice &quot;\$&#123;HADOOP_NICENESS&#125;&quot; \$\$/echo &quot;Skipping renice for \$\$&quot; \&amp;\&amp; true/g&#x27; $HADOOP_HOME/libexec/hadoop-functions.sh </span></span><br><span class="line"></span><br><span class="line"><span class="string">RUN</span> <span class="string">hdfs</span> <span class="string">namenode</span> <span class="string">-format</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自定义entrypoint脚本（优雅方案）</span></span><br><span class="line"><span class="string">COPY</span> <span class="string">custom-entrypoint.sh</span> <span class="string">/opt/custom-entrypoint.sh</span></span><br><span class="line"><span class="string">RUN</span> <span class="string">chmod</span> <span class="string">+x</span> <span class="string">/opt/custom-entrypoint.sh</span></span><br><span class="line"></span><br><span class="line"><span class="string">ENTRYPOINT</span> [ <span class="string">&quot;/opt/custom-entrypoint.sh&quot;</span> ]</span><br><span class="line"><span class="string">CMD</span> [<span class="string">&quot;/opt/bitnami/scripts/spark/run.sh&quot;</span>]</span><br></pre></td></tr></table></figure>



<h3 id="4-2-构建命令"><a href="#4-2-构建命令" class="headerlink" title="4.2. 构建命令"></a>4.2. 构建命令</h3><p>在项目根目录下执行以下命令来构建镜像：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker build -t kongxr7/spark-hadoop:3.5.6-hadoop3.4.0 .</span><br></pre></td></tr></table></figure>

<h2 id="5-配置"><a href="#5-配置" class="headerlink" title="5. 配置"></a>5. 配置</h2><h3 id="5-1-Hadoop配置"><a href="#5-1-Hadoop配置" class="headerlink" title="5.1. Hadoop配置"></a>5.1. Hadoop配置</h3><p>Hadoop的配置文件位于<code>config/</code>目录下。您可以根据需要修改这些文件，例如调整HDFS的副本数或YARN的内存分配。</p>
<ul>
<li><code>core-site.xml</code>: 配置HDFS的默认文件系统。</li>
<li><code>hdfs-site.xml</code>: 配置HDFS的NameNode和DataNode。</li>
<li><code>yarn-site.xml</code>: 配置YARN的ResourceManager和NodeManager。</li>
<li><code>mapred-site.xml</code>: 配置MapReduce作业。</li>
<li><code>workers</code>: 指定Hadoop集群中的Worker节点。</li>
<li><code>hadoop-env.sh</code>: Hadoop的核心环境变量配置文件。它用于设置Hadoop运行所需的环境变量，例如<code>JAVA_HOME</code>（指定Java安装路径）、<code>HADOOP_HOME</code>（指定Hadoop安装路径）、<code>HADOOP_CONF_DIR</code>（指定Hadoop配置目录）等。此外，该文件还允许配置Hadoop守护进程（如NameNode, DataNode, ResourceManager, NodeManager）的JVM选项、日志目录、用户身份等关键参数。</li>
<li><code>ssh_config</code>: SSH客户端配置文件。在此项目中，<code>ssh_config</code>文件用于定义SSH连接的默认行为，特别是为了实现Hadoop和Spark集群节点间的无密码SSH登录。通过配置<code>StrictHostKeyChecking no</code>和<code>UserKnownHostsFile=/dev/null</code>，可以避免在节点间首次建立SSH连接时需要手动确认主机密钥的提示，从而自动化集群的启动和管理。</li>
</ul>
<blockquote>
<p>这些配置文件的内容都记录在文章末尾的附录中</p>
</blockquote>
<h3 id="5-2-Docker-Compose配置"><a href="#5-2-Docker-Compose配置" class="headerlink" title="5.2. Docker Compose配置"></a>5.2. Docker Compose配置</h3><p><code>spark-hadoop/docker-compose-with-zeppelin.yml</code>文件定义了整个集群的服务。</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">version:</span> <span class="string">&#x27;2&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">services:</span></span><br><span class="line">  <span class="attr">spark:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">kongxr7/spark-hadoop:3.5.6-hadoop3.4.0</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">master</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_MODE=master</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_RPC_AUTHENTICATION_ENABLED=no</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_RPC_ENCRYPTION_ENABLED=no</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_SSL_ENABLED=no</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/Users/kxr/learning/docker/spark/share:/opt/share</span></span><br><span class="line">      <span class="comment"># 直接将Hadoop配置目录挂载到共享卷</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">hadoop_conf:/opt/hadoop/etc/hadoop</span></span><br><span class="line">      <span class="comment"># 将容器内的Spark库挂载到共享卷</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">spark_lib:/opt/bitnami/spark</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;8090:8080&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;4040:4040&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;8088:8088&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;8042:8042&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;9870:9870&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;19888:19888&#x27;</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;7077:7077&#x27;</span></span><br><span class="line">  <span class="attr">spark-worker-1:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">kongxr7/spark-hadoop:3.5.6-hadoop3.4.0</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">worker1</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_MODE=worker</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_MASTER_URL=spark://master:7077</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_WORKER_MEMORY=1G</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_WORKER_CORES=1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_RPC_AUTHENTICATION_ENABLED=no</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_RPC_ENCRYPTION_ENABLED=no</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_SSL_ENABLED=no</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/Users/kxr/learning/docker/spark/share:/opt/share</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;8081:8081&#x27;</span></span><br><span class="line">  <span class="attr">spark-worker-2:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">kongxr7/spark-hadoop:3.5.6-hadoop3.4.0</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">worker2</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_MODE=worker</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_MASTER_URL=spark://master:7077</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_WORKER_MEMORY=1G</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_WORKER_CORES=1</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_RPC_AUTHENTICATION_ENABLED=no</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_RPC_ENCRYPTION_ENABLED=no</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_SSL_ENABLED=no</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">/Users/kxr/learning/docker/spark/share:/opt/share</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;8082:8081&#x27;</span></span><br><span class="line">  <span class="attr">zeppelin:</span></span><br><span class="line">    <span class="attr">image:</span> <span class="string">apache/zeppelin:0.12.0</span></span><br><span class="line">    <span class="attr">hostname:</span> <span class="string">zeppelin</span></span><br><span class="line">    <span class="attr">depends_on:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">spark</span></span><br><span class="line">    <span class="attr">environment:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">SPARK_HOME=/opt/spark</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">YARN_CONF_DIR=/opt/hadoop/etc/hadoop</span></span><br><span class="line">    <span class="attr">volumes:</span></span><br><span class="line">      <span class="comment"># 使用共享卷中的Spark库</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">spark_lib:/opt/spark</span></span><br><span class="line">      <span class="comment"># 挂载Hadoop配置目录，从spark容器共享</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">hadoop_conf:/opt/hadoop/etc/hadoop:ro</span></span><br><span class="line">      <span class="comment"># 持久化Zeppelin notebook数据</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zeppelin_notebooks:/opt/zeppelin/notebook</span></span><br><span class="line">      <span class="comment"># 持久化Zeppelin配置</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">zeppelin_conf:/opt/zeppelin/conf</span></span><br><span class="line">    <span class="attr">ports:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">&#x27;8089:8080&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">volumes:</span></span><br><span class="line">  <span class="comment"># 创建一个命名卷来共享Hadoop配置</span></span><br><span class="line">  <span class="attr">hadoop_conf:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br><span class="line">  <span class="comment"># 创建一个命名卷来共享Spark库</span></span><br><span class="line">  <span class="attr">spark_lib:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br><span class="line">  <span class="comment"># Zeppelin notebook持久化卷</span></span><br><span class="line">  <span class="attr">zeppelin_notebooks:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br><span class="line">  <span class="comment"># Zeppelin配置持久化卷</span></span><br><span class="line">  <span class="attr">zeppelin_conf:</span></span><br><span class="line">    <span class="attr">driver:</span> <span class="string">local</span></span><br></pre></td></tr></table></figure>

<h4 id="5-2-1-共享卷"><a href="#5-2-1-共享卷" class="headerlink" title="5.2.1. 共享卷"></a>5.2.1. 共享卷</h4><p>为了实现Zeppelin与Spark&#x2F;Hadoop的无缝集成，我们使用了Docker的共享卷：</p>
<ul>
<li><code>hadoop_conf</code>:<ul>
<li>在<code>spark</code>服务中，我们将容器内的Hadoop配置目录<code>/opt/hadoop/etc/hadoop</code>挂载到该卷。</li>
<li>在<code>zeppelin</code>服务中，我们将该卷挂载到<code>/opt/hadoop/etc/hadoop</code>，从而使Zeppelin能够访问Hadoop的配置。</li>
</ul>
</li>
<li><code>spark_lib</code>:<ul>
<li>在<code>spark</code>服务中，我们将Spark的库目录<code>/opt/bitnami/spark</code>挂载到该卷。</li>
<li>在<code>zeppelin</code>服务中，我们将该卷挂载到<code>/opt/spark</code>，从而使Zeppelin能够使用与集群版本一致的Spark库。</li>
</ul>
</li>
</ul>
<p>这种设计避免了在Zeppelin容器中重复安装Spark和Hadoop，也无需手动复制配置文件，大大简化了架构。</p>
<h4 id="5-2-2-环境变量"><a href="#5-2-2-环境变量" class="headerlink" title="5.2.2. 环境变量"></a>5.2.2. 环境变量</h4><p>在<code>zeppelin</code>服务中，我们设置了以下环境变量，以告知Zeppelin如何找到Spark和Hadoop：</p>
<ul>
<li><code>SPARK_HOME=/opt/spark</code></li>
<li><code>HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop</code></li>
<li><code>YARN_CONF_DIR=/opt/hadoop/etc/hadoop</code></li>
</ul>
<h2 id="6-部署"><a href="#6-部署" class="headerlink" title="6. 部署"></a>6. 部署</h2><p>进入<code>spark-hadoop/</code>目录，执行以下脚本即可一键启动整个集群：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> spark-hadoop</span><br><span class="line">./start-cluster.sh</span><br></pre></td></tr></table></figure>

<p>该脚本会执行<code>docker-compose -f docker-compose-with-zeppelin.yml up -d</code>命令，在后台启动所有服务。</p>
<h2 id="7-使用"><a href="#7-使用" class="headerlink" title="7. 使用"></a>7. 使用</h2><h3 id="7-1-访问服务"><a href="#7-1-访问服务" class="headerlink" title="7.1. 访问服务"></a>7.1. 访问服务</h3><ul>
<li><strong>Spark UI</strong>: <a target="_blank" rel="noopener" href="http://localhost:8090/">http://localhost:8090</a></li>
<li><strong>YARN ResourceManager</strong>: <a target="_blank" rel="noopener" href="http://localhost:8088/">http://localhost:8088</a></li>
<li><strong>HDFS NameNode</strong>: <a target="_blank" rel="noopener" href="http://localhost:9870/">http://localhost:9870</a></li>
<li><strong>Zeppelin</strong>: <a target="_blank" rel="noopener" href="http://localhost:8089/">http://localhost:8089</a></li>
</ul>
<h3 id="7-2-在Zeppelin中使用Spark"><a href="#7-2-在Zeppelin中使用Spark" class="headerlink" title="7.2. 在Zeppelin中使用Spark"></a>7.2. 在Zeppelin中使用Spark</h3><ol>
<li>打开Zeppelin界面。</li>
<li>创建一个新的笔记本。</li>
<li>在笔记本的解释器设置中，将<code>spark</code>解释器的<code>master</code>属性设置为<code>yarn</code>。</li>
<li>现在，就可以在笔记本中编写Spark代码，并将其提交到YARN集群上运行。</li>
</ol>
<h3 id="7-3-示例：Word-Count"><a href="#7-3-示例：Word-Count" class="headerlink" title="7.3. 示例：Word Count"></a>7.3. 示例：Word Count</h3><p>在Zeppelin笔记本中运行以下代码，体验在HDFS上进行单词计数的完整流程：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 1. 写入数据到HDFS</span></span><br><span class="line"><span class="comment">// 使用相对路径 &quot;words&quot;，文件将保存在Zeppelin用户的HDFS主目录 /user/zeppelin/words</span></span><br><span class="line"><span class="keyword">val</span> text = <span class="string">&quot;hello world hello spark hello hadoop&quot;</span></span><br><span class="line">sc.parallelize(text.split(<span class="string">&quot; &quot;</span>)).saveAsTextFile(<span class="string">&quot;words&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2. 从HDFS读取数据并执行Word Count</span></span><br><span class="line"><span class="keyword">val</span> wordCounts = sc.textFile(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">    .flatMap(line =&gt; line.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">    .map(word =&gt; (word, <span class="number">1</span>))</span><br><span class="line">    .reduceByKey(_ + _)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3. 打印结果</span></span><br><span class="line">wordCounts.collect().foreach(println)</span><br></pre></td></tr></table></figure>

<blockquote>
<p><strong>重要提示：HDFS 权限说明</strong></p>
<p>为确保 <code>zeppelin</code> 用户拥有必要的 HDFS 操作权限，系统在启动时已自动创建 <code>/user/zeppelin</code> 目录并将其设置为 <code>zeppelin</code> 用户的主目录。</p>
<p>因此，在 Zeppelin 中读写 HDFS 时，请使用相对路径（如 <code>words</code>）或以 <code>/user/zeppelin/</code> 开头的绝对路径，以避免权限错误。</p>
</blockquote>
<h2 id="附录：配置文件内容"><a href="#附录：配置文件内容" class="headerlink" title="附录：配置文件内容"></a>附录：配置文件内容</h2><h3 id="A-1-Hadoop-配置"><a href="#A-1-Hadoop-配置" class="headerlink" title="A.1 Hadoop 配置"></a>A.1 Hadoop 配置</h3><h4 id="core-site-xml"><a href="#core-site-xml" class="headerlink" title="core-site.xml"></a><code>core-site.xml</code></h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  		<span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  		<span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://master:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="hadoop-env-sh"><a href="#hadoop-env-sh" class="headerlink" title="hadoop-env.sh"></a><code>hadoop-env.sh</code></h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> JAVA_HOME=/opt/bitnami/java</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/opt/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=/opt/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=/opt/hadoop/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$HADOOP_HOME</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">&quot;-Djava.library.path=<span class="variable">$HADOOP_HOME</span>/lib --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.util=ALL-UNNAMED --add-opens java.base/java.lang.reflect=ALL-UNNAMED --add-opens java.base/java.text=ALL-UNNAMED --add-opens java.desktop/java.awt.font=ALL-UNNAMED&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> HDFS_NAMENODE_USER=<span class="string">&quot;root&quot;</span></span><br><span class="line"><span class="built_in">export</span> HDFS_DATANODE_USER=<span class="string">&quot;root&quot;</span></span><br><span class="line"><span class="built_in">export</span> HDFS_SECONDARYNAMENODE_USER=<span class="string">&quot;root&quot;</span></span><br><span class="line"><span class="built_in">export</span> YARN_RESOURCEMANAGER_USER=<span class="string">&quot;root&quot;</span></span><br><span class="line"><span class="built_in">export</span> YARN_NODEMANAGER_USER=<span class="string">&quot;root&quot;</span></span><br></pre></td></tr></table></figure>

<h4 id="hdfs-site-xml"><a href="#hdfs-site-xml" class="headerlink" title="hdfs-site.xml"></a><code>hdfs-site.xml</code></h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///root/hdfs/namenode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>NameNode directory for namespace and transaction logs storage.<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///root/hdfs/datanode<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">description</span>&gt;</span>DataNode directory<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="mapred-site-xml"><a href="#mapred-site-xml" class="headerlink" title="mapred-site.xml"></a><code>mapred-site.xml</code></h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;?xml-stylesheet type=<span class="string">&quot;text/xsl&quot;</span> href=<span class="string">&quot;configuration.xsl&quot;</span>?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Put site-specific property overrides in this file. --&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.app.mapreduce.am.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/opt/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/opt/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.env<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>HADOOP_MAPRED_HOME=/opt/hadoop<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span> </span><br><span class="line">      <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.application.classpath<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">      <span class="tag">&lt;<span class="name">value</span>&gt;</span>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*,$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*,$HADOOP_MAPRED_HOME/share/hadoop/common/*,$HADOOP_MAPRED_HOME/share/hadoop/common/lib/*,$HADOOP_MAPRED_HOME/share/hadoop/yarn/*,$HADOOP_MAPRED_HOME/share/hadoop/yarn/lib/*,$HADOOP_MAPRED_HOME/share/hadoop/hdfs/*,$HADOOP_MAPRED_HOME/share/hadoop/hdfs/lib/*<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="yarn-site-xml"><a href="#yarn-site-xml" class="headerlink" title="yarn-site.xml"></a><code>yarn-site.xml</code></h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="comment">&lt;!--</span></span><br><span class="line"><span class="comment">  Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span></span><br><span class="line"><span class="comment">  you may not use this file except in compliance with the License.</span></span><br><span class="line"><span class="comment">  You may obtain a copy of the License at</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">    http://www.apache.org/licenses/LICENSE-2.0</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment">  Unless required by applicable law or agreed to in writing, software</span></span><br><span class="line"><span class="comment">  distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span></span><br><span class="line"><span class="comment">  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span></span><br><span class="line"><span class="comment">  See the License for the specific language governing permissions and</span></span><br><span class="line"><span class="comment">  limitations under the License. See accompanying LICENSE file.</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!-- Site specific YARN configuration properties --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">	<span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services.mapreduce_shuffle.class<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.mapred.ShuffleHandler<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>master<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.env-whitelist<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure>

<h4 id="workers"><a href="#workers" class="headerlink" title="workers"></a><code>workers</code></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">worker1</span><br><span class="line">worker2</span><br></pre></td></tr></table></figure>

<h4 id="ssh-config"><a href="#ssh-config" class="headerlink" title="ssh_config"></a><code>ssh_config</code></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Host localhost</span><br><span class="line">  StrictHostKeyChecking no</span><br><span class="line"></span><br><span class="line">Host 0.0.0.0</span><br><span class="line">  StrictHostKeyChecking no</span><br><span class="line">  </span><br><span class="line">Host hadoop-*</span><br><span class="line">   StrictHostKeyChecking no</span><br><span class="line">   UserKnownHostsFile=/dev/null</span><br></pre></td></tr></table></figure>

<h4 id="start-cluster-sh"><a href="#start-cluster-sh" class="headerlink" title="start-cluster.sh"></a><code>start-cluster.sh</code></h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line"># 启动集群的脚本</span><br><span class="line"># 此脚本用于启动整个Spark-Hadoop-Zeppelin集群</span><br><span class="line"></span><br><span class="line">echo &quot;=== 启动Spark-Hadoop-Zeppelin集群 ===&quot;</span><br><span class="line"></span><br><span class="line"># 确保docker-compose已停止</span><br><span class="line">docker-compose -f docker-compose-with-zeppelin.yml down</span><br><span class="line"></span><br><span class="line"># 启动docker-compose</span><br><span class="line">docker-compose -f docker-compose-with-zeppelin.yml up -d</span><br><span class="line"></span><br><span class="line">echo &quot;=== 集群启动完成 ===&quot;</span><br><span class="line">echo &quot;Spark UI: http://localhost:8090&quot;</span><br><span class="line">echo &quot;HDFS UI: http://localhost:9870&quot;</span><br><span class="line">echo &quot;YARN UI: http://localhost:8088&quot;</span><br><span class="line">echo &quot;Zeppelin UI: http://localhost:8089&quot;</span><br></pre></td></tr></table></figure>

<p><code>custom-entrypoint.sh</code></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line"># 自定义entrypoint脚本 - 优雅的启动方案</span><br><span class="line"># 不修改原始entrypoint.sh，完全自定义启动流程</span><br><span class="line"></span><br><span class="line">echo &quot;=== Starting Custom Entrypoint ===&quot;</span><br><span class="line"></span><br><span class="line"># 启动SSH服务</span><br><span class="line">echo &quot;Starting SSH service...&quot;</span><br><span class="line">service ssh start</span><br><span class="line"></span><br><span class="line"># 启动Hadoop服务</span><br><span class="line">echo &quot;Starting Hadoop services...&quot;</span><br><span class="line"></span><br><span class="line"># 设置Hadoop环境变量</span><br><span class="line">export HADOOP_NICENESS=0</span><br><span class="line">export HADOOP_SECURE_DN_USER=&quot;&quot;</span><br><span class="line"></span><br><span class="line"># 启动HDFS服务（如果未运行）</span><br><span class="line">if ! pgrep -f &quot;org.apache.hadoop.hdfs.server.namenode.NameNode&quot; &gt; /dev/null; then</span><br><span class="line">    echo &quot;Starting HDFS services...&quot;</span><br><span class="line">    $HADOOP_HOME/sbin/start-dfs.sh || true</span><br><span class="line">else</span><br><span class="line">    echo &quot;HDFS services already running&quot;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># 启动YARN服务（如果未运行）</span><br><span class="line">if ! pgrep -f &quot;org.apache.hadoop.yarn.server.resourcemanager.ResourceManager&quot; &gt; /dev/null; then</span><br><span class="line">    echo &quot;Starting YARN services...&quot;</span><br><span class="line">    $HADOOP_HOME/sbin/start-yarn.sh || true</span><br><span class="line">else</span><br><span class="line">    echo &quot;YARN services already running&quot;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"># 为Zeppelin用户创建HDFS目录并授权</span><br><span class="line">echo &quot;Creating HDFS directories for Zeppelin user...&quot;</span><br><span class="line"># 等待HDFS完全启动</span><br><span class="line">sleep 5</span><br><span class="line"># 创建zeppelin用户目录</span><br><span class="line">hdfs dfs -mkdir -p /user/zeppelin || true</span><br><span class="line"># 更改目录所有权</span><br><span class="line">hdfs dfs -chown zeppelin:zeppelin /user/zeppelin || true</span><br><span class="line"># 设置目录权限</span><br><span class="line">hdfs dfs -chmod 777 /user/zeppelin || true</span><br><span class="line"></span><br><span class="line">echo &quot;HDFS directories for Zeppelin user created and authorized.&quot;</span><br><span class="line"></span><br><span class="line">echo &quot;=== All services started successfully! ===&quot;</span><br><span class="line">echo &quot;=== Calling original Spark entrypoint ===&quot;</span><br><span class="line"></span><br><span class="line"># 调用原始Spark entrypoint，传递所有参数</span><br><span class="line">exec /opt/bitnami/scripts/spark/entrypoint.sh &quot;$@&quot;</span><br></pre></td></tr></table></figure>

</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">XR</div><div class="post-copyright__author_desc">一片叶、一朵云</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://example.com/2025/09/11/Spark%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E5%8F%8AZeppelin%E7%9A%84%E9%95%9C%E5%83%8F%E5%85%B7%E4%BD%93%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('http://example.com/2025/09/11/Spark%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E5%8F%8AZeppelin%E7%9A%84%E9%95%9C%E5%83%8F%E5%85%B7%E4%BD%93%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B/')">Spark、Hadoop集群及Zeppelin的镜像具体构建过程</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://example.com/2025/09/11/Spark%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E5%8F%8AZeppelin%E7%9A%84%E9%95%9C%E5%83%8F%E5%85%B7%E4%BD%93%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=Spark、Hadoop集群及Zeppelin的镜像具体构建过程&amp;url=http://example.com/2025/09/11/Spark%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E5%8F%8AZeppelin%E7%9A%84%E9%95%9C%E5%83%8F%E5%85%B7%E4%BD%93%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B/&amp;pic=https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250804100847374.png" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">凌霄的博客</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"><a class="post-meta__box__tags" href="/tags/Hadoop/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Hadoop<span class="tagsPageCount">4</span></a><a class="post-meta__box__tags" href="/tags/Spark/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Spark<span class="tagsPageCount">11</span></a><a class="post-meta__box__tags" href="/tags/Zeppelin/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Zeppelin<span class="tagsPageCount">4</span></a><a class="post-meta__box__tags" href="/tags/Docker/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>Docker<span class="tagsPageCount">2</span></a><a class="post-meta__box__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><span class="tags-punctuation"> <i class="anzhiyufont anzhiyu-icon-tag"></i></span>大数据<span class="tagsPageCount">7</span></a></div></div></div><div class="post_share"><div class="social-share" data-image="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/image-20250929143618895.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/09/07/Zeppelin%20%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250804092337513.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Zeppelin 使用体验</div></div></a></div><div class="next-post pull-right"><a href="/2025/09/13/%E4%B8%80%E7%AB%99%E5%BC%8F%E6%90%AD%E5%BB%BASpark-Hadoop%E9%9B%86%E7%BE%A4%E5%8F%8AZeppelin/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250804092159955.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">一站式搭建Spark-Hadoop集群及Zeppelin</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="anzhiyufont anzhiyu-icon-thumbs-up fa-fw" style="font-size: 1.5rem; margin-right: 4px"></i><span>喜欢这篇文章的人也看了</span></div><div class="relatedPosts-list"><div><a href="/2025/09/13/%E4%B8%80%E7%AB%99%E5%BC%8F%E6%90%AD%E5%BB%BASpark-Hadoop%E9%9B%86%E7%BE%A4%E5%8F%8AZeppelin/" title="一站式搭建Spark-Hadoop集群及Zeppelin"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250804092159955.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-13</div><div class="title">一站式搭建Spark-Hadoop集群及Zeppelin</div></div></a></div><div><a href="/2025/06/18/hadoop-ecosystem-explained/" title="Hadoop生态：YARN、HDFS、Hive、Spark、HBase是如何协同工作的？"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250619194740317.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-06-18</div><div class="title">Hadoop生态：YARN、HDFS、Hive、Spark、HBase是如何协同工作的？</div></div></a></div><div><a href="/2025/09/07/Zeppelin%20%E4%BD%BF%E7%94%A8%E4%BD%93%E9%AA%8C/" title="Zeppelin 使用体验"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250804092337513.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-07</div><div class="title">Zeppelin 使用体验</div></div></a></div><div><a href="/2025/09/17/Zeppelin%20%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E6%9E%84%E5%BB%BA%E4%B8%8E%E6%89%93%E5%8C%85%E9%83%A8%E7%BD%B2/" title="Zeppelin 源码编译构建与打包部署"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250916100006470.png" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-09-17</div><div class="title">Zeppelin 源码编译构建与打包部署</div></div></a></div><div><a href="/2025/07/08/Spark%E4%B8%93%E6%A0%8F%E6%95%B4%E4%BD%93%E6%96%87%E7%AB%A0%E5%A4%A7%E7%BA%B2/" title="Spark专栏整体文章大纲"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-07-08</div><div class="title">Spark专栏整体文章大纲</div></div></a></div><div><a href="/2025/01/15/Spark%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84%E4%B8%8E%E7%BB%84%E4%BB%B6%E8%AF%A6%E8%A7%A3/" title="Spark集群架构与组件详解：从Driver到Executor的深度解析"><img class="cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/" alt="cover"><div class="content is-center"><div class="date"><i class="anzhiyufont anzhiyu-icon-calendar-days fa-fw"></i> 2025-01-15</div><div class="title">Spark集群架构与组件详解：从Driver到Executor的深度解析</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/24/64e6ce9c507bb.png" alt="status"/></div></div><div class="author-info__description"></div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">XR</h1><div class="author-info__desc">一片叶、一朵云</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/kongxiaoran" target="_blank" title="Github"></a></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Spark%E3%80%81Hadoop%E9%9B%86%E7%BE%A4%E5%8F%8AZeppelin%E7%9A%84%E9%95%9C%E5%83%8F%E5%85%B7%E4%BD%93%E6%9E%84%E5%BB%BA%E8%BF%87%E7%A8%8B"><span class="toc-number">1.</span> <span class="toc-text">Spark、Hadoop集群及Zeppelin的镜像具体构建过程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E6%A6%82%E8%BF%B0"><span class="toc-number">1.1.</span> <span class="toc-text">1. 概述</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E6%A0%B8%E5%BF%83%E7%BB%84%E4%BB%B6"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1. 核心组件</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-%E6%9E%B6%E6%9E%84%E5%9B%BE"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2. 架构图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E7%8E%AF%E5%A2%83%E5%87%86%E5%A4%87"><span class="toc-number">1.2.</span> <span class="toc-text">2. 环境准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84"><span class="toc-number">1.3.</span> <span class="toc-text">3. 目录结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%9E%84%E5%BB%BADocker%E9%95%9C%E5%83%8F"><span class="toc-number">1.4.</span> <span class="toc-text">4. 构建Docker镜像</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-Dockerfile%E5%88%B6%E4%BD%9C"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1. Dockerfile制作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E6%9E%84%E5%BB%BA%E5%91%BD%E4%BB%A4"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2. 构建命令</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E9%85%8D%E7%BD%AE"><span class="toc-number">1.5.</span> <span class="toc-text">5. 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-Hadoop%E9%85%8D%E7%BD%AE"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1. Hadoop配置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-Docker-Compose%E9%85%8D%E7%BD%AE"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2. Docker Compose配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-1-%E5%85%B1%E4%BA%AB%E5%8D%B7"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">5.2.1. 共享卷</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-2-%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F"><span class="toc-number">1.5.2.2.</span> <span class="toc-text">5.2.2. 环境变量</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E9%83%A8%E7%BD%B2"><span class="toc-number">1.6.</span> <span class="toc-text">6. 部署</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E4%BD%BF%E7%94%A8"><span class="toc-number">1.7.</span> <span class="toc-text">7. 使用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E8%AE%BF%E9%97%AE%E6%9C%8D%E5%8A%A1"><span class="toc-number">1.7.1.</span> <span class="toc-text">7.1. 访问服务</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E5%9C%A8Zeppelin%E4%B8%AD%E4%BD%BF%E7%94%A8Spark"><span class="toc-number">1.7.2.</span> <span class="toc-text">7.2. 在Zeppelin中使用Spark</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-%E7%A4%BA%E4%BE%8B%EF%BC%9AWord-Count"><span class="toc-number">1.7.3.</span> <span class="toc-text">7.3. 示例：Word Count</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%99%84%E5%BD%95%EF%BC%9A%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E5%86%85%E5%AE%B9"><span class="toc-number">1.8.</span> <span class="toc-text">附录：配置文件内容</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#A-1-Hadoop-%E9%85%8D%E7%BD%AE"><span class="toc-number">1.8.1.</span> <span class="toc-text">A.1 Hadoop 配置</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#core-site-xml"><span class="toc-number">1.8.1.1.</span> <span class="toc-text">core-site.xml</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hadoop-env-sh"><span class="toc-number">1.8.1.2.</span> <span class="toc-text">hadoop-env.sh</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#hdfs-site-xml"><span class="toc-number">1.8.1.3.</span> <span class="toc-text">hdfs-site.xml</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#mapred-site-xml"><span class="toc-number">1.8.1.4.</span> <span class="toc-text">mapred-site.xml</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#yarn-site-xml"><span class="toc-number">1.8.1.5.</span> <span class="toc-text">yarn-site.xml</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#workers"><span class="toc-number">1.8.1.6.</span> <span class="toc-text">workers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ssh-config"><span class="toc-number">1.8.1.7.</span> <span class="toc-text">ssh_config</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#start-cluster-sh"><span class="toc-number">1.8.1.8.</span> <span class="toc-text">start-cluster.sh</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/09/29/SecretPad%20All%20in%20One%20%E4%B8%AD%E5%BF%83%E5%8C%96%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/" title="SecretPad All-in-One中心化部署模式安装与测试"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/image-20250929143618895.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="SecretPad All-in-One中心化部署模式安装与测试"/></a><div class="content"><a class="title" href="/2025/09/29/SecretPad%20All%20in%20One%20%E4%B8%AD%E5%BF%83%E5%8C%96%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/" title="SecretPad All-in-One中心化部署模式安装与测试">SecretPad All-in-One中心化部署模式安装与测试</a><time datetime="2025-09-29T10:00:00.000Z" title="发表于 2025-09-29 18:00:00">2025-09-29</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/26/%E5%8D%95%E6%9C%BA%E6%90%AD%E5%BB%BA%20kuscia%E5%A4%9A%E6%9C%BA%E9%83%A8%E7%BD%B2%E7%82%B9%E5%AF%B9%E7%82%B9%E9%9B%86%E7%BE%A4/" title="单机模拟Kuscia多机部署点对点集群实践指南"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250804092337513.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="单机模拟Kuscia多机部署点对点集群实践指南"/></a><div class="content"><a class="title" href="/2025/09/26/%E5%8D%95%E6%9C%BA%E6%90%AD%E5%BB%BA%20kuscia%E5%A4%9A%E6%9C%BA%E9%83%A8%E7%BD%B2%E7%82%B9%E5%AF%B9%E7%82%B9%E9%9B%86%E7%BE%A4/" title="单机模拟Kuscia多机部署点对点集群实践指南">单机模拟Kuscia多机部署点对点集群实践指南</a><time datetime="2025-09-26T11:00:00.000Z" title="发表于 2025-09-26 19:00:00">2025-09-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/24/%E9%9A%90%E8%AF%ADSecretflow%E2%80%94%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E4%BD%93%E9%AA%8C/" title="隐语Secretflow—源码编译安装体验"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/image-20250924140004853.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="隐语Secretflow—源码编译安装体验"/></a><div class="content"><a class="title" href="/2025/09/24/%E9%9A%90%E8%AF%ADSecretflow%E2%80%94%E6%BA%90%E7%A0%81%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%E4%BD%93%E9%AA%8C/" title="隐语Secretflow—源码编译安装体验">隐语Secretflow—源码编译安装体验</a><time datetime="2025-09-24T06:00:00.000Z" title="发表于 2025-09-24 14:00:00">2025-09-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/22/DNS%E6%8A%95%E6%AF%92%E5%8E%9F%E7%90%86%E4%B8%8E%E8%BF%87%E7%A8%8B/" title="DNS投毒原理与过程"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250716144607754.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DNS投毒原理与过程"/></a><div class="content"><a class="title" href="/2025/09/22/DNS%E6%8A%95%E6%AF%92%E5%8E%9F%E7%90%86%E4%B8%8E%E8%BF%87%E7%A8%8B/" title="DNS投毒原理与过程">DNS投毒原理与过程</a><time datetime="2025-09-22T13:30:00.000Z" title="发表于 2025-09-22 21:30:00">2025-09-22</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/09/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%B2%E7%83%A7/" title="计算机网络核心概念串烧"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/09c33b5dbe1bd3fec63ad2e4128b55b6.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="计算机网络核心概念串烧"/></a><div class="content"><a class="title" href="/2025/09/22/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5%E4%B8%B2%E7%83%A7/" title="计算机网络核心概念串烧">计算机网络核心概念串烧</a><time datetime="2025-09-22T02:00:00.000Z" title="发表于 2025-09-22 10:00:00">2025-09-22</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2024 - 2025 By <a class="footer-bar-link" href="/" title="XR" target="_blank">XR</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">69</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">99</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">7</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://image.anheyu.com/favicon.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span><div class="card-tags"><div class="item-headline"></div><div class="card-tag-cloud"><a href="/tags/Argon2/" style="font-size: 0.88rem;">Argon2<sup>1</sup></a><a href="/tags/DNS/" style="font-size: 0.88rem;">DNS<sup>4</sup></a><a href="/tags/GRUB/" style="font-size: 0.88rem;">GRUB<sup>1</sup></a><a href="/tags/HDFS/" style="font-size: 0.88rem;">HDFS<sup>4</sup></a><a href="/tags/HTTP/" style="font-size: 0.88rem;">HTTP<sup>1</sup></a><a href="/tags/Hadoop/" style="font-size: 0.88rem;">Hadoop<sup>4</sup></a><a href="/tags/HyperEnclave/" style="font-size: 0.88rem;">HyperEnclave<sup>5</sup></a><a href="/tags/Hypervisor/" style="font-size: 0.88rem;">Hypervisor<sup>2</sup></a><a href="/tags/KVM/" style="font-size: 0.88rem;">KVM<sup>2</sup></a><a href="/tags/Kerberos/" style="font-size: 0.88rem;">Kerberos<sup>1</sup></a><a href="/tags/Kubernetes/" style="font-size: 0.88rem;">Kubernetes<sup>1</sup></a><a href="/tags/Linux/" style="font-size: 0.88rem;">Linux<sup>7</sup></a><a href="/tags/Linux%E8%BF%90%E7%BB%B4/" style="font-size: 0.88rem;">Linux运维<sup>1</sup></a><a href="/tags/TEE/" style="font-size: 0.88rem;">TEE<sup>10</sup></a><a href="/tags/TPM/" style="font-size: 0.88rem;">TPM<sup>1</sup></a><a href="/tags/UEFI/" style="font-size: 0.88rem;">UEFI<sup>1</sup></a><a href="/tags/VMware/" style="font-size: 0.88rem;">VMware<sup>1</sup></a><a href="/tags/Xen/" style="font-size: 0.88rem;">Xen<sup>1</sup></a><a href="/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/" style="font-size: 0.88rem;">云原生<sup>1</sup></a><a href="/tags/%E4%BA%91%E8%AE%A1%E7%AE%97/" style="font-size: 0.88rem;">云计算<sup>1</sup></a><a href="/tags/%E4%BB%A3%E7%90%86/" style="font-size: 0.88rem;">代理<sup>1</sup></a><a href="/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/" style="font-size: 0.88rem;">分布式存储<sup>2</sup></a><a href="/tags/%E5%8F%AF%E4%BF%A1%E5%90%AF%E5%8A%A8/" style="font-size: 0.88rem;">可信启动<sup>1</sup></a><a href="/tags/%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E9%99%90%E5%88%B6/" style="font-size: 0.88rem;">地理位置限制<sup>1</sup></a><a href="/tags/%E5%AD%A6%E4%B9%A0%E8%B7%AF%E7%BA%BF/" style="font-size: 0.88rem;">学习路线<sup>1</sup></a><a href="/tags/%E5%AE%89%E5%85%A8%E5%90%AF%E5%8A%A8/" style="font-size: 0.88rem;">安全启动<sup>1</sup></a><a href="/tags/%E5%AF%86%E7%A0%81%E5%93%88%E5%B8%8C/" style="font-size: 0.88rem;">密码哈希<sup>1</sup></a><a href="/tags/%E5%AF%86%E7%A0%81%E5%AD%A6/" style="font-size: 0.88rem;">密码学<sup>5</sup></a><a href="/tags/%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5/" style="font-size: 0.88rem;">故障排查<sup>1</sup></a><a href="/tags/%E6%97%A5%E5%BF%97/" style="font-size: 0.88rem;">日志<sup>1</sup></a><a href="/tags/%E6%9C%BA%E5%AF%86%E8%AE%A1%E7%AE%97/" style="font-size: 0.88rem;">机密计算<sup>2</sup></a><a href="/tags/%E6%B5%81%E5%AA%92%E4%BD%93%E8%A7%A3%E9%94%81/" style="font-size: 0.88rem;">流媒体解锁<sup>1</sup></a><a href="/tags/%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4/" style="font-size: 0.88rem;">磁盘空间<sup>1</sup></a><a href="/tags/%E7%B3%BB%E7%BB%9F%E6%97%A5%E5%BF%97/" style="font-size: 0.88rem;">系统日志<sup>1</sup></a><a href="/tags/%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93/" style="font-size: 0.88rem;">缓存污染<sup>1</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C%E5%88%86%E6%9E%90/" style="font-size: 0.88rem;">网络分析<sup>1</sup></a><a href="/tags/%E7%BD%91%E7%BB%9C%E5%AE%89%E5%85%A8/" style="font-size: 0.88rem;">网络安全<sup>1</sup></a><a href="/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/" style="font-size: 0.88rem;">虚拟化<sup>5</sup></a><a href="/tags/%E8%AE%BA%E6%96%87%E7%BF%BB%E8%AF%91/" style="font-size: 0.88rem;">论文翻译<sup>1</sup></a><a href="/tags/%E9%9A%90%E7%A7%81%E8%AE%A1%E7%AE%97/" style="font-size: 0.88rem;">隐私计算<sup>6</sup></a></div></div><hr/></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("12/26/2024 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2024 By 安知鱼 V1.6.14",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 XR 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdn.cbd.int/mermaid@10.2.4/dist/mermaid.min.js').then(runMermaid)
  }

  anzhiyu.addGlobalFn('themeChange', runMermaid, 'mermaid')

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'cbSQtAqs68yENzUQ5wpQK826-MdYXbMMI',
      appKey: 'MR93sqmbPdh7Zm1bZzjXNvlm',
      avatar: 'mp',
      serverURLs: 'https://cbsqtaqs.api.lncldglobal.com',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.cbd.int/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"></div><script src="https://cdn.cbd.int/blueimp-md5@2.19.0/js/md5.min.js"></script><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getIcon = (icon, mail) => {
    if (icon) return icon
    let defaultIcon = '?d=mp'
    let iconUrl = `https://gravatar.loli.net/avatar/${md5(mail.toLowerCase()) + defaultIcon}`
    return iconUrl
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const getComment = () => {
    const serverURL = 'https://cbsqtaqs.api.lncldglobal.com'

    var settings = {
      "method": "GET",
      "headers": {
        "X-LC-Id": 'cbSQtAqs68yENzUQ5wpQK826-MdYXbMMI',
        "X-LC-Key": 'MR93sqmbPdh7Zm1bZzjXNvlm',
        "Content-Type": "application/json"
      },
    }

    fetch(`${serverURL}/1.1/classes/Comment?limit=6&order=-createdAt`,settings)
      .then(response => response.json())
      .then(data => {
        const valineArray = data.results.map(function (e) {
          return {
            'avatar': getIcon(e.QQAvatar, e.mail),
            'content': changeContent(e.comment),
            'nick': e.nick,
            'url': e.url + '#' + e.objectId,
            'date': e.updatedAt,
          }
        })
        saveToLocal.set('valine-newest-comments', JSON.stringify(valineArray), 10/(60*24))
        generateHtml(valineArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      }) 
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('valine-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>