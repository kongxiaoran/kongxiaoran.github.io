<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no"><title>Redis学习笔记 | 凌霄博客</title><meta name="author" content="XR"><meta name="copyright" content="XR"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#f7f9fe"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-touch-fullscreen" content="yes"><meta name="apple-mobile-web-app-title" content="Redis学习笔记"><meta name="application-name" content="Redis学习笔记"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="#f7f9fe"><meta property="og:type" content="article"><meta property="og:title" content="Redis学习笔记"><meta property="og:url" content="http://example.com/2025/06/07/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html"><meta property="og:site_name" content="凌霄博客"><meta property="og:description" content="Redis学习笔记"><meta property="og:locale" content="zh-CN"><meta property="og:image" content="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250607204045262.png"><meta property="article:author" content="XR"><meta property="article:tag"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250607204045262.png"><meta name="description" content="Redis学习笔记"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="http://example.com/2025/06/07/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><link rel="preconnect" href="//cdn.cbd.int"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="xxx"/><meta name="baidu-site-verification" content="code-xxx"/><meta name="msvalidate.01" content="xxx"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  linkPageTop: undefined,
  peoplecanvas: undefined,
  postHeadAiDescription: {"enable":true,"gptName":"AnZhiYu","mode":"local","switchBtn":false,"btnLink":"https://afdian.net/item/886a79d4db6711eda42a52540025c377","randomNum":3,"basicWordCount":1000,"key":"xxxx","Referer":"https://xx.xx/"},
  diytitle: {"enable":true,"leaveTitle":"w(ﾟДﾟ)w 不要走！再看看嘛！","backTitle":"♪(^∇^*)欢迎肥来！"},
  LA51: undefined,
  greetingBox: undefined,
  twikooEnvId: '',
  commentBarrageConfig:undefined,
  music_page_default: "nav_music",
  root: '/',
  preloader: {"source":3},
  friends_vue_info: undefined,
  navMusic: true,
  mainTone: undefined,
  authorStatus: {"skills":["🤖️ 数码科技爱好者","🔍 分享与热心帮助","🧱 团队小组发动机"]},
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简","rightMenuMsgToTraditionalChinese":"转为繁体","rightMenuMsgToSimplifiedChinese":"转为简体"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":330},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    simplehomepage: true,
    post: false
  },
  runtime: '天',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"copy":true,"copyrightEbable":false,"limitCount":50,"languages":{"author":"作者: XR","link":"链接: ","source":"来源: 凌霄博客","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","copySuccess":"复制成功，复制和转载请标注本文地址"}},
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#425AEF","bgDark":"#1f1f1f","position":"top-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.min.js',
      css: 'https://cdn.cbd.int/flickr-justified-gallery@2.1.2/dist/fjGallery.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  shortcutKey: undefined,
  autoDarkmode: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  configTitle: '凌霄博客',
  title: 'Redis学习笔记',
  postAI: '',
  pageFillDescription: 'Redis学习笔记, 一、Redis 的安装, 1.1 Redis 安装（window）, 1.2 Redis 安装（docker）, 1.3 Redis 配置, 二、Redis 的基础篇, 2.1 五种基本数据结构, 2.1.1 String, 2.1.2 List, 2.1.3 Hash, 2.1.4 Set, 2.1.5 SortSet, 2.2 三种特殊数据结构, 2.3 Redis命令, 2.1.1 通用命令, 2.1.2 String类型, 2.1.3 Key的层级格式, 2.1.4 Hash类型, 2.1.4 List类型, 2.1.5 Set类型, 2.1.6 SortedSet类型, 2.2 Redis客户端, 2.2.1 Jedis 客户端, 2.2.2 SpringDataRedis, 2.3 SpringDataRedis 客户端使用, 2.3.1 SpringDataRedis 的默认序列化, 2.3.2 SpringDataRedis 提供的序列化器, 2.3.3 自定义序列化器, 2.3.4 使用自定义序列化器存储对象, 2.3.5 使用StringRedisTemplate存储JSON对象, 2.3.6 RedisTemplate 操作 Hash 类型, 三、Redis 实战, 3.1 Redis与MySQL双写一致性如何保证？, 3.1.1 一致性, 3.1.2 三种经典的缓存模式, 3.1.3 操作缓存的时候删除缓存呢还是更新缓存？, 3.1.3 双写的情况下先操作数据库还是先操作缓存？, 3.1.4 缓存延时双删, 3.1.5 删除缓存重试机制, 队列+重试机制, 基于订阅binlog的同步机制, 3.2 缓存雪崩、穿透、击穿、污染, 3.2.1 缓存雪崩, 3.2.2 缓存穿透, 3.2.3 缓存击穿, 3.2.4 缓存污染, 缓存淘汰策略, 3.3 Ix2FO多路复用, 3.3.1 有哪几种Ix2FO模型, 3.3.2 Reactor设计模式, 3.3.3 Ix2FO多路复用模块, 3.4 脑裂问题, 3.4.1 哨兵模式下的脑裂, 3.4.2 cluster 模式下的脑裂, 手动解决问题, 自动解决问题, 如何避免脑裂, 3.4 搭建哨兵集群, 四、Redis应用, 4.1 分布式锁, 4.2 延时队列, 4.2.1 异步消息队列, 4.2.2 延迟队列的实现, 4.3 位图, 4.3.1 基本使用, 4.3.2 统计和查找, 4.3.3 魔术指令 bitfield, 4.4 HyperLogLog, 4.4.1 使用方法, 4.4.2 数学原理, 4.4.3 redis实现, 4.5 布隆过滤器, 4.5.1 基本使用, 4.5.2 原理, 4.5.3 空间占用估计, 4.6 简单限流, 4.7 漏斗限流, 4.8 近水楼台-GeoHash, 4.8.1 用数据库来算附近的人, 4.8.2 GeoHash算法, 4.8.3 基本使用, 4.9 大海捞针 scan, 4.9.1 scan 基础使用, 4.9.2 字典的结构, 4.9.3 scan 遍历顺序, 4.9.4 字典扩容, 4.9.5 scan 考虑 渐进式 rehash, 4.9.6 更多 scan 指令, 4.9.7 大Key的扫描, 五、Redis 原理, 5.1 线程 IO 模型, 5.2 通信协议, 5.2.1 RESP （Redis Serialization Protocol）, 5.2.2 小结, 5.3 持久化, 5.3.1 快照, 5.3.2 AOF的写入, 命令传播, 缓存追加, 文件写入和保存, AOF 保存模式, 5.3.3 AOF 文件的读取和数据还原, 5.3.4 AOF 重写, AOF 重写的实现, AOF 后台重写, 5.3.5 混合持久化, 5.4 管道, 管道压力测试, 管道本质, 5.5 事务, 5.5.1 事务流程, 开始事务, 命令入队, 执行事务, 5.5.2 事务里的命令, 5.5.3 DISCARD 、 MULTI 和 WATCH 命令, 5.5.4 带 WATCH 的事务, WATCH 命令的实现, WATCH 的触发, 5.5.6 事务的 ACID 性质, 原子性（Atomicity）, 一致性（Consistency）, 隔离性（Isolation）, 持久性（Durability）, 5.5.7 小结, 5.6 订阅与发布, 5.6.1 频道的订阅与信息发送, 订阅频道, 发送信息到频道, 退订频道, 5.6.2 模式的订阅与信息发送, 订阅模式, 发送信息到模式, 退订模式, 5.6.3 小结, 5.7 Redis集群模式—主从复制, 5.7.1 主从复制概述, 5.7.2 全量复制, 5.7.3 增量复制, 5.7.4 更多理解, 1.当主服务器不进行持久化时 复制的安全性, 2.为什么主从全量复制使用 RDB 而不使用 AOF？, 3.为什么有无磁盘复制模式？, 4.为什么还有 从库的从库的设计？, 5.读写分离及其中的问题, 5.8 Redis集群模式— 哨兵机制（Redis Sentinel）, 5.8.1 哨兵集群的搭建, 5.8.2 哨兵监控 Redis 库, 5.8.3 主库下线的判定, 5.8.4 哨兵集群的选举, 5.8.5 新主库的选出、故障转移, 5.9 Redis集群模式-Redis Cluster（高可用集群）, 5.9.1 哈希槽, 5.9.2 Key Hash Tags, 5.9.3 请求重定向, MOVED 重定向, ASK 重定向, 两者的区别, 5.9.4 故障转移, 5.9.5 脑裂问题, 5.9.6 状态检测及维护, Gossip协议, Gossip协议的使用, 基于Gossip 协议的故障检测, 5.9.7 通讯状态和维护, 5.9.8 扩容、缩容, 5.9.9 Write Safety 分析, 5.9.10 availability 分析, replicas migration 功能, 六、Redisson, 6.1 分布式锁, 6.1.1 常见redis 分布式锁, 6.1.2 Redisson 的解决方案, 七、Redis应用问题, 7.1 Redis与MySQL双写一致性如何保证？, , 7.2 Redis 的大key如何处理？, 7.3 如何选择持久化策略？, 八、Redis 涉及的算法, 1.一致性Hash, 1.1 问题的由来, 1.2 直接使用哈希算法？, 1.3 使用一致性哈希算法有什么问题?, 1.3 通过虚拟节点提高均衡度, 1.4 总结学习笔记诞生于年作为一个基于内存的键值型数据库其有如下特点键值型支持多种不同数据结构单线程每个命令具有原子性不存在很多并发带来的问题但是此单线程只是指代命令是但线程执行的其他模块还有各自的线程版本中引入了多线程但指代的是多线程如网络数据的读写和协议解析时多线程低延迟速度快基于内存多路复用良好的编码支持数据持久化支持主从集群分片集群支持多语言客户端一的安装安装下方提供各个版本的下载页面我这里下载的是版本将下载包解压到本地目录然后在目录下进行输入不同的命令进行不同的安装方式临时服务安装如果你仅仅是用作学习使用可以选择此安装方式在目录下使用执行以下命令该命令会创建临时服务生成的信息表明了在本机的端口提供服务该种方式不能关闭此窗口如果关闭则会停止服务保持服务窗口开启状态双击目录下的即可使用命令行操控比如这里使用命令存储了一个键值对然后通过将键对应的值取出默认服务安装这种方式不用像临时安装方式一样每次去打开临时服务而且像正常服务一样开机自启进入目录下通过输入通过命令行可以发现我们已经将作为服务安装好了但是你可能不能在的服务列表中找到服务必须通过命令行启动暂停和卸载启动服务暂停服务卸载服务自定义服务安装自定义服务安装就是将服务重命名进入安装包下输入这里起的名字是与默认安装一样不同的是在启动暂停卸载服务时需要加上自定义的服务名主从服务安装即像一般的数据库的主从库一样也可以配置主从库配置的方法很简单就是通过自定义服务器安装方式安装两个服务修改两个服务里文件主服务器保持其从服务器修改修改配置文件后依次启动服务然后可以在双击主服务文件夹下的去执行一个添加键值操作双击执行从服务器文件夹下的去取出键对应的值你就发现可以取到在上直接删除服务的方法使用管理员权限打开然后输入服务名安装下拉最新的镜像并检查是否下拉成功运行容器并映射到宿主机端口查看是否运行成功查看容器运行信息通过连接使用服务配置常见配置监听的地址默认是这使得只能本地访问如果修改成则可以在任意地址访问守护进程修改为之后即可后台运行密码设置后访问必须输入密码监听的端口默认就是工作目录默认是当前目录也就是运行时的命令日志持久化等文件都会保存在这个目录数据库数量设置为代表只使用个库默认有个库编号设置能够使用的最大内存日志文件默认为空不记录日志可以指定日志文件名启动时指定配置文件二的基础篇五种基本数据结构共有种基本数据结构字符串列表集合散列有序集合这种数据结构是直接提供给用户使用的是数据的保存形式其底层实现主要依赖这种数据结构简单动态字符串双向链表哈希表跳跃表整数集合压缩列表快速列表基本数据结构的底层数据结构实现如下之前底层实现是或者之后引入了和的结合的底层实现变为你可以在官网上找到数据结构非常详细的介绍未来随着新版本的发布可能会有新的数据结构出现通过查阅官网对应的介绍你总能获取到最靠谱的信息是中最简单同时也是最常用的一个数据结构是一种二进制安全的数据结构可以用来存储任何类型的数据比如字符串整数浮点数图片图片的编码或者解码或者图片的路径序列化后的对象虽然是用语言写的但是并没有使用的字符串表示而是自己构建了一种简单动态字符串相比于的原生字符串的不光可以保存文本数据还可以保存二进制数据并且获取字符串长度复杂度为字符串为除此之外的是安全的不会造成缓冲区溢出许多高级编程语言都内置了链表的实现比如中的但是语言并没有实现链表所以实现了自己的链表数据结构的的实现为一个双向链表即可以支持反向查找和遍历更方便操作不过带来了部分额外的内存开销中的是一个类型的键值对的映射表特别适合用于存储对象后续操作的时候你可以直接修改这个对象中的某些字段的值类似于前的内部实现也差不多数组链表不过的做了更多优化中的类型是一种无序集合集合中的元素没有先后顺序但都唯一有点类似于中的当你需要存储一个列表数据又不希望出现重复数据时是一个很好的选择并且提供了判断某个元素是否在一个集合内的重要接口这个也是所不能提供的你可以基于轻易实现交集并集差集的操作比如你可以将一个用户所有的关注人存在一个集合中将其所有粉丝存在一个集合这样的话可以非常方便的实现如共同关注共同粉丝共同喜好等功能这个过程也就是求交集的过程类似于但和相比增加了一个权重参数使得集合中的元素能够按进行有序排列还可以通过的范围来获取元素的列表有点像是中和的结合体三种特殊数据结构命令通用命令通用指令是不分数据类型的都可以使用的指令常见的有查看符合模板的所有不建议在生产环境设备上使用删除一个指定的判断是否存在给一个设置有效期有效期到期时该自动删除可通过查看的剩余有效期通过可以查看一个命令的具体用法使用打开的命令行实操类型类型也就是字符串类型是中最简单的存储类型其是字符串不过根据字符串的格式不同又可以分为类普通字符串整数类型可以做自增自减操作浮点类型可以做自增自减操作但是必须指定增减的值不管何种格式底层都是字节数组形式存储只不过是编码方式不同的字符串是动态字符串是可以修改的字符串内部结构实现类似于的预分配冗余空间的方式来减少内存的频繁分配字符串长度小于扩容都是加倍现有空间如果长度大于每次扩容增加字符串类型的最大空间不能超过的常见命令有添加或者修改已经存在的一个类型的键值对根据获取类型的批量添加多个类型的键值对根据多个获取多个类型的让一个整型的自增让一个整型的自增并指定步长例如即可让的值自增添加一个类型的键值对前提是这个不存在否则不执行添加一个类型的键值对并指定有效期的层级格式没有类似中的的概念我们该如何区分不同类型的呢一般采用将名称进行分层设计例如学生的以开头的允许有多个单词组成层级结构多个单词之间用隔开格式如下项目名业务名类型当然这种格式是可以自己定义的有些公司是使用线间隔如果存储对象是对象则可将对象转化为字符串当作存储下来类型类型也叫散列其中是一个无序字典类型于中的结构结构是将对象序列化为字符串后存储当需要修改对象某个字段时很不方便结构可以将对象中的每个字段独立存储可以针对单个字段类型常见命令有添加或者修改类型的的值获取一个类型的的值批量添加多个类型的的值男为的字段添加属性值分别为男获取一个类型的中所有的和获取一个类型的中所有的获取一个类型的中所有的让一个类型的字段值自增并指定步长添加一个类型的的值前提时这个不存在否则不执行底层原理的在字典很大时是个耗时操作需要一次性全部为了高性能不能堵塞服务就采用了渐进式策略渐进式在的同时保留新旧两个结构查询时会同时查询两个结构然后再后续的定时任务中以及的子指令中循序渐进地将旧的内容一点点迁移到新的结构中类型中的类型与中的类似可以看做是一个双向链表结构既可以支持正向检索也支持反向检索特点也和类似有序元素可以重复插入和删除快查询速度一般的常见命令像列表左侧插入一个或多个元素移除并返回列表左侧的第一个元素没有则返回向列表右侧插入一个或多个元素移除并返回列表右侧第一个元素返回一段角标范围内的所有元素和与类似只不过在没有元素时等待指定时间而不是直接返回相当于链表的方法它需要对链表进行遍历其性能随着参数增大而变差使用定义了一个区间保留着区间内的值区间外统统去除这样可以实现一个定长的链表可以为负数表示倒数第一个元素表示倒数第二个元素应用场景常用来做异步队列使用将需要延后处理的任务结构体序列化成字符串塞进的列表另一个线程从这个列表中轮询数据进行处理通过控制右边进左边出可以实现队列通过控制右边进右边出可以实现栈原理列表底层存储不是一个简单的而是成为快速列表的一个结构首先在列表元素较少的情况下会使用一块连续的内存存储这个结构是压缩列表它将所有的元素紧紧挨在一起存储分配的是一块连续的内存当数据量比较多时才会改成因为普通的链表需要的附件指针空间太大会比较浪费空间而且加重内存的碎片化所以将多个使用双向指针串起来使用这样既满足了快速的插入删除性能有不会出现太大的空间冗余类型的结构与中的类似可以看做是一个为的因为也是一个表因此具备与类似的特征无序元素不可重复查找快支持交集并集差集等功能常见命令向中添加一个或多个元素移除中指定的元素返回中元素的个数判断一个元素是否存在于中获取中的所有元素求与的交集求与的差集求与的并集类型的是一个可排序的集合与中的有些类似但底层数据结构却差别很大中的每个元素都带有一个属性可以基于属性对元素排序底层的实现是一个跳表加表具备下列特性可排序元素不重复查询速度快因为的可排序特性经常被用来实现排行榜这样的功能的常见命令有添加一个或多个元素到如果已经存在则更新其值删除中的一个指定元素获取中的指定元素的值获取中的指定元素的排名获取中的元素个数统计值在给定范围内的所有元素的个数让中的指定元素自增步长为指定的值按照排序后获取指定范围内的元素按照排序后获取指定范围内的元素求差集交集并集注意所有的排名默认都是升序如果要降序则在命令的后面添加即可客户端的客户端主要有以命令作为方法名称学习成本低简单实用但是实例是线程不安全的多线程情况下需要基于连接池实用基于实现的支持同步异步和响应式编程方式并且是线程安全的支持的哨兵模式集群模式和管道模式是一个基于实现的分布式可伸缩的数据结构集合包含了诸如等强大功能而集成了客户端可以下拉该项目的分支该分支已经实现了整合可以下拉看看本身是线程不安全的并且频繁的创建和销毁连接会有性能损耗因此我们推荐大家使用连接池代替的直连方式是中数据操作的模块包含对各种数据库的集成其中对的集成模块就叫做官网地址提供了对不同客户端的整合提供了统一来操作支持的发布订阅模型支持哨兵和集群支持基于的响应式编程支持基于字符串对象的数据序列化及反序列化支持基于的实现客户端使用提供了工具类其中封装了各种对的操作并且将不同数据类型的操作封装到了不同类型中返回值类型说明操作类型数据操作类型数据操作类型数据操作类型数据操作类型数据通用命令该项目的分支使用整合了可以自行下拉运行的默认序列化可以接收任意作为值写入只不过写入前会把序列化为字节形式默认是采用序列化你好呀得到的结果是这样的缺点很明显可读性差内存占用较大这是因为什么呢查看类可以知道当没有特别配置的序列化策略时会选择使用序列化器而此序列化器是不是适合字符串的序列化的所以如果你的通常是用字符串格式那么可以考虑在序列化时采用其他序列化器比如提供的序列化器查看的实现可以看到有种序列化器字节数组序列化同类似而是由阿里巴巴包提供具有速度快兼容性强占用内存小底层使用进行序列化并存入对于普通类型如数值类型字符存入对象时由于没有存入类信息则无法反序列化同一样但它可以将任何对象泛化为字符串并序列化注意事项需要调用者给传一个对象到字符串互转的使用起来其比较麻烦所以不太推荐使用将对象序列化为字符串优点速度快序列化后的字符串短小精悍不需要实现缺点必须要提供要序列化对象的类型信息对象使用自带的序列化机制将对象序列化为一个字符串优点在于通用性强反序列化时不需要提供类型信息缺点在于序列化速度慢序列化内存占用大序列化对象必须实现接口可读性差将对象序列化为字符串以格式存储但还是类型解析起来比较复杂且占用空间大默认的序列化器优点可读性强不需要转换缺点只能对字符串序列化不能对对象序列化自定义序列化器所以我们可以针对自己的需要自定义来实现对不同使用不同的序列化器创建设置连接工厂设置序列化工具和采用序列化和采用序列化使用自定义序列化器存储对象羽写入数据获取数据由图可以知道该序列化器在序列化对象也会将对象的字节码名称写入这样在我们反序列化时知道对象的类型从而反序列化成对应对象使用存储对象但是这一个存在一个问题序列化器将类的类型写入了结果中存入了会带来额外的内存开销为了节省内存空间我们并不会使用序列化器来处理而是统一使用序列化器要求只能存储类型的和当需要存储对象时手动完成对象的序列化和反序列化所以还是建议手动完成对象的序列化羽写入数据这里使用的时进行序列化获取数据操作类型凌霄羽三实战与双写一致性如何保证一致性一致性就是数据保持一致在分布式系统中可以理解为多个节点中数据的值是一致的强一致性这种一致性级别是最符合用户直觉的它要求系统写入什么读出来的也会是什么用户体验好但实现起来往往对系统的性能影响大弱一致性这种一致性级别约束了系统在写入成功后不承诺立即可以读到写入的值也不承诺多久之后数据能够达到一致但会尽可能地保证到某个时间级别比如秒级别后数据能够达到一致状态最终一致性最终一致性是弱一致性的一个特例系统会保证在一定时间内能够达到一个数据一致的状态这里之所以将最终一致性单独提出来是因为它是弱一致性中非常推崇的一种一致性模型也是业界在大型分布式系统的数据一致性上比较推崇的模型三种经典的缓存模式缓存可以提升性能缓解数据库压力但是使用缓存也会导致数据不一致性的问题一般我们是如何使用缓存呢有三种经典的缓存模式即旁路缓存模式它的提出是为了尽可能地解决缓存与数据库的数据不一致问题读写更新的时候先更新数据库然后再删除缓存读的时候先读缓存缓存命中的话直接返回数据缓存没有命中的话就去读数据库从数据库取出数据放入缓存后同时返回响应模式中服务端把缓存作为主要数据存储应用程序跟数据库缓存交互都是通过抽象缓存层完成的读这个简要流程是不是跟很像呢其实就是多了一层写当发生写请求时也是由缓存抽象层完成数据源和缓存数据的更新先更新数据源再更新缓存从缓存读取数据读到直接返回如果读取不到的话从数据库加载写入缓存后再返回响应跟有相似的地方都是由来负责缓存和数据库的读写它两又有个很大的不同是同步更新缓存和数据的则是只更新缓存不直接更新数据库通过批量异步的方式来更新数据库这种方式下缓存和数据库的一致性不强对一致性要求高的系统要谨慎使用但是它适合频繁写的场景的机制就使用到这种模式操作缓存的时候删除缓存呢还是更新缓存一般业务场景我们使用的就是模式有些小伙伴可能会问在写入请求的时候为什么是删除缓存而不是更新缓存呢我们在操作缓存的时候到底应该删除缓存还是更新缓存呢我们先来看个例子线程先发起一个写操作第一步先更新数据库线程再发起一个写操作第二步更新了数据库由于网络等原因线程先更新了缓存线程后更新缓存这时候缓存保存的是的数据老数据数据库保存的是的数据新数据数据不一致了脏数据出现啦如果是删除缓存取代更新缓存则不会出现这个脏数据问题更新缓存相对于删除缓存还有两点劣势如果你写入的缓存值是经过复杂计算才得到的话更新缓存频率高的话就浪费性能啦在写数据库场景多读数据场景少的情况下数据很多时候还没被读取到又被更新了这也浪费了性能呢实际上写多的场景用缓存也不是很划算了双写的情况下先操作数据库还是先操作缓存缓存模式中有些小伙伴还是有疑问在写入请求的时候为什么是先操作数据库呢为什么不先操作缓存呢线程发起一个写操作第一步此时线程发起一个读操作线程继续读读出来一个老数据然后线程把老数据设置入线程写入最新的数据酱紫就有问题啦缓存和数据库的数据不一致了缓存保存的是老数据数据库保存的是新数据因此缓存模式选择了先操作数据库而不是先操作缓存缓存延时双删有些小伙伴可能会说不一定要先操作数据库呀采用缓存延时双删策略就好啦什么是延时双删呢先删除缓存再更新数据库休眠一会比如秒再次删除缓存这个休眠一会一般多久呢都是秒这个休眠时间读业务逻辑数据的耗时几百毫秒为了确保读请求结束写请求可以删除读请求可能带来的缓存脏数据删除缓存重试机制不管是延时双删还是的先操作数据库再删除缓存如果第二步的删除缓存失败呢删除失败会导致脏数据哦删除缓存重试机制会造成很多业务代码入侵其实也可以通过数据库的来异步淘汰所以我们需要一些重试机制确保被删除了队列重试机制流程如下所示更新数据库数据缓存因为种种问题删除失败将需要删除的发送至消息队列自己消费消息获得需要删除的继续重试删除操作直到成功然而该方案有一个缺点对业务线代码造成大量的侵入于是有了方案二在方案二中启动一个订阅程序去订阅数据库的获得需要操作的数据在应用程序中另起一段程序获得这个订阅程序传来的信息进行删除缓存操作基于订阅的同步机制技术整体思路增量订阅消费消息队列增量数据更新到读热数据基本都在写增删改都是操作更新数据的数据操作来更新到更新数据操作主要分为两大块一个是全量将全部数据一次写入到一个是增量实时更新这里说的是增量指的是的变更数据读取后分析利用消息队列推送更新各台的缓存数据这样一旦中产生了新的写入更新删除等操作就可以把相关的消息推送至再根据中的记录对进行更新其实这种机制很类似的主从备份机制因为的主备也是通过来实现的数据一致性这里可以结合使用阿里的一款开源框架通过该框架可以对的进行订阅而正是模仿了的数据库的备份请求使得的数据更新达到了相同的效果当然这里的消息推送工具你也可以采用别的第三方等来实现推送更新缓存雪崩穿透击穿污染缓存雪崩对于系统假设每天高峰期每秒个请求本来缓存在高峰期可以扛住每秒个请求但是缓存机器意外发生了全盘宕机缓存挂了此时秒个请求全部落数据库数据库必然扛不住它会报一下警然后就挂了此时如果没有采用什么特别的方案来处理这个故障很着急重启数据库但是数据库立马又被新的流量给打死了或者缓存中数据大批量到过期时间大批量数据同时查询数据库引起数据库压力过大甚至宕机这就是缓存雪崩大约在年前国内比较知名的一个互联网公司曾因为缓存事故导致雪崩后台系统全部崩溃事故从当天下午持续到晚上凌晨点公司损失了几千万缓存雪崩的事前事中事后的解决方案如下事前高可用主从哨兵避免全盘崩溃事中本地缓存限流降级避免被打死事后持久化一旦重启自动从磁盘上加载数据快速恢复缓存数据除此之外实际使用时缓存数据的过期时间设置随机防止同一时间大量数据过期现象发生如果缓存数据库是分布式部署将热点数据均匀分布在不同的缓存数据库中热点数据的过期时间尽量设置长用户发送一个请求系统收到请求后先查本地缓存如果没查到再查如果和都没有再查数据库将数据库中的结果写入和中限流组件可以设置每秒的请求有多少能通过组件剩余的未通过的请求怎么办走降级可以返回一些默认的值或者友情提示或者空值好处数据库绝对不会死限流组件确保了每秒只有多少个请求能通过只要数据库不死就是说对用户来说的请求都是可以被处理的只要有的请求可以被处理就意味着你的系统没死对用户来说可能就是点击几次刷不出来页面但是多点几次就可以刷出来了缓存穿透对于系统假设一秒个请求结果其中个请求是黑客发出的恶意攻击黑客发出的那个攻击缓存中查不到每次你去数据库里查也查不到举个栗子数据库是从开始的结果黑客发过来的请求全部都是负数这样的话缓存中不会有请求每次都视缓存于无物直接查询数据库这种恶意攻击场景的缓存穿透就会直接把数据库给打死解决方案设置空值解决方式很简单每次系统从数据库中只要没查到就写一个空值到缓存里去比如然后设置一个过期时间这样的话下次有相同的来访问的时候在缓存失效之前都可以直接从缓存中取数据布隆过滤器当然如果黑客如果每次使用不同的负数来攻击写空值的方法可能就不奏效了更为经常的做法是在缓存之前增加布隆过滤器将数据库中所有可能的数据哈希映射到布隆过滤器中然后对每个请求进行如下判断使用布隆过滤器能够对访问的请求起到了一定的初筛作用避免了因数据不存在引起的查询压力请求数据的不存在于布隆过滤器中可以确定数据就一定不会存在于数据库中系统可以立即返回不存在请求数据的存在于布隆过滤器中则继续再向缓存中查询校验对所有可能查询的参数以形式存储在控制层先进行校验不符合则丢弃缓存击穿缓存击穿就是说某个非常热点访问非常频繁处于集中式高并发访问的情况当这个在失效的瞬间大量的请求就击穿了缓存直接请求数据库就像是在一道屏障上凿开了一个洞不同场景下的解决方式可如下若缓存的数据是基本不会发生更新的则可尝试将该热点数据设置为永不过期若缓存的数据更新不频繁且缓存刷新的整个流程耗时较少的情况下则可以采用基于等分布式中间件的分布式互斥锁或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存其余线程则在锁释放后能访问到新缓存在缓存失效后通过加锁或者队列来控制读数据库写缓存的线程数量比如对某个只允许一个线程查询数据和写缓存其他线程等待若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间以保证所有的请求能一直访问到对应的缓存缓存污染缓存污染问题说的是缓存中一些只会被访问一次或者几次的的数据被访问完后再也不会被访问到但这部分数据依然留存在缓存中消耗缓存空间缓存污染会随着数据的持续增加而逐渐显露随着服务的不断运行缓存中会存在大量的永远不会再次被访问的数据缓存空间是有限的如果缓存空间满了再往缓存里写数据时就会有额外开销影响性能这部分额外开销主要是指写的时候判断淘汰策略根据淘汰策略去选择要淘汰的数据然后进行删除操作缓存淘汰策略共支持八种淘汰策略分别是和策略怎么理解呢主要看分三类看不淘汰后默认的对设置了过期时间的数据中进行淘汰随机全部数据进行淘汰随机该策略是的默认策略在这种策略下一旦缓存被写满了再有写请求来时不再提供服务而是直接返回错误这种策略不会淘汰数据所以无法解决缓存污染问题一般生产环境不建议使用其他七种规则都会根据自己相应的规则来选择数据进行删除操作这个算法比较简单在设置了过期时间的键值对中进行随机删除因为是随机删除无法把不再访问的数据筛选出来所以可能依然会存在缓存污染现象无法解决缓存污染问题这种算法判断淘汰数据时参考的指标比随机删除时多进行一步过期时间的排序在筛选需删除的数据时越早过期的数据越优先被选择算法算法的全称是按照最近最少使用的原则来筛选数据这种模式下会使用算法筛选设置了过期时间的键值对优化的算法实现会记录每个数据的最近一次被访问的时间戳在在决定淘汰的数据时第一次会随机选出个数据把它们作为一个候选集合接下来会比较这个数据的字段把字段值最小的数据从缓存中淘汰出去通过随机读取待删除集合可以让不用维护一个巨大的链表也不用操作链表进而提升性能选出的数据个数通过配置参数进行配置个数越大则候选集合越大选择到的最久未被使用的就更准确越小选择到最久未被使用的数据的概率也会随之减小会使用算法选择设置了过期时间的键值对算法缓存策略是在策略基础上为每个数据增加了一个计数器来统计这个数据的访问次数当使用策略筛选淘汰数据时首先会根据数据的访问次数进行筛选把访问次数最低的数据淘汰出缓存如果两个数据的访问次数相同策略再比较这两个数据的访问时效性把距离上一次访问时间更久的数据淘汰出缓存的算法实现当策略筛选数据时会在候选集合中根据数据字段的后选择访问次数最少的数据进行淘汰当访问次数相同时再根据字段的前值大小选择访问时间最久远的数据进行淘汰只使用了记录数据的访问次数而记录的最大值是这样在访问快速的情况下如果每次被访问就将访问次数加一很快某条数据就达到最大值可能很多数据都是那么退化成算法了所以为了解决这个问题实现了一个更优的计数规则并可以通过配置项来控制计数器增加的速度参数用计数器当前的值乘以配置项再加再取其倒数得到一个值然后把这个值和一个取值范围在间的随机数值比大小只有值大于值时计数器才加控制访问次数衰减策略会计算当前时间和数据最近一次访问时间的差值并把这个差值换算成以分钟为单位然后策略再把这个差值除以值所得的结果就是数据要衰减的值设置越大递增概率越低设置越大衰减速度会越慢我们在应用策略时一般可以将取值为如果业务应用中有短时高频访问的数据的话建议把值设置为可以快速衰减访问次数策略是后新增使用算法在所有数据中进行筛选具体算法跟上述中介绍的一致只是筛选的数据范围是全部缓存这里就不在重复从所有键值对中随机选择并删除数据跟算法一样随机删除就无法解决缓存污染问题使用算法在所有数据中进行筛选具体算法跟上述中介绍的一致只是筛选的数据范围是全部缓存这里就不在重复策略是后新增多路复用有哪几种模型为什么中要使用多路复用这种技术呢首先是跑在单线程中的所有的操作都是按照顺序线性执行的但是由于读写操作等待用户输入或输出都是阻塞的所以操作在一般情况下往往不能直接返回这会导致某一文件的阻塞导致整个进程无法对其它客户提供服务而多路复用就是为了解决这个问题而出现的先来看一下传统的阻塞模型到底是如何工作的当使用或者对某一个文件描述符以下简称进行读写时如果当前不可读或不可写整个服务就不会对其它的操作作出响应导致整个服务不可用这也就是传统意义上的也就是我们在编程中使用最多的阻塞模型但是由于它会影响其他对应的服务所以需要处理多个客户端任务的时候往往都不会使用阻塞模型多路复用阻塞式的模型并不能满足这里的需求我们需要一种效率更高的模型来支撑的多个客户这里涉及的就是多路复用模型了在多路复用模型中最重要的函数调用就是该方法的能够同时监控多个文件描述符的可读可写情况当其中的某些文件描述符可读或者可写时方法就会返回可读以及可写的文件描述符个数与此同时也有其它的多路复用函数它们相比性能更优秀同时也能支撑更多的服务设计模式服务采用的方式来实现文件事件处理器每一个网络连接其实都对应一个文件描述符文件事件处理器使用多路复用模块同时监听多个当和文件事件产生时文件事件处理器就会回调绑定的事件处理器虽然整个文件事件处理器是在单线程上运行的但是通过多路复用模块的引入实现了同时对多个读写的监控提高了网络通信模型的性能同时也可以保证整个服务实现的简单多路复用模块多路复用模块封装了底层的以及这些多路复用函数为上层提供了相同的接口因为需要在多个平台上运行同时为了最大化执行的效率与性能所以会根据编译平台的不同选择不同的多路复用函数作为子模块提供给上层统一的接口在中我们通过宏定义的使用合理的选择不同的子模块会优先选择时间复杂度为的多路复用函数作为底层实现包括中的中的和中的上述的这些函数都使用了内核内部的结构并且能够服务几十万的文件描述符但是如果当前编译环境没有上述函数就会选择作为备选方案由于其在使用时会扫描全部监听的描述符所以其时间复杂度较差并且只能同时服务个文件描述符所以一般并不会以作为第一方案使用脑裂问题如果在中形式上就是有了两个记住了两个才是脑裂的前提哨兵模式下的脑裂个与个组成的哨兵模式哨兵独立部署于其他节点两个客户端都连接上了但是如果与及哨兵之间网络发生了故障但是哨兵与之间通讯正常这时个其中个经过哨兵投票后提升为新如果恰好此时仍然连接的是旧的而连接到了新的数据就不一致了基于指令的分布式锁可能会拿到相同的锁基于生成的全局唯一也可能出现重复模式下的脑裂模式下这种情况要更复杂例如集群中有组分片每给分片节点都有主从如果出现网络分区时各种节点之间的分区组合都有可能手动解决问题在正常情况下如果挂了那么写入就会失败如果是手动解决那么人为会检测以及的网络状况然后视情况如果是挂了重启如果是与之间的连接断了可以调试网络这样虽然麻烦但是是可以保证只有一个的所以只要认真负责不会出现脑裂自动解决问题中有一个哨兵机制哨兵机制的作用就是通过哨兵来检测服务的状态如果一旦发现挂了就在中选举新的节点以实现故障自动转移如何避免脑裂合理设置两个参数第一个参数标识连接到的最少数量第二个参数标识连接到的最大延迟时间问题就出现在这个自动故障转移上如果是哨兵和同时与断了联系即哨兵可以监测到但是监测不到而虽然连接不上和哨兵但是还是在正常运行这样如果哨兵因为监测不到认为它挂了会在中选举新的而有一部分应用仍然与旧的交互当旧的与新的重新建立连接旧的会同步新的中的数据而旧的中的数据就会丢失所以我认为脑裂就是自动故障转移造成的搭建哨兵集群新建一个文件内容如下分别新建三个文件内容都如下自定义集群名其中为的为的端口为最小投票数因为有台所以可以设置成四个文件都放在同义目录下并使用命令测试进入发现当前为主节点然后将该关闭四应用分布式锁分布式锁本质上要实现的目标就是在里面占一个茅坑当别的进程也要进来占时发现已经有人蹲在那里了就只好放弃或者稍后再试占坑一般是使用指令只允许被一个客户端占坑先来先占用完了再调用指令释放茅坑但是如果逻辑执行到中间出现异常了可能会导致指令没有被调用这样就会陷入死锁锁永远得不得释放于是我们在拿到锁之后再给锁加上一个过期时间比如这样即使中间出现异常也可以保证之后锁会自动释放但是以上逻辑还是有问题因为如果在和之间服务器进程突然挂掉了就会导致得不到执行也会造成死锁这种问题的根源在于和是两条指令而不是原子指令如果这两条指令可以一起执行就不会出现问题这里也不可以使用事务来解决因为是依赖于的执行结果的如果没抢到锁是不应该执行的事务里没有分支逻辑事务的特点是一口气执行要么全部执行要么一个都不执行为了解决这个问题开源社区涌现出很大分布式锁的专门用来解决这个问题其实现方式极为复杂如果需要使用分布式锁不能仅仅使用或者就行了还得引入分布式锁的为了治理这个乱象版本中加入了指令的扩展参数是的和可以一起执行彻底解决了分布式锁的乱象的分布式锁不能解决超时问题如果在加锁和释放之间的逻辑执行的太长以至于超出了锁的超时限制就会出现问题因为这时候锁过期了第二个线程重新持有了这把锁但是紧接着第一个线程执行完了业务逻辑就把锁给释放了第三个线程就会在第二个线程执行完之前就拿到了锁为了避免这个问题分布式锁不要用于较长时间的任务如果真的偶尔出现了数据出现小波错乱可能需要人工介入解决有一个更安全的方案是为指令的参数设置为一个随机数释放锁时先匹配随机数是否一致然后再删除但是匹配和删除不是一个原子操作也没有提供类似于这样的指令这就需要使用脚本来处理了因为脚本可以保证连续多个指令的原子性执行可重入性可重入性就是指线程在持有锁的情况下再次请求加锁如果一个锁支持同一个线程的多次加锁那么这个锁就是可重入的分布式锁如果需要支持可重入需要对客户端的方法进行包装使用线程的变量存储当前持有锁的计数延时队列平时习惯使用和作为消息队列中间件来给应用程序之间增加异步消息传递功能这个两个中间件都是专业的消息队列中间件其能力很强但是使用起来也较为繁琐的消息队列实现很简单但是并不是专业的消息队列它没有非常多的高级特性没有保证如果对消息的可靠性有着极致的追求那么它就不适合使用异步消息队列的列表数据结构常用来作为异步消息队列使用使用操作入队列使用和来出队列客户端是通过队列的操作来获取消息然后进行处理处理完了再接着获取消息再进行处理如此往复如果队列空了客户端就会陷入的死循环不停地这就是浪费生命的空循环空轮询不但拉高了客户端的的也会被拉高如果这样空轮询的客户端有几十来个的慢查询可能会显著增多通常使用来解决这个问题让线程休眠一会但是这样会造成消费者的延迟可以有更好的解决方案使用前缀字符代表的就是即堵塞读堵塞读在队列没有数据的时候会立即进行休眠状态一旦数据到来则立刻醒过来消息的延迟几乎为这个方案有个弊端就是注意空连接问题因为线程一直堵塞在那的客户端连接就成了闲置连接闲置过久服务器一般就会主动断开连接减少闲置资源的占用这时会抛出异常所以在编写客户端消费者时注意捕获异常和重试延迟队列的实现上一节提及的分布式锁当客户端在处理请求时加锁没加成功怎么办一般是有种策略来处理加锁失败直接抛出异常通知用户稍后重试一会再重试这种方式会堵塞当前的消息处理线程导致队列的后续消息处理出现延迟如果碰撞出现较多或者队列里的消息较多可能并不合适因为个别死锁的导致加锁不成功线程会彻底堵死导致后续消息永远得不到及时处理将请求转移到延迟队列过会再试这种方式较好延时队列可以通过的有序列表来实现我们将消息序列化成一个字符串作为的这个消息的到期处理时间作为然后用多个线程轮询获取到期的任务进行处理多个线程是为了保障可用性万一挂了一个线程还有其他线程可以继续处理因为有多个线程所以需要考虑并发争抢任务确保任务不能被多次执行延迟队列是空当休息的方法是多线程多进程抢任务的关键它的返回值决定了当前实例有没有抢到任务因为方法可能被多个线程多个进程调用同一任务可能会被多个进程线程抢到通过来决定唯一的属主同时注意对进行异常捕获上述方案还是存在明显缺点原子性问题先查询再删除这两个操作不是原子的明显会出现并发问题虽然我这里判断了的数量但是可能会出现部分被其他机器给消费的情况性能问题还好但是如果在时间间隔内产生了大量消息如果同时处理的性能会急剧下降性能问题解决多线程并发消费将定时任务的启动延迟时间或者每次循环的时间随机让每台机器处理消息点有一定间隔这样单次时间间隔内要处理的消息的数据会大大减少命令设置限制单次处理消息的数据原子性问题解决使用脚本解决和不是原子化操作的问题位图在平时开发过程中会有一些型数据需要存取比如用户一年的签到记录签了是没签是要记录天如果使用普通的每个用户要记录个当用户上亿时需要的存储空间是惊人的位图不是特殊的数据结构它的内容其实就是普通的字符串也就是数组我们可以使用普通的直接获取和设置整个位图的内容也可以使用位图操作等将数组看成位数组来处理的位数组是自动扩展如果设置了某个偏移位置超过了现有的内容范围就会自动将位数组进行零扩充基本使用上面的例子可以理解为零存整取同样也可以零存零取整存整取零存就是使用对位值进行逐个设置整存就是使用字符串一次性填充所有位数组覆盖掉旧值统计和查找提供了位图统计指令和位图查找指令用来统计指定位置范围内的个数用来查找指定范围内出现的第一个或遗憾的是和参数是字节索引也就是说指定的位范围必须是的倍数而不能任意指定整存第一个字符中的位数前两个字符中的位数第一个零位第二到第三字符中第一个出现的位置魔术指令之前我们设置或者获取指定位的值都是单个位的如果要一次操作多个位就必须要使用管道来处理之后新增命令可以使用其下有三个子指令分别是它们都可以对指定位片段进行读写但是最多只能处理个连续的位如果超过位就得使用多个子指令可以一次执行多个子指令从第一位开始取个位取出结果为无符号数从第三位开始取个位取出结果为有符号数可以一次执行多个子指令从第个位开始将接下来的个位用无符号数替换所谓有符号数是指取出来的位数组中第一个位是当作符号位剩下的才是值如果第一位是那就是负数无符号数表示非负数没有符号位获取到位数组全部都是值有符号数最多可以获取位无符号数只能获取位第三个指令它用来对指定范围的位进行自增操作既然提到了自增就有可能出现溢出如果增加了正数会出现上溢如果增加负数会出现下溢出如果出现溢出就将溢出的符号位丢掉如果是位无符号数加就变成提供的是一个不精确但是节省空间的去重计数方案如果页面访问量非常大比如一个爆款页面几千万的就需要一个很大的集合来统计这就非常浪费空间如果这样的页面很多那所需要的存储空间是惊人的如果对统计精确度不需要太精确就可以使用它的标准误差是使用方法提供了两个指令和一个是增加计数一个是获取计数除了上面两个指令还有一个用于将多个计数值累计在一起形成一个新的值数学原理极大似然估计的直观理解其使用的数学原理是统计学中的极大似然估计接下去我将用多个场景逐步深入解析场景现在有个不透明的口袋其中都装有个球口袋中是个白球个黑球口袋中是个黑球个白球当我们随机挑选一个口袋然后从中拿出一个球如果拿出的球是白色的那么我们可以说大概率我们取出的是口袋这种直觉的推测其实就包含了极大似然估计的思想场景我们只保留口袋其中个白球个黑球很容易我们就可以得出结论从中取出任意一个球是白球的概率为是黑球的概率为这是一种正向的推测我们知道了条件个白球个黑球从而推测出结果取出任意一个球是白球的概率为但这只是理论上的推测如果实际取球次每次都放回那么取出黑球的次数并不一定是次可能是次也可能超过次我们取球的次数越多实际情况将越符合理论情况场景还是口袋只不过此时其中白球和黑球的数量我们并不知晓于是我们开始从中拿球每拿出一个球都记录下结果并将其放回如果我们取球次其中次是白球次是黑球我们可以说口袋中可能是个白球但并不能非常肯定当我们取球次的时候其中次是白球次是黑球此时我们就可以大概率确定口袋中是个白球而这种确定程度随着我们实际取球次数的增加也将不断增加这就是一种反向的推测我们观察了结果取次球次是白球次是黑球可以推测出条件口袋中放了个白球个黑球当然这种推测的结果并非是准确的而是一种大概率的估计无论是正向推测或是反向推测只有当实际执行操作的次数足够多的时候才能使得实际情况更接近理论推测这就非常符合的特点只有当数据量足够大的时候误差才会足够小因此极大似然估计的本质就是当能观察的结果数量足够多时我们就可以大概率确定产生相应结果所需要的条件的状态这种通过大量结果反向估计条件的数学方法就是极大似然估计伯努利实验与极大似然估计了解极大似然估计之后我们就需要引入第二个数学概念伯努利实验不要被这个名字唬住伯努利实验其实就是扔硬币接下去我们就来了解下这枚硬币要怎么扔下文所说的硬币都是最普通的硬币只有正反两面且每一面朝上的概率都是场景我们随机扔一次硬币那么得到正面或反面的可能性是相同的如果我们扔次硬币那么可以估计到大概率是接近次正面次反面这是最简单的正向推测场景如果我们扔次硬币是否可能次都是正面当然有可能并且概率为如果我们扔次硬币呢是否可能次都是正面虽然概率很小但依然是有可能的概率为同样的无论是次次即使概率很小也依然存在全部都是正面朝上的情况假如扔了次那么次都是正面的概率为这也是正向的推测只不过增加了全都是正面朝上的限定场景现在我们按下面这种规则扔硬币不断扔硬币如果是正面朝上那么就继续扔直到出现反面朝上此时记录下扔硬币的总次数例如我们抛了次硬币前次都是正面朝上第次是反面朝上我们就记录下次数通过场景我们可以知道这种情况发生的概率为按我们的直觉可以推测如果一个结果发生的概率是那么我们大体上就需要做次同样的事情才能得到这个结果当然从更严谨的数学角度并不能这么说但本文不想涉及专业的数学描述所以姑且这么理解其实也挺符合一般常识判断的那么假如张三做了若干次这种实验我观察结果发现记录下的总次数的最大值是那就说明在这若干次实验中至少发生了一次次正面朝上第次反面朝上的情况而这种情况发生的概率是于是我推测张三大概率总共做了次实验这就是一种反向推测即根据结果发生了一次概率才会出现的结果推测条件大概率做了次实验更通俗来说如果一个结果出现的概率很小但却实际发生了了就可以推测这件事情被重复执行了很多次结果出现的概率越小事情被重复执行的次数就应当越多就像生活中中彩票的概率很低普通人如果想中那可不就得买很多次嘛中奖概率越低一般需要购买彩票的次数就越多相应的如果一个人中奖了我们可以说这个人大概率上购买了非常多次彩票这就是伯努利实验与极大似然估计结合的通俗理解另外特别注意的我们推测条件时需要观察的总次数的最大值因为最大值代表了最小概率而最小概率才是推测条件的依据下文同理实现实现本质也是利用了扔硬币产生的极大似然估计原理因此接下去我们就详细看看是怎么扔硬币的在伯努利试验的场景中我们做的实验有个特点硬币只有正反两面硬币正反面出现的概率相同单次实验需要投掷多次硬币而计算机中的算法正好可以满足这个条件结果的每一个只有和代表硬币的正反两面如果算法足够好得到的结果就足够随机可以近似认为每一个的和产生的概率是相同的的结果如果是个正好代表投掷了次硬币因此执行一次就相当于完整地进行了一次场景中的投币实验按照约定实验完成后我们需要记录硬币投掷的结果假定现在有个用户先对进行假定得到如下个的结果此时从右到左我们约定表示反面表示正面于是在这次实验中第一个为的出现在第三位相当于先投出了次反面然后投出次正面于是我们记录下这次实验的投掷次数为因为约定只要投出正面当次实验就结束所以第一个左边的所有就不再考虑了再对进行假定得到第一个为的出现在第位于是记录下对于每个用户的访问请求我们都可以对用户的进行相当于场景中进行一次实验并记录下第一个为的出现的位数相当于场景中记录下硬币的投掷次数那么通过记录到的位数的最大值我们就可以大概估计出一共进行了多少次实验相当于场景中的反向推测也就是有多少个不同的用户发生了访问例如某个页面有若干个用户进行了访问我们观察记录下的数据发现记录下的最大值是就意味着的结果至少出现了一次右边个都为的情况而这种情况发生的概率为于是我们可以推测大概有个用户访问过该页面才有可能出现一次这种结果所以其实可以这样理解每个用户的结果相当于此用户的投币结果我们看下值从右向左第一次出现的位置如果比之前用户记录出现的位置更靠左则记录这样如果最后记录的最大值是则可以推测个用户访问过又因为同一用户结果是唯一的所以同一个用户即使多次实验也不会影响精准性当用户越多则我们通过概率推测的用户数量越接近实际情况布隆过滤器可以用来进行估值它非常有价值可以解决很多精确度要求不高的统计需求但是如果我们想要知道某一个值是不是已经不在结构里面了它就无能为力的现实中比如推荐系统用户的视频推荐系统每次推荐需要查看用户是否观看过此视频问题是当用户量很大每个用户观看过的视频总数又很大的情况下去重工作在在性能上考验很大如果数据存储在关系数据库中去重就需要频繁地对数据库进行查询如果使用缓存但是这么多历史记录全部缓存起来就得浪费很多存储空间布隆过滤器可以解决此问题它可以起到去重的同时在空间上还能节省以上只是稍微那么不精确当布隆过滤器说某个值存在时这个值可能不存在当它说这个值不存在时那就肯定不存在那么可以使用布隆过滤器判断需要推荐的时候是否在用户观看历史记录集合中如果不在则推荐如果判断在历史记录中实际可能在也可能不在因为会有概率误判所以可以保证推荐的内容肯定是用户没看过的但可能也会把极少量用户没有看过的内容误判成用户看过而过滤掉基本使用官方提供的布隆过滤器到了提供了插件功能之后正式登场可以通过直接体验布隆过滤器基本指令添加元素进入过滤器查询元素是否存在返回表示存在表示不存在一次添加多个元素进入过滤器一次查询多个元素是否在过滤器上面指令使用的布隆过滤器只是默认参数的布隆过滤器它在外面第一次的时候被自动创建还提供了自定义参数的布隆过滤器需要我们在之前使用指令显式创建如果对应的已经存在了会报错有三个参数分别是和错误率越低需要的空间越大参数表示预计放入的元素数量当实际数量超过这个值误判率会上升所以一般需要设置一个较大的数值避免超过导致误判率升高如果不使用默认的是默认的是注意如果估计的过大也会浪费存储空间估计的过小就会影响准确率原理每个布隆过滤器在的数据结构里面就是一个大型的位数组和几个不一样的无偏函数所以无偏就是能够把元素的值算的比较均匀向过滤器中添加时会使用多个函数对进行算得一个整数索引值然后对位数组长度进行取模运算得到一个位置每个函数都会算得一个不同的位置再把位数组的这几个位置都置为就完成了操作向布隆过滤器询问是否存在时跟一样也会把函数的几个位置都计算出来看看位数组中这几个位置是否都为只要有一个为那么说明布隆过滤器中这个不存在如果都是这并不能说明这个就一定存在只是极有可能存在因为这些位被置成可能是因为添加其他时导致的如果这个位数组比较稀疏这个误判的概率就很小如果这个数组比较拥挤误判的概率就会变大使用时如果实际元素开始超过初始化大小应该对布隆过滤器进行重建重新分配一个更大的过滤器再将所有历史元素批量进去空间占用估计布隆过滤器有两个参数第一个是预计元素的数量第二个是错误率公式根据这两个输入得到两个输出第一个输出是位数组的长度也就是需要的存储空间大小第二个输出是函数的最佳数量函数的数量也会直接影响到错误率最佳的数据会有最低的错误率约等于表示次方计算从公式可以看出位数组相对越长错误率越低位数组相对越长函数需要的最佳数量也越多影响计算效率当一个元素平均需要个字节的指纹空间错误率大约错误率为一个元素需要的平均指纹空间为个错误率为一个元素需要的平均指纹空间为个从上面可以看到一个元素需要占据那相对集合的空间优势是不是就没有那么明显了中会存储每个元素的内容而布隆过滤器仅仅存储元素的指纹元素的内容大小就是字符串的长度它一般有多个字节甚至几十个字节每个元素本身还需要一个指针被集合来引用简单限流在中可以使用数据结构实现该功能可以把中的值设置为时间戳这样就可以圈出一个时间段内的所有数据即只要时间窗口内的数据时间窗口外的数据都可以砍掉那么的填什么值呢也可以填时间戳只需保证其唯一性就行这样就可以用记录用户的行为历史每个行为都会作为一个中的一个保存下来同一个用户同一种行为会使用一个记录为了节省内存我们只需要保留时间窗口内的行为记录同时如果用户是冷用户滑动时间窗口内的行为是空记录那么这个就可以从内存中移除不再占用空间通过统计滑动窗口内的行为数量与阈值进行比较就可以得出当前的行为是否允许整体思路每一个行为到来时都维护一次时间窗口将时间窗口外的记录全部清理掉只保留窗口内的记录集合中只有值非常重要没有特别的意义缺点要记录时间窗口内所有的行为记录如果这个量很大比如限定内操作不得超过次那么这就不适合这样做限流了因为会消耗大量的存储空间漏斗限流提供了一个限流模块它叫该模块也使用了漏斗算法并提供了原子的限流指令该模块只有条指令它的参数和返回值都略显复杂是键名第二个参数是漏斗容量第三个参数第四个参数表示内最多次可以当作漏斗的流速第五个参数为可选参数默认为指令会返回五个参数分别表示表示允许表示拒接漏斗容量漏斗剩余空间如果拒接了需要多长时间之后再试多久后漏斗有空间单位秒多长时间后漏斗完全空出来单位秒在执行限流指令时如果被拒绝了就需要丢弃或重试指令考虑的非常周到连重试时间给我们了直接取返回结果数组的第四个值进行即可如果不想堵塞线程也可以异步定时任务来重试近水楼台在版本以后增加了模块意味着我们可以使用来实现微信附近的人美团附件的餐馆这样的功能了用数据库来算附近的人地图元素的位置数据使用二维的经纬度表示经度范围纬度范围纬度正负以赤道为界北正南负经度正负以本初子午线为界东正西负当两个距离不是很远时可以直接使用勾股定理就能算得元素之间的距离平时使用的附近的人的功能元素距离都不是很大勾股定理算距离足以不过需要注意的是经纬度坐标的密度不一样经度总共度纬度总共度勾股定理计算平方差时之后再求和时需要按一定的系数比加权求和如果使用关系型数据库基本采用元素经度纬度存储那此时就很难通过遍历来计算所有的元素和目标元素的距离然后再进行排序这个计算量太大了性能指标肯定无法满足一般的方法都是通过矩形区域来限定元素的数量然后对区域内的元素进行全量距离计算再排序为了满足高性能的矩形区域算法数据表需要在经纬度坐标上加上双向复合索引这样可以最大优化查询性能但是数据库查询性能毕竟有限如果附近的人查询请求非常多在高并发场合这可能并不是一个很好的方案算法业界比较通用的地理距离排序算法是算法也使用算法算法将二维的经纬度数据映射到一维的整数这样所有的元素都将挂载到一条线上距离靠近的二维坐标映射到一维后的点之间距离也会很近当我们想要计算附近的人时首先将目标的位置映射到这条线上然后在这个一维的线上获取附近的点就行了那这个映射算法具体是怎么计算的它将整个地球看成一个二维平面然后划分成了一系列正方形的方格就好比围棋棋盘所有的地图元素坐标都将放置于唯一的方格中方格越小坐标越精确然后对这些方格进行整数编码越是靠近的方格编码越是接近那如何编码呢一个最简单的方案就是切蛋糕法设想一个正方形的蛋糕摆在你面前二刀下去均分分成四个小正方形这四个小正方形可以分别标记为四个二进制整数然后对每个小正方形继续用二分刀法切割一下这时每个小小正方形使用的二进制整数予以表示然后继续切下去正方形就会越来越小二进制整数也会越来越长精确度就会越来越高上面使用的是二刀法进行编码实际上还有其他很多方法进行编码编码之后每个地图元素的坐标都将变成一个整数通过这个整数可以还原出元素的坐标整数越长还原出来的坐标值的损失程度就越小算法会继续对这个整数做一次编码去掉四个字母变成一个字符串在里面经纬度使用位的整数进行编码放进了里面的元素的是的位的整数值的虽然是浮点数但是对于位的整数值它可以无损存储在使用进行查询时我们要时刻想到它的内部结构实际上只是一个通过的排序就要可以得到坐标附近的其他元素实际情况要复杂一点通过将还原成坐标值就可以得到元素的原始坐标基本使用提供的指令只有个增加指令携带集合名称以及多个经纬度名称三元组这里也可以一次性添加多个元组实际使用没有提供删除指令但是因为的底层实现是所以可以使用命令实现对地理位置信息的删除查看距离可以用来计算两个元素之间的距离携带集合名称个名称和距离单位获取元素位置指令可以获取集合中任意元素的经纬度坐标可以一次获取多个我们观察到获取的经纬度坐标和进去的坐标有轻微的误差原因是对二维坐标进行的一维映射是有损的通过映射再还原回来的值会出现较小的差别获取元素的值可以获取元素的经纬度编码字符串上面说过它是编码你可以使用这个编码值去中直接定位它是的标准编码值附近的指令是最为关键的指令它可以用来查询指定元素附近的其他元素它的参数非常复杂范围公里以内最多个元素按距离正排它不会排除自身三个可选参数用来携带附加参数查询指定坐标附近的元素除了指令根据元素查询附近的元素还提供了根据坐标值来查询附近的元素这个指令更加有用它可以根据用户的定位来计算它的参数和基本一致除了将目标元素改成经纬度坐标值在一个地图应用中车的数据餐馆的数据人的数据可能会有百万千万条如果使用的数据结构它们将全部放在一个集合中在的集群环境中集合可能从一个节点迁移到另一个节点如果单个的数据过大会对集群的迁移工作造成较大影响在集群环境中的单个对应的数据量不宜超过否则会导致集群迁移出现卡顿现象影响线上服务的正常运行所以这里建议的数据使用单独的实例部署不使用集群环境如果数据量过亿甚至更大就需要对数据进行拆分在人口特大的城市甚至可以按区划分这样就可以显著降低单个集合的大小大海捞针有时候需要从实例成千上万的中找出特定前缀的列表来手动处理数据可能是修改它的值也可能是删除这里就有一个问题如何从海量中找到满足特定前缀的列表提供了一个简单暴力的指令用来列出所有满足特定正则字符串规则的这个指令非常简单提供一个简单的正则字符串即可但是有很明显的两个缺点没有参数一次性吐出所有满足条件的万一实例中有几百万个满足条件则打印字符串太多算法是遍历算法复杂度是如果实例中有上千万级以上的这个指令就会导致服务卡顿所有读写的其他指令都会被延后甚至超时因为是单线程程序顺序执行所有指令其他指令必须等到当前指令执行完成后才可以继续为解决这个问题在版本加入了相比具备以下优点复杂度虽然也是但是它是通过游标分布进行的不会堵塞线程提供参数可以控制每次返回结果的最大条数只是要给返回的参数可多可少同一样提供模式匹配功能服务器不需要为游标保存状态游标的唯一状态就是返回给客户端的游标整数遍历的过程中如果有数据修改改动后的数据能不能被遍历到是不确定的单次返回的结果是空的并不意味着遍历结束而要看返回的游标值是否为零基础使用往插入了条数据到提供了三个参数第一个是整数值第二个是的正则模式第三个是遍历的第一次遍历时值为然后将返回结果中第一个整数值作为下一次遍历的一直遍历到返回的值为时结束从上面实际测试中可以知道游标不是每次递增并且所填的不是指代返回的结果数量而是单次遍历的字典槽位数量约等于可能单次的返回结果为空但是这并不意味着遍历已经结束只有当返回的游标值为才算整个遍历结束字典的结构在中所有的都存储在一个很大的字典中整个字典的结构和中的一样是一维数组二维链表结构第一维数组的大小总是扩容一次数组大小空间加倍也就是指令返回的游标就是第一个维数组的位置索引我们将整个位置索引称作槽如果不考虑字典的扩容缩容直接按数组下标挨个遍历就行了参数就表示需要遍历的槽位数之所以返回的结果可能多可能少是因为不是所有的槽位都会挂接链表有些槽位可能是空的还有些槽位上挂接的链表上的元素可能会有多个每次遍历都会将数量的槽位上挂接的所有链表元素进行模式匹配过滤后一次性返回给客户端遍历顺序的遍历顺序非常特别它不是从第一维数组的第位一直遍历到末尾而是采用了高位进位加法来遍历之所以使用这样特殊的方式进行遍历是考虑到字典的扩容和缩容时避免槽位和遍历重复和遗漏后面有具体分析高位进位法从左边加进位往右边移动同普通加法正好相反但是它们都会遍历所有的槽位并且没有重复字典扩容中的有扩容的概念当达到阈值时需要重新分配一个新的倍大小的数组然后将所有的元素全部挂到新的数组下面就是将元素的值对数组长度进行取模运算因为长度变了所以每个元素挂接的槽位可能也发生了变化有因为数组的长度是次方所以取模运算等价于位与操作这里的又称之为字典的值的作用就是保留值的低位高位都被设置为看看前后元素槽位的变化假设当前的字段的数组长度由位扩容到位那么号槽位将会被到号槽位和号槽位也就是说该槽位链表中大约有一半的元素还是号槽位其它的元素会放到号槽位这个数字的二进制是就是对的二进制增加了一个高位抽象一点说假设开始槽位的二进制是那么该槽位中的元素将被到和即中如果字典长度由位扩容到位那么对于二进制槽位中的元素将被到和中对比扩容前后的遍历顺序观察这张图片我们发现采用高位进位加法的遍历顺序后的槽位在遍历顺序上是相邻的假设当前即将遍历这个位置那么扩容后当前槽位上所有的元素对应的新槽位是和也就是在槽位的二进制数增加一个高位或这时我们可以直接从这个槽位开始往后继续遍历槽位之前的所有槽位都是已经遍历过的这样就可以避免扩容后对已经遍历过的槽位进行重复遍历再考虑缩容假设当前即将遍历这个位置那么缩容后当前槽位所有的元素对应的新槽位是也就是去掉槽位二进制最高位这时我们可以直接从这个槽位继续往后遍历槽位之前的所有槽位都是遍历过的这样可以避免缩容的重复遍历不顾缩容还是不太一样它会对图中这个槽位上的元素进行重复遍历因为缩容后槽位的元素是和上挂接的元素的融合考虑渐进式的在扩容时会一次性将旧数组下挂接的元素全部转移到新的数组下面如果中元素特别多线程就会出现卡顿现象为了解决这个问题它采用渐进式它同时保留旧数组和新数组然后在定时任务中以及后续对的指令操作中渐渐将旧的数组中挂接的元素迁移到新数组上这意味着要操作处于中的字典需要同时访问新旧两个数组结构如果在旧数组下面找不到元素还需要去新数组下面寻找也需要考虑这个问题对于中的字典它需要同时扫描新旧槽位然后将结果融合后返回给客户端更多指令指令是一系列指令处理可以遍历所有的以外还可以对指定的容器集合进行遍历比如遍历集合元素遍历字典的元素大的扫描因为业务人员的使用不当在实例中会形成很大的对象比如一个很大的一个很大的这样的对象对的集群数据迁移带来了很大问题因为在集群环境下如果某一个太大会导致数据迁移卡顿另外在内存分配上如果一个太大那么当它需要扩容时会一次性申请更大的一块内存这也会导致卡顿如果这个大被删除内存会一次性回收卡顿现象再一次产生所以在开发中请避免大的产生如何定位到大呢可以使用命令对于扫描出来的每一个使用指令获取类型然后使用相应的数据结构的或者方法来得到它的大小对于每一种类型保留大小的前名作为扫描结果展示出来官方已经提供了实现上面功能的指令如果担心这个指令会大幅抬升的还可以增加一个休眠参数这个指令每隔条指令就会休眠就不会剧烈抬升但是扫描的时间会变长五原理线程模型记住高并发的中间件是单线程的除此之外也是单线程但是它们都是服务器高性能的典范详细可以看通信协议的作者认为数据库系统的瓶颈一般不在于网络流量而是数据库自身内部逻辑处理上所以即使使用了浪费流量的文本协议依然可以取得极高的访问性能是序列化协议的简写它是一种直观的文本协议优势在于实现异常简单解析性能极好协议将传输的结构数据分为种单元类型单元结束时统一加上回车换行符号单行字符串以符号开头多行字符串以符号开头后跟字符串长度整数值以符号开头后跟整数的字符串形式错误信息以符号开头数组以号开头后跟数组长度小结协议里有大量冗余的回车换行符但是这个并不影响它成为互联网技术领域非常受欢迎的一个文本协议有很多开源项目使用作为它的通讯协议在技术领域性能并不总是一切还有简单性易理解性和易实现性这些都需要进行适当权衡持久化的数据全部在内存中如果突然宕机数据就会全部丢失因此必须有一种机制来保证的数据不会因为故障而丢失这种机制就是的持久化机制持久化机制有两种第一种是快照第二种是日志将数据库的快照以二进制的方式保存到磁盘中则以协议文本的方式将所有对数据库进行过写入的命令及其参数记录到文件以此达到记录数据库状态的目的日志在长期的运行过程中会变的无比庞大数据库重启时需要加载日志进行指令重放这个时间就会无比漫长所以需要定期进行重写给日志进行瘦身快照我们都知道是单线程程序这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写在服务线上请求的同时如果还需要进行内存快照需要使用文件操作那就很难保持不堵塞除此之外持久化的同时内存数据结构还在改变这如何应对使用操作系统的多进程机制来实现快照持久化在持久化时会调用的函数产生一个子进程快照持久化完全交给子进程来处理父进程继续处理客户端请求子进程刚刚产生时它和父进程共享内存里面的代码段和数据段这是为节约内存资源所以让其共享起来在子进程创建时内存增长几乎没有明显变化子进程做数据持久化它不会修改现有的内存数据结构它只是对数据结构进行遍历读取然后序列化写入到磁盘但是父进程不一样它必须持续接受客户端请求然后对内存数据结构进行不间断修改这时候就会使用操作系统的机制来进行数据段页面的分离数据段页面是由很多操作系统的页面组合而成当父进程对其中一个页面的数据进行修改时会将被共享的页面复制一份分离出来然后对这个复制的页面进行修改这时子进程相应的页面是没有变化的还是进程产生时那一瞬间的数据随着父进程修改操作的持续进行越来越多的共享页面被分离出来内存就会持续增长但是也不会超过原有数据内存的倍大小另一个实例里冷数据占的比例往往是比较高的所以很少会出现所有的页面都会被分离被分离的往往只有其中一部分页面每个页面的大小只有一个实例里面一般都会有成千上万的页面子进程因为数据没有变化它能看到的内存里的数据在进程产生的那一瞬间就凝固了再也不会改变这也是为什么的持久化叫快照的原因的写入将所有对数据库进行过写入的命令及其参数记录到文件以此达到记录数据库状态的目的为了方便起见我们称呼这种记录过程为同步举个例子如果执行以下命令那么其中四条对数据库有修改的写入命令就会被同步到文件中除了命令是程序自己加上去的之外其他命令都是之前我们在终端里执行的命令同步命令到文件的整个过程可以分为三个阶段命令传播将执行完的命令命令的参数命令的参数个数等信息发送到程序中缓存追加程序根据接收到的命令数据将命令转换为网络通讯协议的格式然后将协议内容追加到服务器的缓存中文件写入和保存缓存中的内容被写入到文件末尾如果设定的保存条件被满足的话函数或者函数会被调用将写入的内容真正地保存到磁盘中以下几个小节将详细地介绍这三个步骤命令传播当一个客户端需要执行命令时它通过网络连接将协议文本发送给服务器比如说要执行命令客户端将向服务器发送文本服务器在接到客户端的请求之后它会根据协议文本的内容选择适当的命令函数并将各个参数从字符串文本转换为字符串对象比如说针对上面的命令例子将客户端的命令指针指向实现命令的函数并创建三个字符串对象分别保存和三个参数命令也算作参数每当命令函数成功执行之后命令参数都会被传播到程序以及程序本节不讨论这个列在这里只是为了完整性的考虑缓存追加当命令被传播到程序之后程序会根据命令以及命令的参数将命令从字符串对象转换回原来的协议文本比如说如果程序接受到的三个参数分别保存着和三个字符串那么它将生成协议文本协议文本生成之后它会被追加到结构的末尾结构维持着服务器的状态域则保存着所有等待写入到文件的协议文本文件写入和保存每当服务器常规任务函数被执行或者事件处理器被执行时函数都会被调用这个函数执行以下两个工作根据条件将中的缓存写入到文件根据条件调用或函数将文件保存到磁盘中两个步骤都需要根据一定的条件来执行而这些条件由所使用的保存模式来决定以下小节就来介绍所使用的三种保存模式以及在这些模式下步骤和的调用条件保存模式目前支持三种保存模式它们分别是不保存在这种模式下每次调用函数都会被执行但会被略过在这种模式下只会在以下任意一种情况中被执行这三种情况下的操作都会引起主进程阻塞被关闭功能被关闭系统的写缓存被刷新可能是缓存已经被写满或者定期保存操作被执行每一秒钟保存一次在这种模式中原则上每隔一秒钟就会执行一次因为操作是由后台子线程调用的所以它不会引起服务器主进程阻塞注意在上一句的说明里面使用了词语原则上在实际运行中程序在这种模式下对或的调用并不是每秒一次它和调用函数时所处的状态有关每当函数被调用时可能会出现以下四种情况根据以上说明可以知道在每一秒钟保存一次模式下如果在情况中发生故障停机那么用户最多损失小于秒内所产生的所有数据如果在情况中发生故障停机那么用户损失的数据是可以超过秒的官网上所说的在每一秒钟保存一次时发生故障只丢失秒钟数据的说法实际上并不准确子线程正在执行并且这个的执行时间未超过秒那么程序直接返回并不执行或新的这个已经执行超过秒那么程序执行但不执行新的注意因为这时的写入必须等待子线程先完成旧的因此这里会比平时阻塞更长时间子线程没有在执行并且上次成功执行距今不超过秒那么程序执行但不执行上次成功执行距今已经超过秒那么程序执行和每执行一个命令保存一次在这种模式下每次执行完一个命令之后和都会被执行另外因为是由主进程执行的所以在执行期间主进程会被阻塞不能接受命令请求总结模式是否阻塞是否阻塞停机时丢失的数据量阻塞阻塞操作系统最后一次对文件触发操作之后的数据阻塞不阻塞一般情况下不超过秒钟的数据阻塞阻塞最多只丢失一个命令的数据文件的读取和数据还原文件保存了的数据库状态而文件里面包含的都是符合通讯协议格式的命令文本这也就是说只要根据文件里的协议重新执行一遍里面指示的所有命令就可以还原的数据库状态了读取文件并还原数据库的详细步骤如下创建一个不带网络连接的伪客户端读取所保存的文本并根据内容还原出命令命令的参数以及命令的个数根据命令命令的参数和命令的个数使用伪客户端执行该命令执行和直到文件中的所有命令执行完毕完成第步之后文件所保存的数据库就会被完整地还原出来注意因为的命令只能在客户端的上下文中被执行而还原时所使用的命令来自于文件而不是网络所以程序使用了一个没有网络连接的伪客户端来执行命令伪客户端执行命令的效果和带网络连接的客户端执行命令的效果完全一样重写文件通过同步服务器所执行的命令从而实现了数据库状态的记录但是这种同步方式会造成一个问题随着运行时间的流逝文件会变得越来越大举个例子如果服务器执行了以下命令那么光是记录键的状态文件就需要保存四条命令而实质上我们其实只要保存最新状态的内存数据就可以另一方面有些被频繁操作的键对它们所调用的命令可能有成百上千甚至上万条如果这样被频繁操作的键有很多的话文件的体积就会急速膨胀对甚至整个系统的造成影响为了解决以上的问题需要对文件进行重写创建一个新的文件来代替原有的文件新文件和原有文件保存的数据库状态完全一样但新文件的体积小于等于原有文件的体积重写的实现所谓的重写其实是一个有歧义的词语实际上重写并不需要对原有的文件进行任何写入和读取它针对的是数据库中键的当前值如同上面对进行的四个操作后那么当前列表键在里的值就为如果我们要保存这个列表的当前状态并且尽量减少所使用的命令数那么最简单的方式不是去文件上分析前面执行的四条命令而是直接读取键在数据库的当前值然后用一条命令来代替前面的四条命令除了列表和集合之外字符串有序集哈希表等键也可以用类似的方法来保存状态并且保存这些状态所使用的命令数量比起之前建立这些键的状态所使用命令的数量要大大减少后台重写上一节展示的重写程序可以很好地完成创建一个新文件的任务但是在执行这个程序的时候调用者线程会被阻塞很明显作为一种辅佐性的维护手段不希望重写造成服务器无法处理请求所以决定将重写程序放到后台子进程里执行这样处理的最大好处是子进程进行重写期间主进程可以继续处理命令请求子进程带有主进程的数据副本使用子进程而不是线程可以在避免锁的情况下保证数据的安全性不过使用子进程也有一个问题需要解决因为子进程在进行重写期间主进程还需要继续处理命令而新的命令可能对现有的数据进行修改这会让当前数据库的数据和重写后的文件中的数据不一致为了解决这个问题增加了一个重写缓存这个缓存在出子进程之后开始启用主进程在接到新的写命令之后除了会将这个写命令的协议内容追加到现有的文件之外还会追加到这个缓存中换言之当子进程在执行重写时主进程需要执行以下三个工作处理命令请求将写命令追加到现有的文件中将写命令追加到重写缓存中这样一来可以保证现有的功能会继续执行即使在重写期间发生停机也不会有任何数据丢失所有对数据库进行修改的命令都会被记录到重写缓存中当子进程完成重写之后它会向父进程发送一个完成信号父进程在接到完成信号之后会调用一个信号处理函数并完成以下工作将重写缓存中的内容全部写入到新文件中对新的文件进行改名覆盖原有的文件当步骤执行完毕之后现有文件新文件和数据库三者的状态就完全一致了当步骤执行完毕之后程序就完成了新旧两个文件的交替这个信号处理函数执行完毕之后主进程就可以继续像往常一样接受命令请求了在整个后台重写过程中只有最后的写入缓存和改名操作会造成主进程阻塞在其他时候后台重写都不会对主进程造成阻塞这将重写对性能造成的影响降到了最低混合持久化为了集成了两者的优点提出了混合使用日志和内存快照也叫混合持久化既保证了重启速度又降低数据丢失风险混合持久化工作在日志重写过程当开启了混合持久化时在重写日志时出来的重写子进程会先将与主线程共享的内存数据以方式写入到文件然后主线程处理的操作命令会被记录在重写缓冲区里重写缓冲区里的增量命令会以方式写入到文件写入完成后通知主进程将新的含有格式和格式的文件替换旧的的文件也就是说使用了混合持久化文件的前半部分是格式的全量数据后半部分是格式的增量数据这样的好处在于重启加载数据的时候由于前半部分是内容这样加载的时候速度会很快加载完的内容后才会加载后半部分的内容这里的内容是后台子进程重写期间主线程处理的操作命令可以使得数据更少的丢失混合持久化优点混合持久化结合了和持久化的优点开头为的格式使得可以更快的启动同时结合的优点有减低了大量数据丢失的风险混合持久化缺点文件中添加了格式的内容使得文件的可读性变得很差兼容性差如果开启混合持久化那么此混合持久化文件就不能用在之前版本了管道管道并不是服务器直接提供的技术这个技术实际是由客户端提供的跟服务器没有本质关系的消息交互当我们使用客户端对进行一次操作时客户端将请求传送给服务器服务器处理完成后再将响应回复给客户端这就需要花费一个网络数据包来回的时间如果连续执行多条指令那就会花费多个网络数据包来回的时间从客户端层面上来看客户端时经历了发送请求接受响应发送请求接受响应这样那么我们实际上可以调整一下多个指令请求的请求响应顺序即发送请求发送请求接受请求接受请求这这样两个连续的发送请求操作和两个连续的等待请求响应操作总共只会花费一次网络来回这便是管道操作的本质服务器根本没有区别对待还是收到一条消息执行一条消息回复一条消息的正常流程客户端通过对管道中指令列表改变操作顺序就可以大幅节省时间管道中的指令越多效果越好管道压力测试自带了一个压力测试工具使用这个工具就可以进行管道测试首先我们对一个普通的指令进行压测大约加入管道选项参数它表示单个管道内并行的请求数量看下面时就可以达到发现到后面提高参数已经无法提高了这一般都是因为处理能力已经达到了瓶颈管道本质下面就介绍一下一个请求的交互流程客户端进行调用将消息写到操作系统内核为套接字分配的发送缓冲客户端操作系统内核将发送缓冲的内容发送到网卡网卡硬件将数据通过网际路由送到服务器网卡服务器操作系统内核将网卡的数据放到内核为套接字分配的接受缓冲服务器进程调用从接受缓冲区中取出消息进行处理服务器进程调用将响应消息写到内核为套接字分配的发送缓冲服务器操作系统内核将发送缓冲的内容发送到网卡网卡硬件将数据通过网际路由发送到客户端的网卡客户端操作系统内核将网卡的数据放到内核为套接字分配的接受缓冲客户端进程调用从接收缓冲区中取出消息返回给上层业务逻辑进行处理我们一开始可能以为操作要等到对方收到消息才返回但实际上不是这样的操作只负责将数据写到本地操作系统内核的发送缓冲区然后就返回了剩下的事交给操作系统内核异步将数据送到目标机器但是如果发送缓冲区满了那么就需要等待缓冲区空出这个就是写操作操作的真正耗时同理操作并不是从目标机器拉取数据操作只负责将数据从本地操作系统内核的接收缓冲区取出来就了事但是如果缓冲区是空的那么就需要等待数据到来这个就是读操作操作的真正耗时所以对于客户端的这样的命令来说操作几乎没有耗时直接写到发送缓冲区就返回而操作比较耗时了因为它要等待消息经过网络路由到目标机器处理后的响应消息再发送到当前内核读缓冲才可以返回这才是一个网络来回的真正开销而对于管道来说连续的操作根本就没有耗时之后第一个操作会等待一个网络的来回开销然后响应信息到达客户端系统内核的读缓冲了因为是连续发送且几乎没有耗时所以当第一个之后后续所有基本也同时随之到达读缓冲事务通过和四个命令来实现事务功能事务提供了一种将多个命令打包然后一次性按顺序地执行的机制并且事务在执行的期间不会主动中断服务器在执行完事务中的所有命令之后才会继续处理其他客户端的命令例子事务流程一个事务从开始到执行会经历三个阶段开始事务命令入队执行事务开始事务命令的执行标记着事务的开始这个命令唯一做的就是将客户端的选项打开让客户端从非事务状态切换到事务状态命令入队当客户端处于非事务状态下时所有发送给服务端的命令都会立即被服务器执行但是当客户端进入事务状态之后服务器在收到来自客户端的命令时不会立即执行命令而是将这些命令全部放进一个事务队列里然后返回表示命令已入队事务队列是一个数组每个数组项是都包含三个属性要执行的命令命令的参数参数的个数执行事务前面说到当客户端进入事务状态之后客户发送的命令就会被放进事务队列里但其实并不是所有的命令都会被放进事务队列其中的例外就是和这四个命令当这四个命令从客户端发送到服务器时它们会像客户端处于非事务状态一样直接被服务器执行如果客户端正处于事务状态那么当命令执行时服务器根据客户端所保存的事务队列以先进先出的方式执行事务队列中的命令最先入队的命令最先执行而最后入队的命令最后执行当事务队列里的所有命令被执行完之后命令会将回复队列作为自己的执行结果返回给客户端客户端从事务状态返回到非事务状态至此事务执行完毕事务的整个执行过程的伪代码表示创建空白的回复队列取出事务队列里的所有命令参数和参数数量执行命令并取得命令的返回值将返回值追加到回复队列末尾清除客户端的事务状态清空事务队列将事务的执行结果返回给客户端优化上面的事务在发送每个指令到事务缓存队列时都要经过一次网络读写当一个事务内部的指令较多时需要的网络时间也会线性增长所以通常客户端在执行事务时都会结合一起使用这样可以将多次操作压缩为单次操作事务里的命令无论是在事务状态下还是非事务状态下命令都是由同一个函数执行所有它们共享很多服务器的一般设置比如配置的配置以及内存限制等等事务中的命令执行和普通命令执行主要是两天区别非事务状态下的命令以单个命令执行为单位前一个命令和后一个命令不一定是同一个客户端而事务状态则是以一个事务为单位执行事务队列中的所有命令除非当前事务执行完毕否则服务器不会中断事务也不会执行其他客户端的命令在非事务状态下执行命令所得的结果会立即被返回给客户端而事务则将所有命令所得返回结果集合到回复队列再作为命令的结果返回给客户端和命令除了之外服务器在客户端处于事务状态下不加入到事务队列而执行的另外三个命令是和命令用于取消一个事务它清空客户端的整个事务队列然后将客户端从事务状态调整回非事务状态最后返回字符串给客户端说明事务已被取消的事务是不可嵌套的当客户端已经处于事务状态而客户端又再向服务器发送时服务器只是简单地向客户端发送一个错误然后继续等待其他命令的入队命令的发送不会造成整个事务失败也不会修改事务队列中已有的数据只能在客户端进入事务状态之前执行在事务状态下发送命令会引发一个错误但它不会造成整个事务失败也不会修改事务队列中已有的数据和前面处理的情况一样带的事务命令用于在事务开始之前监视任意数量的键当调用命令执行事务时如果任意一个被监视的键已经被其他客户端修改了那么整个事务不再执行直接返回失败以下示例展示了一个执行失败的事务例子第一个客户端执行第二个客户端执行在第一个客户端之后事务执行之前在第二个客户端中修改的值这样当第一个客户端的执行事务时会发现整个被监视的键已经被修改因此客户端的事务不会被执行而是直接返回失败命令的实现在每个代表数据的结构类型中都保存了一个字典字典的键这个数据库被监视的键而字典的值则是一个链表链表中保存了所有监视这个键的客户端其中键正在被和三个客户端监视其他一些键也分别被其他客户端监视着命令的作用就是将当前客户端和要监视的键在中进行关联举个例子如果当前客户端为那么当客户端执行时前面展示的将被修改成这个样子通过字典如果程序想检查某个键是否被监视那么它只要检查字典中是否存在这个键即可如果程序要获取监视某个键的所有客户端那么只要取出键的值一个链表然后对链表进行遍历即可的触发在任何对数据库键空间进行修改的命令成功执行之后比如诸如此类函数都会被调用它检查数据库的字典看是否有客户端在监视已经被命令修改的键如果有的话程序将所有监视这个这些被修改键的客户端的选项打开当客户端发送命令触发事务执行时服务器会对客户端的状态进行检查如果客户端的选项已经被打开那么说明被客户端监视的键至少有一个已经被修改了事务的安全性已经被破坏服务器会放弃执行这个事务直接向客户端返回空回复表示事务执行失败如果选项没有被打开那么说明所有监视键都安全服务器正式执行事务举个例子假设数据库的字典如下图所示如果某个客户端对进行了修改比如执行那么所有监视的客户端包括和的选项都会被打开当客户端和执行的时候它们的事务都会以失败告终最后当一个客户端结束它的事务时无论事务是成功执行还是失败字典中和这个客户端相关的资料都会被清除事务的性质传统数据库常常用性质来检验事务是否安全事务保证了一致性隔离性但并不能保证原子性和持久性原子性单个命令执行肯定是原子性的但没有在事务上增加任何维持原子性的机制所有事务的执行并不是原子性的如果一个事务队列中的所有命令都被成功地执行那么称这个事务执行成功另一方面如果服务器进程在执行事务的过程中被停止比如接到信号宿主机器停机等等那么事务执行失败当事务失败时也不会进行任何的重试或者回滚动作简单总结命令入队时就报错会放弃事务执行保证原子性命令入队时没报错实际执行时报错不保证原子性命令执行时实例故障如果开启日志可以保证原子性其保证的是部分原子性可以保证多个命令要么就一起执行要么就一起不执行但是不能保证多个命令要么一起执行成功要么都不执行成功入队后如果有命令执行失败其之前命令执行操作并不会回退其之后命令也照常执行一致性一致性表示事务执行结束后数据库的完整性约束没有被破坏事务执行的前后顺序都是合法数据状态实体完整性如行的主键存在且唯一列完整性如字段的类型大小长度要符合要求外键约束用户自定义完整性如转账前后两个账户余额的和应该不变的一致性问题可以分为三部分来讨论入队错误执行错误进程被终结入队错误在命令入队的过程中如果客户端向服务器发送了错误的命令比如命令的参数数量不对等等那么服务器将向客户端返回一个出错信息并且将客户端的事务状态设为当客户端执行命令时会拒绝执行状态为的事务并返回失败信息因此带有不正确入队命令的事务不会被执行也不会影响数据库的一致性执行错误如果命令在事务执行的过程中发生错误比如说对一个不同类型的执行了错误的操作那么只会将错误包含在事务的结果中这不会引起事务中断或整个失败不会影响已执行事务命令的结果也不会影响后面要执行的事务命令所以它对事务的一致性也没有影响进程被终结如果服务器进程在执行事务的过程中被其他进程终结或者被管理员强制杀死那么根据所使用的持久化模块可能由以下情况出现内存模块如果没有采取任何持久化机制那么重启后的数据库总是空白的所以数据总是一致的模块在执行事务时不会中断事务去执行保存的工作只有在事务执行之后保存的工作才可能开始所以当模式下的服务器进程在事务中途被杀死时事务内执行的命令不管成功了多少都不会被保存到文件里恢复数据库需要使用现有的文件而这个文件的数据保存的是最近一次的数据库快照所以它的数据可能不是最新的但只要文件本身没有因为其他问题而出错那么还原后的数据库就是一致的模式因为保存文件的工作在后台线程进行所以即使是在事务执行的中途保存文件的工作也可以继续进行因此根据事务语句是否被写入并保存到文件有以下两种情况发送如果事务语句未写入到文件或未被调用保存到磁盘那么当进程被杀死之后可以根据最近一次成功保存到磁盘的文件来还原数据库只要文件本身没有因为其他问题而出错那么还原后的数据库总是一致的但其中的数据不一定是最新的如果事务的部分语句被写入到文件中并且文件被成功保存那么不完整的事务执行信息就会遗留在文件里当重启时程序会检测到文件并不完整会退出并报告错误需要使用工具将部分成功的事务命令移除之后才能再次启动服务器还原之后的数据总是一致的而且数据也是最新的直到事务执行之前为止隔离性是单进程程序并且它保证在执行事务时不会对事务进行中断事务可以运行直到执行完所有事务队列中的命令为止因此的事务是总是带有隔离性的持久性因为事务不过是用队列包裹了一组命令并没有提供任何额外的持久性功能所以事务的持久性由所使用的持久化模块决定单纯的内存模式下事务肯定是不持久的在模块下服务器可能在事务执行之后文件更新之前的这段时间失败所以模式下的事务也不持久的在的总是模式下事务的每条命令在执行成功之后都会立即调用或将事务数据写入到文件但是这种保存是由后台线程进行的主线程不会堵塞直到保存成功所以命令执行成功到数据保存到硬盘之间还是有一段非常小的间隔所以这种模式下的事务也是不持久的其他模式也和总是模式类似所以它们都是不持久的小结事务提供了一种将多个命令打包然后一次性有序地执行的机制事务在执行过程中不会被中断所有事务命令执行完之后事务才能结束多个命令会被入队到事务队列中然后按先进先出的顺序执行带命令的事务会将客户端和被监视的键在数据库的字典中进行关联当键被修改时程序会将所有监视被修改键的客户端的选项打开只有在客户端的选项未被打开时才能执行事务否则事务直接返回失败的事务保证了中的一致性和隔离性但并不保证原子性和持久性订阅与发布通过等命令实现了订阅与发布模式这个功能提供两种信息机制分别是订阅发布到频道和订阅发布到模式下文先讨论订阅发布到频道的实现再讨论订阅发布到模式的实现频道的订阅与信息发送的命令可以让客户端订阅任意数量的频道每当有新消息发送到被订阅的频道时信息就会被发送给所有订阅指定频道的客户端当有新消息通过命令发送给频道时这个消息就会被发送给订阅它的三个客户端订阅频道每个服务器进程都维持着一个表示服务器状态的结构结构的属性是一个字典这个字典就用于保存订阅频道的信息其中字典的键为正在被订阅的频道而字典的值则是一个链表链表中保存了所有订阅这个频道的客户端比如说在下图展示的这个示例中和就订阅了而其他频道也分别被别的客户端所订阅当客户端调用命令时程序就将客户端和要订阅的频道在字典中关联起来举个例子如果客户端执行命令那么前面展示的将变成下面这个样子通过字典程序只要检查某个频道是否为字典的键就可以知道该频道是否正在被客户端订阅只要取出某个键的值就可以得到所有订阅该频道的客户端的信息发送信息到频道了解了字典的结构之后解释命令的实现就非常简单了当调用命令程序首先根据定位到字典的键然后将信息发送给字典值链表中的所有客户端比如说对于以下这个实例如果某个客户端执行命令那么和三个客户端都将接收到信息退订频道使用命令可以退订指定的频道这个命令执行的是订阅的反操作它从字典的给定频道键中删除关于当前客户端的信息这样被退订频道的信息就不会再发送给这个客户端模式的订阅与信息发送当使用命令发送信息到某个频道时不仅所有订阅该频道的客户端会收到信息如果有某个某些模式和这个频道匹配的话那么所有订阅这个这些频道的客户端也同样会受到信息下图展示了一个带有频道和模式的例子其中模式匹配了频道和频道并且有不同的客户端分别订阅它们三个当有信息发送到频道时信息除了发送给和之外还会发送给订阅模式的和另一方面如果接收到信息的是频道那么和同样会收到信息订阅模式属性是一个链表链表中保存着所有和模式相关的信息链表中的每个节点都包含一个结构属性保存着订阅模式的客户端而属性则保存着被订阅的模式每当调用命令订阅一个模式时程序就创建一个包含客户端信息和被订阅模式的结构并将该结构添加到链表中作为例子下图展示了一个包含两个模式的链表其中和都正在订阅模式如果这时客户端执行那么链表将被更新成这样通过遍历整个链表程序可以检查所有正在被订阅的模式以及订阅这些模式的客户端发送信息到模式发送信息到模式的工作也是由命令进行的除了将发送到所有订阅的客户端之外它还会将和中的模式进行对比如果和某个模式匹配的话那么也将发送到订阅那个模式的客户端举个例子如果服务器的状态如下那么当某个客户端发送信息到频道时除了所有订阅了频道的客户端会收到信息之外客户端和也同样会收到信息因为这两个客户端订阅的模式和频道匹配退订模式使用命令可以退订指定的模式这个命令执行的是订阅模式的反操作程序会删除链表中所有和被退订模式相关联的结构这样客户端就不会再收到和模式相匹配的频道发来的信息小结要点订阅信息由服务器进程维持的字典保存字典的键为被订阅的频道字典的值为订阅频道的所有客户端当有新消息发送到频道时程序遍历频道键所对应的值所有客户端然后将消息发送到所有订阅频道的客户端上订阅模式的信息由服务器进程维持的链表保存链表的每个节点都保存着一个结构结构中保存着被订阅的模式以及订阅该模式的客户端程序通过遍历链表来查找某个频道是否和某个模式匹配当有新消息发送到频道时除了订阅频道的客户端会收到消息之外所有订阅了匹配频道的模式的客户端也同样会收到消息退订频道和退订模式分别是订阅频道和订阅模式的反操作缺点的生产者产地过来一个消息会直接找到相应的消费者传递过去如果一个消费者也没有那么消息直接丢弃如果开始有三个消费者一个消费者突然挂掉了生产者会继续发送消息另外两个消费者可以持续受到消息但是挂掉的消费者重新连上的时候这断连期间生产者发送的消息对于这个消费者来说就彻底消失了如果停机重启的消息是不会持久化的毕竟宕机就相当于一个消费者都没有所有的消息直接丢弃正是因为有这些缺点它几乎找不到合适的应用场景所以的作者单独开启了一个项目专门做多播消息队列地址但是在新增了数据结构这个功能给带来了持久化消息队列从此可以消失了估计也不会发出它的正式版了集群模式主从复制我们知道要避免单点故障即保证高可用便需要冗余副本方式提供集群服务而提供了主从库模式以保证数据副本的一致主从库之间采用的是读写分离的方式主从复制概述主从复制是指将一台服务器的数据复制到其他的服务器前者称为主节点后者称为从节点数据的复制是单向的只能从主节点到从节点主从复制的作用主要包括数据冗余主从复制实现了数据的热备份是持久化之外的一种数据冗余方式故障恢复当主节点出现问题时可以由从节点提供服务实现快速的故障恢复实际上是一种服务的冗余负载均衡在主从复制的基础上配合读写分离可以由主节点提供写服务由从节点提供读服务即写数据时应用连接主节点读数据时应用连接从节点分担服务器负载尤其是在写少读多的场景下通过多个从节点分担读负载可以大大提高服务器的并发量高可用基石除了上述作用以外主从复制还是哨兵和集群能够实施的基础因此说主从复制是高可用的基础主从库之间采用的是读写分离的方式读操作主库从库都可以接收写操作首先到主库执行然后主库将写操作同步给从库在版本之前只有全量复制而版本之后有全量和增量复制全量同步复制比如第一次同步时增量同步复制只会把主从库网络断连期间主库收到的命令同步给从库全量复制当我们启动多个实例的时候它们相互之间就可以通过之前使用命令形成主库和从库的关系之后会按照三个阶段完成数据的第一次同步建立主从关系这里我们创建了两个实例查看所有容器的地址使用容器的命令行存入使用容器内的命令行查询未获取到值然后使用同步命令将作为从库建立主从关系并同步数据从上面的测试可以看到在建立主从关系后从库会慢慢从主库中同步全量数据全量复制的三个阶段第一阶段是主从库间建立连接协商同步的过程主要是为了全量复制做准备在这一步从库和主库建立连接并告诉主库即将开始进行同步主库确认回复后主从库间就可以开始同步了具体的来说从库给主库发送命令表示要进行数据同步主库根据这个命令的参数来启动复制命令包括了主库的和复制进度两个参数是每个实例启动时都会自动生成的一个随机用来唯一标记这个实例当从库和主库第一次复制时因为不知道主库的所以将设为此时设为表示第一次复制主库收到命令后会用响应命令带上两个参数主库和主库目前的复制进度返回给从库从库收到响应后会记录下这两个参数这里有个地方需要注意响应表示第一次复制采用的全量复制也就是说主库会把当前所有的数据都复制给从库第二个阶段主库将所有数据同步给从库从库收到数据后在本地完成数据加载这个过程依赖于内存快照生成文件具体来说主库执行命令生成文件接着将文件发送给从库从库接收到文件后会先清空当前数据库然后加载文件这是因为从库在通过命令开始和主库同步前可能保存了其他数据为了避免之前数据的影响从库需要先把当前数据库清空在主库将数据同步给从库的过程中主库不会被堵塞仍然可以正常接受请求但是请求中的写操作并没有记录到刚刚生成的文件中为了保证主从库的数据一致性主库会在内存中用专门的记录文件生成后收到的所有写操作第三个阶段主库会把第二阶段执行过程中新收到的写命令再发给从库具体的操作是当主库完成文件发送后就会把此时中的修改操作发给从库从库再重新执行这些操作这样以来主从库就实现同步了增量复制在版本引入了增量复制为什么会设计增量复制如果主从库在命令传播时出现了网络闪断那么从库就会和主库重新进行一次全量复制开销非常大从开始网络断了之后主从库会采用增量复制的方式继续同步增量复制流程先看两个概念和它是为了从库断开之后如何找到主从差异数据而设计的环形缓冲区从而避免全量复制带来的性能开销如果从库断开时间太久环形缓冲区被主库的写命令覆盖了那么从库连上主库后只能乖乖地进行一次全量复制所以配置尽量大一些可以降低主从断开后全量复制的概率而在中找主从差异的数据后如何发给从库呢这就用到了和客户端通信也好和从库通信也好都需要给分配一个内存进行数据交互客户端是一个从库也是一个我们每个连上后都会分配一个所有数据交互都是通过这个进行的先把数据写到这个中然后再把中的数据发到中再通过网络发送出去这样就完成了数据交互所以主从在增量同步时从库作为一个也会分配一个只不过这个专门用来传播用户的写命令到从库保证主从数据一致我们通常把它叫做对于这个问题来说有两个关键点如果在网络断开期间环形缓冲区写满之后从库是会丢失掉那部分被覆盖掉的数据还是直接进行全量复制呢一个从库如果和主库断连时间过长造成它在主库的位置上的数据已经被覆盖掉了此时从库和主库间将进行全量复制每个从库会记录自己的每个从库的复制进度也不一定相同在和主库重连进行恢复时从库会通过命令把自己记录的发给主库主库会根据从库各自的复制进度来决定这个从库可以进行增量复制还是全量复制更多理解当主服务器不进行持久化时复制的安全性强烈建议主服务器开启持久化如果真的不能开启持久化那么一定要禁止实例自动重启为什么不持久化的主服务器自动重启非常危险呢为了更好的理解这个问题看下面这个失败的例子其中主服务器和从服务器中数据库都被删除了我们设置节点为主服务器关闭持久化节点和从节点复制数据这时出现了一个崩溃但具有自动重启系统重启了进程因为关闭了持久化节点重启后只有一个空的数据集节点和从节点进行复制现在节点是空的所以节点和上的复制数据也会被删除当在高可用系统中使用关闭了主服务器的持久化并且允许自动重启这种情况是很危险的比如主服务器可能在很短的时间就完成了重启以至于都无法检测到这次失败那么上面说的这种失败的情况就发生了如果数据比较重要并且在使用主从复制时关闭了主服务器持久化功能的场景中都应该禁止实例自动重启为什么主从全量复制使用而不使用文件内容时经过压缩的二进制数据不同数据类型数据做了针对性优化文件很小而文件记录的是每一次写操作的命令写操作越多文件会变得很大其中还包括很多对同一个的多次冗余操作在主从全量数据同步时传输文件可以尽量降低对主库机器网络带宽的消耗从库在加载文件时一是文件小读取整个文件的速度会很快二是因为文件存储的都是二进制数据从库直接按照协议解析还原数据即可速度会非常快而需要依次重放每个写命令这个过程会经历冗长的处理逻辑恢复速度相比会慢得多所以使用进行主从全量复制的成本最低假设要使用做全量复制意味着必须打开功能打开功能就要选择文件的刷盘的策略选择不当会严重影响性能而只有在需要定时备份和主从全量复制数据时才会触发生成一次快照而在很多就是数据不敏感的业务场景其实时不需要开启的为什么有无磁盘复制模式默认时磁盘复制但是如果使用比较低速的磁盘这种操作会给主服务器带来比较大的压力从版本开始尝试支持无磁盘的复制使用这种设置时子进程直接将通过网络发送给从服务器不使用磁盘作为中间存储无磁盘复制模式创建一个新进程直接到的不经过主进程不经过硬盘适用于较慢并且网络较快的时候使用配置参数来启动无磁盘复制使用参数来配置传输开始的延迟时间等待一个的秒数如果没来的话就直接传后来的得排队等了否则就可以一起传为什么还有从库的从库的设计通过分析主从库间第一次数据同步的过程你可以看到一次全量复制中对于主库来说需要完成两个耗时的操作生成文件和传输文件如果从库数量很多而且都要和主库进行全量复制的话就会导致主库忙于子进程生成文件进行数据全量复制这个操作会阻塞主线程处理正常请求从而导致主库响应应用程序的请求速度变慢此外传输文件也会占用主库的网络带宽同样会给主库的资源使用带来压力那么有没有好的解决方法可以分担主库压力呢其实是有的这就是主从从模式在刚才介绍的主从库模式中所有的从库都是和主库连接所有的全量复制也都是和主库进行的现在我们可以通过主从从模式将主库生成和传输的压力以级联的方式分散到从库上简单来说我们在部署主从集群的时候可以手动选择一个从库比如选择内存资源配置较高的从库用于级联其他的从库然后我们可以再选择一些从库例如三分之一的从库在这些从库上执行如下命令让它们和刚才所选的从库建立起主从关系所选从库的这样一来这些从库就会知道在进行同步时不用再和主库进行交互了只要和级联的从库进行写操作同步就行了这就可以减轻主库上的压力如下图所示级联的主从从模式好了到这里我们了解了主从库间通过全量复制实现数据同步的过程以及通过主从从模式分担主库压力的方式那么一旦主从库完成了全量复制它们之间就会一直维护一个网络连接主库会通过这个连接将后续陆续收到的命令操作再同步给从库这个过程也称为基于长连接的命令传播可以避免频繁建立连接的开销读写分离及其中的问题在主从复制基础上实现的读写分离可以实现的读负载均衡由主节点提供写服务由一个或者多个从节点提供读服务多个从节点既可以提供数据冗余程度也可以最大化读负载能力在读负载较大的应用场景下可以大大提高服务器的并发量下面介绍在使用读写分离时需要注意的问题延迟与不一致问题前面已经讲到由于主从复制的命令传播是异步的延迟与数据的不一致不可避免如果应用对数据不一致的接受程度程度较低可能的优化措施包括优化主从节点之间的网络环境如在同机房部署监控主从节点延迟通过判断如果从节点延迟过大通知应用不再通过该从节点读取数据使用集群同时扩展写负载和读负载等在命令传播阶段以外的其他情况下从节点的数据不一致可能更加严重例如连接在数据同步阶段或从节点失去与主节点的连接时等从节点的参数便与此有关它控制这种情况下从节点的表现如果为默认值则从节点仍能够响应客户端的命令如果为则从节点只能响应等少数命令该参数的设置与应用对数据一致性的要求有关如果对数据一致性要求很高则应设置为数据过期问题在单机版中存在两种删除策略惰性删除服务器不会主动删除数据只有当客户端查询某个数据时服务器判断该数据是否过期如果过期则删除定期删除服务器执行定时任务删除过期数据但是考虑到内存和的折中删除会释放内存但是频繁的删除操作对不友好该删除的频率和执行时间都受到了限制在主从复制场景下为了主从节点的数据一致性从节点不会主动删除数据而是由主节点控制从节点中过期数据的删除由于主节点的惰性删除和定期删除策略都不能保证主节点及时对过期数据执行删除操作因此当客户端通过从节点读取数据时很容易读取到已经过期的数据中从节点在读取数据时增加了对数据是否过期的判断如果该数据已过期则不返回给客户端将升级到可以解决数据过期问题故障切换问题在没有使用哨兵的读写分离场景下应用针对读和写分别连接不同的节点当主节点或从节点出现问题而发生更改时需要及时修改应用程序读写数据的连接连接的切换可以手动进行或者自己写监控程序进行切换但前者响应慢容易出错后者实现复杂成本都不算低总结在使用读写分离之前可以考虑其他方法增加的读负载能力如尽量优化主节点减少慢查询减少持久化等其他情况带来的阻塞等提高负载能力使用集群同时提高读负载能力和写负载能力等如果使用读写分离可以使用哨兵使主从节点的故障切换尽可能自动化并减少对应用程序的侵入集群模式哨兵机制在上文主从复制的基础上如果节点出现故障该怎么办在集群中哨兵机制是实现主从库自动切换的关键机制它有效的解决了主从复制模式下的故障转移的问题其与版本开始引用哨兵是一个独立的进程作为进程它会独立运行其原理是哨兵通过发送命令等待服务器响应从而监控运行的多个实例哨兵实现了什么功能呢下面是官方文档的描述监控哨兵会不断地检查主节点和从节点是否运作正常自动故障转移当主节点不能正常工作时哨兵会开始自动故障转移操作它会将失效主节点的其中一个从节点升级为新的主节点并让其他从节点改为复制新的主节点配置提供者客户端在初始化时通过连接哨兵来获得当前服务的主节点地址通知哨兵可以将故障转移的结果发送给客户端其中监控和自动故障转移功能使得哨兵可以及时发现主节点故障并完成转移而配置提供者和通知功能则需要在与客户端的交互中才能体现哨兵集群的搭建上图中哨兵集群式如何组建起来的哨兵实例之间相互发现要归功于提供的机制即发布订阅机制在主从集群中主库上由一个名为的频道不同哨兵就是通过它来相互发现实现互相通信的在下图哨兵把自己的和端口发布到频道上哨兵和订阅了该频道那么此时哨兵和就可以从这个频道直接获取哨兵的地址和端口号然后哨兵可以和哨兵建立网络连接通过这个方式哨兵也可以建立网络连接这样一来哨兵集群就形成了它们相互间可以通过网络连接进行通信比如说对主库有没有下线这件事儿进行判断和协商哨兵监控库哨兵监控什么并且如何完成监控的这是由哨兵向主库发送命令完成的如下图哨兵给主库发送命令主库接受到这个命令后就会把从库列表返回给哨兵接着哨兵就可以根据从库列表中的连接信息和每个从库建立连接并在这个连接上持续的对从库进行监控哨兵和可以通过相同的方法和从库建立连接哨兵的工作内容每个以每秒钟一次的频率向它所知的以及其他实例发送一个命令心跳机制如果一个实例距离最后一次有效回复命令的时间超过选项所指定的值则这个实例会被标记为主观下线如果一个被标记为主观下线则正在监视这个的所有要以每秒一次的频率确认的确进入了主观下线状态确认投票下线当有足够数量的大于等于配置文件指定的值在指定的时间范围内确认的确进入了主观下线状态则会被标记为客观下线在一般情况下每个会以每秒一次的频率向它已知的所有发送命令同步数据当被标记为客观下线时向下线的的所有发送命令的频率会从秒一次改为每秒一次若没有足够数量的同意已经下线的客观下线状态就会被移除若重新向的命令返回有效回复的主观下线状态就会被移除主库下线的判定哨兵如何判断主库已经下线了首先要区别两个概念主观下线任何一个哨兵都是可以监控探测并作出下线的判断客观下线有哨兵集群共同决定节点是否下线当某个哨兵判断主库主观下线后就会给其他哨兵发送命令接着其他哨兵会根据自己和主库的连接情况做出或的响应相当于赞成票相当于反对票如果赞成票数是大于等于哨兵配置文件中的配置项比如这里如果则就可以判定主库客观下线了哨兵集群的选举判断完主库下线后由哪个哨兵节点来执行主从切换呢这里就需要哨兵集群的选举机制了为什么必然会出现选举共识机制为了避免哨兵的单点情况发生所以需要一个哨兵的分布式集群作为分布式集群必然涉及到共识问题即选举问题哨兵的选举机制是什么样的发现主库客观下线的哨兵节点这里称为向每个哨兵节点发送命令要求对方选举自己为领头哨兵如果目标哨兵没有选举过其他人则同意将选举为领头哨兵如果发现有超过半数且超过参数值的哨兵节点同意选自己成为领头哨兵则哨兵成功选举为领头哨兵集群执行故障转移时需要选举此时涉及到代表集群中大部分节点的个数只有大于等于个节点给某个节点投票才能确定该节点为的计算方式为当有多个哨兵节点同时参与领头哨兵选举时出现没有任何节点当选可能此时每个参选节点等待一个随机时间进行下一轮选举直到选出领头哨兵任何一个想要执行主从切换操作的哨兵要满足两个条件第一拿到半数以上的赞成票第二拿到的票数同时还需要大于等于哨兵配置文件中的值以个哨兵为例假设此时的设置为那么任何一个想成为的哨兵只要拿到张赞成票就可以了更进一步理解这里很多人会搞混判定客观下线和是否能够主从切换用到选举机制两个概念我们再看一个例子主从个哨兵哨兵配置为如果个哨兵故障当主库宕机时哨兵能否判断主库客观下线能否自动切换经过实际测试哨兵集群可以判定主库主观下线由于所以当一个哨兵判断主库主观下线后询问另外一个哨兵后也会得到同样的结果个哨兵都判定主观下线达到了的值因此哨兵集群可以判定主库为客观下线但哨兵不能完成主从切换哨兵标记主库客观下线后在选举哨兵领导者时一个哨兵必须拿到超过多数的选票票但目前只有个哨兵活着无论怎么投票一个哨兵最多只能拿到票永远无法达到选票的结果新主库的选出故障转移主库既然判定客观下线了并且选举出了领头哨兵那么如何从剩余的节点从库中选择一个新的主库呢过滤掉不健康的下线或断线没有回复过哨兵响应的从节点选择从节点优先级最高的选择复制偏移量最大即复制主节点最完整的从节点新的主库选择出来了就可以开始进行故障的转移了假设根据我们一开始的图我们假设判断主库客观下线了同时选出是哨兵故障转移流程如下将脱离原从节点中应该是升级主节点将从节点指向新的主节点通知客户端主节点已更换将原主节点变成从节点指向新的主节点集群模式高可用集群前面两节主从复制和哨兵机制保障了高可用就读写分离而言虽然节点扩展了主从的读并发能力但是写能力和存储能力是没有得到扩展如果面对海量数据写入就必须构建主节点分片之间的集群同时必然需要吸收高可用主从复制和哨兵机制能力即每个分片节点还需要由节点这是分布式系统中典型的纵向扩展集群的分片技术是一种服务器技术分片和路由都是在服务端实现采用多主多从每一个分区都是由一个主机和多个从机组成片区和片区之间是相互平行的集群采用了的模式完全去中心化如上图官方推荐集群部署至少要台以上的节点好使用主从六个节点的模式集群具有如下几个特点集群完全去中心化采用多主多从所有的节点彼此互联机制内部使用二进制协议优化传输速度和带宽客户端与节点直连不需要中间代理层客户端不需要连接集群所有节点连接集群中任何一个可用节点即可每一个分区都是由一个主机和多个从机组成分片和分片之间是相互平行的每一个节点负责维护一部分槽以及槽所映射的键值数据集群中每个节点都有全量的槽信息通过槽每个都知道具体数据存储到哪个上哈希槽没有使用一致性而是引入了哈希槽的概念中有的次方个哈希槽每个通过校验后对取模来决定放置在哪个槽中的每个节点负责一部分槽一致性在算法章节说比如集群中存在三个节点则可能存在下面类似分配节点包含到号哈希槽节点包含到号哈希槽节点包含到哈希槽哈希槽为什么不直接哈希槽这样就可以有个值这是因为节点发送心跳包时需要将所有的槽放到这个心跳包如果需占用空间而只占用并且一般情况下集群主节点数量基本不可能超过个超过个一般会导致网络堵塞如果更少虽然能进一步降低心跳包大小但是会更容易出现碰撞概率命中失效所以比较合理因为分布在不同节点所以操作就会受限实际场景比如这类命令会操作多个事务在一个事务中会操作多个脚本在脚本中也会操作多个提供了一种途径用来将多个分配到相同的中这时中实现操作的基础包含一个字符并且如果在这个的右面有一个字符并且如果在和之间存在至少一个字符例如和这两个会被到相同的中因为只有会被用来计算值这个不会启用因为第一个和之间没有字符这个中全部内容会被用来计算这个中的会被用来计算计算而不会请求重定向采用去中心化的架构集群的主节点各自负责一部分槽客户端如何确定到底会映射到哪个节点上呢这就涉及到请求重定向在模式下节点对请求的处理过程如下检查当前是否存在于当前通过有效部分使用函数计算散列值再对取余计算出的编号计算得到键对应的槽后需要查找槽所对应的节点集群内通过消息交换每个节点都会知道所有节点的槽信息从而得到负责该槽的节点指针若不是由自身负责则返回重定向若由自身负责且在中则返回该对应结果若不存在此中检查该是否正在迁出正在迁出返回错误重定向客户端到迁移的目的服务器上若未迁出检查是否在导入中若导入中且由标记则直接操作否则返回重定向请求处理过程中可能涉及到两个重定向分别时重定向重定向重定向通过计算和本地缓存得到负责的节点一般就去请求了但是可能有两种情况槽命中直接返回结果槽不命中即当前键命令所请求的键不在当前请求的节点中则当前节点会向客户端发送一个重定向客户端根据重定向所包含的内容找到目标节点再一次发送命令会帮你自动重定向如果没有集群方式启动即没加参数不会自动重定向由于本地会缓存映射的存在所以绝大部分时候都不会触发而是用来协助客户端更新映射重定向集群伸缩时集群伸缩会导致槽迁移槽迁移过程中一个槽内的会分为多个批次依次迁移所以存在一部分数据在源节点一般部分数据在迁移的目标节点重定向由此诞生出现上述情况客户端的命令执行流程如下客户端根据本地缓存发送命令到源节点如果存在键对象则直接执行并返回结果给客户端如果键对象不存在则可能存在于目标节点这时源节点会回复重定向异常格式如下客户端从重定向异常中提取目标节点信息发送命令到目标节点打开客户端连接标识再执行键命令如果存在则执不存在则返回不存在信息两者的区别与虽然都是对客户端的重定向控制但是有着本质区别重定向说明集群正在进行数据迁移客户端无法知道什么时候迁移完成因此只能是临时性的重定向客户端不会更新缓存但是重定向说明键对应的槽已经明确指定到新的节点因此需要更新缓存故障转移集群自身实现了高可用高可用首先需要解决集群部分失败的场景当集群内少量节点出现故障时通过自动故障转移保证集群可以正常对外提供服务集群内节点通过消息实现节点通信消息不但可以传播节点槽信息还可以传播其他状态如主从状态节点故障等因此故障发现也是通过消息传播机制实现的主要环节包括主观下线和客观下线主观下线流程当某个节点判断另一个节点主观下线后相应的节点状态会跟随消息在集群内传播消息的消息体会携带集群的其他节点状态数据当接受节点发现消息体中含有主观下线的节点状态时会在本地找到故障节点的结构保存到下线报告链表中通过消息传播集群内节点不断收集到故障节点的下线报告当半数以上持有槽的主节点都标记某个节点是主观下线时触发客观下线流程故障恢复故障节点变为客观下线后如果下线节点是持有槽的主节点则需要在它的从节点中选出一个替换它从而保证集群的高可用下线主节点的所有从节点承担故障恢复的义务当从节点通过内部定时任务发现自身复制的主节点进入客观下线时将会触发故障恢复流程从节点与主节点断线时间超过则当前从节点不具备故障转移资格参数用于从节点的有效因子默认为当从节点符合故障转移资格后更新触发故障选举的时间只有到达该时间后才能执行后续流程这里之所以采用延迟触发机制主要是通过对多个从节点使用不同的延迟选举时间来支持优先级问题复制偏移量越大说明从节点延迟越低那么它应该具有更高的优先级来替换故障主节点发起选举集群没有直接使用从节点进行领导者选举主要因为从节点数必须大于等于个才能保证凑够个节点将导致从节点资源浪费使用集群内所有持有槽的主节点进行领导者选举即使只有一个从节点也可以完成选举过程当从节点收集到个持有槽的主节点投票时从节点可以执行替换主节点操作预估故障转移时间毫秒主观下线识别时间主观下线状态消息传播时间消息通信机制对超过未通信节点会发起消息消息体在选择包含哪些节点时会优先选取下线状态节点所以通常这段时间内能够收集到半数以上主节点的报告从而完成故障发现从节点转移时间毫秒由于存在延迟发起选举机制偏移量最大的从节点会最多延迟秒发起选举通常第一次选举就会成功故障转移时间跟参数息息相关默认秒配置时可以根据业务容忍度做出适当调整但不是越小越好脑裂问题什么是脑裂在主从架构中部署方式一般是一主多从主节点提供写操作从节点提供读操作如果主节点的网络突然发生了问题它与所有的从节点都失联了但是此时的主节点和客户端的网络是正常的这个客户端并不知道内部已经出现了问题还在照样的向这个失联的主节点写数据过程此时这些数据被旧主节点缓存到了缓冲区里因为主从节点之间的网络问题这些数据都是无法同步给从节点的这时哨兵也发现主节点失联了它就认为主节点挂了但实际上主节点正常运行只是网络出问题了于是哨兵就会在从节点中选举出一个作为主节点这时集群就有两个主节点了脑裂出现了脑裂可能会导致数据丢失然后网络突然好了哨兵因为之前已经选举出一个新主节点了它就会把旧主节点降级为从节点然后从节点会向新主节点请求数据同步因为第一次同步是全量同步的方式此时的从节点会清空掉自己本地的数据然后再做全量同步所以之前客户端在过程写入的数据就会丢失了也就是集群产生脑裂数据丢失的问题总结一句话就是由于网络问题集群节点之间失去联系主从数据不同步重新平衡选举产生两个主服务等网络恢复旧主节点会降级为从节点再与新主节点进行同步复制的时候由于会从节点会清空自己的缓冲区所以导致之前客户端写入的数据丢失了解决方案当主节点发现从节点下线或者通信超时的总数量小于阈值时那么禁止主节点进行写数据直接把错误返回给客户端在的配置文件中有两个参数我们可以设置主节点必须要有至少个从节点连接如果小于这个数主节点会禁止写数据主从数据复制和同步的延迟不能超过秒如果超过主节点会禁止写数据我们可以把和这两个配置项搭配起来使用分别给它们设置一定的阈值假设为和这两个配置项组合后的要求是主库连接的从库中至少有个从库和主库进行数据复制时的消息延迟不能超过秒否则主库就不会再接收客户端的写请求了即使原主库是假故障它在假故障期间也无法响应哨兵心跳也不能和从库进行同步自然也就无法和从库进行确认了这样一来和的组合要求就无法得到满足原主库就会被限制接收客户端写请求客户端也就不能在原主库中写入新数据了等到新主库上线时就只有新主库能接收和处理客户端请求此时新写的数据会被直接写到新主库中而原主库会被哨兵降为从库即使它的数据被清空了也不会有新数据丢失再来举个例子假设我们将设置为把设置为把哨兵的设置为主库因为某些原因卡住了导致哨兵判断主库客观下线开始进行主从切换同时因为原主库卡住了没有一个从库能和原主库在内进行数据复制原主库也无法接收客户端请求了这样一来主从切换完成后也只有新主库能接收请求不会发生脑裂也就不会发生数据丢失的问题了状态检测及维护中节点状态如何维护呢这些就涉及有哪些状态底层协议及具体的通讯机制中每个节点都维护一份在自己看来当前整个集群的状态主要包括当前集群的状态集群中各节点所负责的信息及其状态集群中各节点的状态集群中各节点的存活状态及不可达投票当集群状态发生变化如如新节点加入迁移节点宕机提升为新我们希望这些变化尽快的被发现传播到整个集群的所有节点并达成一致节点之间相互的心跳及其携带的数据是集群状态传播最主要的途径协议通讯底层是协议所以需要对协议有一定了解协议又称协议是基于流行病传播方式的节点或者进程之间信息交换的协议在分布式系统中被广泛使用比如我们可以使用协议来确保网络中所有节点的数据一样协议已经是网络中比较成熟的协议了协议的最大的好处是即使集群节点的数量增加每个节点的负载也不会增加很多几乎是恒定的这就允许管理的集群规模能横向扩展到数千个节点算法又被称为反熵熵是物理学上的一个概念代表杂乱无章而反熵就是在杂乱无章中寻求一致这充分说明了的特点在一个有界网络中每个节点都随机地与其他节点通信经过一番杂乱无章的通信最终所有节点的状态都会达成一致每个节点可能知道所有其他节点也可能仅知道几个邻居节点只要这些节可以通过网络连通最终他们的状态都是一致的当然这也是疫情传播的特点上面的描述都比较学术其实协议对于我们吃瓜群众来说一点也不陌生协议也成为流言协议说白了就是八卦协议这种传播规模和传播速度都是非常快的你可以体会一下所以计算机中的很多算法都是源自生活而又高于生活的协议的使用集群是去中心化的彼此之间状态同步考协议通讯集群的消息有以下几种类型通过命令已有集群的节点会向新的节点发送邀请加入现有集群节点每秒会向集群中其他节点发送消息消息中带有自己已知的两个节点的地址槽状态信息最后一次通信时间等节点收到消息后会回复消息消息中同样带有自己已知的两个节点信息节点不通某节点后会向集群所有节点广播该节点挂掉的消息其他节点收到消息后标记已下线基于协议的故障检测集群中每个节点都会定期地向集群中其他节点发送消息以此交换各个节点状态信息检测各个节点状态在线状态疑似下线状态已下线状态自己保存信息当主节点通过消息得知主节点认为主节点进入了疑似下线状态时主节点会在自己的字典中找到主节点所对应的结构并将主节点的下线报告添加到结构的链表中并后续关于结点疑似下线的状态通过协议通知其他节点一起裁定如果集群里面半数以上的主节点都将主节点报告为疑似下线那么主节点将被标记为已下线状态将主节点标记为已下线的节点会向集群广播主节点的消息所有收到消息的节点都会立即更新里面主节点状态标记为已下线最终裁定将标记为需要满足以下两个条件有半数以上的主节点将标记为状态当前节点也将标记为状态通讯状态和维护我们理解了协议基础后就可以进一步理解节点之间相互的通讯心跳实现和维护了什么时候进行心跳节点会记录其向每个节点上次发出和收到的时间心跳发送时机与这两个值有关通过下面的方式既能保证及时更新集群状态又不至于使心跳数过多每次向所有未建立链接的节点发送或每秒从所有已知节点中随机选取个向其中上次收到最久远的一个发送每次向收到超过的节点发送收到或立即回复发送那些心跳数据发送者自己的信息所负责的的信息主从信息信息状态信息发送者所了解的部分其他节点的信息信息状态信息比如发送者认为该节点已经不可到达会在状态信息中标记其为或如何处理心跳新节点加入发送包加入集群从包中的得到未知的其他节点循环上述过程直到最终加入集群信息判断发送者声明的信息跟本地记录的是否不同如果不同且发送者较大更新本地记录如果不同且发送者较小发送信息通知发送者信息发现发送者的信息变化更新本地状态节点探测故障发现的存在使得集群状态的改变可以更快的达到整个集群每个心跳包中会包含多个包那么多少个才是合适的呢的选择是其中是节点数这样可以保证在投票的过期时间内节点可以收到机器关于失败节点的从而使其顺利进入状态超过超时时间仍然没有收到包的节点会被当前节点标记为标记会随着传播每次收到心跳包会检测其中对其他节点的标记当做对该节点的的投票维护在本机对某个节点的标记达到大多数时将其变为标记并广播消息只能通过心跳传递信息当需要发布一些非常重要需要立即发送的信息时上述心跳的方式就显得捉襟见肘了这时就需要向所有集群内机器广播信息使用广播发的场景节点的信息当发现某一个节点不可达时探测节点会将其标记为状态并通过心跳传播出去当某一个节点发现这个节点的超过半数时修改其为并发起广播信息尝试发起时广播其要求投票的信息新信息成功的节点向整个集群广播自己的信息扩容缩容当集群出现容量限制或者其他一些原因需要扩容时提供了比较优雅的集群扩容方案首先将新节点加入到集群中可以通过在集群中任何一个客户端执行新节点端口或者通过添加新添加的节点默认在集群中都是主节点迁移数据迁移数据的大致流程是首先需要确定哪些槽需要被迁移到目标节点然后获取槽中将槽中的全部迁移到目标节点然后向集群所有主节点广播槽数据全部迁移到了目标节点直接通过工具做数据迁移很方便现在假设将节点的槽迁移到节点过程如下循环获取槽中将迁移到节点向集群广播槽已经迁移到节点缩容的大致过程与扩容一致需要判断下线的节点是否是主节点以及主节点上是否有槽若主节点上有槽需要将槽迁移到集群中其他主节点槽迁移完成之后需要向其他节点广播该节点准备下线最后需要将该下线主节点的从节点指向其他主节点当然最好是先将从节点下线分析是的分布式实现就如同官方文档里强调的其设计优先考虑的是高性能和线性扩展能力尽量保证这里所说的丢失是指回复客户端响应后后续请求中出现未做变更或者丢失的情况导致该问题主要在主从切换实例重启脑裂三种情况下主从切换被动情景为主节点负责其对应的从节点是当挂掉后在最多倍的时间内把标记成进而触发逻辑在成功切换为前仍然由负责访问也会报错当切换为后广播路由变更在这个过程中访问仍然可以得到正常回应而访问其他持有老路由的请求会被到挂掉的访问报错问题如果写到上的数据还没来得及同步到就挂掉了那么这部分数据就会丢失重启后不存在操作即写入的数据丢失回复于同步几乎同时进行的这种情况很少发生时间窗口小但是这存在这个风险主动主动通过在上执行命令触发完整的可以概括为以下步骤该命令的三个选项分别由不同的行为发起请求消息携带标识阻塞停服时间为倍目前版本为追赶主从复制数据开始发起选举并最终当选切换自身接管并广播新的路由信息其他节点更改路由路由打平默认选项执行完整的流程由停服行为因此不存在丢失问题选项从第四步开始执行在统计选票阶段仍然可以正常接收用户请求且主从异步复制这些都可能导致丢失将在未来的某个时间点开始执行时间为现版本为每次都会检查选项从第五步开始执行直接增加自己的无需其他同意接管从切换为到原更新路由这段期间发送到原从的请求都可能存在丢失的可能一般在一个的时间内完成时间窗口很小和以外节点更新路由滞后只会带来多一次的错误不会导致丢失重启结构体中有一个成员变量表示的全局状态控制着当前是否可以提供服务有以下两种取值状态初始化重启后被初始化为此状态下的是拒绝访问的这对保证是非常必要的可以想象如果挂掉后对应的通过选举成功当选为新此时重启且恰好有一些看到的路由没有更新它们仍然会往上写数据如果接受这些就会丢数据才是这个大家公认的所以重启后需要先禁用服务直到路由变更完成所以如果内未能更新路由可能就导致丢失状态变更什么时候才会出现的状态变更呢从定时任务中可以知道状态变更要延迟毫秒当前版本是访问延迟就是为等待路由变更那么什么时候触发路由变更呢一个新刚启动它与其他进行通信的都是在里检查出来后会依次连接并发送作为一个路由过期的老节点收到其他节点发来的消息更改自身路由毫秒后节点恢复访问我们认为的时间窗口足够更新路由网络分区网络分区发生由于网络的不可靠网络分区时一个必须要考虑的问题当网络分区发生后被割裂成和两部分这里以分区中的节点来区分对于部分会发起选举但是不能收到大多数的选票也就无法完成正常的流程同时在里的大部分节点会被标记为状态进而触发集群状态更新在中状态在一段时间后会被更改为但对于一个划分到的节点在状态更改前是一直可以访问的这就有一个时间窗口会导致丢失在函数中可以计算出这个时间窗口大小从时间开始算起时间后才会有标记为加上消息传播会偏向于携带的节点节点不必等到把遍就可以把标记为可以推算出时间窗口大约为另外会记录下禁用服务的时间即对于部分会发起选举切换为新的并提供服务如果时间小于以至于没有标识出现就不会有丢失网络分区恢复当网络分区恢复后中老的重新加进要想提供服务就必须先将状态从修改为那么应该什么时候改呢我们知道老中应该是旧路由此时它应该变更为所以还是需要等待一段时间做路由变更否则有可能出现丢失的问题从函数的逻辑里可以看出时间窗口为总结可能因为选举和主从异步复制数据偏差带来丢失重启通过延迟等状态变更为可以重新访问不存在丢失中的部分在状态变更为之前可能存在丢失恢复后通过延迟等状态变更为可以重新访问不存在丢失分析主要在三种情况下出现不可用网络故障在发生网络分区后部分是不可用的假设部分有过半数和所有不在的其下的一个那么经过时间加额外几秒钟给进行恢复可用状态缺失故障默认情况下当检测到有没有绑定就会停止接受请求在这种配置下三主三从如果部分节点挂掉一个主节点和其对应的从节点都挂了也就是说一个范围内的不再有节点负责最终整个会变的不能提供服务有时候服务部分可用比整个不可用更有意义因此即使一部分可用也要让提供服务将这种选择权交到了用户手中里提供参数如果该参数为那么有未绑定或者确实也是可以接受请求的当集群节点宕机出现集群节点个数小于个的时候或者集群可用节点个数为偶数的时候基于这种选举机制的自动主从切换过程可能会不能正常工作标记以及选举新的过程都可能异常功能举个例子如果一个包含个的集群每个有唯一单个出现故障必定仍然可用第二个再出现再出现故障如果第二个节点正好是上面已经故障的节点的则此时集群不可用如果第二个节点是其他节点则集群仍然可用所以集群不可用的概率是为了提高可用性这个是用于在每次故障之后重新布局集群的给没有的配备上以此来更好应对下次故障具体实现这种负责部分但是没有健康的就称为当检测到自己的拥有不少于个健康且中恰好有时触发函数逻辑尝试进行漂移步骤有如下四步集群漂移非集群本来旧无法正常接收请求所以也不需要漂移检查参数提供了参数用来决定数量达到多少个才会把冗余漂移出去只有健康的个数超过配置的数量时才会漂移选出要漂移的以及漂移给谁选择最小的漂移给遍历到的第一个执行漂移在期间有一段时间是没有为了防止误漂漂移必须有一定的延迟时间为现版本为六分布式锁分布式锁是控制分布式系统不同进程共同访问共享资源的一种锁的实现秒杀下单抢红包等等业务场景都需要用到分布式锁常见分布式锁一般分布式锁有如下几种实现方案命令分开写加锁设置过期时间业务处理释放锁如果执行完加锁正要执行设置过期时间进行或者重启维护那么这个锁就一直被锁住了别的线程永远获取不到锁了所以分布式不能这种实现值过期时间为了解决方案一发生异常锁得不到释放的场景系统时间设置的过期时间如果当前锁不存在返回加锁成功如果锁已经存在获取锁的过期时间如果获取到的过期时间小于系统当前时间表示已经过期锁已过期获取上一个锁的过期时间并设置现在锁的过期时间考虑多线程并发的情况只有一个线程的设置值和当前值相同它才可以加锁其他情况均返回加锁失败这一方案巧妙移除了单独设置过期时间的操作把过期时间放到了的值中解决了发生异常锁得不到释放的问题但是此方案也有自己的缺点过期时间是客户端自己生成的是当前系统的时间必须要求分布式环境下每个客户端的时间必须同步如果锁过期的时候并发多个客户端同时请求过来都执行最终只能有一个客户端加锁成功但是该客户端锁的过期时间可能被别的客户端覆盖该锁没有保存持有者的唯一标识可能被别的客户端释放解锁的扩展命令的扩展参数是原子性的设定的过期时间时间单位是秒设定的过期时间单位是毫秒表示不存在的时候才能成功也即保证只有第一个客户端请求才能获取锁而其他客户端请求只能等起释放锁才能获取仅当存在时设置值加锁业务处理释放锁但是呢这个方案还是可能存在问题问题一锁过期释放了业务还没执行完假设线程获取锁成功一直在执行临界区的代码但是过去后它还没执行完但是这时候锁已经过期了此时线程又请求过来显然线程就可以获得锁成功也开始执行临界区的代码那么问题就来了临界区的业务代码都不是严格串行执行的啦问题二锁被别的线程误删假设线程执行完后去释放锁但是它不知道当前的锁可能是线程持有的线程去释放锁时有可能过期时间已经到了此时线程进来占有了锁那线程就把线程的锁释放掉了但是线程临界区业务代码可能都还没执行完呢校验唯一随机值再删除既然锁可能被别的线程误删那我们给值设置一个标记当前线程唯一的随机数在删除的时候校验一下不就了嘛伪代码如下加锁业务处理判断是不是当前线程加的锁是才释放释放锁在这里判断是不是当前线程加的锁和释放锁不是一个原子操作如果调用释放锁的时候可能这把锁已经不属于当前客户端会解除他人加的锁因为部分执行时不能保证原子性一般也是用脚本代替的解决方案单机方案其实上面的方案还是会存在锁过期释放业务没有执行完的问题所以其实我们可以开启一个定时守护线程每隔一段时间检查锁是否还存在存在则对锁过期时间延长防止锁过期提前释放只要线程加锁成功就会启动一个它是一个后台线程会每隔秒检查一下锁如果线程还持有锁那么就会不断的延长锁的过期时间因此解决了业务还没执行完锁就过期释放的问题基于故障转移的算法上面的所有的方案都是基于单机版的然而实际上生产环境都是集群部署直接在主从集群中使用上面的方案会有如下问题客户端在的节点上拿到了锁但是这个锁还没有同步到节点上节点就发生了故障然后进行了故障转移节点升级为节点因此客户端加的锁丢失了因此作者基于分布式环境下提出了一种更高级的分布式锁的实现方式架构图应用前提在的分布式环境中我们假设有个这些节点完全互相独立不存在主从复制或者其他集群协调机制我们确保将在个实例上使用与在单实例下相同方法获取和释放锁现在我们假设有个节点同时我们需要在台服务器上面运行这些实例这样保证他们不会同时都宕掉实现步骤获取当前的时间戳依次尝试向个实例使用相同的和具有唯一性的例如获取锁客户端请求各实例获取锁时应有设置响应超时时间并且这个响应超时时间尽量远小于锁的失效时间如此设计的原因是因为我们不能在已经挂掉的上花费太多时间如果花费太多时间会造成还没向全部请求完锁的失效时间就已经到了因此如果服务器端没有在规定时间内响应客户端应该尽快尝试去另外一个实例请求获取锁客户端使用当前时间减去开始获取锁的时间步骤记录的时间就可以得到获取锁所用的时间当且仅当从大多数这里是个节点的节点都取到锁并且整个过程使用的时间小于锁失效时间时锁才算获取成功如果取到了锁的真正有效时间等于有效时间减去获取锁所使用的时间步骤计算的结果如果因为某些原因获取锁失败没有在至少个实例取到锁或者取锁时间已经超过了有效时间客户端应该在所有的实例上进行解锁即便某些实例根本就没有加锁成功防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁七应用问题与双写一致性如何保证一旦出现数据更新与数据库之间的数据一致性问题就会出现一致性就是数据保持一致在分布式系统中可以理解为多个节点中数据的值是一致的强一致性这种一致性级别是最符合用户直觉的它要求系统写入什么读出来的也会是什么用户体验好但实现起来往往对系统的性能影响大弱一致性这种一致性级别约束了系统在写入成功后不承诺立即可以读到写入的值也不承诺多久之后数据能够达到一致但会尽可能地保证到某个时间级别比如秒级别后数据能够达到一致状态最终一致性最终一致性是弱一致性的一个特例系统会保证在一定时间内能够达到一个数据一致的状态这里之所以将最终一致性单独提出来是因为它是弱一致性中非常推崇的一种一致性模型也是业界在大型分布式系统的数据一致性上比较推崇的模型是选择更新缓存还是删除缓存如果线程先更新数据库之后线程也向数据库中更新同一值但是请求快先写入了缓存后写入了缓存那么实际上缓存中还是旧值而数据库中是更改后的新值导致数据最终不一致但是你选择的是删除缓存那么在最后一次删除缓存后请求再来时会查询数据库最新数据那么就避免了这个问题所以我们选择删除缓存不管是先删除缓存再更新数据库还是先更新数据库再删除缓存都有可能存在数据不一致的情况先删除缓存再更新数据库在删除缓存后更新数据库前就可能会有个请求获取缓存此时缓存没有它就去查数据库了就得到了脏数据并将脏数据塞入了缓存中这就导致了缓存与数据库最终不一致先更新数据库再删除缓存在删除缓存之前去读到的都是脏数据在并发写不高删除失败概率不大时可以一定程度实现最终一致性但是在并发写较高就会出现下面的情况此时再有线程进来读取缓存就会读取到就是但是实际数据库中这就导致了数据最终不一致此方案可以考虑在写并发极低的情况下使用但是综合来看上面两个方案即使在不考虑删除可能失败的情况也不能保证缓存和数据库数据最终一致延迟双删延迟双删再上面方案的基础上增加了一步延迟一定时间后再删除缓存从而避免方案造成的脏数据存在缓存中达到下面左图到效果这样就可以实现数据最终一致性但是我们也可以清楚的发现如果延迟时间不够很有可能会出现的写入缓存操作在第二次删除缓存之后发生那么此时数据又会出现不一致的情况所以我们应当设置一个合理的延迟时间但是即使合理也不能说一定能保证在任何情况下写入操作都在第二次删缓存之后异步更新缓存基于的同步机制通过数据变更跟踪将缓存与数据库的一致性同步从业务中独立出来统一处理保证数据一致性整体思路更新写数据库后会产生数据变更记录中有日志中有变更表通过数据变更记录来更新中数据这里可以使用来实现对数据库变更数据的追踪处理数据变更记录存入消息队列消费者有序实现更新上面的所有方案中都没有考虑删除缓存失败的可能如果考虑删除缓存失败可能所有方案都保证不了数据最终一致性所以在删除缓存这一操作可以考虑失败重试或者将需要删除的存入消息队列中依次保证删除缓存的成功从整个大局来看我们会发现如果缓存不设置过期时间是比较容易造成与数据库最终一致性难以保证的最简单的方法就是设置过期时间这样即使脏数据在缓存中也不会存在很久个人看法小团队或者小项目可以考虑使用方案设置过期时间较大项目可以考虑使用方案的大如何处理什么是大大并不是指的值很大而是对应的很大一般而言下面这两种情况被称为大类型的值大于类型的元素的个数超过个大会造成什么问题大会带来以下四种影响客户端超时阻塞由于执行命令是单线程处理然后在操作大时会比较耗时那么就会阻塞从客户端这一视角看就是很久很久都没有响应引发网络阻塞每次获取大产生的网络流量较大如果一个的大小是每秒访问量为那么每秒会产生的流量这对于普通千兆网卡的服务器来说是灾难性的阻塞工作线程如果使用删除大时会阻塞工作线程这样就没办法处理后续的命令内存分布不均集群模型在分片均匀情况下会出现数据和查询倾斜情况部分有大的节点占用内存多也会比较大如何找到大查找大可以通过命令查找大使用的时候注意事项最好选择在从节点上执行该命令因为主节点上执行时会阻塞主节点如果没有从节点那么可以选择在实例业务压力的低峰阶段进行扫描查询以免影响到实例的正常运行或者可以使用参数控制扫描间隔避免长时间扫描降低实例的性能该方式的不足之处这个方法只能返回每种类型中最大的那个无法得到大小排在前位的对于集合类型来说这个方法只统计集合元素个数的多少而不是实际占用的内存量但是一个集合中的元素个数多并不一定占用的内存就多因为有可能每个元素占用的内存很小这样的话即使元素个数有很多总内存开销也不大使用命令查找大使用命令对数据库扫描然后用命令获取返回的每一个的类型对于类型可以直接使用命令获取字符串的长度也就是占用的内存空间字节数对于集合类型来说有两种方法可以获得它占用的内存大小如果能够预先从业务层知道集合元素的平均大小那么可以使用下面的命令获取集合元素的个数然后乘以集合元素的平均大小这样就能获得集合占用的内存大小了类型命令类型命令类型命令类型命令如果不能提前知道写入集合的元素大小可以使用命令需要及以上版本查询一个键值对占用的内存空间使用工具查找大使用第三方开源工具可以用来解析快照文件找到其中的大比如下面这条命令将大于的输出到一个表格文件如何优化大对大进行拆分和压缩例如将含有数万成员的一个拆分为多个使用方法获得值并确保每个的成员数量在合理范围这样的拆分主要是为了减少单台操作的压力而是将压力平摊到集群各个实例中降低单台机器的操作对大可以进行清理将不适用能力的数据存至其它存储并在中删除此类数据在集群架构中对热进行复制在集群架构中由于热的迁移粒度问题无法将请求分散至其他数据分片导致单个数据分片的压力无法下降此时可以将对应热进行复制并迁移至其他数据分片例如将热复制出个内容完全一样的并名为将这三个迁移到其他数据分片来解决单个数据分片的热压力使用读写分离架构如果热的产生来自于读请求您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力甚至可以不断地增加从节点但是读写分离架构在增加业务代码复杂度的同时也会增加集群架构复杂度如何选择持久化策略优点是数据恢复速度快但是快照的频率不好把握频率太低丢失的数据就会比较多频率太高就会影响性能优点是丢失数据少但是数据恢复不快为了集成了两者的优点提出了混合使用日志和内存快照也叫混合持久化既保证了重启速度又降低数据丢失风险混合持久化工作在日志重写过程当开启了混合持久化时在重写日志时出来的重写子进程会先将与主线程共享的内存数据以方式写入到文件然后主线程处理的操作命令会被记录在重写缓冲区里重写缓冲区里的增量命令会以方式写入到文件写入完成后通知主进程将新的含有格式和格式的文件替换旧的的文件也就是说使用了混合持久化文件的前半部分是格式的全量数据后半部分是格式的增量数据这样的好处在于重启加载数据的时候由于前半部分是内容这样加载的时候速度会很快加载完的内容后才会加载后半部分的内容这里的内容是后台子进程重写期间主线程处理的操作命令可以使得数据更少的丢失混合持久化优点混合持久化结合了和持久化的优点开头为的格式使得可以更快的启动同时结合的优点有减低了大量数据丢失的风险混合持久化缺点文件中添加了格式的内容使得文件的可读性变得很差兼容性差如果开启混合持久化那么此混合持久化文件就不能用在之前版本了八涉及的算法一致性问题的由来大多数应用背后肯定不只有一台服务器提供服务因为高可用或并发量的需要都会使用多台服务器组成集群对外提供服务那么问题来了这么多服务器要如何分配客户端请求呢其实这个问题就是负载均衡问题了解决负载均衡问题的算法很多不同的负载均衡算法适用于不同的应用场景和需求一般最简单的方式就是引入一个中间的负载均衡层让它将外界的请求轮流转发给内部的集群比如集群有三个节点并收到了个请求那么每个节点都会处理一个请求考虑到每个节点的硬件配置有区别一般引用权重值按不同节点的权重值来分配请求让处理能力更抢的节点分担更多请求但是这种加权轮询使用场景是建立前提每个节点存储的数据都是相同的这样访问任意一个节点都可以获取相同的结果但是这就无法应对分布式系统因为分布式系统每个节点存储的数据是不同的比如分布式存储系统一般为了提高系统的容量就会把数据水平切分到不同的节点来存储比如某个应该到哪个或者那些节点上获的应该是确定的而不是任意访问一个节点都可以获取对应的直接使用哈希算法很容易就会想到算法其可以通过一个进行哈希计算每次都可以得到相同的值这样就可以将某个确定到一个节点了可以满足分布式系统的负载均衡需求哈希算法最简单的做法就是进行取模运算比如分布式系统中有个节点基于公式对数据进行了映射如果客户端要获取指定的数据通过上面的公式定位节点但是这有一个很致命的问题如果节点数据发生了变化也就是在对系统做扩容或者缩容时可能造成大部分映射关系改变并且必须迁移改变了映射关系的数据否则会查询不到数据的问题假设总数据条数为哈希算法在面对节点数量变化时最坏情况下所有数据都需要迁移所以它的数据迁移规模时这样数据迁移成本太高使用一致性哈希算法有什么问题一致性哈希算法就很好地解决了分布式系统在扩容或者缩容时发生过多的数据迁移的问题一致哈希算法也用了取模运算但于哈希算法不同的是哈希算法是对节点数量进行取模而一致哈希算法是对进行取模运算们可以把一致哈希算法是对进行取模运算的结果值组织成一个圆环这个圆想可以想象成由个点组成的圆这个圆环被称为哈希环如下图一致性哈希要进行两步哈希第一步对存储节点进行哈希计算也就是对存储节点做哈希映射比如根据节点的地址进行哈希第二步当对数据进行存储或访问时对数据进行哈希映射所以一致性哈希是指将存储节点和数据都映射到一个首尾相连的哈希环上问题来了对数据进行哈希映射得到一个结果要怎么找到存储该数据的节点呢答案是映射的结果值往顺时针的方向的找到第一个节点就是存储该数据的节点举个例子有个节点经过哈希计算映射到了如下图的位置接着对要查询的进行哈希计算确定此映射在哈希环的位置然后从这个位置往顺时针的方向找到第一个节点就是存储该数据的节点比如下图中的映射的位置往顺时针的方向找到第一个节点就是节点所以当需要对指定的值进行读写的时候要通过下面步进行寻址首先对进行哈希计算确定此在环上的位置然后从这个位置沿着顺时针方向走遇到的第一节点就是存储的节点知道了一致哈希寻址的方式我们来看看如果增加一个节点或者减少一个节点会发生大量的数据迁移吗假设节点数量从增加到了新的节点经过哈希计算后映射到了下图中的位置你可以看到都不受影响只有需要被迁移节点假设节点数量从减少到了比如将节点移除你可以看到和不会受到影响只有需要被迁移节点因此在一致哈希算法中如果增加或者移除一个节点仅影响该节点在哈希环上顺时针相邻的后继节点其它数据也不会受到影响上面这些图中个节点映射在哈希环还是比较分散的所以看起来请求都会均衡到每个节点但是一致性哈希算法并不保证节点能够在哈希环上分布均匀这样就会带来一个问题会有大量的请求集中在一个节点上比如下图中个节点的映射位置都在哈希环的右半边这时候有一半以上的数据的寻址都会找节点也就是访问请求主要集中的节点上这肯定不行的呀说好的负载均衡呢这种情况一点都不均衡另外在这种节点分布不均匀的情况下进行容灾与扩容时哈希环上的相邻节点容易受到过大影响容易发生雪崩式的连锁反应比如上图中如果节点被移除了当节点宕机后根据一致性哈希算法的规则其上数据应该全部迁移到相邻的节点上这样节点的数据量访问量都会迅速增加很多倍一旦新增的压力超过了节点的处理能力上限就会导致节点崩溃进而形成雪崩式的连锁反应所以一致性哈希算法虽然减少了数据迁移量但是存在节点分布不均匀的问题通过虚拟节点提高均衡度要想解决节点能在哈希环上分配不均匀的问题就是要有大量的节点节点越多哈希环上的节点分布就越均匀但问题是实际上我们没有那么多节点所以这个时候我们就加入虚拟节点也就是对一个真实节点做多个副本具体做法是不再将真实节点映射到哈希环上而是将虚拟节点映射到哈希环上并将虚拟节点映射到实际节点所以这里有两层映射关系比如对每个节点分别设置个虚拟节点对节点加上编号来作为虚拟节点对节点加上编号来作为虚拟节点对节点加上编号来作为虚拟节点引入虚拟节点后原本哈希环上只有个节点的情况就会变成有个虚拟节点映射到哈希环上哈希环上的节点数量多了倍你可以看到节点数量多了后节点在哈希环上的分布就相对均匀了这时候如果有访问请求寻址到这个虚拟节点接着再通过虚拟节点找到真实节点这样请求就能访问到真实节点了上面为了方便你理解每个真实节点仅包含个虚拟节点这样能起到的均衡效果其实很有限而在实际的工程中虚拟节点的数量会大很多比如的一致性哈希算法每个权重为的真实节点就含有个虚拟节点另外虚拟节点除了会提高节点的均衡度还会提高系统的稳定性当节点变化时会有不同的节点共同分担系统的变化因此稳定性更高比如当某个节点被移除时对应该节点的多个虚拟节点均会移除而这些虚拟节点按顺时针方向的下一个虚拟节点可能会对应不同的真实节点即这些不同的真实节点共同分担了节点被移除导致的压力而且有虚拟节点的概念也方便了对不同节点进行权重区分硬件配置更好的节点增加更多虚拟节点总结轮训这类的策略只能适用与每个节点的数据都是相同的场景访问任意节点都能请求到数据但是不适用分布式系统因为分布式系统意味着数据水平切分到了不同的节点上访问数据的时候一定要寻址存储该数据的节点哈希算法虽然能建立数据和节点的映射关系但是每次在节点数量发生变化的时候最坏情况下所有数据都需要迁移这样太麻烦了所以不适用节点数量变化的场景为了减少迁移的数据量就出现了一致性哈希算法一致性哈希是指将存储节点和数据都映射到一个首尾相连的哈希环上如果增加或者移除一个节点仅影响该节点在哈希环上顺时针相邻的后继节点其它数据也不会受到影响但是一致性哈希算法不能够均匀的分布节点会出现大量请求都集中在一个节点的情况在这种情况下进行容灾与扩容时容易出现雪崩的连锁反应为了解决一致性哈希算法不能够均匀的分布节点的问题就需要引入虚拟节点对一个真实节点做多个副本不再将真实节点映射到哈希环上而是将虚拟节点映射到哈希环上并将虚拟节点映射到实际节点所以这里有两层映射关系引入虚拟节点后可以会提高节点的均衡度还会提高系统的稳定性所以带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景而且适合节点规模会发生变化的场景摘录文章设计与实现第一版美团二面与双写一致性如何保证',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2025-06-07 20:51:22',
  postMainColor: '',
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#18171d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#f7f9fe')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(e => {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.3.0"></head><body data-type="anzhiyu"><div id="web_bg"></div><div id="an_music_bg"></div><div id="loading-box" onclick="document.getElementById(&quot;loading-box&quot;).classList.add(&quot;loaded&quot;)"><div class="loading-bg"><img class="loading-img nolazyload" alt="加载头像" src="https://npm.elemecdn.com/anzhiyu-blog-static@1.0.4/img/avatar.jpg"/><div class="loading-image-dot"></div></div></div><script>const preloader = {
  endLoading: () => {
    document.getElementById('loading-box').classList.add("loaded");
  },
  initLoading: () => {
    document.getElementById('loading-box').classList.remove("loaded")
  }
}
window.addEventListener('load',()=> { preloader.endLoading() })
setTimeout(function(){preloader.endLoading();},10000)

if (true) {
  document.addEventListener('pjax:send', () => { preloader.initLoading() })
  document.addEventListener('pjax:complete', () => { preloader.endLoading() })
}</script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.10/progress_bar/progress_bar.css"/><script async="async" src="https://cdn.cbd.int/pace-js@1.2.4/pace.min.js" data-pace-options="{ &quot;restartOnRequestAfter&quot;:false,&quot;eventLag&quot;:false}"></script><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><div id="nav-group"><span id="blog_name"><a id="site-name" href="/" accesskey="h"><div class="title">凌霄博客</div><i class="anzhiyufont anzhiyu-icon-house-chimney"></i></a></span><div class="mask-name-container"><div id="name-container"><a id="page-name" href="javascript:anzhiyu.scrollToDest(0, 500)">PAGE_NAME</a></div></div><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle/"><i class="anzhiyufont anzhiyu-icon-artstation faa-tada" style="font-size: 0.9em;"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/bangumis/"><i class="anzhiyufont anzhiyu-icon-bilibili faa-tada" style="font-size: 0.9em;"></i><span> 追番页</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-conditioner/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> 小空调</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div></div><div id="nav-right"><div class="nav-button" id="randomPost_button"><a class="site-page" onclick="toRandomPost()" title="随机前往一个文章" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-dice"></i></a></div><div class="nav-button" id="search-button"><a class="site-page social-icon search" href="javascript:void(0);" title="搜索🔍" accesskey="s"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span> 搜索</span></a></div><input id="center-console" type="checkbox"/><label class="widget" for="center-console" title="中控台" onclick="anzhiyu.switchConsole();"><i class="left"></i><i class="widget center"></i><i class="widget right"></i></label><div id="console"><div class="console-card-group-reward"><ul class="reward-all console-card"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png" target="_blank"><img class="post-qr-code-img" alt="微信" src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png" target="_blank"><img class="post-qr-code-img" alt="支付宝" src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div><div class="console-card-group"><div class="console-card-group-left"><div class="console-card" id="card-newest-comments"><div class="card-content"><div class="author-content-item-tips">互动</div><span class="author-content-item-title"> 最新评论</span></div><div class="aside-list"><span>正在加载中...</span></div></div></div><div class="console-card-group-right"><div class="console-card tags"><div class="card-content"><div class="author-content-item-tips">兴趣点</div><span class="author-content-item-title">寻找你感兴趣的领域</span></div></div><div class="console-card history"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-box-archiv"></i><span>文章</span></div><div class="card-archives"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-archive"></i><span>归档</span></div><ul class="card-archive-list"><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2025/06/"><span class="card-archive-list-date">六月 2025</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">7</span><span>篇</span></div></a></li><li class="card-archive-list-item"><a class="card-archive-list-link" href="/archives/2024/12/"><span class="card-archive-list-date">十二月 2024</span><div class="card-archive-list-count-group"><span class="card-archive-list-count">2</span><span>篇</span></div></a></li></ul></div><hr/></div></div></div><div class="button-group"><div class="console-btn-item"><a class="darkmode_switchbutton" title="显示模式切换" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-moon"></i></a></div><div class="console-btn-item" id="consoleHideAside" onclick="anzhiyu.hideAsideBtn()" title="边栏显示控制"><a class="asideSwitch"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></a></div><div class="console-btn-item" id="consoleMusic" onclick="anzhiyu.musicToggle()" title="音乐开关"><a class="music-switch"><i class="anzhiyufont anzhiyu-icon-music"></i></a></div></div><div class="console-mask" onclick="anzhiyu.hideConsole()" href="javascript:void(0);"></div></div><div class="nav-button" id="nav-totop"><a class="totopbtn" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i><span id="percent" onclick="anzhiyu.scrollToDest(0,500)">0</span></a></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);" title="切换"><i class="anzhiyufont anzhiyu-icon-bars"></i></a></div></div></div></nav><div id="post-info"><div id="post-firstinfo"><div class="meta-firstline"><a class="post-meta-original">原创</a><span class="post-meta-categories"><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-inbox post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E5%90%8E%E7%AB%AF/" itemprop="url">后端</a></span><span class="article-meta tags"></span></div></div><h1 class="post-title" itemprop="name headline">Redis学习笔记</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="anzhiyufont anzhiyu-icon-calendar-days post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" itemprop="dateCreated datePublished" datetime="2025-06-06T16:00:00.000Z" title="发表于 2025-06-07 00:00:00">2025-06-07</time><span class="post-meta-separator"></span><i class="anzhiyufont anzhiyu-icon-history post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" itemprop="dateCreated datePublished" datetime="2025-06-07T12:51:22.024Z" title="更新于 2025-06-07 20:51:22">2025-06-07</time></span></div><div class="meta-secondline"><span class="post-meta-separator"></span><span class="post-meta-pv-cv" id="" data-flag-title="Redis学习笔记"><i class="anzhiyufont anzhiyu-icon-fw-eye post-meta-icon"></i><span class="post-meta-label" title="阅读量">阅读量:</span><span id="busuanzi_value_page_pv"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-spin"></i></span></span><span class="post-meta-separator">       </span><span class="post-meta-position" title="作者IP属地为杭州"><i class="anzhiyufont anzhiyu-icon-location-dot"></i>杭州</span></div></div></div><section class="main-hero-waves-area waves-area"><svg class="waves-svg" xmlns="http://www.w3.org/2000/svg" xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M -160 44 c 30 0 58 -18 88 -18 s 58 18 88 18 s 58 -18 88 -18 s 58 18 88 18 v 44 h -352 Z"></path></defs><g class="parallax"><use href="#gentle-wave" x="48" y="0"></use><use href="#gentle-wave" x="48" y="3"></use><use href="#gentle-wave" x="48" y="5"></use><use href="#gentle-wave" x="48" y="7"></use></g></svg></section><div id="post-top-cover"><img class="nolazyload" id="post-top-bg" src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250607204045262.png"></div></header><main id="blog-container"><div class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container" itemscope itemtype="http://example.com/2025/06/07/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"><header><a class="post-meta-categories" href="/categories/%E5%90%8E%E7%AB%AF/" itemprop="url">后端</a><h1 id="CrawlerTitle" itemprop="name headline">Redis学习笔记</h1><span itemprop="author" itemscope itemtype="http://schema.org/Person">XR</span><time itemprop="dateCreated datePublished" datetime="2025-06-06T16:00:00.000Z" title="发表于 2025-06-07 00:00:00">2025-06-07</time><time itemprop="dateCreated datePublished" datetime="2025-06-07T12:51:22.024Z" title="更新于 2025-06-07 20:51:22">2025-06-07</time></header><h1 id="Redis学习笔记"><a href="#Redis学习笔记" class="headerlink" title="Redis学习笔记"></a>Redis学习笔记</h1><p> Redis诞生于2009年，作为一个基于内存的键值型NoSQL数据库。其有如下特点</p>
<ul>
<li>键值（key-value）型，value支持多种不同数据结构，</li>
<li>单线程，每个命令具有原子性。不存在很多并发带来的问题。但是此单线程只是指代命令是但线程执行的，其他模块还有各自的线程。6.0版本中引入了多线程，但指代的是 IO多线程，如：网络数据的读写和协议解析时多线程。</li>
<li>低延迟、速度快（基于内存、IO多路复用、良好的编码）</li>
<li>支持数据持久化</li>
<li>支持主从集群、分片集群</li>
<li>支持多语言客户端</li>
</ul>
<h2 id="一、Redis-的安装"><a href="#一、Redis-的安装" class="headerlink" title="一、Redis 的安装"></a>一、Redis 的安装</h2><h3 id="1-1-Redis-安装（window）"><a href="#1-1-Redis-安装（window）" class="headerlink" title="1.1 Redis 安装（window）"></a>1.1 Redis 安装（window）</h3><p>下方提供 Redis 各个版本的下载页面，我这里下载的是 3.2.100 版本。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/microsoftarchive/redis/releases">https://github.com/microsoftarchive/redis/releases</a></p>
<p>将下载包 解压到本地目录，然后在 redis目录下进行 cmd ，输入不同的命令进行不同的安装方式：</p>
<ul>
<li><p>临时服务安装如果你仅仅是用作学习使用，可以选择此安装方式。在 redis目录下 使用cmd 执行以下命令：redis-server.exe  redis.windows.conf该命令会创建 Redis 临时服务，生成的信息表明了 redis 在本机的 6379 端口提供服务。该种方式，不能关闭此 cmd 窗口，如果关闭则会停止 Redis 服务。<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779113128-ac60fad7-e10e-436c-af9d-67273d4e024e.png" alt="img">保持 Redis 服务窗口开启状态，双击 redis目录下的 redis-cli.exe 即可使用 命令行操控 redis 。比如这里 使用 set 命令，存储了一个键值对 uid：1，然后通过 get 将键 uid 对应的值取出。<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779113107-4136bd49-5e0e-45b0-b024-f5ac7d019f96.png" alt="img"></p>
</li>
<li><p>默认服务安装这种方式不用像临时安装方式一样，每次去打开 redis 临时服务，而且像正常服务一样开机自启。进入 Redis 目录下，通过cmd输入redis-server.exe –service-install redis.windows.conf –loglevel verbose<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779113047-a2d84234-558c-4ca4-ae91-0564d9534dca.png" alt="img">通过命令行可以发现，我们已经将redis作为服务安装好了。但是你可能不能在window的服务列表中找到，redis服务必须通过命令行启动、暂停和卸载</p>
</li>
<li><ul>
<li>启动服务：redis-server.exe –service-start</li>
<li>暂停服务redis-server.exe –service-stop</li>
<li>卸载服务redis-server.exe –service-uninstall</li>
</ul>
</li>
<li><p>自定义服务安装自定义服务安装，就是将服务重命名。进入 Redis 安装包下，输入redis-server.exe –service-install redis.windows.conf –Service-name RedisServer1 –loglevel verbose这里起的名字是 RedisServer1 。与默认安装一样，不同的是在启动、暂停、卸载服务时 需要加上自定义的 Redis 服务名redis-server.exe –service-start –Service-name RedisServer1redis-server.exe –service-stop –Service-name RedisServer1redis-server.exe –service-uninstall –Service-name RedisServer1</p>
</li>
<li><p>主从服务安装即像一般的数据库的主从库一样，redis也可以配置主从库。配置的方法很简单，就是通过<strong>自定义服务器安装</strong>方式安装两个服务。<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779111633-3351c423-c9db-4128-a4d6-3561b5e963a8.png" alt="img">修改两个服务里 redis.windows.conf 文件：主服务器（RedisServer1）：保持其 port 6379从服务器（RedisServer2）：修改</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">port 6380</span><br><span class="line"> slaveof 127.0.0.1 6379</span><br></pre></td></tr></table></figure>

<p>修改配置文件后，依次启动服务。然后可以在 双击主服务文件夹下的 redis-cli，去执行一个添加键值操作。双击执行 从服务器文件夹下的 redis-cli，去取出键name 对应的值，你就发现可以取到。在 Window 上 直接删除服务的方法：使用管理员权限 打开 cmd ，然后输入sc delete 服务名</p>
<h3 id="1-2-Redis-安装（docker）"><a href="#1-2-Redis-安装（docker）" class="headerlink" title="1.2 Redis 安装（docker）"></a>1.2 Redis 安装（docker）</h3><ul>
<li>下拉最新的 redis 镜像，并检查是否下拉成功</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull redis:latest</span><br><span class="line">docker images</span><br></pre></td></tr></table></figure>

<ul>
<li>运行容器，并映射到宿主机端口docker run -it -d –name redis-test -p 6379:6379 redis</li>
<li>查看是否运行成功（查看容器运行信息）docker ps</li>
<li>通过 redis-cli 连接使用 redis 服务</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-test /bin/bash</span><br><span class="line">redis-cli</span><br></pre></td></tr></table></figure>

<h3 id="1-3-Redis-配置"><a href="#1-3-Redis-配置" class="headerlink" title="1.3 Redis 配置"></a>1.3 Redis 配置</h3><p>redis.config 常见配置：</p>
<ul>
<li>bind 0.0.0.0 监听的地址默认是127.0.0.1，这使得只能本地访问。如果修改成 0.0.0.0 则可以在任意 IP 地址访问。</li>
<li>daemonize yes守护进程，修改为 yes 之后，即可后台运行</li>
<li>requirepass 111111密码，设置后访问 Redis 必须输入密码</li>
<li>port 6379监听的端口，默认就是 6379</li>
<li>dir .工作目录，默认是当前目录，也就是运行 redis-server 时的命令，日志、持久化等文件都会保存在这个目录</li>
<li>databases 1数据库数量，设置为1，代表只使用1个库，默认有16个库，编号 0-15</li>
<li>maxmemory 512mb设置 redis 能够使用的最大内存</li>
<li>logfile “redis.log”日志文件，默认为空，不记录日志，可以指定日志文件名。</li>
</ul>
<p>启动时，指定配置文件 </p>
<p>redis-server redis.conf</p>
<h2 id="二、Redis-的基础篇"><a href="#二、Redis-的基础篇" class="headerlink" title="二、Redis 的基础篇"></a>二、Redis 的基础篇</h2><h4 id="2-1-五种基本数据结构"><a href="#2-1-五种基本数据结构" class="headerlink" title="2.1 五种基本数据结构"></a>2.1 五种基本数据结构</h4><p>Redis 共有 5 种基本数据结构：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。</p>
<p>这 5 种数据结构是直接提供给用户使用的，是数据的保存形式，其底层实现主要依赖这 8 种数据结构：简单动态字符串（SDS）、LinkedList（双向链表）、Hash Table（哈希表）、SkipList（跳跃表）、Intset（整数集合）、ZipList（压缩列表）、QuickList（快速列表）。</p>
<p>Redis 基本数据结构的底层数据结构实现如下：</p>
<table>
<thead>
<tr>
<th>String</th>
<th>List</th>
<th>Hash</th>
<th>Set</th>
<th>Zset</th>
</tr>
</thead>
<tbody><tr>
<td>SDS</td>
<td>LinkedList&#x2F;ZipList&#x2F;QuickList</td>
<td>Hash Table、ZipList</td>
<td>ZipList、Intset</td>
<td>ZipList、SkipList</td>
</tr>
</tbody></table>
<p>Redis 3.2 之前，List 底层实现是 LinkedList 或者 ZipList。 Redis 3.2 之后，引入了 LinkedList 和 ZipList 的结合 QuickList，List 的底层实现变为 QuickList。</p>
<p>你可以在 Redis 官网上找到 Redis 数据结构非常详细的介绍：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://redis.com/redis-enterprise/data-structures/">Redis Data Structuresopen in new window</a></li>
<li><a target="_blank" rel="noopener" href="https://redis.io/docs/manual/data-types/data-types-tutorial/">Redis Data types tutorialopen in new window</a></li>
</ul>
<p>未来随着 Redis 新版本的发布，可能会有新的数据结构出现，通过查阅 Redis 官网对应的介绍，你总能获取到最靠谱的信息。</p>
<h5 id="2-1-1-String"><a href="#2-1-1-String" class="headerlink" title="2.1.1 String"></a>2.1.1 String</h5><p>String 是 Redis 中最简单同时也是最常用的一个数据结构。</p>
<p>String 是一种二进制安全的数据结构，可以用来存储任何类型的数据比如字符串、整数、浮点数、图片（图片的 base64 编码或者解码或者图片的路径）、序列化后的对象。</p>
<p> 虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 <strong>简单动态字符串</strong>（Simple Dynamic String，<strong>SDS</strong>）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外，Redis 的 SDS API 是安全的，不会造成缓冲区溢出。</p>
<h5 id="2-1-2-List"><a href="#2-1-2-List" class="headerlink" title="2.1.2 List"></a>2.1.2 List</h5><p> 许多高级编程语言都内置了链表的实现比如 Java 中的 LinkedList，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 List 的实现为一个 <strong>双向链表</strong>，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</p>
<h5 id="2-1-3-Hash"><a href="#2-1-3-Hash" class="headerlink" title="2.1.3 Hash"></a>2.1.3 Hash</h5><p>Redis 中的 Hash 是一个 String 类型的 field-value（键值对） 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接修改这个对象中的某些字段的值。</p>
<p>Hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 Hash 做了更多优化。</p>
<h5 id="2-1-4-Set"><a href="#2-1-4-Set" class="headerlink" title="2.1.4 Set"></a>2.1.4 Set</h5><p>Redis 中的 Set 类型是一种无序集合，集合中的元素没有先后顺序但都唯一，有点类似于 Java 中的 HashSet 。当你需要存储一个列表数据，又不希望出现重复数据时，Set 是一个很好的选择，并且 Set 提供了判断某个元素是否在一个 Set 集合内的重要接口，这个也是 List 所不能提供的。</p>
<p>你可以基于 Set 轻易实现交集、并集、差集的操作，比如你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。这样的话，Set 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。</p>
<h4 id="2-1-5-SortSet"><a href="#2-1-5-SortSet" class="headerlink" title="2.1.5 SortSet"></a>2.1.5 SortSet</h4><p>Sorted Set 类似于 Set，但和 Set 相比，Sorted Set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。</p>
<h4 id="2-2-三种特殊数据结构"><a href="#2-2-三种特殊数据结构" class="headerlink" title="2.2 三种特殊数据结构"></a>2.2 三种特殊数据结构</h4><h4 id="2-3-Redis命令"><a href="#2-3-Redis命令" class="headerlink" title="2.3 Redis命令"></a>2.3 Redis命令</h4><h5 id="2-1-1-通用命令"><a href="#2-1-1-通用命令" class="headerlink" title="2.1.1 通用命令"></a>2.1.1 通用命令</h5><p>Redis通用指令是不分数据类型的，都可以使用的指令，常见的有：</p>
<ul>
<li>KEYS：查看符合模板的所有 key，不建议在生产环境设备上使用</li>
<li>DEL：删除一个指定的 key</li>
<li>EXISTS：判断 key 是否存在</li>
<li>EXPIRE：给一个 key 设置有效期，有效期到期时该 key 自动删除。可 通过 TTL KeyName，查看 key 的剩余有效期</li>
</ul>
<p>通过 help [command] 可以查看一个命令的具体用法、</p>
<p>使用 redis.cli.exe 打开 redis的命令行，实操：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779112046-b5cf96d3-7890-4471-a0ce-0c02c4c4d789.png" alt="img"></p>
<h5 id="2-1-2-String类型"><a href="#2-1-2-String类型" class="headerlink" title="2.1.2 String类型"></a>2.1.2 String类型</h5><p>String 类型，也就是字符串类型，是 Redis 中最简单的存储类型。其 value 是字符串，不过根据字符串的格式不同，又可以分为3类:</p>
<ul>
<li>String：普通字符串</li>
<li>int：整数类型，可以做自增、自减操作</li>
<li>float：浮点类型，可以做自增、自减操作，但是必须指定 增减的 值。</li>
</ul>
<p>不管何种格式，底层都是字节数组形式存储，只不过是编码方式不同。</p>
<p>Redis的字符串是动态字符串，是可以修改的字符串，内部结构实现类似于Java的ArrayList，预分配冗余空间的方式来减少内存的频繁分配。字符串长度小于1M，扩容都是加倍现有空间，如果长度大于1M，每次扩容增加1M。字符串类型的最大空间不能超过 512M</p>
<p>String的常见命令有：</p>
<ul>
<li>SET：添加或者修改 已经存在的一个 String 类型的键值对</li>
<li>GET：根据 key 获取 String 类型的 value</li>
<li>MSET：批量添加多个 String 类型的键值对</li>
<li>MGET：根据多个 key 获取多个 String 类型的 value</li>
<li>INCR：让一个整型的 key 自增 1 </li>
<li>INCRBY：让一个整型的 key 自增并指定步长，例如：INCRBY num 2，即可让 key &#x3D; num 的值，自增2</li>
<li>SETNX：添加一个 String 类型的键值对，前提是 这个 key 不存在，否则不执行</li>
<li>SETEX：添加一个String 类型的键值对，并指定有效期</li>
</ul>
<h5 id="2-1-3-Key的层级格式"><a href="#2-1-3-Key的层级格式" class="headerlink" title="2.1.3 Key的层级格式"></a>2.1.3 Key的层级格式</h5><p>Redis没有类似 MySQL 中的 Table 的概念，我们该如何区分不同类型的 key 呢？一般采用将 key 名称进行 分层设计。例如：学生的key，key 以 studen_ 开头。</p>
<p>Redis 的 key 允许有多个单词组成层级结构，多个单词之间用 “:” 隔开，格式如下：</p>
<p>项目名:业务名:类型:id</p>
<p>当然这种格式是可以自己定义的，有些公司是使用 ”__“线间隔。</p>
<p>如果存储对象是 Java对象，则可将对象转化为 JSON 字符串当作value存储下来。</p>
<h5 id="2-1-4-Hash类型"><a href="#2-1-4-Hash类型" class="headerlink" title="2.1.4 Hash类型"></a>2.1.4 Hash类型</h5><p>Hash类型，也叫散列，其中value是一个无序字典，类型于 Java 中的 HashMap 结构</p>
<p>String 结构是将对象序列化为 JSON 字符串后 存储，当需要修改对象某个字段时 很不方便。Hash 结构可以将对象中的每个字段独立存储，可以针对 单个字段 CRUD</p>
<p>Hash类型常见命令有：</p>
<ul>
<li>HSET key field value：添加或者修改 hash类型 key的field 的值</li>
<li>HGET key field：获取一个 hash 类型 key的field的值</li>
<li>HMSET：批量添加 多个 hash类型 key的field 的值HMSET student_1 name liming sex 男   &#x2F;&#x2F;为key&#x3D;student_1 的字段 添加属性 name、sex 值分别为 liming、男</li>
<li>HGETALL：获取一个 hash 类型的key中所有的 field和value</li>
<li>HKEYS：获取一个 hash 类型的key中所有的 field</li>
<li>HVALS：获取一个hash 类型的key中所有的 value</li>
<li>HINCRBY：让一个hash类型 key 的字段值自增，并指定步长</li>
<li>HSETNX：添加一个 hash 类型的 key 的 field值，前提时 这个 field 不存在，否则不执行</li>
</ul>
<p>底层原理：</p>
<p>Java的HashMap在字典很大时，rehash是个耗时操作，需要一次性全部rehash。Redis为了高性能，不能堵塞服务，就采用了渐进式rehash策略</p>
<p>渐进式rehash：在rehash的同时，保留新旧两个hash结构，查询时会同时查询两个hash结构，然后再后续的定时任务中以及hash的子指令中，循序渐进地将旧hash的内容一点点迁移到新的hash结构中。</p>
<h5 id="2-1-4-List类型"><a href="#2-1-4-List类型" class="headerlink" title="2.1.4 List类型"></a>2.1.4 List类型</h5><p>Redis中的 List 类型与 Java 中的LinkedList 类似，可以看做是一个双向链表结构。既可以支持正向检索，也支持反向检索。特点也和LinkedList类似：</p>
<ul>
<li>有序</li>
<li>元素可以重复</li>
<li>插入和删除快</li>
<li>查询速度一般</li>
</ul>
<p>List的常见命令：</p>
<ul>
<li>LPUSH key element ：像列表左侧插入一个或多个元素</li>
<li>LPOP key ：移除并返回列表左侧的第一个元素，没有则返回nil</li>
<li>RPUSH key element：向列表右侧插入一个或多个元素</li>
<li>RPOP key：移除并返回列表右侧第一个元素</li>
<li>LRANGE key start end：返回一段角标范围内的所有元素</li>
<li>BLPOP和BRPOP：与LPOP、RPOP类似，只不过在没有元素时等待指定时间，而不是直接返回nil</li>
<li>lindex key index：lindex 相当于 Java 链表的 get(index) 方法，它需要对链表进行遍历。其性能随着参数index增大而变差。</li>
<li>ltrim key startIndex endIndex：使用startIndex 、endIndex定义了一个区间，保留着区间内的值，区间外统统去除。这样可以实现一个定长的链表。index可以为负数，-1表示倒数第一个元素，-2表示倒数第二个元素。</li>
</ul>
<p>应用场景：常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进Redis的列表，另一个线程从这个列表中轮询数据进行处理。通过控制，右边进左边出，可以实现队列。通过控制，右边进右边出，可以实现栈。</p>
<p>原理：Redis列表底层存储不是一个简单的 linkedlist，而是成为快速列表quicklist的一个结构。首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是压缩列表ziplist。它将所有的元素紧紧挨在一起存储，分配的是一块连续的内存。当数据量比较多时，才会改成 quicklist。因为普通的链表需要的附件指针空间太大，会比较浪费空间，而且加重内存的碎片化。所以Redis将 多个 ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，有不会出现太大的空间冗余。</p>
<h5 id="2-1-5-Set类型"><a href="#2-1-5-Set类型" class="headerlink" title="2.1.5 Set类型"></a>2.1.5 Set类型</h5><p>Redis的Set结构与 Java 中的HashSet类似，可以看做是一个 value 为 null 的 HashMap。因为也是一个 hash 表，因此具备与 HashSet类似的特征</p>
<ul>
<li>无序</li>
<li>元素不可重复</li>
<li>查找快</li>
<li>支持交集、并集、差集等功能</li>
</ul>
<p>Set常见命令：</p>
<ul>
<li>SADD key member：向set中添加一个或多个元素</li>
<li>SREM key member：移除set中指定的元素</li>
<li>SCARD key：返回set中元素的个数</li>
<li>SISMEMBER key member：判断一个元素是否存在于 set 中</li>
<li>SMEMBERS：获取 set 中的所有元素</li>
<li>SINTER key1 key2 ：求 key1 与 key2 的交集</li>
<li>SDIFF key1 key2：求 key1 与 key2 的差集 </li>
<li>SUNION key1 key2 ：求 key1 与 key2 的并集</li>
</ul>
<h5 id="2-1-6-SortedSet类型"><a href="#2-1-6-SortedSet类型" class="headerlink" title="2.1.6 SortedSet类型"></a>2.1.6 SortedSet类型</h5><p>Redis 的 SortedSet 是一个可排序的 set 集合，与 Java 中的 TreeSet 有些类似，但底层数据结构却差别很大。SortedSet 中的每个元素都带有一个 score 属性，可以基于 score 属性对 元素排序，底层的实现是一个跳表（SkipList）加hash表。</p>
<p>SortedSet具备下列特性：</p>
<ul>
<li>可排序</li>
<li>元素不重复</li>
<li>查询速度快</li>
</ul>
<p>因为 SortedSet 的可排序特性，经常被用来实现排行榜这样的功能。</p>
<p>SortedSet的常见命令有：</p>
<ul>
<li>ZADD key score member：添加一个或多个元素到 SortedSet，如果已经存在则更新其 score 值</li>
<li>ZREM key member：删除 SortedSet中的一个指定元素</li>
<li>ZSCORE key member：获取 SortedSet 中的指定元素的 score 值</li>
<li>ZRANK key member：获取 SortedSet 中的指定元素的排名</li>
<li>ZCAED key：获取 SortedSet 中的元素个数</li>
<li>ZCOUNT key min max：统计 score 值在给定范围内的所有元素的个数</li>
<li>ZINCRBY key increment member：让 SortedSet中的指定元素自增，步长为指定的increment值</li>
<li>ZRANGE key min max：按照 score 排序后，获取指定 score 范围内的元素</li>
<li>ZRANGEBYSCORE key min max：按照 score 排序后，获取指定 score 范围内的元素</li>
<li>ZDIFF、ZINTER、ZUNION：求差集、交集、并集</li>
</ul>
<p>注意：所有的排名默认都是 升序，如果要降序则在命令的Z后面添加REV即可</p>
<h4 id="2-2-Redis客户端"><a href="#2-2-Redis客户端" class="headerlink" title="2.2 Redis客户端"></a>2.2 Redis客户端</h4><p>Redis的客户端主要有</p>
<ul>
<li>Jedis：以Redis命令作为方法名称，学习成本低，简单实用。但是Jedis实例是线程不安全的，多线程情况下需要基于连接池实用</li>
<li>Lettuce：基于Netty实现的，支持同步、异步和响应式编程方式，并且是线程安全的。支持Redis的哨兵模式、集群模式和管道模式。</li>
<li>Redisson：是一个基于Redis实现的分布式、可伸缩的 Java 数据结构集合。包含了诸如 Map、Queue、Lock、Semaphore、AtomicLong等强大功能。</li>
</ul>
<p>而 SpringData Redis 集成了 Jedis、Lettuce</p>
<h5 id="2-2-1-Jedis-客户端"><a href="#2-2-1-Jedis-客户端" class="headerlink" title="2.2.1 Jedis 客户端"></a>2.2.1 Jedis 客户端</h5><p><a target="_blank" rel="noopener" href="https://github.com/kongxiaoran/redisDemo">https://github.com/kongxiaoran/redisDemo</a></p>
<p>可以下拉该项目的 Jedis 分支，该分支已经 实现了 springboot 整合 jedis 。可以下拉看看</p>
<p>Jedis本身是线程不安全的，并且频繁的创建和销毁连接会有性能损耗，因此我们推荐大家使用 Jedis 连接池代替 Jedis 的直连方式。</p>
<h5 id="2-2-2-SpringDataRedis"><a href="#2-2-2-SpringDataRedis" class="headerlink" title="2.2.2 SpringDataRedis"></a>2.2.2 SpringDataRedis</h5><p>SpringData 是 Spring 中数据操作的模块，包含对各种数据库的集成，其中对 Redis 的集成模块就叫做 SpringDataRedis，官网地址：</p>
<ul>
<li>提供了对不同 Redis 客户端的整合（Lettuce、Jedis）</li>
<li>提供了 RedisTemplate 统一 API 来操作</li>
<li>支持 Redis 的发布订阅模型</li>
<li>支持 Redis 哨兵和 Redis 集群</li>
<li>支持基于 Lettuce 的响应式编程</li>
<li>支持基于 JDK、JSON、字符串、Spring对象的数据序列化及反序列化</li>
<li>支持基于 Redistribution的 JDK Collection实现</li>
</ul>
<h4 id="2-3-SpringDataRedis-客户端使用"><a href="#2-3-SpringDataRedis-客户端使用" class="headerlink" title="2.3 SpringDataRedis 客户端使用"></a>2.3 SpringDataRedis 客户端使用</h4><p>SpringDataRedis 提供了 RedisTemplate 工具类，其中封装了各种对 Redis 的操作。并且将不同数据类型的操作API 封装到了不同类型中：</p>
<table>
<thead>
<tr>
<th><strong>API</strong></th>
<th><strong>返回值类型</strong></th>
<th><strong>说明</strong></th>
</tr>
</thead>
<tbody><tr>
<td>redisTemplate.opsForValue()</td>
<td>ValueOperations</td>
<td>操作 String 类型数据</td>
</tr>
<tr>
<td>redisTemplate.opsForHash()</td>
<td>HashOperations</td>
<td>操作 Hash 类型数据</td>
</tr>
<tr>
<td>redisTemplate.opsForList()</td>
<td>ListIOperations</td>
<td>操作 List 类型数据</td>
</tr>
<tr>
<td>redisTemplate.opsForSet()</td>
<td>SetOperations</td>
<td>操作 Set 类型数据</td>
</tr>
<tr>
<td>redisTemplate.opsForZSet()</td>
<td>ZSetOperations</td>
<td>操作 SortedSet 类型数据</td>
</tr>
<tr>
<td>redisTemplate</td>
<td></td>
<td>通用命令</td>
</tr>
</tbody></table>
<p><a target="_blank" rel="noopener" href="https://github.com/kongxiaoran/redisDemo">https://github.com/kongxiaoran/redisDemo</a></p>
<p>该项目的 master 分支，使用 SpringBoot 整合了 SpringDataRedis，可以自行下拉运行。</p>
<h5 id="2-3-1-SpringDataRedis-的默认序列化"><a href="#2-3-1-SpringDataRedis-的默认序列化" class="headerlink" title="2.3.1 SpringDataRedis 的默认序列化"></a>2.3.1 SpringDataRedis 的默认序列化</h5><p>RedisTemplate 可以接收任意 Object 作为值 写入 Redis，只不过写入 前会把 Object 序列化为字节形式，默认是采用 JDK 序列化。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redisTemplate.opsForValue().set(&quot;springboot&quot;,&quot;你好呀，springboot&quot;);   </span><br><span class="line">String springboot = (String) redisTemplate.opsForValue().get(&quot;springboot&quot;);</span><br><span class="line">System.out.println(springboot);</span><br></pre></td></tr></table></figure>

<p>得到的结果是这样的：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779112780-bf2ddbf3-24a4-47aa-b14d-5ba839abecdd.png" alt="img"></p>
<p>缺点很明显：</p>
<ul>
<li>可读性差</li>
<li>内存占用较大</li>
</ul>
<p>这是因为什么呢？查看 RedisTemplate 类，可以知道 当没有特别配置 key、value、hashKey 的 序列化策略时，</p>
<p>RedisTemplate 会选择使用 JDK序列化器（JdkSerializationRedisSerializer)，而此序列化器是不是适合字符串的序列化的。所以如果你的 key 通常是用 字符串格式，那么可以考虑 在序列化key时，采用其他序列化器。比如：String</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779116223-bc409176-9ef0-4441-87c3-073ae4c8bc51.png" alt="img"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779116227-ff9eae7b-6954-4282-91dc-cd89ac3f5cd8.png" alt="img"></p>
<h5 id="2-3-2-SpringDataRedis-提供的序列化器"><a href="#2-3-2-SpringDataRedis-提供的序列化器" class="headerlink" title="2.3.2 SpringDataRedis 提供的序列化器"></a>2.3.2 SpringDataRedis 提供的序列化器</h5><p>查看 RedisSerializer 的实现，可以看到有 7 种序列化器：</p>
<ul>
<li><p>ByteArrayRedisSerializer：字节数组序列化</p>
</li>
<li><p>GenericJackson2JsonRedisSerializer：同 FastJsonRedisSerializer 类似，而 FastJsonRedisSerializer 是由阿里巴巴FastJson包提供。具有：1. 速度快 2. 兼容性强 3. 占用内存小</p>
</li>
<li><ul>
<li>底层使用Jackson进行序列化并存入Redis。对于普通类型(如数值类型，字符</li>
<li>存入对象时由于没有存入类信息，则无法反序列化。</li>
</ul>
</li>
<li><p>GenericToStringSerializer：同StringRedisSerializer一样，但它可以将任何对象泛化为字符串并序列化。注意事项：GenericToStringSerializer需要调用者给传一个对象到字符串互转的Converter，使用起来其比较麻烦，所以不太推荐使用。</p>
</li>
<li><p>Jackson2JsonRedisSerializer：将对象序列化为json字符串</p>
</li>
<li><ul>
<li>·优点：速度快、序列化后的字符串短小精悍、不需要实现 Serializable</li>
<li>缺点：必须要提供要序列化对象的类型信息（.class对象）</li>
</ul>
</li>
<li><p>JdkSerializationRedisSerializer：使用Java自带的序列化机制将对象序列化为一个字符串。</p>
</li>
<li><ul>
<li>优点在于：通用性强、反序列化时不需要提供类型信息。、</li>
<li>缺点在于：序列化速度慢、序列化内存占用大、序列化对象必须实现 Serializable 接口、可读性差</li>
</ul>
</li>
<li><p>OxmSerializer：将对象序列化为xml字符串。以 xml 格式存储（但还是String类型），解析起来比较复杂，且占用空间大</p>
</li>
<li><p>StringRedisSerializer：StringRedisTemplate默认的序列化器。</p>
</li>
<li><ul>
<li>优点：可读性强、不需要转换</li>
<li>缺点：只能对字符串序列化，不能对 对象 序列化</li>
</ul>
</li>
</ul>
<h5 id="2-3-3-自定义序列化器"><a href="#2-3-3-自定义序列化器" class="headerlink" title="2.3.3 自定义序列化器"></a>2.3.3 自定义序列化器</h5><p>所以我们可以针对自己的需要，自定义 RedisTemplate，来实现对不同 key、value 使用不同的序列化器</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public RedisTemplate&lt;String,Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory)</span><br><span class="line">    throws UnknownHostException&#123;</span><br><span class="line"></span><br><span class="line">    // 创建 Template</span><br><span class="line">    RedisTemplate&lt;String,Object&gt; redisTemplate = new RedisTemplate&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    // 设置连接工厂</span><br><span class="line">    redisTemplate.setConnectionFactory(redisConnectionFactory);</span><br><span class="line"></span><br><span class="line">    // 设置序列化工具</span><br><span class="line">    GenericJackson2JsonRedisSerializer jackson2JsonRedisSerializer =</span><br><span class="line">    new GenericJackson2JsonRedisSerializer();</span><br><span class="line"></span><br><span class="line">    // key 和 hashKey 采用 String序列化</span><br><span class="line">    redisTemplate.setKeySerializer(RedisSerializer.string());</span><br><span class="line">    redisTemplate.setHashKeySerializer(RedisSerializer.string());</span><br><span class="line"></span><br><span class="line">    // value 和 hashValue 采用 JOSN序列化</span><br><span class="line">    redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);</span><br><span class="line">    redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer);</span><br><span class="line"></span><br><span class="line">    return redisTemplate;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="2-3-4-使用自定义序列化器存储对象"><a href="#2-3-4-使用自定义序列化器存储对象" class="headerlink" title="2.3.4 使用自定义序列化器存储对象"></a>2.3.4 使用自定义序列化器存储对象</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void testEmployee()&#123;</span><br><span class="line">    Employee employee = new Employee(3,&quot;羽&quot;,&quot;28235x02x7&quot;,1,1);</span><br><span class="line">    // 写入数据</span><br><span class="line">    redisTemplate.opsForValue().set(&quot;user_3&quot;,employee);</span><br><span class="line"></span><br><span class="line">    // 获取数据</span><br><span class="line">    Employee getEmployee = (Employee) redisTemplate.opsForValue().get(&quot;user_3&quot;);</span><br><span class="line">    System.out.println(getEmployee.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779116323-2e3c4c31-c032-4f95-985f-2c0da0eb6c51.png" alt="img"></p>
<p>由图可以知道，该序列化器在序列化对象，也会将 对象的字节码名称写入。这样在我们反序列化时知道对象的类型，从而反序列化成对应对象。</p>
<h5 id="2-3-5-使用StringRedisTemplate存储JSON对象"><a href="#2-3-5-使用StringRedisTemplate存储JSON对象" class="headerlink" title="2.3.5 使用StringRedisTemplate存储JSON对象"></a>2.3.5 使用StringRedisTemplate存储JSON对象</h5><p>但是这一个存在一个问题，JSON序列化器将类的class类型写入了 JSON结果中，存入了 Redis ，会带来额外的内存开销。为了节省内存空间，我们并不会使用 JSON 序列化器来处理 value，而是统一使用 String 序列化器，要求只能存储 String 类型的 key 和 value。当需要存储 Java 对象时，<strong>手动完成对象的序列化和反序列化</strong>。</p>
<p>所以还是建议手动完成对象的序列化：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void testEmployeeStringRedisTemplate()&#123;</span><br><span class="line">    Employee employee = new Employee(3,&quot;羽&quot;,&quot;2823x302x7&quot;,1,1);</span><br><span class="line">    // 写入数据 （这里使用的时 fastJson2进行序列化）</span><br><span class="line">    stringRedisTemplate.opsForValue().set(&quot;user_4&quot;, JSON.toJSONString(employee));</span><br><span class="line">    // 获取数据</span><br><span class="line">    Employee getEmployee = JSON.parseObject(stringRedisTemplate.opsForValue().get(&quot;user_4&quot;), Employee.class);</span><br><span class="line">    System.out.println(getEmployee.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h5 id="2-3-6-RedisTemplate-操作-Hash-类型"><a href="#2-3-6-RedisTemplate-操作-Hash-类型" class="headerlink" title="2.3.6 RedisTemplate 操作 Hash 类型"></a>2.3.6 RedisTemplate 操作 Hash 类型</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void testHash()&#123;</span><br><span class="line">    stringRedisTemplate.opsForHash().put(&quot;xiucheng&quot;,&quot;user1&quot;,&quot;凌霄&quot;);</span><br><span class="line">    stringRedisTemplate.opsForHash().put(&quot;xiucheng&quot;,&quot;user2&quot;,&quot;羽&quot;);</span><br><span class="line"></span><br><span class="line">    Map&lt;Object, Object&gt; xiucheng = stringRedisTemplate.opsForHash().entries(&quot;xiucheng&quot;);</span><br><span class="line">    System.out.println(xiucheng.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="三、Redis-实战"><a href="#三、Redis-实战" class="headerlink" title="三、Redis 实战"></a>三、Redis 实战</h2><h3 id="3-1-Redis与MySQL双写一致性如何保证？"><a href="#3-1-Redis与MySQL双写一致性如何保证？" class="headerlink" title="3.1 Redis与MySQL双写一致性如何保证？"></a>3.1 Redis与MySQL双写一致性如何保证？</h3><h4 id="3-1-1-一致性"><a href="#3-1-1-一致性" class="headerlink" title="3.1.1 一致性"></a>3.1.1 一致性</h4><p>一致性就是数据保持一致，在分布式系统中，可以理解为多个节点中数据的值是一致的。</p>
<ul>
<li><strong>强一致性</strong>：这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大</li>
<li><strong>弱一致性</strong>：这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态</li>
<li><strong>最终一致性</strong>：最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型</li>
</ul>
<h4 id="3-1-2-三种经典的缓存模式"><a href="#3-1-2-三种经典的缓存模式" class="headerlink" title="3.1.2 三种经典的缓存模式"></a>3.1.2 三种经典的缓存模式</h4><p>缓存可以提升性能、缓解数据库压力，但是使用缓存也会导致数据<strong>不一致性</strong>的问题。一般我们是如何使用缓存呢？有三种经典的缓存模式：</p>
<ul>
<li><strong>Cache-Aside Pattern</strong>Cache-Aside Pattern，即<strong>旁路缓存模式</strong>，它的提出是为了尽可能地解决缓存与数据库的数据不一致问题。读：写：更新的时候，先<strong>更新数据库，然后再删除缓存</strong>。</li>
</ul>
<ol>
<li><ol>
<li>读的时候，先读缓存，缓存命中的话，直接返回数据</li>
<li>缓存没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应。</li>
</ol>
</li>
</ol>
<ul>
<li><strong>Read-Through&#x2F;Write through</strong>Read&#x2F;Write Through模式中，服务端把缓存作为主要数据存储。应用程序跟数据库缓存交互，都是通过<strong>抽象缓存层</strong>完成的。读：<img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/webp/35838370/1682779116373-baeadbf7-a12c-4bb1-9fae-bff4afb23d3b.webp" alt="img">这个简要流程是不是跟<strong>Cache-Aside</strong>很像呢？其实<strong>Read-Through</strong>就是多了一层<strong>Cache-Provider</strong>。写：当发生写请求时，也是由<strong>缓存抽象层</strong>完成数据源和缓存数据的更新：先更新数据源，再更新缓存。</li>
</ul>
<ol>
<li><ol>
<li>从缓存读取数据，读到直接返回</li>
<li>如果读取不到的话，从数据库加载，写入缓存后，再返回响应。</li>
</ol>
</li>
</ol>
<ul>
<li><strong>Write behind****Write behind</strong>跟<strong>Read-Through&#x2F;Write-Through</strong>有相似的地方，都是由Cache Provider来负责缓存和数据库的读写。它两又有个很大的不同：<strong>Read&#x2F;Write Through</strong>是同步更新缓存和数据的，<strong>Write Behind</strong>则是只更新缓存，不直接更新数据库，通过<strong>批量异步</strong>的方式来更新数据库。这种方式下，缓存和数据库的一致性不强，<strong>对一致性要求高的系统要谨慎使用</strong>。但是它适合频繁写的场景，MySQL的<strong>InnoDB Buffer Pool机制</strong>就使用到这种模式。</li>
</ul>
<h4 id="3-1-3-操作缓存的时候，删除缓存呢，还是更新缓存？"><a href="#3-1-3-操作缓存的时候，删除缓存呢，还是更新缓存？" class="headerlink" title="3.1.3 操作缓存的时候，删除缓存呢，还是更新缓存？"></a>3.1.3 操作缓存的时候，删除缓存呢，还是更新缓存？</h4><p>一般业务场景，我们使用的就是<strong>Cache-Aside</strong>模式。 有些小伙伴可能会问， <strong>Cache-Aside</strong>在写入请求的时候，为什么是<strong>删除缓存而不是更新缓存</strong>呢？我们在操作缓存的时候，到底应该删除缓存还是更新缓存呢？我们先来看个例子：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/webp/35838370/1682779116395-a6501b26-db7f-4d05-87f6-60706161333e.webp" alt="img"></p>
<ol>
<li>线程A先发起一个写操作，第一步先更新数据库</li>
<li>线程B再发起一个写操作，第二步更新了数据库</li>
<li>由于网络等原因，线程B先更新了缓存</li>
<li>线程A后更新缓存。</li>
</ol>
<p>这时候，缓存保存的是A的数据（老数据），数据库保存的是B的数据（新数据），数据<strong>不一致</strong>了，脏数据出现啦。如果是<strong>删除缓存取代更新缓存</strong>则不会出现这个脏数据问题。</p>
<p><strong>更新缓存相对于删除缓存</strong>，还有两点劣势：</p>
<ul>
<li>如果你写入的缓存值，是经过复杂计算才得到的话。更新缓存频率高的话，就浪费性能啦。</li>
<li>在写数据库场景多，读数据场景少的情况下，数据很多时候还没被读取到，又被更新了，这也浪费了性能呢(实际上，写多的场景，用缓存也不是很划算了)</li>
</ul>
<h4 id="3-1-3-双写的情况下，先操作数据库还是先操作缓存？"><a href="#3-1-3-双写的情况下，先操作数据库还是先操作缓存？" class="headerlink" title="3.1.3 双写的情况下，先操作数据库还是先操作缓存？"></a>3.1.3 双写的情况下，先操作数据库还是先操作缓存？</h4><p>Cache-Aside缓存模式中，有些小伙伴还是有疑问，在写入请求的时候，为什么是<strong>先操作数据库呢</strong>？为什么<strong>不先操作缓存</strong>呢？</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779117654-0e13d67f-a1bb-47ad-93a2-85dc01b9fa12.webp" alt="img"></p>
<ol>
<li>线程A发起一个写操作，第一步del cache</li>
<li>此时线程B发起一个读操作，cache miss</li>
<li>线程B继续读DB，读出来一个老数据</li>
<li>然后线程B把老数据设置入cache</li>
<li>线程A写入DB最新的数据</li>
</ol>
<p>酱紫就有问题啦，<strong>缓存和数据库的数据不一致了。缓存保存的是老数据，数据库保存的是新数据</strong>。因此，Cache-Aside 缓存模式，选择了先操作数据库而不是先操作缓存。</p>
<h4 id="3-1-4-缓存延时双删"><a href="#3-1-4-缓存延时双删" class="headerlink" title="3.1.4 缓存延时双删"></a>3.1.4 缓存延时双删</h4><p>有些小伙伴可能会说，不一定要先操作数据库呀，采用<strong>缓存延时双删</strong>策略就好啦？什么是延时双删呢？</p>
<ol>
<li>先删除缓存</li>
<li>再更新数据库</li>
<li>休眠一会（比如1秒），再次删除缓存。</li>
</ol>
<p>这个休眠一会，一般多久呢？都是1秒？</p>
<p>这个休眠时间 &#x3D; 读业务逻辑数据的耗时 + 几百毫秒。 为了确保读请求结束，写请求可以删除读请求可能带来的缓存脏数据。</p>
<h4 id="3-1-5-删除缓存重试机制"><a href="#3-1-5-删除缓存重试机制" class="headerlink" title="3.1.5 删除缓存重试机制"></a>3.1.5 删除缓存重试机制</h4><p>不管是<strong>延时双删</strong>还是<strong>Cache-Aside的先操作数据库再删除缓存</strong>，如果第二步的删除缓存失败呢，删除失败会导致脏数据哦~</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/webp/35838370/1682779117889-0a62c399-8c30-4227-9a71-ef940b73fba0.webp" alt="img"></p>
<p>删除缓存重试机制，会造成很多业务代码入侵。其实也可以通过 数据库的CDC 来异步淘汰 Key。</p>
<p>所以我们需要一些重试机制，确保 redis key 被删除了</p>
<h5 id="队列-重试机制"><a href="#队列-重试机制" class="headerlink" title="队列+重试机制"></a>队列+重试机制</h5><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779118664-a9c22f28-ced6-4e2d-a840-99031155209e.png" alt="img"></p>
<p>流程如下所示</p>
<ul>
<li>更新数据库数据</li>
<li>缓存因为种种问题删除失败</li>
<li>将需要删除的key发送至消息队列</li>
<li>自己消费消息，获得需要删除的key</li>
<li>继续重试删除操作，直到成功</li>
</ul>
<p>然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。</p>
<h5 id="基于订阅binlog的同步机制"><a href="#基于订阅binlog的同步机制" class="headerlink" title="基于订阅binlog的同步机制"></a>基于订阅binlog的同步机制</h5><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779118663-d1ce53ca-9fdb-4552-89cc-0f3b181677a5.png" alt="img"><strong>技术整体思路</strong>：</p>
<p>MySQL binlog增量订阅消费+消息队列+增量数据更新到redis</p>
<p>1）读Redis：热数据基本都在Redis</p>
<p>2）写MySQL: 增删改都是操作MySQL</p>
<p>3）更新Redis数据：MySQ的数据操作binlog，来更新到Redis</p>
<p><strong>Redis更新</strong></p>
<p>1）<strong>数据操作</strong>主要分为两大块：</p>
<ul>
<li>一个是全量(将全部数据一次写入到redis)</li>
<li>一个是增量（实时更新）</li>
</ul>
<p>这里说的是增量,指的是mysql的update、insert、delate变更数据。</p>
<p>2）<strong>读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据</strong>。</p>
<p>这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。</p>
<p>其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。</p>
<p>这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。</p>
<p>当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis。</p>
<h3 id="3-2-缓存雪崩、穿透、击穿、污染"><a href="#3-2-缓存雪崩、穿透、击穿、污染" class="headerlink" title="3.2 缓存雪崩、穿透、击穿、污染"></a>3.2 缓存雪崩、穿透、击穿、污染</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683633583708-42a49740-34d1-42e6-a6e8-8489be91fc87.png" alt="img"></p>
<h4 id="3-2-1-缓存雪崩"><a href="#3-2-1-缓存雪崩" class="headerlink" title="3.2.1 缓存雪崩"></a>3.2.1 缓存雪崩</h4><p>对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。或者缓存中 数据大批量到过期时间，大批量数据同时查询数据库，引起数据库压力过大甚至宕机。</p>
<p>这就是缓存雪崩。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/redis-caching-avalanche.png"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://github.com/doocs/advanced-java/raw/main/docs/high-concurrency/images/redis-caching-avalanche.png" alt="img"></a></p>
<p>大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。</p>
<p>缓存雪崩的事前事中事后的解决方案如下：</p>
<ul>
<li>事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。</li>
<li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li>
<li>事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li>
</ul>
<p>除此之外实际使用时：</p>
<ul>
<li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li>
<li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。</li>
<li>热点数据的过期时间尽量设置长</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/redis-caching-avalanche-solution.png" alt="img"></p>
<p>用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 Redis。如果 ehcache 和 Redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 Redis 中。</p>
<p>限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？<strong>走降级</strong>！可以返回一些默认的值，或者友情提示，或者空值。</p>
<p>好处：</p>
<ul>
<li>数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。</li>
<li>只要数据库不死，就是说，对用户来说，2&#x2F;5 的请求都是可以被处理的。</li>
<li>只要有 2&#x2F;5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来了。</li>
</ul>
<h4 id="3-2-2-缓存穿透"><a href="#3-2-2-缓存穿透" class="headerlink" title="3.2.2 缓存穿透"></a>3.2.2 缓存穿透</h4><p>对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p>
<p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p>
<p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“<strong>视缓存于无物</strong>”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/redis-caching-penetration.png"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/redis-caching-penetration.png" alt="img"></a></p>
<p>解决方案：</p>
<ul>
<li>设置空值解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 UNKNOWN 。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/redis-caching-avoid-penetration.png"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/redis-caching-avoid-penetration.png" alt="img"></a></p>
<ul>
<li><p>布隆过滤器。当然，如果黑客如果每次使用不同的负数 id 来攻击，写空值的方法可能就不奏效了。更为经常的做法是在缓存之前增加布隆过滤器，将数据库中所有可能的数据哈希映射到布隆过滤器中。然后对每个请求进行如下判断：使用布隆过滤器能够对访问的请求起到了一定的初筛作用，避免了因数据不存在引起的查询压力。</p>
</li>
<li><ul>
<li>请求数据的 key 不存在于布隆过滤器中，可以确定数据就一定不会存在于数据库中，系统可以立即返回不存在。</li>
<li>请求数据的 key 存在于布隆过滤器中，则继续再向缓存中查询。</li>
</ul>
</li>
<li><p>Key校验对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则丢弃。</p>
</li>
</ul>
<h4 id="3-2-3-缓存击穿"><a href="#3-2-3-缓存击穿" class="headerlink" title="3.2.3 缓存击穿"></a>3.2.3 缓存击穿</h4><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p>
<p>不同场景下的解决方式可如下：</p>
<ul>
<li>若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li>
<li>若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。</li>
<li>若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。</li>
</ul>
<h4 id="3-2-4-缓存污染"><a href="#3-2-4-缓存污染" class="headerlink" title="3.2.4 缓存污染"></a>3.2.4 缓存污染</h4><p>缓存污染问题说的是缓存中一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，但这部分数据依然留存在缓存中，消耗缓存空间。</p>
<p>缓存污染会随着数据的持续增加而逐渐显露，随着服务的不断运行，缓存中会存在大量的永远不会再次被访问的数据。缓存空间是有限的，如果缓存空间满了，再往缓存里写数据时就会有额外开销，影响Redis性能。这部分额外开销主要是指写的时候判断淘汰策略，根据淘汰策略去选择要淘汰的数据，然后进行删除操作。</p>
<h5 id="缓存淘汰策略"><a href="#缓存淘汰策略" class="headerlink" title="缓存淘汰策略"></a>缓存淘汰策略</h5><p>Redis共支持八种淘汰策略，分别是noeviction、volatile-random、volatile-ttl、volatile-lru、volatile-lfu、allkeys-lru、allkeys-random 和 allkeys-lfu 策略。</p>
<p><strong>怎么理解呢</strong>？主要看分三类看：</p>
<ul>
<li><p>不淘汰 </p>
</li>
<li><ul>
<li>noeviction （v4.0后默认的）</li>
</ul>
</li>
<li><p>对设置了过期时间的数据中进行淘汰 </p>
</li>
<li><ul>
<li>随机：volatile-random</li>
<li>ttl：volatile-ttl</li>
<li>lru：volatile-lru</li>
<li>lfu：volatile-lfu</li>
</ul>
</li>
<li><p>全部数据进行淘汰 </p>
</li>
<li><ul>
<li>随机：allkeys-random</li>
<li>lru：allkeys-lru</li>
<li>lfu：allkeys-lfu</li>
</ul>
</li>
</ul>
<ol>
<li>noeviction该策略是Redis的默认策略。在这种策略下，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。这种策略不会淘汰数据，所以无法解决缓存污染问题。一般生产环境不建议使用。其他七种规则都会根据自己相应的规则来选择数据进行删除操作。</li>
<li>volatile-random。这个算法比较简单，在设置了过期时间的键值对中，进行随机删除。因为是随机删除，无法把不再访问的数据筛选出来，所以可能依然会存在缓存污染现象，无法解决缓存污染问题。</li>
<li>volatile-ttl。这种算法判断淘汰数据时参考的指标比随机删除时多进行一步过期时间的排序。Redis在筛选需删除的数据时，越早过期的数据越优先被选择。</li>
<li>volatile-lru。LRU算法：LRU 算法的全称是 Least Recently Used，按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。Redis优化的 <strong>LRU算法实现</strong>：Redis会记录每个数据的最近一次被访问的时间戳。在Redis在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。通过随机读取待删除集合，可以让Redis不用维护一个巨大的链表，也不用操作链表，进而提升性能。Redis 选出的数据个数 N，通过 配置参数 maxmemory-samples 进行配置。个数N越大，则候选集合越大，选择到的最久未被使用的就更准确，N越小，选择到最久未被使用的数据的概率也会随之减小。</li>
<li>volatile-lfu。会使用 LFU 算法选择设置了过期时间的键值对。<strong>LFU 算法</strong>：LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 Redis的LFU算法实现:当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255，这样在访问快速的情况下，如果每次被访问就将访问次数加一，很快某条数据就达到最大值255，可能很多数据都是255，那么退化成LRU算法了。所以Redis为了解决这个问题，实现了一个更优的计数规则，并可以通过配置项，来控制计数器增加的速度。<strong>参数</strong> ：lfu-log-factor ，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。lfu-decay-time， 控制访问次数衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。lfu-log-factor设置越大，递增概率越低，lfu-decay-time设置越大，衰减速度会越慢。我们在应用 LFU 策略时，一般可以将 lfu_log_factor 取值为 10。 如果业务应用中有短时高频访问的数据的话，建议把 lfu_decay_time 值设置为 1。可以快速衰减访问次数。volatile-lfu 策略是 Redis 4.0 后新增。</li>
<li><strong>allkeys-lru</strong>使用 LRU 算法在所有数据中进行筛选。具体LFU算法跟上述 volatile-lru 中介绍的一致，只是筛选的数据范围是全部缓存，这里就不在重复。</li>
<li>allkeys-random从所有键值对中随机选择并删除数据。volatile-random 跟 allkeys-random算法一样，随机删除就无法解决缓存污染问题。</li>
<li>allkeys-lfu使用 LFU 算法在所有数据中进行筛选。具体LFU算法跟上述 volatile-lfu 中介绍的一致，只是筛选的数据范围是全部缓存，这里就不在重复。</li>
</ol>
<p>allkeys-lfu 策略是 Redis 4.0 后新增。</p>
<h3 id="3-3-I-O多路复用"><a href="#3-3-I-O多路复用" class="headerlink" title="3.3 I&#x2F;O多路复用"></a>3.3 I&#x2F;O多路复用</h3><h4 id="3-3-1-有哪几种I-O模型"><a href="#3-3-1-有哪几种I-O模型" class="headerlink" title="3.3.1 有哪几种I&#x2F;O模型"></a>3.3.1 有哪几种I&#x2F;O模型</h4><p>为什么 Redis 中要使用 I&#x2F;O 多路复用这种技术呢？</p>
<p>首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I&#x2F;O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I&#x2F;O 阻塞导致整个进程无法对其它客户提供服务，而 <strong>I&#x2F;O 多路复用</strong>就是为了解决这个问题而出现的。</p>
<ul>
<li><strong>Blocking I&#x2F;O。</strong>先来看一下传统的阻塞 I&#x2F;O 模型到底是如何工作的：当使用 read 或者 write 对某一个**文件描述符（File Descriptor 以下简称 FD)**进行读写时，如果当前 FD 不可读或不可写，整个 Redis 服务就不会对其它的操作作出响应，导致整个服务不可用。这也就是传统意义上的，也就是我们在编程中使用最多的阻塞模型。但是由于它会影响其他 FD 对应的服务，所以需要处理多个客户端任务的时候，往往都不会使用阻塞模型。</li>
<li><strong>I&#x2F;O多路复用。</strong>阻塞式的 I&#x2F;O 模型并不能满足这里的需求，我们需要一种效率更高的 I&#x2F;O 模型来支撑 Redis 的多个客户（redis-cli），这里涉及的就是 I&#x2F;O 多路复用模型了。在 I&#x2F;O 多路复用模型中，最重要的函数调用就是 select，该方法的能够同时监控多个文件描述符的可读可写情况，当其中的某些文件描述符可读或者可写时，select 方法就会返回可读以及可写的文件描述符个数。与此同时也有其它的 I&#x2F;O 多路复用函数 epoll&#x2F;kqueue&#x2F;evport，它们相比 select 性能更优秀，同时也能支撑更多的服务。</li>
</ul>
<h4 id="3-3-2-Reactor设计模式"><a href="#3-3-2-Reactor设计模式" class="headerlink" title="3.3.2 Reactor设计模式"></a>3.3.2 Reactor设计模式</h4><p>Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符）</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779118964-d5b2cf6f-b475-4166-bbc7-fcdb1c5a8759.png" alt="img"></p>
<p>文件事件处理器使用 I&#x2F;O 多路复用模块同时监听多个 FD，当 accept、read、write 和 close 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器。</p>
<p>虽然整个文件事件处理器是在单线程上运行的，但是通过 I&#x2F;O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，提高了网络通信模型的性能，同时也可以保证整个 Redis 服务实现的简单。</p>
<h4 id="3-3-3-I-O多路复用模块"><a href="#3-3-3-I-O多路复用模块" class="headerlink" title="3.3.3 I&#x2F;O多路复用模块"></a>3.3.3 I&#x2F;O多路复用模块</h4><p>I&#x2F;O 多路复用模块封装了底层的 select、epoll、avport 以及 kqueue 这些 I&#x2F;O 多路复用函数，为上层提供了相同的接口。</p>
<p>因为 Redis 需要在多个平台上运行，同时为了最大化执行的效率与性能，所以会根据编译平台的不同选择不同的 I&#x2F;O 多路复用函数作为子模块，提供给上层统一的接口；在 Redis 中，我们通过宏定义的使用，合理的选择不同的子模块。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779120227-db19f80f-4483-408b-8c31-bf41394af344.jpeg" alt="img"></p>
<p>Redis 会优先选择时间复杂度为 O(1) 的 I&#x2F;O 多路复用函数作为底层实现，包括 Solaries 10 中的 evport、Linux 中的 epoll 和 macOS&#x2F;FreeBSD 中的 kqueue，上述的这些函数都使用了内核内部的结构，并且能够服务几十万的文件描述符。</p>
<p>但是如果当前编译环境没有上述函数，就会选择 select 作为备选方案，由于其在使用时会扫描全部监听的描述符，所以其时间复杂度较差 O(n)O(n)，并且只能同时服务 1024 个文件描述符，所以一般并不会以 select 作为第一方案使用。</p>
<h3 id="3-4-脑裂问题"><a href="#3-4-脑裂问题" class="headerlink" title="3.4 脑裂问题"></a>3.4 脑裂问题</h3><p>如果在 Redis 中，形式上就是有了两个 master，记住了两个 master 才是脑裂的前提</p>
<h4 id="3-4-1-哨兵模式下的脑裂"><a href="#3-4-1-哨兵模式下的脑裂" class="headerlink" title="3.4.1 哨兵模式下的脑裂"></a>3.4.1 哨兵模式下的脑裂</h4><p>1个 master 与 3个 slave组成的哨兵模式（哨兵独立部署于其他节点）。两个客户端 server1、server2 都连接上了 master。但是如果 master 与 slave 及哨兵之间 网络发生了故障，但是哨兵与slave之间通讯正常，这时3个slave其中1个经过哨兵投票后，提升为新master。如果恰好此时 server1 仍然连接的是旧的master，而server2连接到了新的master。</p>
<p>数据就不一致了，基于 setNX 指令的分布式锁，可能会拿到相同的锁；基于 incr 生成的全局唯一 id，也可能出现重复。</p>
<h4 id="3-4-2-cluster-模式下的脑裂"><a href="#3-4-2-cluster-模式下的脑裂" class="headerlink" title="3.4.2 cluster 模式下的脑裂"></a>3.4.2 cluster 模式下的脑裂</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779121684-93b3e741-7f57-49e9-b067-ea538dd0980b.png" alt="img"></p>
<p>cluster 模式下，这种情况要更复杂，例如集群中有 6 组分片，每给分片节点都有 1 主 1 从，如果出现网络分区时，各种节点之间的分区组合都有可能。</p>
<h5 id="手动解决问题"><a href="#手动解决问题" class="headerlink" title="手动解决问题"></a>手动解决问题</h5><p>在正常情况下，如果 master 挂了，那么写入就会失败，如果是手动解决，那么人为会检测 master 以及 slave 的网络状况，然后视情况，如果是 master 挂了，重启 master，如果是 master 与 slave 之间的连接断了，可以调试网络，这样虽然麻烦，但是是可以保证只有一个 master 的，所以只要认真负责，不会出现脑裂。</p>
<h5 id="自动解决问题"><a href="#自动解决问题" class="headerlink" title="自动解决问题"></a>自动解决问题</h5><p>Redis 中有一个哨兵机制，哨兵机制的作用就是通过 redis 哨兵来检测 redis 服务的状态，如果一旦发现 master 挂了，就在 slave 中选举新的 master 节点以实现故障自动转移。</p>
<h5 id="如何避免脑裂"><a href="#如何避免脑裂" class="headerlink" title="如何避免脑裂"></a>如何避免脑裂</h5><p>合理设置 min-slaves-to-write、min-slaves-max-lag两个参数</p>
<ul>
<li>第一个参数标识连接到 master 的最少 slave 数量</li>
<li>第二个参数标识 slave连接到 master 的最大延迟时间</li>
</ul>
<p>问题，就出现在这个自动故障转移上，如果是哨兵和 slave 同时与 master 断了联系，即哨兵可以监测到 slave，但是监测不到 master，而 master 虽然连接不上 slave 和哨兵，但是还是在正常运行，这样如果哨兵因为监测不到 master，认为它挂了，会在 slave 中选举新的 master，而有一部分应用仍然与旧的 master 交互。当旧的 master 与新的 master 重新建立连接，旧的 master 会同步新的 master 中的数据，而旧的 master 中的数据就会丢失。所以我认为 redis 脑裂就是自动故障转移造成的。</p>
<h3 id="3-4-搭建哨兵集群"><a href="#3-4-搭建哨兵集群" class="headerlink" title="3.4 搭建哨兵集群"></a>3.4 搭建哨兵集群</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-4-9-centos ~]# docker run -it -d --name redis3 -p 6378:6378 redis</span><br><span class="line">1d3ab7315ac93a217136fe0fb0837104ca4e5500b0671d2acb989f92ecd8e38b</span><br><span class="line">[root@VM-4-9-centos ~]#  docker inspect -f &#x27;&#123;&#123;.Name&#125;&#125; - &#123;&#123;.NetworkSettings.IPAddress &#125;&#125;&#x27; $(docker ps -aq)</span><br><span class="line">/redis3 - 172.17.0.6</span><br><span class="line">/redis2 - 172.17.0.5</span><br><span class="line">/redis1 - 172.17.0.4</span><br><span class="line">[root@VM-4-9-centos ~]# docker exec -it redis3 /bin/bash</span><br><span class="line">root@1d3ab7315ac9:/data# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; replicaof 172.17.0.4 6379</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">&quot;kongxr&quot;</span><br><span class="line"># https://segmentfault.com/a/1190000040755506</span><br><span class="line">#1.新建一个文件： docker-compose.yml 内容如下：</span><br><span class="line">version: &#x27;3.7&#x27;</span><br><span class="line">services:</span><br><span class="line">  sentinel1:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: redis-sentinel-1</span><br><span class="line">    restart: always</span><br><span class="line">    ports:</span><br><span class="line">      - 26379:26379</span><br><span class="line">    command: redis-sentinel /usr/local/etc/redis/sentinel.conf</span><br><span class="line">    volumes:</span><br><span class="line">      - ./sentinel1.conf:/usr/local/etc/redis/sentinel.conf</span><br><span class="line">  sentinel2:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: redis-sentinel-2</span><br><span class="line">    restart: always</span><br><span class="line">    ports:</span><br><span class="line">    - 26380:26379</span><br><span class="line">    command: redis-sentinel /usr/local/etc/redis/sentinel.conf</span><br><span class="line">    volumes:</span><br><span class="line">      - ./sentinel2.conf:/usr/local/etc/redis/sentinel.conf</span><br><span class="line">  sentinel3:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: redis-sentinel-3</span><br><span class="line">    ports:</span><br><span class="line">      - 26381:26379</span><br><span class="line">    command: redis-sentinel /usr/local/etc/redis/sentinel.conf</span><br><span class="line">    volumes:</span><br><span class="line">      - ./sentinel3.conf:/usr/local/etc/redis/sentinel.conf</span><br><span class="line">      </span><br><span class="line">#2.分别新建三个文件： sentinel1.conf、sentinel2.conf、sentinel1.conf 内容都如下：</span><br><span class="line"># 自定义集群名，其中172.17.0.4 为 redis-master 的 ip，6380 为 redis-master 的端口，2 为最小投票数（因为有 3 台 Sentinel 所以可以设置成 2）</span><br><span class="line"></span><br><span class="line">port 26379</span><br><span class="line">dir /tmp</span><br><span class="line">sentinel monitor mymaster 172.17.0.4 6380 2</span><br><span class="line">sentinel down-after-milliseconds mymaster 30000</span><br><span class="line">sentinel parallel-syncs mymaster 1</span><br><span class="line">sentinel auth-pass mymaster redispwd</span><br><span class="line">sentinel failover-timeout mymaster 180000</span><br><span class="line">sentinel deny-scripts-reconfig yes</span><br><span class="line"></span><br><span class="line">#3.四个文件都放在同义目录下，并使用命令</span><br><span class="line">[root@VM-4-9-centos redis-sentinel]# docker-compose up -d</span><br><span class="line">Creating network &quot;redis-sentinel_default&quot; with the default driver</span><br><span class="line">Creating redis-sentinel-1 ... done</span><br><span class="line">Creating redis-sentinel-3 ... done</span><br><span class="line">Creating redis-sentinel-2 ... done</span><br><span class="line"></span><br><span class="line">#4.测试：进入redis1 发现，当前redis为主节点。然后将该redis关闭。</span><br><span class="line">[root@VM-4-9-centos redis-sentinel]#  docker exec -it redis1 /bin/bash</span><br><span class="line">root@f21ca2cacfea:/data# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; info replication</span><br><span class="line"># Replication</span><br><span class="line">role:master</span><br><span class="line">[root@VM-4-9-centos redis-sentinel]# docker stop redis1</span><br><span class="line">redis1</span><br></pre></td></tr></table></figure>

<h2 id="四、Redis应用"><a href="#四、Redis应用" class="headerlink" title="四、Redis应用"></a>四、Redis应用</h2><h3 id="4-1-分布式锁"><a href="#4-1-分布式锁" class="headerlink" title="4.1 分布式锁"></a>4.1 分布式锁</h3><p>分布式锁本质上要实现的目标就是在 Redis 里面占一个茅坑，当别的进程也要进来占时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。</p>
<p>占坑一般是使用 setnx 指令，只允许被一个客户端占坑。先来先占，用完了，再调用 del 指令释放茅坑。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; setnx lock01 true</span><br><span class="line">OK</span><br><span class="line">... do something critical ...</span><br><span class="line">&gt;del lock01</span><br><span class="line">(integer)1</span><br></pre></td></tr></table></figure>

<p>但是如果 逻辑执行到中间 出现异常了，可能会导致 del 指令没有被调用，这样就会陷入死锁，锁永远得不得释放。于是我们在拿到锁之后，再给锁加上一个过期时间，比如5s，这样即使中间出现异常也可以保证5s之后锁会自动释放。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; setnx lock01 true</span><br><span class="line">OK</span><br><span class="line">&gt;expire lock01 5</span><br><span class="line">... do something critical</span><br><span class="line">&gt;del lock01</span><br><span class="line">(integer)1</span><br></pre></td></tr></table></figure>

<p>但是以上逻辑还是有问题，因为如果在 setnx 和 expire 之间服务器进程突然挂掉了，就会导致 expire 得不到执行，也会造成死锁。</p>
<p>这种问题的根源在于 setnex 和 expire 是两条指令而不是原子指令。如果这两条指令可以一起执行就不会出现问题。这里也不可以使用Redis事务来解决。因为 expire 是依赖于 setnx 的执行结果的，如果 setnx 没抢到锁，expire 是不应该执行的。事务里没有 if-else 分支逻辑，事务的特点是一口气执行，要么全部执行要么一个都不执行。</p>
<p>为了解决这个问题，Redis开源社区涌现出很大分布式锁的library，专门用来解决这个问题，其实现方式极为复杂。如果需要使用分布式锁，不能仅仅使用 Jedis 或者 redis-py 就行了，还得引入分布式锁的 library。为了治理这个乱象，Redis2.8版本中 加入了 set 指令的扩展参数，是的 setnx 和 expire 可以一起执行，彻底解决了分布式锁的乱象。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; set lock01 true ex 5 nx</span><br><span class="line">OK</span><br><span class="line">&gt; del lock01</span><br></pre></td></tr></table></figure>

<p>Redis 的分布式锁不能解决超时问题，如果在加锁和释放之间的逻辑执行的太长，以至于超出了锁的超时限制，就会出现问题。因为这时候锁过期了，第二个线程重新持有了这把锁，但是紧接着第一个线程执行完了业务逻辑，就把锁给释放了，第三个线程就会在第二个线程执行完之前就拿到了锁。</p>
<p>为了避免这个问题，Redis 分布式锁不要用于较长时间的任务。如果真的偶尔出现了，数据出现小波错乱可能需要人工介入解决</p>
<p>有一个更安全的方案是为 set 指令的 value 参数设置为 一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key。但是匹配 value 和删除 key 不是一个原子操作，Redis也没有提供类似于 delifequals 这样的指令，这就需要使用 Lua 脚本来处理了，因为 Lua 脚本可以保证连续多个指令的原子性执行。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># delifequals</span><br><span class="line">if redis.call(&quot;get&quot;,KEYS[1])==ARGV[1] then return redis.call(&quot;del&quot;,KEYS[1]) else return 0 end</span><br></pre></td></tr></table></figure>

<p>可重入性</p>
<p>可重入性就是指 线程在持有锁的情况下再次请求加锁，如果一个锁支持同一个线程的多次加锁，那么这个锁就是可重入的。Redis分布式锁如果需要支持可重入，需要对客户端的 set 方法进行包装，使用线程的 Threadlocal 变量存储当前持有锁的计数。</p>
<h3 id="4-2-延时队列"><a href="#4-2-延时队列" class="headerlink" title="4.2 延时队列"></a>4.2 延时队列</h3><p>平时习惯使用 RabbitMQ和Kafka作为消息队列中间件，来给应用程序之间增加异步消息传递功能。这个两个中间件都是专业的消息队列中间件，其能力很强，但是使用起来也较为繁琐。Redis的消息队列实现很简单，但是并不是专业的消息队列，它没有非常多的高级特性，没有ack保证，如果对消息的可靠性有着极致的追求，那么它就不适合使用。</p>
<h4 id="4-2-1-异步消息队列"><a href="#4-2-1-异步消息队列" class="headerlink" title="4.2.1 异步消息队列"></a>4.2.1 异步消息队列</h4><p>Redis 的 list（列表）数据结构 常用来作为异步消息队列使用，使用 rpush&#x2F;lpush 操作入队列，使用 lpop 和 rpop 来出队列。</p>
<p>客户端是通过队列的 pop 操作来获取消息，然后进行处理。处理完了再接着获取消息，再进行处理，如此往复。</p>
<p>如果队列空了，客户端就会陷入 pop 的死循环，不停地 pop。这就是浪费生命的空循环。空轮询不但拉高了客户端的CPU，redis的QPS也会被拉高，如果这样空轮询的客户端有几十来个，Redis 的慢查询可能会显著增多。</p>
<p>通常使用 sleep 来解决这个问题，让线程休眠一会。但是这样会造成消费者的延迟。可以有更好的解决方案：使用 blpop、brpop，前缀字符b代表的就是 blocking，即堵塞读。堵塞读在队列没有数据的时候，会立即进行休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为0。这个方案有个弊端，就是注意空连接问题。因为线程一直堵塞在那，Redis的客户端连接就成了闲置连接，闲置过久，服务器一般就会主动断开连接，减少闲置资源的占用。这时 blpop、brpop 会抛出异常。所以在 编写客户端消费者时，注意捕获异常和重试。</p>
<h4 id="4-2-2-延迟队列的实现"><a href="#4-2-2-延迟队列的实现" class="headerlink" title="4.2.2 延迟队列的实现"></a>4.2.2 延迟队列的实现</h4><p>上一节提及的 分布式锁。当客户端在处理请求时 加锁没加成功 怎么办。一般是有 3种 策略来处理加锁失败：</p>
<ul>
<li>直接抛出异常，通知用户稍后重试。</li>
<li>sleep，一会再重试。这种方式，会堵塞当前的消息处理线程，导致队列的后续消息处理出现延迟。如果碰撞出现较多或者队列里的消息较多，sleep 可能并不合适。因为个别 死锁的key 导致加锁不成功，线程会彻底堵死，导致后续消息永远得不到及时处理。</li>
<li>将请求转移到延迟队列，过会再试。这种方式较好。</li>
</ul>
<p>延时队列可以通过 Redis的 zset(有序列表)来实现。我们将消息序列化成一个字符串作为 zset 的 value，这个消息的到期处理时间作为 score，然后用多个线程轮询 zset 获取到期的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其他线程可以继续处理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def delay(msg):</span><br><span class="line">	msg.id = str(uuid.uuid4())</span><br><span class="line">	value = json.dumps(msg)</span><br><span class="line">	retry_ts = time.time() + 5</span><br><span class="line">	redis.zadd(&quot;delay-queue&quot;,retry_ts,value)</span><br><span class="line">def loop():</span><br><span class="line">	while True:</span><br><span class="line">		values = redis.zrangebyscore(&quot;delay-queue&quot;,0,time.time(),start=0,num=1)</span><br><span class="line">		if not values:</span><br><span class="line">			time.sleep(1)	#延迟队列是空当，休息1s</span><br><span class="line">			continue</span><br><span class="line">		value = value[0]</span><br><span class="line">		success = redis.zrem(&quot;delay-queue&quot;,value)</span><br><span class="line">		if success:</span><br><span class="line">			msg = json.loads(value)</span><br><span class="line">			handle_msg(msg)</span><br></pre></td></tr></table></figure>

<p>Redis 的 zrem 方法是多线程多进程抢任务的关键，它的返回值决定了当前实例有没有抢到任务，因为loop方法可能被多个线程、多个进程调用，同一任务可能会被多个进程线程抢到，通过 zrem 来决定唯一的属主。同时注意对 handle_msg 进行异常捕获。</p>
<p>上述方案还是存在明显缺点：1.原子性问题：先查询再删除 这两个操作不是原子的，明显会出现并发问题，虽然我这里判断了 zrem 的数量，但是可能会出现部分 key 被其他机器给消费的情况；2.性能问题：zrangebyscore还好，但是如果在时间间隔内产生了大量消息，如果同时处理，zrem 的性能会急剧下降。</p>
<p>性能问题解决：</p>
<ul>
<li>多线程并发消费</li>
<li>将定时任务的启动延迟时间或者每次循环的时间随机，让每台机器处理消息点有一定间隔，这样单次时间间隔内要处理的消息的数据会大大减少。</li>
<li>zrangebyscore 命令设置 limit，限制单次处理消息的数据</li>
</ul>
<p>原子性问题解决：</p>
<p>使用Lua脚本 解决zrangebyscore 和 zrem 不是原子化操作的问题。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">local key = KEYS[1]</span><br><span class="line">local min = ARGV[1]</span><br><span class="line">local max = ARGV[2]</span><br><span class="line">local result = redis.call(&#x27;zrangebyscore&#x27;,key,min,max,&#x27;LIMIT&#x27;,0,10)</span><br><span class="line">if next(result) ~= nil and #result &gt; 0 then</span><br><span class="line">	local re = redis.call(&#x27;zrem&#x27;,key,unpack(reslut));</span><br><span class="line">	if(re &gt; 0) then</span><br><span class="line">		return result;</span><br><span class="line">	end</span><br><span class="line">else</span><br><span class="line">	return &#123;&#125;</span><br><span class="line">end</span><br></pre></td></tr></table></figure>

<h3 id="4-3-位图"><a href="#4-3-位图" class="headerlink" title="4.3 位图"></a>4.3 位图</h3><p>在平时开发过程中，会有一些bool型数据需要存取，比如用户一年的签到记录，签了是1，没签是0，要记录365天。如果使用普通的 key&#x2F;value，每个用户要记录 365个，当用户上亿时，需要的存储空间是惊人的。</p>
<p>位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。我们可以使用普通的 get&#x2F;set 直接获取和设置整个位图的内容，也可以使用 位图操作 getbit&#x2F;setbit 等 将byte数组看成 位数组 来处理。</p>
<p>Redis 的位数组是自动扩展，如果设置了某个偏移位置超过了现有的内容范围，就会自动将位数组进行零扩充。</p>
<h4 id="4-3-1-基本使用"><a href="#4-3-1-基本使用" class="headerlink" title="4.3.1 基本使用"></a>4.3.1 基本使用</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt; setbit bitArray01 1 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 2 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 4 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 9 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 10 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 13 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 15 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; get bitArray01</span><br><span class="line">&quot;he&quot;</span><br></pre></td></tr></table></figure>

<p>上面的例子，可以理解为 零存整取，同样也可以 零存零取，整存整取。零存：就是使用 setbit 对位值 进行逐个设置。整存：就是使用字符串一次性填充所有位数组，覆盖掉旧值。</p>
<h4 id="4-3-2-统计和查找"><a href="#4-3-2-统计和查找" class="headerlink" title="4.3.2 统计和查找"></a>4.3.2 统计和查找</h4><p>Redis 提供了位图统计指令 bitcount 和位图查找指令 bitpos，bitcount 用来统计指定位置范围内 1 的个数，bitops 用来查找指定范围内出现的第一个 0或1。</p>
<p>遗憾的是，start 和 end 参数是 字节索引，也就是说指定的位范围必须是 8的倍数，而不能任意指定。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">set w hello			# 整存</span><br><span class="line">bitcount w 0 0 # 第一个字符中1的位数</span><br><span class="line">bitcount w 0 1 # 前两个字符中1的位数</span><br><span class="line">bitops w 0 # 第一个零位</span><br><span class="line">bitops w 1 0 1 2 # 第二到第三字符中 第一个出现1的位置</span><br></pre></td></tr></table></figure>

<h4 id="4-3-3-魔术指令-bitfield"><a href="#4-3-3-魔术指令-bitfield" class="headerlink" title="4.3.3 魔术指令 bitfield"></a>4.3.3 魔术指令 bitfield</h4><p>之前我们设置或者获取 指定位的值 都是单个位的，如果要一次操作多个位，就必须要使用管道来处理。Redis3.2之后，新增命令 bitfield 可以使用。其下有三个子指令分别是 get&#x2F;set&#x2F;incrby，它们都可以对指定位片段进行读写，但是最多只能处理64个连续的位，如果超过64位，就得使用多个子指令，bitfield 可以一次执行多个子指令。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">set w hello</span><br><span class="line">bitfield w get u4 0 # 从第一位开始取4个位，取出结果为无符号数（u）</span><br><span class="line">bitfield w get i3 2 # 从第三位开始取3个位，取出结果为有符号数（i）</span><br><span class="line">bitfield w get u4 0 get i3 2 # 可以一次执行多个子指令</span><br><span class="line">bitfield w et u8 8 97 #从第8个位开始，将接下来的8个位 用无符号数97 替换</span><br></pre></td></tr></table></figure>

<p>所谓有符号数是指 取出来的位数组中第一个位是当作符号位，剩下的才是值。如果第一位是1，那就是负数。无符号数表示非负数，没有符号位，获取到位数组全部都是值。有符号数 最多可以获取64位，无符号数 只能获取63位。</p>
<p>第三个指令 incrby，它用来对指定范围的位进行自增操作。既然提到了自增，就有可能出现溢出。如果增加了正数，会出现上溢。如果增加负数，会出现下溢出。如果出现溢出，就将溢出的符号位丢掉。如果是8位无符号数255，加1就变成 0。</p>
<h3 id="4-4-HyperLogLog"><a href="#4-4-HyperLogLog" class="headerlink" title="4.4 HyperLogLog"></a>4.4 HyperLogLog</h3><p>HyperLogLog提供的是一个不精确但是节省空间的去重计数方案：如果页面访问量非常大，比如一个爆款页面几千万的 UV，就需要一个很大的 Set集合 来统计，这就非常浪费空间。如果这样的页面很多，那所需要的存储空间是惊人的。如果对统计精确度不需要太精确，就可以使用HyperLogLog，它的标准误差是0.81%。</p>
<h4 id="4-4-1-使用方法"><a href="#4-4-1-使用方法" class="headerlink" title="4.4.1 使用方法"></a>4.4.1 使用方法</h4><p>HyperLogLog 提供了两个指令 pfadd 和 pfcount，一个是增加计数，一个是获取计数。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; pfadd w user1</span><br><span class="line">(integer)1</span><br><span class="line">&gt; pcount w</span><br><span class="line">(integer)1</span><br></pre></td></tr></table></figure>

<p>除了上面两个指令，还有一个 pfmerge，用于将多个 pf 计数值累计在一起形成一个新的 pf 值。</p>
<h4 id="4-4-2-数学原理"><a href="#4-4-2-数学原理" class="headerlink" title="4.4.2 数学原理"></a>4.4.2 数学原理</h4><p><strong>极大似然估计的直观理解</strong></p>
<p>其使用的数学原理是统计学中的极大似然估计。接下去我将用多个场景逐步深入解析。<br><strong>场景1：</strong>现在有2个不透明的口袋，其中都装有100个球，A口袋中是99个白球1个黑球，B口袋中是99个黑球1个白球。当我们随机挑选一个口袋，然后从中拿出一个球。如果拿出的球是白色的，那么我们可以说“大概率”我们取出的是A口袋。这种直觉的推测其实就包含了“极大似然估计”的思想。</p>
<p><strong>场景2：</strong>我们只保留A口袋，其中99个白球，1个黑球。很容易我们就可以得出结论，从中取出任意一个球，是白球的概率为99%，是黑球的概率为1%。这是一种<strong>正向的推测</strong>：<br><em>我们知道了</em>**<em>条件（99个白球，1个黑球）*<em><strong>，从而推测出</strong></em></em>结果（取出任意一个球，是白球的概率为99%）***。<br>但这只是理论上的推测，如果实际取球100次，每次都放回，那么取出黑球的次数并不一定是1次，可能是0次，也可能超过1次。我们取球的次数越多，实际情况将越符合理论情况。</p>
<p><strong>场景3：</strong>还是A口袋，只不过此时其中白球和黑球的数量我们并不知晓。于是我们开始从中拿球，每拿出一个球都记录下结果，并将其放回。如果我们取球100次，其中99次是白球，1次是黑球，我们可以说A口袋中可能是99个白球，但并不能非常肯定。当我们取球10000次的时候，其中9900次是白球，100次是黑球，此时我们就可以大概率确定A口袋中是99个白球，而这种确定程度随着我们实际取球次数的增加也将不断增加。这就是一种<strong>反向的推测</strong>：<br><em>我们观察了</em>**<em>结果（取10000次球，9900次是白球，100次是黑球）*<em><strong>，可以推测出</strong></em></em>条件（A口袋中放了99个白球，1个黑球）***。<br>当然这种推测的结果并非是准确的，而是一种大概率的估计。<br>无论是正向推测或是反向推测，只有当实际执行操作的次数足够多的时候，才能使得实际情况更接近理论推测。这就非常符合hyperloglog的特点，只有当数据量足够大的时候，误差才会足够小。</p>
<p>因此极大似然估计的本质就是：当能观察的结果数量足够多时，我们就可以大概率确定产生相应结果所需要的条件的状态。这种通过大量结果反向估计条件的数学方法就是极大似然估计。</p>
<p><strong>伯努利实验与极大似然估计</strong></p>
<p>了解极大似然估计之后，我们就需要引入第二个数学概念，伯努利实验。<br>不要被这个名字唬住，伯努利实验其实就是扔硬币，接下去我们就来了解下这枚硬币要怎么扔。下文所说的硬币都是最普通的硬币，只有正反两面，且每一面朝上的概率都是50%。<br><strong>场景1：</strong>我们随机扔一次硬币，那么得到正面或反面的可能性是相同的。如果我们扔10000次硬币，那么可以估计到大概率是接近5000次正面，5000次反面。这是最简单的正向推测。</p>
<p><strong>场景2：</strong>如果我们扔2次硬币，是否可能2次都是正面？当然有可能，并且概率为1&#x2F;4。如果我们扔10次硬币呢，是否可能10次都是正面？虽然概率很小，但依然是有可能的，概率为1&#x2F;1024。同样的，无论是100次、1000次，即使概率很小，也依然存在全部都是正面朝上的情况，假如扔了n次，那么n次都是正面的概率为12𝑛12�。这也是正向的推测，只不过增加了全都是正面朝上的限定。</p>
<p><strong>场景3：</strong>现在我们按下面这种规则扔硬币：不断扔硬币，如果是正面朝上，那么就继续扔，直到出现反面朝上，此时记录下扔硬币的总次数。例如我们抛了5次硬币，前4次都是正面朝上，第5次是反面朝上，我们就记录下次数5。通过场景2，我们可以知道这种情况发生的概率为1&#x2F;32。按我们的直觉可以推测，如果一个结果发生的概率是1&#x2F;32，那么我们大体上就需要做32次同样的事情才能得到这个结果（当然从更严谨的数学角度，并不能这么说，但本文不想涉及专业的数学描述，所以姑且这么理解，其实也挺符合一般常识判断的）。<br>那么假如张三做了若干次这种实验，我观察结果，发现记录下的总次数的<strong>最大值</strong>是5，那就说明在这若干次实验中，至少发生了一次4次正面朝上，第5次反面朝上的情况，而这种情况发生的概率是1&#x2F;32，于是我推测，张三大概率总共做了32次实验。这就是一种反向推测：<br><em>即根据</em><strong><em>结果（发生了一次1&#x2F;32概率才会出现的结果）*<em><strong>，推测</strong></em></em>条件（大概率做了32次实验）*<strong>。<br>更通俗来说，如果一个结果出现的概率很小，但却实际发生了了，就可以推测这件事情被重复执行了很多次。结果出现的概率越小，事情被重复执行的次数就应当越多。就像生活中中彩票的概率很低，普通人如果想中那可不就得买很多次嘛，中奖概率越低，一般需要购买彩票的次数就越多。相应的如果一个人中奖了，我们可以说这个人</strong>大概率</strong>上购买了非常多次彩票。这就是伯努利实验与极大似然估计结合的通俗理解。</p>
<p><strong>另外特别注意的，我们推测条件时，需要观察的总次数的最大值，因为最大值代表了最小概率，而最小概率才是推测条件的依据。下文redis同理。</strong></p>
<h4 id="4-4-3-redis实现"><a href="#4-4-3-redis实现" class="headerlink" title="4.4.3 redis实现"></a>4.4.3 redis实现</h4><p>redis实现本质也是利用了“扔硬币”产生的“极大似然估计”原理，因此接下去我们就详细看看redis是怎么扔硬币的。<br>在伯努利试验的场景3中，我们做的实验有3个特点：<br>1.硬币只有正反两面。<br>2.硬币正反面出现的概率相同。<br>2.单次实验需要投掷多次硬币。</p>
<p>而计算机中的hash算法正好可以满足这3个条件：<br>1.hash结果的每一个bit只有0和1，代表硬币的正反两面。<br>2.如果hash算法足够好，得到的结果就足够随机，可以近似认为每一个bit的0和1产生的概率是相同的。<br>3.hash的结果如果是64个bit，正好代表投掷了64次硬币。</p>
<p>因此执行一次hash，就相当于完整地进行了一次场景3中的投币实验。按照约定，实验完成后，我们需要记录硬币投掷的结果。<br>假定现在有2个用户id；user1、user2<br>先对user1进行hash，假定得到如下8个bit的结果：<br>10100100<br>此时从右到左，我们约定0表示反面，1表示正面，于是在这次实验中，第一个为1的bit出现在第三位，相当于先投出了2次反面，然后投出1次正面，于是我们记录下这次实验的投掷次数为3。因为约定只要投出正面，当次实验就结束，所以第一个1左边的所有bit就不再考虑了。<br>再对user2进行hash，假定得到：<br>01101000<br>第一个为1的bit出现在第4位，于是记录下4。<br>对于<strong>每个用户的访问请求，我们都可以对用户的id进行hash</strong>（相当于场景3中进行一次实验），并记录下第一个为1的bit出现的位数（相当于场景3中记录下硬币的投掷次数），那么<strong>通过记录到的位数的最大值，我们就可以大概估计出一共进行了多少次实验</strong>（相当于场景3中的反向推测），也就是有多少个不同的用户发生了访问。<br>例如某个页面有若干个用户进行了访问，我们观察记录下的数据，发现记录下的最大值是10，就意味着hash的结果至少出现了一次右边9个bit都为0的情况。而这种情况发生的概率为1&#x2F;1024，于是我们可以推测大概有1024个用户访问过该页面，才有可能出现一次这种结果。</p>
<p>所以其实可以这样理解：</p>
<p>每个用户ID的 hash结果相当于此用户的投币结果，我们看下 hash值从右向左第一次出现1的位置。如果比之前用户hash记录出现1的位置更靠左，则记录。这样如果最后记录的最大值是10，则可以推测1024个用户访问过。</p>
<p>又因为同一用户ID hash结果是唯一的，所以同一个用户ID即使多次实验，也不会影响精准性。当用户越多，则我们通过概率推测的用户数量 越接近实际情况。</p>
<h3 id="4-5-布隆过滤器"><a href="#4-5-布隆过滤器" class="headerlink" title="4.5 布隆过滤器"></a>4.5 布隆过滤器</h3><p>HyperLogLog 可以用来进行估值，它非常有价值，可以解决很多精确度要求不高的统计需求。但是如果我们想要知道某一个值是不是已经不在 HyperLogLog 结构里面了，它就无能为力的。</p>
<p>现实中，比如推荐系统：用户的视频推荐系统，每次推荐 需要查看用户是否观看过此视频。问题是，当用户量很大，每个用户观看过的视频总数又很大的情况下，去重工作在在性能上考验很大。如果数据存储在 关系数据库中，去重就需要频繁地对数据库进行 exists 查询。</p>
<p>如果使用缓存，但是这么多历史记录全部缓存起来，就得浪费很多存储空间。布隆过滤器可以解决此问题，它可以起到去重的同时，在空间上还能节省90%以上，只是稍微那么不精确。</p>
<p>当布隆过滤器说 某个值存在时，这个值可能不存在；当它说这个值不存在时，那就肯定不存在。</p>
<p>那么可以使用布隆过滤器 判断 需要推荐的时候，是否在用户观看历史记录集合中。如果不在，则推荐。如果判断在历史记录中，实际可能在 也可能不在，因为会有概率误判。所以 可以保证推荐的内容肯定是用户没看过的，但可能 也会把极少量用户没有看过的内容 误判成用户看过，而过滤掉。</p>
<h4 id="4-5-1-基本使用"><a href="#4-5-1-基本使用" class="headerlink" title="4.5.1 基本使用"></a>4.5.1 基本使用</h4><p>Redis官方提供的布隆过滤器到了Redis4.0提供了插件功能之后正式登场。可以通过docker直接体验</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; docker pull redislabs/rebloom</span><br><span class="line">&gt; docker run -p 6379:6379 redislabs/rebloom</span><br><span class="line">&gt; redis-cli</span><br></pre></td></tr></table></figure>

<p>布隆过滤器基本指令：</p>
<ul>
<li>bf.add [collection] [element]：添加 元素element 进入 过滤器collection</li>
<li>bf.exists [collection] [element]：查询 元素element 是否存在，返回1表示存在，0表示不存在</li>
<li>bf.madd [collection] [element01] [element02]：一次 添加多个 元素进入 过滤器</li>
<li>bf.mexists：一次 查询多个元素 是否在过滤器</li>
</ul>
<p>上面指令使用的布隆过滤器只是默认参数的布隆过滤器，它在外面第一次add的时候被自动创建。Redis还提供了自定义参数的布隆过滤器，需要我们在 add 之前，使用 bf.reserve 指令显式创建。如果对应的key已经存在了，bf.reserve 会报错。bf.reserve 有三个参数，分别是 key，error_rate 和 initial_size。错误率越低，需要的空间越大。initial_size 参数表示预计放入的元素数量，当实际数量超过这个值，误判率会上升。所以一般 initial_size 需要设置一个较大的数值，避免超过，导致误判率升高。如果不使用 bf.reserve，默认的 error_rate 是 0.01,默认的 initial_size 是 100。</p>
<p>注意：如果 initial_size 估计的过大，也会浪费存储空间，估计的过小，就会影响准确率。</p>
<h4 id="4-5-2-原理"><a href="#4-5-2-原理" class="headerlink" title="4.5.2 原理"></a>4.5.2 原理</h4><p>每个布隆过滤器在Redis的数据结构里面就是 一个大型的位数组和几个不一样的无偏hash函数。所以无偏就是能够把元素的 hash值 算的比较均匀。</p>
<p>向过滤器中添加key时，会使用多个 hash 函数对 key 进行 hash算得一个整数索引值，然后对位数组长度进行取模运算，得到一个位置。每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为1，就完成了 add 操作。</p>
<p>向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 函数的几个位置都计算出来，看看 位数组中 这几个位置是否都 为1，只要有一个为 0，那么说明布隆过滤器中 这个key不存在。如果都是1，这并不能说明这个key就一定存在，只是极有可能存在。因为这些位被置成1，可能是因为添加其他 key 时导致的。</p>
<p>如果这个 位数组比较稀疏，这个误判的概率就很小，如果这个数组比较拥挤，误判的概率就会变大。使用时如果实际元素开始超过初始化大小，应该对布隆过滤器进行重建，重新分配一个size更大的过滤器，再将所有历史元素批量 add 进去。</p>
<h4 id="4-5-3-空间占用估计"><a href="#4-5-3-空间占用估计" class="headerlink" title="4.5.3 空间占用估计"></a>4.5.3 空间占用估计</h4><p>布隆过滤器有两个参数：第一个是预计元素的数量n，第二个是错误率 f。公式根据这两个输入 得到两个输出，第一个输出是 位数组的长度i，也就是需要的存储空间大小（bit），第二个输出是 hash 函数的最佳数量 k。hash函数的数量也会直接影响到错误率，最佳的数据会有最低的错误率。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">k = 0.7 * (i/n)  # 约等于</span><br><span class="line">f = 0.6185^(i/n)		# ^表示次方计算</span><br></pre></td></tr></table></figure>

<p>从公式可以看出：</p>
<ul>
<li>位数组 相对越长(i&#x2F;n)，错误率 f 越低</li>
<li>位数组 相对越长(i&#x2F;n)，hash函数需要的最佳数量也越多，影响计算效率</li>
<li>当一个元素平均需要 1个字节(8 bit)的指纹空间(i&#x2F;n&#x3D;8)，错误率大约2%</li>
<li>错误率为10%，一个元素需要的平均指纹空间为 4.792个bit</li>
<li>错误率为0.1%，一个元素需要的平均指纹空间为 14.377个bit</li>
</ul>
<p>从上面可以看到，一个元素需要占据15bit，那相对set集合的空间优势是不是就没有那么明显了？set中会存储每个元素的内容，而布隆过滤器仅仅存储元素的指纹。元素的内容大小就是字符串的长度，它一般有多个字节甚至几十个字节，每个元素本身还需要一个指针被set集合来引用。</p>
<h3 id="4-6-简单限流"><a href="#4-6-简单限流" class="headerlink" title="4.6 简单限流"></a>4.6 简单限流</h3><p>在Redis中，可以使用 ZSet 数据结构 实现该功能。可以把 zset 中的 score 值设置为 时间戳 ，这样就可以圈出一个时间段内的所有数据。即 只要 时间窗口内的数据，时间窗口外的数据都可以砍掉。那么 zset 的value 填什么值呢，也可以填时间戳，只需保证其唯一性就行。</p>
<p>这样就可以 用 ZSet 记录用户的行为历史，每个行为都会作为一个 zset 中的一个 key 保存下来。同一个用户同一种行为 会使用一个 zset 记录。为了节省内存，我们只需要保留时间窗口内的行为记录，同时如果用户是冷用户，滑动时间窗口内的行为是空记录，那么这个 zset 就可以从内存中移除，不再占用空间。</p>
<p>通过统计滑动窗口内的行为数量与阈值 max_count 进行比较就可以得出当前的行为是否允许。</p>
<p>整体思路：每一个行为到来时，都维护一次时间窗口。将时间窗口外的记录全部清理掉，只保留窗口内的记录。zset集合中 只有 score 值非常重要，value没有特别的意义。</p>
<p>缺点：要记录时间窗口内所有的行为记录。如果这个量很大，比如限定 60s 内操作不得超过 100w 次，那么这就不适合这样做限流了，因为会消耗大量的存储空间。</p>
<h3 id="4-7-漏斗限流"><a href="#4-7-漏斗限流" class="headerlink" title="4.7 漏斗限流"></a>4.7 漏斗限流</h3><p>Redis4.0 提供了一个限流 Redis 模块，它叫 redis-cell。该模块也使用了漏斗算法，并提供了原子的限流指令。</p>
<p>该模块只有1条指令 cl.throttle ，它的参数和返回值都略显复杂。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; cl.throttle key 15 30 60 1</span><br><span class="line"># key是键名 </span><br><span class="line"># 第二个参数是 漏斗容量</span><br><span class="line"># 第三个参数、第四个参数 表示 60s内 最多 30次（可以当作漏斗的流速）</span><br><span class="line"># 第五个参数为 可选参数,默认为1.</span><br><span class="line"> </span><br><span class="line">指令会返回五个参数，分别表示：</span><br><span class="line"># 0表示允许，1表示拒接</span><br><span class="line"># 漏斗容量</span><br><span class="line"># 漏斗剩余空间</span><br><span class="line"># 如果拒接了，需要多长时间之后再试（多久后漏斗有空间，单位秒）</span><br><span class="line"># 多长时间后，漏斗完全空出来（单位秒）</span><br></pre></td></tr></table></figure>

<p>在执行限流指令时，如果被拒绝了，就需要丢弃或重试，cl.throttle 指令考虑的非常周到，连重试时间给我们了，直接取返回结果数组的第四个值进行 sleep 即可，如果不想堵塞线程，也可以异步定时任务来重试。</p>
<h3 id="4-8-近水楼台-GeoHash"><a href="#4-8-近水楼台-GeoHash" class="headerlink" title="4.8 近水楼台-GeoHash"></a>4.8 近水楼台-GeoHash</h3><p>Redis在 3.2 版本以后增加了 GEO 模块，意味着我们可以使用 Redis 来实现 微信[附近的人]、美团[附件的餐馆]这样的功能了。</p>
<h4 id="4-8-1-用数据库来算附近的人"><a href="#4-8-1-用数据库来算附近的人" class="headerlink" title="4.8.1 用数据库来算附近的人"></a>4.8.1 用数据库来算附近的人</h4><p>地图元素的位置数据使用二维的经纬度表示，经度范围 (-180,180]，纬度范围 (-90,90],纬度正负以赤道为界，北正南负，经度正负以本初子午线为界，东正西负。</p>
<p>当两个距离不是很远时，可以直接使用勾股定理就能算得元素之间的距离。平时使用的 [附近的人] 的功能，元素距离都不是很大，勾股定理算距离足以。不过需要注意的是，经纬度坐标的密度不一样（经度总共360度，纬度总共180度），勾股定理计算平方差时之后再求和时，需要按一定的系数比加权求和。</p>
<p>如果使用关系型数据库，基本采用（元素ID,经度,纬度）存储。那此时就很难通过遍历来计算所有的元素和目标元素的距离然后再进行排序，这个计算量太大了，性能指标肯定无法满足。一般的方法都是通过矩形区域来限定元素的数量，然后对区域内的元素进行 全量距离 计算再排序。</p>
<p>为了满足高性能的矩形区域算法，数据表需要在经纬度坐标上加上双向复合索引（x,y），这样可以最大优化查询性能。但是数据库查询性能毕竟有限，如果 附近的人 查询请求非常多，在高并发场合，这可能并不是一个很好的方案。</p>
<h4 id="4-8-2-GeoHash算法"><a href="#4-8-2-GeoHash算法" class="headerlink" title="4.8.2 GeoHash算法"></a>4.8.2 GeoHash算法</h4><p>业界比较通用的地理距离排序算法是 GeoHash 算法，Redis 也使用 GeoHash 算法。GeoHash 算法将二维的经纬度数据映射到一维的整数，这样所有的元素都将挂载到一条线上，距离靠近的二维坐标映射到一维后的点之间距离也会很近。当我们想要计算 [附近的人时]，首先将目标的位置 映射到这条线上，然后在这个一维的线上获取附近的点就行了。</p>
<p>那这个映射算法具体是怎么计算的？它将整个地球看成一个二维平面，然后划分成了一系列正方形的方格，就好比围棋棋盘。所有的地图元素坐标都将放置于唯一的方格中。方格越小，坐标越精确。然后对这些方格进行整数编码，越是靠近的方格编码越是接近。那如何编码呢？一个最简单的方案就是切蛋糕法。设想一个正方形的蛋糕摆在你面前，二刀下去均分分成四个小正方形，这四个小正方形可以分别标记为00，01，10，11四个二进制整数。然后对每个小正方形继续用二分刀法切割一下，这时每个小小正方形使用4bit的二进制整数予以表示。然后继续切下去，正方形就会越来越小，二进制整数也会越来越长，精确度就会越来越高。</p>
<p>上面使用的是二刀法，进行编码。实际上还有其他很多方法进行编码。</p>
<p>编码之后，每个地图元素的坐标都将变成一个整数，通过这个整数可以还原出元素的坐标，整数越长，还原出来的坐标值的损失程度就越小。GeoHash算法会继续对这个整数做一次 base32 编码（0-9,a-z去掉a,i,l,o四个字母）变成一个字符串。在Redis里面，经纬度使用52位的整数进行编码，放进了zset里面，zset的 value 元素的key，score 是 GeoHash 的52位的整数值。zset 的 score 虽然是浮点数，但是对于 52位的整数值，它可以无损存储。</p>
<p>在使用 Redis 进行 Geo 查询时，我们要时刻想到它的内部结构实际上只是一个 zset(skiplist)。通过 zset 的 score 排序就要可以得到坐标附近的其他元素（实际情况要复杂一点），通过将 score 还原成坐标值就可以得到元素的原始坐标。</p>
<h4 id="4-8-3-基本使用"><a href="#4-8-3-基本使用" class="headerlink" title="4.8.3 基本使用"></a>4.8.3 基本使用</h4><p>Redis 提供的 Geo 指令只有 6 个。</p>
<ul>
<li>增加geoadd 指令携带 集合名称以及多个经纬度名称三元组。这里也可以一次性 添加多个元组。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 实际使用</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.48105 39.996794 x</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.48105 39.996794 xr</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.48110 39.996894 xrt</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.48410 39.996294 xrty 112.14517 38.12541 xrtu</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure>

<p>Redis 没有提供 geo 删除指令，但是因为 geo 的底层实现是 zset，所以可以使用 zrem key member 命令实现对 地理位置信息的删除。</p>
<ul>
<li>查看距离geodist 可以用来计算两个元素之间的距离，携带 集合名称、2个名称和距离单位</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geodist company xr xrt km</span><br><span class="line">&quot;0.0120&quot;</span><br></pre></td></tr></table></figure>



<ul>
<li>获取元素位置geopos 指令可以获取集合中任意元素的经纬度坐标，可以一次获取多个。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geopos company xr</span><br><span class="line">1) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">   2) &quot;39.99679348858259686&quot;</span><br><span class="line">127.0.0.1:6379&gt; geopos company xr xrt</span><br><span class="line">1) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">   2) &quot;39.99679348858259686&quot;</span><br><span class="line">2) 1) &quot;116.4810982346534729&quot;</span><br><span class="line">   2) &quot;39.99689487742897143&quot;</span><br></pre></td></tr></table></figure>

<p>我们观察到获取的经纬度坐标和 geoadd 进去的坐标有轻微的误差，原因是 geohash 对二维坐标进行的一维映射是有损的，通过映射再还原回来的值会出现较小的差别。</p>
<ul>
<li>获取元素的 Hash 值geohash 可以获取元素的经纬度编码字符串，上面说过它是 base32 编码。你可以使用这个编码值去 <a target="_blank" rel="noopener" href="http://geohash.org/$%7Bhash%7D">http://geohash.org/${hash}</a> 中直接定位，它是 geohash 的标准编码值。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geohash company xr</span><br><span class="line">1) &quot;wx4gd94yjn0&quot;</span><br></pre></td></tr></table></figure>



<ul>
<li>附近的georadiusbymember 指令是最为关键的指令，它可以用来查询指定元素附近的其他元素，它的参数非常复杂。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 范围20公里以内最多3个元素按距离正排，它不会排除自身</span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember company xr 20 km count 3 asc</span><br><span class="line">1) &quot;finchina&quot;</span><br><span class="line">2) &quot;xr&quot;</span><br><span class="line">3) &quot;xrt&quot;</span><br><span class="line"># 三个可选参数 withcoord withdist withhash 用来携带附加参数</span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember company xr 20 km withcoord withdist withhash count 3 asc</span><br><span class="line">1) 1) &quot;finchina&quot;</span><br><span class="line">   2) &quot;0.0000&quot;</span><br><span class="line">   3) (integer) 4069887154388167</span><br><span class="line">   4) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">      2) &quot;39.99679348858259686&quot;</span><br><span class="line">2) 1) &quot;xr&quot;</span><br><span class="line">   2) &quot;0.0000&quot;</span><br><span class="line">   3) (integer) 4069887154388167</span><br><span class="line">   4) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">      2) &quot;39.99679348858259686&quot;</span><br><span class="line">3) 1) &quot;xrt&quot;</span><br><span class="line">   2) &quot;0.0120&quot;</span><br><span class="line">   3) (integer) 4069887154432781</span><br><span class="line">   4) 1) &quot;116.4810982346534729&quot;</span><br><span class="line">      2) &quot;39.99689487742897143&quot;</span><br></pre></td></tr></table></figure>



<ul>
<li>查询指定坐标附近的元素除了 georadiusbymember 指令根据元素查询附近的元素，Redis还提供了根据坐标值来查询附近的元素 georadius，这个指令更加有用，它可以根据用户的定位来计算。它的参数和 georadiusbymember 基本一致，除了将目标元素改成经纬度坐标值</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; georadius company 116.18119895 39.9977934 100 km withdist count 2 desc</span><br><span class="line">1) 1) &quot;xrty&quot;</span><br><span class="line">   2) &quot;25.8103&quot;</span><br><span class="line">2) 1) &quot;xrt&quot;</span><br><span class="line">   2) &quot;25.5539&quot;</span><br></pre></td></tr></table></figure>



<p>在一个地图应用中，车的数据、餐馆的数据、人的数据 可能会有百万千万条，如果使用 Redis 的 geo 数据结构，它们将全部放在一个 zset 集合中。在 Redis 的集群环境中，集合可能从一个节点迁移到另一个节点，如果单个key的数据过大，会对集群的迁移工作造成较大影响，在集群环境中的单个key对应的数据量不宜超过 1M，否则会导致集群迁移出现卡顿现象，影响线上服务的正常运行。</p>
<p>所以，这里建议 geo 的数据使用单独的 Redis 实例部署，不使用集群环境。</p>
<p>如果数据量过亿甚至更大，就需要对 geo 数据进行拆分。在人口特大的城市，甚至可以按区划分，这样就可以显著降低单个 zset 集合的大小。</p>
<h3 id="4-9-大海捞针-scan"><a href="#4-9-大海捞针-scan" class="headerlink" title="4.9 大海捞针 scan"></a>4.9 大海捞针 scan</h3><p>有时候需要从 Redis 实例成千上万的 key 中找出特定前缀的 key 列表来手动处理数据，可能是修改它的值，也可能是删除key。这里就有一个问题，如何从海量 key 中找到满足特定前缀的 key 列表？</p>
<p>Redis 提供了一个简单暴力的指令 keys 用来列出所有满足 特定正则字符串规则的 key。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set code1 a</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; mset code2 2 code3 3 code4 4 code5 5</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; keys code*</span><br><span class="line">1) &quot;code5&quot;</span><br><span class="line">2) &quot;code4&quot;</span><br><span class="line">3) &quot;code1&quot;</span><br><span class="line">4) &quot;code3&quot;</span><br><span class="line">5) &quot;code2&quot;</span><br></pre></td></tr></table></figure>

<p>这个指令非常简单，提供一个简单的正则字符串即可，但是有很明显的两个缺点。 </p>
<p>1.没有 offset、limit参数，一次性吐出所有满足条件的 key，万一实例中有几百万个 key 满足条件，则打印字符串太多。</p>
<p>2.keys 算法是 遍历算法，复杂度是 O(n)，如果实例中有上千万级以上的 key，这个指令就会导致 redis 服务卡顿，所有读写 redis 的其他指令都会被延后甚至超时，因为redis是单线程程序，顺序执行所有指令，其他指令必须等到当前 keys 指令执行完成后才可以继续。</p>
<p>Redis为解决这个问题，在2.8版本加入了 scan 。scan 相比 keys具备以下优点：</p>
<ul>
<li>复杂度虽然也是0(n)，但是它是通过游标分布进行的，不会堵塞线程。</li>
<li>提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是要给 hint，返回的参数可多可少。</li>
<li>同 keys 一样提供 模式匹配功能。</li>
<li>服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数。</li>
<li>遍历的过程中，如果有数据修改，改动后的数据能不能被遍历到是不确定的。</li>
<li>单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零。</li>
</ul>
<h4 id="4-9-1-scan-基础使用"><a href="#4-9-1-scan-基础使用" class="headerlink" title="4.9.1 scan 基础使用"></a>4.9.1 scan 基础使用</h4><p>往redis插入了10条数据，code1到code10。</p>
<p>scan 提供了三个参数，第一个是 cursor 整数值，第二个是 key 的正则模式，第三个是 遍历的 limit hint。第一次遍历时，cursor值为0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0时结束。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0 match code* count 4</span><br><span class="line">1) &quot;6&quot;</span><br><span class="line">2) 1) &quot;code8&quot;</span><br><span class="line">   2) &quot;code1&quot;</span><br><span class="line">   3) &quot;code4&quot;</span><br><span class="line">   </span><br><span class="line">127.0.0.1:6379&gt; scan 6 match code* count 4</span><br><span class="line">1) &quot;9&quot;</span><br><span class="line">2) 1) &quot;code2&quot;</span><br><span class="line">   2) &quot;code6&quot;</span><br><span class="line">   3) &quot;code9&quot;</span><br><span class="line">   4) &quot;codex&quot;</span><br><span class="line">   </span><br><span class="line">127.0.0.1:6379&gt; scan 9 match code* count 4</span><br><span class="line">1) &quot;7&quot;</span><br><span class="line">2) 1) &quot;code5&quot;</span><br><span class="line">   2) &quot;code3&quot;</span><br><span class="line">   3) &quot;code10&quot;</span><br><span class="line">   4) &quot;code7&quot;</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; scan 7 match code* count 4</span><br><span class="line">1) &quot;0&quot;</span><br><span class="line">2) 1) &quot;code11&quot;</span><br></pre></td></tr></table></figure>

<p>从上面实际测试中可以知道，游标不是每次递增，并且所填的 limit hint 不是指代返回的结果数量，而是单次遍历的字典槽位数量(约等于)。可能 单次的 返回结果为空，但是这并不意味着 遍历已经结束。只有当返回的游标值为 0 ，才算整个遍历结束。</p>
<h4 id="4-9-2-字典的结构"><a href="#4-9-2-字典的结构" class="headerlink" title="4.9.2 字典的结构"></a>4.9.2 字典的结构</h4><p>在 Redis 中所有的 key 都存储在一个很大的字典中，整个字典的结构和 Java中的 HashMap 一样，是一维数组+二维链表结构。第一维数组的大小总是 2^n （n&gt;&#x3D;0)，扩容一次数组大小空间加倍，也就是 n++</p>
<p>scan 指令返回的游标就是第一个维数组的位置索引，我们将整个位置索引称作槽。如果不考虑字典的扩容缩容，直接按数组下标挨个遍历就行了。limit 参数就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位都会挂接 链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每次遍历都会将 limit 数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端。</p>
<h4 id="4-9-3-scan-遍历顺序"><a href="#4-9-3-scan-遍历顺序" class="headerlink" title="4.9.3 scan 遍历顺序"></a>4.9.3 scan 遍历顺序</h4><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1684724453802-b8a3e03e-5bad-4829-9d57-ec6e6b10696d.png" alt="img"></p>
<p>scan的遍历顺序非常特别。它不是从第一维数组的第0位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历。是考虑到字典的扩容和缩容时避免槽位和遍历重复和遗漏（后面有具体分析）。高位进位法从左边加，进位往右边移动，同普通加法正好相反。但是它们都会遍历所有的槽位并且没有重复。</p>
<h4 id="4-9-4-字典扩容"><a href="#4-9-4-字典扩容" class="headerlink" title="4.9.4 字典扩容"></a>4.9.4 字典扩容</h4><p>Java 中的 HashMap 有扩容的概念，当 loadFactor 达到阈值时，需要重新分配一个新的 2 倍大小的数组，然后将所有的元素全部 rehash 挂到新的数组下面。rehash 就是将元素的 hash值对数组长度进行取模运算，因为长度变了，所以每个元素挂接的槽位可能也发生了变化。有因为数组的长度是 2^n 次方，所以取模运算等价于 位与 操作。</p>
<p>a%8 &#x3D; a&amp;(8-1) &#x3D; a&amp;7</p>
<p>a%16 &#x3D; a&amp;(16-1) &#x3D; a&amp;15</p>
<p>a%32 &#x3D; a&amp;(32-1) &#x3D; a&amp;31</p>
<p>这里的 7、15、31 又称之为字典的 mask值，mask的作用就是保留 hash 值的低位，高位都被设置为 0。</p>
<p>看看 rehash 前后元素槽位的变化</p>
<p>假设当前的字段的数组长度由 8 位扩容到 16位，那么 3号槽位 011 将会被 rehash 到3号槽位和11号槽位，也就是说该槽位链表中大约有一半的元素还是3号槽位，其它的元素会放到11号槽位，11这个数字的二进制是 1011，就是对 3 的二进制 011 增加了一个高位1。</p>
<p>抽象一点说，假设开始槽位的二进制是 xxx，那么该槽位中的元素将被 rehash 到 0xxx 和 1xxx 即 xxx+8中。如果字典长度由16位扩容到32位，那么对于二进制槽位 xxxx 中的元素将被 rehash 到 0xxxx 和 1xxxx中。</p>
<p><strong>对比扩容前后的遍历顺序：</strong></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1684724547827-d86608c6-5109-46c3-8cc2-843deba5e1f6.png" alt="img"></p>
<p>观察这张图片，我们发现采用高位进位加法的遍历顺序，rehash 后的槽位 在遍历顺序上是相邻的。</p>
<p>假设当前即将遍历 110这个位置，那么扩容后，当前槽位上所有的元素对应的新槽位是 0110 和 1110，也就是在槽位的二进制数增加一个高位0或1.这时我们可以i直接从 0110 这个槽位开始往后继续遍历，0110 槽位之前的所有槽位都是已经遍历过的，这样就可以避免扩容后对已经遍历过的槽位进行重复遍历。</p>
<p>再考虑缩容，假设当前即将遍历 110 这个位置，那么缩容后，当前槽位所有的元素对应的新槽位是 10，也就是去掉槽位二进制最高位。这时我们可以直接从10这个槽位继续往后遍历，10槽位之前的所有槽位都是遍历过的，这样可以避免缩容的重复遍历。不顾缩容还是不太一样，它会对图中 010 这个槽位上的元素进行重复遍历，因为缩容后 10 槽位的元素是 010 和 110上挂接的元素的融合。</p>
<h4 id="4-9-5-scan-考虑-渐进式-rehash"><a href="#4-9-5-scan-考虑-渐进式-rehash" class="headerlink" title="4.9.5 scan 考虑 渐进式 rehash"></a>4.9.5 scan 考虑 渐进式 rehash</h4><p>Java的 HashMap 在扩容时会一次性将旧数组下挂接的元素全部转移到新的数组下面。如果 Map 中元素特别多，线程就会出现卡顿现象。Redis为了解决这个问题，它采用渐进式 rehash。</p>
<p>它同时保留旧数组和新数组，然后在定时任务中以及后续对 hash 的指令操作中渐渐将旧的数组中挂接的元素迁移到新数组上。这意味着要操作处于 rehash 中的字典，需要同时访问新旧两个数组结构。如果在旧数组下面找不到元素，还需要去新数组下面寻找。</p>
<p>scan 也需要考虑这个问题，对于 rehash中的字典，它需要同时扫描新旧槽位，然后将结果融合后返回给客户端。</p>
<h4 id="4-9-6-更多-scan-指令"><a href="#4-9-6-更多-scan-指令" class="headerlink" title="4.9.6 更多 scan 指令"></a>4.9.6 更多 scan 指令</h4><p>scan指令是一系列指令，处理可以遍历所有的 key以外，还可以对指定的容器集合进行遍历。比如 zscan 遍历 zset 集合元素，hscan 遍历 hash 字典的元素。</p>
<h4 id="4-9-7-大Key的扫描"><a href="#4-9-7-大Key的扫描" class="headerlink" title="4.9.7 大Key的扫描"></a>4.9.7 大Key的扫描</h4><p>因为业务人员的使用不当，在 Redis 实例中会形成很大的对象，比如一个很大的 hash，一个很大的 zset。这样的对象对Redis的集群数据迁移带来了很大问题，因为在集群环境下，如果某一个key太大，会导致数据迁移卡顿。另外在内存分配上，如果一个key太大，那么当它需要扩容时，会一次性申请更大的一块内存，这也会导致卡顿。如果这个大key被删除，内存会一次性回收，卡顿现象再一次产生。</p>
<p>所以在开发中请避免大key的产生。如何定位到 大key呢？可以使用 scan 命令，对于扫描出来的每一个key，使用 type 指令获取类型，然后使用相应的数据结构的 size 或者 len 方法来得到 它的大小，对于每一种类型，保留大小的前 N名作为扫描结果展示出来。</p>
<p>Redis 官方已经提供了 实现上面功能的 指令：redis-cli -h 127.0.0.1 -p 6379 –bigkeys 。如果担心这个指令会大幅抬升 Redis 的 ops，还可以增加一个休眠参数。redis-cli -h 127.0.0.1 -p 6379 –bigkeys -i 0.1，这个指令每隔100条 scan 指令就会休眠 0.1s，ops 就不会剧烈抬升，但是扫描的时间会变长。</p>
<h2 id="五、Redis-原理"><a href="#五、Redis-原理" class="headerlink" title="五、Redis 原理"></a>五、Redis 原理</h2><h3 id="5-1-线程-IO-模型"><a href="#5-1-线程-IO-模型" class="headerlink" title="5.1 线程 IO 模型"></a>5.1 线程 IO 模型</h3><p>记住高并发的 Redis 中间件是 单线程的，除此之外，Node.js、Nginx 也是单线程，但是它们都是服务器高性能的典范。</p>
<p>详细可以看 3.3</p>
<h3 id="5-2-通信协议"><a href="#5-2-通信协议" class="headerlink" title="5.2 通信协议"></a>5.2 通信协议</h3><p>Redis 的作者认为 数据库系统的瓶颈一般不在于网络流量，而是数据库自身内部逻辑处理上。所以即使 redis 使用了浪费流量的文本协议，依然可以取得极高的访问性能。</p>
<h4 id="5-2-1-RESP-（Redis-Serialization-Protocol）"><a href="#5-2-1-RESP-（Redis-Serialization-Protocol）" class="headerlink" title="5.2.1 RESP （Redis Serialization Protocol）"></a>5.2.1 RESP （Redis Serialization Protocol）</h4><p>RESP 是 Redis 序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。Redis 协议将传输的结构数据 分为5种单元类型，单元结束时统一加上回车换行符号\r\n。</p>
<ul>
<li>单行字符串 以 + 符号开头。</li>
<li>多行字符串 以 $ 符号开头，后跟字符串长度</li>
<li>整数值 以 : 符号开头，后跟整数的字符串形式</li>
<li>错误信息 以 - 符号开头</li>
<li>数组 以 * 号开头，后跟数组长度</li>
</ul>
<h4 id="5-2-2-小结"><a href="#5-2-2-小结" class="headerlink" title="5.2.2 小结"></a>5.2.2 小结</h4><p>Redis 协议里有大量冗余的回车换行符，但是这个并不影响它成为互联网技术领域非常受欢迎的一个文本协议。有很多开源项目使用 RESP 作为它的通讯协议。在技术领域性能并不总是一切，还有简单性、易理解性和易实现性，这些都需要进行适当权衡。</p>
<h3 id="5-3-持久化"><a href="#5-3-持久化" class="headerlink" title="5.3 持久化"></a>5.3 持久化</h3><p>Redis 的数据全部在内存中，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的持久化机制。</p>
<p>Redis 持久化机制有两种，第一种是快照，第二种是AOF日志。</p>
<ul>
<li>RDB 将数据库的快照（snapshot）以二进制的方式保存到磁盘中。</li>
<li>AOF 则以协议文本的方式，将所有对数据库进行过写入的命令（及其参数）记录到 AOF 文件，以此达到记录数据库状态的目的。</li>
</ul>
<p>AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行AOF重写，给AOF日志进行瘦身。</p>
<h4 id="5-3-1-快照"><a href="#5-3-1-快照" class="headerlink" title="5.3.1 快照"></a>5.3.1 快照</h4><p>我们都知道 Redis 是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。在服务线上请求的同时，Redis 如果还需要进行内存快照（需要使用 文件IO操作），那就很难保持不堵塞。除此之外，持久化的同时，内存数据结构还在改变。这如何应对？</p>
<p>Redis 使用操作系统的多进程 COW (copy on write) 机制来实现快照持久化。</p>
<p>Redis 在持久化时会调用 glibc 的函数 fork 产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。（这是Linux为节约内存资源，所以让其共享起来，在子进程创建时，内存增长几乎没有明显变化）</p>
<p>子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写入到磁盘。但是父进程不一样，它必须持续接受客户端请求，然后对内存数据结构进行不间断修改。</p>
<p>这时候就会使用操作系统的 COW 机制来进行数据段页面的分离。数据段页面是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。</p>
<p>随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的2倍大小。另一个Redis实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有 4k，一个 Redis 实例里面一般都会有成千上万的页面。</p>
<p>子进程因为数据没有变化，它能看到的内存里的数据在进程产生的那一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫 快照的原因。</p>
<h4 id="5-3-2-AOF的写入"><a href="#5-3-2-AOF的写入" class="headerlink" title="5.3.2 AOF的写入"></a>5.3.2 AOF的写入</h4><p>Redis 将所有对数据库进行过写入的命令（及其参数）记录到 AOF 文件， 以此达到记录数据库状态的目的， 为了方便起见， 我们称呼这种记录过程为同步。</p>
<p>举个例子， 如果执行以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; RPUSH list 1 2 3 4</span><br><span class="line">(integer) 4</span><br><span class="line"></span><br><span class="line">redis&gt; LRANGE list 0 -1</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;3&quot;</span><br><span class="line">4) &quot;4&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; KEYS *</span><br><span class="line">1) &quot;list&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; RPOP list</span><br><span class="line">&quot;4&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; LPOP list</span><br><span class="line">&quot;1&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; LPUSH list 1</span><br><span class="line">(integer) 3</span><br><span class="line"></span><br><span class="line">redis&gt; LRANGE list 0 -1</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;3&quot;</span><br></pre></td></tr></table></figure>

<p>那么其中四条对数据库有修改的写入命令就会被同步到 AOF 文件中</p>
<p>除了 SELECT 命令是 AOF 程序自己加上去的之外， 其他命令都是之前我们在终端里执行的命令。</p>
<p>同步命令到 AOF 文件的整个过程可以分为三个阶段：</p>
<ol>
<li>命令传播：Redis 将执行完的命令、命令的参数、命令的参数个数等信息发送到 AOF 程序中。</li>
<li>缓存追加：AOF 程序根据接收到的命令数据，将命令转换为网络通讯协议的格式，然后将协议内容追加到服务器的 AOF 缓存中。</li>
<li>文件写入和保存：AOF 缓存中的内容被写入到 AOF 文件末尾，如果设定的 AOF 保存条件被满足的话， fsync 函数或者 fdatasync 函数会被调用，将写入的内容真正地保存到磁盘中。</li>
</ol>
<p>以下几个小节将详细地介绍这三个步骤。</p>
<h5 id="命令传播"><a href="#命令传播" class="headerlink" title="命令传播"></a>命令传播</h5><p>当一个 Redis 客户端需要执行命令时， 它通过网络连接， 将协议文本发送给 Redis 服务器。比如说， 要执行命令 SET KEY VALUE ， 客户端将向服务器发送文本 “*3\r\n$3\r\nSET\r\n$3\r\nKEY\r\n$5\r\nVALUE\r\n” 。</p>
<p>服务器在接到客户端的请求之后， 它会根据协议文本的内容， 选择适当的命令函数， 并将各个参数从字符串文本转换为 Redis 字符串对象（StringObject）。</p>
<p>比如说， 针对上面的 <a target="_blank" rel="noopener" href="http://redis.readthedocs.org/en/latest/string/set.html#set">SET</a> 命令例子， Redis 将客户端的命令指针指向实现 <a target="_blank" rel="noopener" href="http://redis.readthedocs.org/en/latest/string/set.html#set">SET</a> 命令的 setCommand 函数， 并创建三个 Redis 字符串对象， 分别保存 SET 、 KEY 和 VALUE 三个参数（命令也算作参数）。</p>
<p>每当命令函数成功执行之后， 命令参数都会被传播到 AOF 程序， 以及 REPLICATION 程序（本节不讨论这个，列在这里只是为了完整性的考虑）。</p>
<h5 id="缓存追加"><a href="#缓存追加" class="headerlink" title="缓存追加"></a>缓存追加</h5><p>当命令被传播到 AOF 程序之后， 程序会根据命令以及命令的参数， 将命令从字符串对象转换回原来的协议文本。</p>
<p>比如说， 如果 AOF 程序接受到的三个参数分别保存着 SET 、 KEY 和 VALUE 三个字符串， 那么它将生成协议文本 “*3\r\n$3\r\nSET\r\n$3\r\nKEY\r\n$5\r\nVALUE\r\n” 。</p>
<p>协议文本生成之后， 它会被追加到 redis.h&#x2F;redisServer 结构的 aof_buf 末尾。</p>
<p>redisServer 结构维持着 Redis 服务器的状态， aof_buf 域则保存着所有等待写入到 AOF 文件的协议文本：</p>
<h5 id="文件写入和保存"><a href="#文件写入和保存" class="headerlink" title="文件写入和保存"></a>文件写入和保存</h5><p>每当服务器常规任务函数被执行、 或者事件处理器被执行时， aof.c&#x2F;flushAppendOnlyFile 函数都会被调用， 这个函数执行以下两个工作：</p>
<p>WRITE：根据条件，将 aof_buf 中的缓存写入到 AOF 文件。</p>
<p>SAVE：根据条件，调用 fsync 或 fdatasync 函数，将 AOF 文件保存到磁盘中。</p>
<p>两个步骤都需要根据一定的条件来执行， 而这些条件由 AOF 所使用的保存模式来决定， 以下小节就来介绍 AOF 所使用的三种保存模式， 以及在这些模式下， 步骤 WRITE 和 SAVE 的调用条件。</p>
<h5 id="AOF-保存模式"><a href="#AOF-保存模式" class="headerlink" title="AOF 保存模式"></a>AOF 保存模式</h5><p>Redis 目前支持三种 AOF 保存模式，它们分别是：</p>
<ul>
<li><p>AOF_FSYNC_NO ：不保存在这种模式下， 每次调用 flushAppendOnlyFile 函数， WRITE 都会被执行， 但 SAVE 会被略过。在这种模式下， SAVE 只会在以下任意一种情况中被执行：这三种情况下的 SAVE 操作都会引起 Redis 主进程阻塞。</p>
</li>
<li><ul>
<li>Redis 被关闭</li>
<li>AOF 功能被关闭</li>
<li>系统的写缓存被刷新（可能是缓存已经被写满，或者定期保存操作被执行）</li>
</ul>
</li>
<li><p>AOF_FSYNC_EVERYSEC ：每一秒钟保存一次。在这种模式中， SAVE 原则上每隔一秒钟就会执行一次， 因为 SAVE 操作是由后台子线程调用的， 所以它不会引起服务器主进程阻塞。注意， 在上一句的说明里面使用了词语“原则上”， 在实际运行中， 程序在这种模式下对 fsync 或 fdatasync 的调用并不是每秒一次， 它和调用 flushAppendOnlyFile 函数时 Redis 所处的状态有关。每当 flushAppendOnlyFile 函数被调用时， 可能会出现以下四种情况：根据以上说明可以知道， 在“每一秒钟保存一次”模式下， 如果在情况 1 中发生故障停机， 那么用户最多损失小于 2 秒内所产生的所有数据。如果在情况 2 中发生故障停机， 那么用户损失的数据是可以超过 2 秒的。Redis 官网上所说的， AOF 在“每一秒钟保存一次”时发生故障， 只丢失 1 秒钟数据的说法， 实际上并不准确。</p>
</li>
<li><ul>
<li>子线程正在执行 SAVE ，并且：</li>
</ul>
</li>
</ul>
<ol>
<li><ol>
<li><ol>
<li>这个 SAVE 的执行时间未超过 2 秒，那么程序直接返回，并不执行 WRITE 或新的 SAVE 。</li>
<li>这个 SAVE 已经执行超过 2 秒，那么程序执行 WRITE ，但不执行新的 SAVE 。注意，因为这时 WRITE 的写入必须等待子线程先完成（旧的） SAVE ，因此这里 WRITE 会比平时阻塞更长时间。</li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><ul>
<li>子线程没有在执行 SAVE ，并且：</li>
</ul>
</li>
</ul>
<ol>
<li><ol>
<li><ol>
<li>上次成功执行 SAVE 距今不超过 1 秒，那么程序执行 WRITE ，但不执行 SAVE 。</li>
<li>上次成功执行 SAVE 距今已经超过 1 秒，那么程序执行 WRITE 和 SAVE 。</li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li>AOF_FSYNC_ALWAYS ：每执行一个命令保存一次。在这种模式下，每次执行完一个命令之后， WRITE 和 SAVE 都会被执行。另外，因为 SAVE 是由 Redis 主进程执行的，所以在 SAVE 执行期间，主进程会被阻塞，不能接受命令请求。</li>
</ul>
<p>总结：</p>
<table>
<thead>
<tr>
<th><strong>模式</strong></th>
<th><strong>WRITE 是否阻塞？</strong></th>
<th><strong>SAVE 是否阻塞？</strong></th>
<th><strong>停机时丢失的数据量</strong></th>
</tr>
</thead>
<tbody><tr>
<td>AOF_FSYNC_NO</td>
<td>阻塞</td>
<td>阻塞</td>
<td>操作系统最后一次对 AOF 文件触发 SAVE 操作之后的数据。</td>
</tr>
<tr>
<td>AOF_FSYNC_EVERYSEC</td>
<td>阻塞</td>
<td>不阻塞</td>
<td>一般情况下不超过 2 秒钟的数据。</td>
</tr>
<tr>
<td>AOF_FSYNC_ALWAYS</td>
<td>阻塞</td>
<td>阻塞</td>
<td>最多只丢失一个命令的数据。</td>
</tr>
</tbody></table>
<h4 id="5-3-3-AOF-文件的读取和数据还原"><a href="#5-3-3-AOF-文件的读取和数据还原" class="headerlink" title="5.3.3 AOF 文件的读取和数据还原"></a>5.3.3 AOF 文件的读取和数据还原</h4><p>AOF 文件保存了 Redis 的数据库状态， 而文件里面包含的都是符合 Redis 通讯协议格式的命令文本。</p>
<p>这也就是说， 只要根据 AOF 文件里的协议， 重新执行一遍里面指示的所有命令， 就可以还原 Redis 的数据库状态了。</p>
<p>Redis 读取 AOF 文件并还原数据库的详细步骤如下：</p>
<ol>
<li>创建一个不带网络连接的伪客户端（fake client）。</li>
<li>读取 AOF 所保存的文本，并根据内容还原出命令、命令的参数以及命令的个数。</li>
<li>根据命令、命令的参数和命令的个数，使用伪客户端执行该命令。</li>
<li>执行 2 和 3 ，直到 AOF 文件中的所有命令执行完毕。</li>
</ol>
<p>完成第 4 步之后， AOF 文件所保存的数据库就会被完整地还原出来。</p>
<p>注意， 因为 Redis 的命令只能在客户端的上下文中被执行， 而 AOF 还原时所使用的命令来自于 AOF 文件， 而不是网络， 所以程序使用了一个没有网络连接的伪客户端来执行命令。 伪客户端执行命令的效果， 和带网络连接的客户端执行命令的效果， 完全一样。</p>
<h4 id="5-3-4-AOF-重写"><a href="#5-3-4-AOF-重写" class="headerlink" title="5.3.4 AOF 重写"></a>5.3.4 AOF 重写</h4><p>AOF 文件通过同步 Redis 服务器所执行的命令， 从而实现了数据库状态的记录， 但是， 这种同步方式会造成一个问题： 随着运行时间的流逝， AOF 文件会变得越来越大。</p>
<p>举个例子， 如果服务器执行了以下命令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">RPUSH list 1 2 3 4      // [1, 2, 3, 4]</span><br><span class="line"></span><br><span class="line">RPOP list               // [1, 2, 3]</span><br><span class="line"></span><br><span class="line">LPOP list               // [2, 3]</span><br><span class="line"></span><br><span class="line">LPUSH list 1            // [1, 2, 3]</span><br></pre></td></tr></table></figure>

<p>那么光是记录 list 键的状态， AOF 文件就需要保存四条命令。而实质上，我们其实只要保存 list 最新状态的内存数据，就可以。</p>
<p>另一方面， 有些被频繁操作的键， 对它们所调用的命令可能有成百上千、甚至上万条， 如果这样被频繁操作的键有很多的话， AOF 文件的体积就会急速膨胀， 对 Redis 、甚至整个系统的造成影响。</p>
<p>为了解决以上的问题， Redis 需要对 AOF 文件进行重写（rewrite）： 创建一个新的 AOF 文件来代替原有的 AOF 文件， 新 AOF 文件和原有 AOF 文件保存的数据库状态完全一样， 但新 AOF 文件的体积小于等于原有 AOF 文件的体积。</p>
<h5 id="AOF-重写的实现"><a href="#AOF-重写的实现" class="headerlink" title="AOF 重写的实现"></a>AOF 重写的实现</h5><p>所谓的“重写”其实是一个有歧义的词语， 实际上， AOF 重写并不需要对原有的 AOF 文件进行任何写入和读取， 它针对的是数据库中键的当前值。</p>
<p>如同上面对 list 进行的四个操作后，那么当前 列表键在 Redis里的值就为 [1,2,3]。如果我们要保存这个列表的当前状态， 并且尽量减少所使用的命令数， 那么最简单的方式不是去 AOF 文件上分析前面执行的四条命令， 而是直接读取 list 键在数据库的当前值， 然后用一条 RPUSH 1 2 3 命令来代替前面的四条命令。</p>
<p>除了列表和集合之外， 字符串、有序集、哈希表等键也可以用类似的方法来保存状态， 并且保存这些状态所使用的命令数量， 比起之前建立这些键的状态所使用命令的数量要大大减少。</p>
<h5 id="AOF-后台重写"><a href="#AOF-后台重写" class="headerlink" title="AOF 后台重写"></a>AOF 后台重写</h5><p>上一节展示的 AOF 重写程序可以很好地完成创建一个新 AOF 文件的任务， 但是， 在执行这个程序的时候， 调用者线程会被阻塞。</p>
<p>很明显， 作为一种辅佐性的维护手段， Redis 不希望 AOF 重写造成服务器无法处理请求， 所以 Redis 决定将 AOF 重写程序放到（后台）子进程里执行， 这样处理的最大好处是：</p>
<ol>
<li>子进程进行 AOF 重写期间，主进程可以继续处理命令请求。</li>
<li>子进程带有主进程的数据副本，使用子进程而不是线程，可以在避免锁的情况下，保证数据的安全性。</li>
</ol>
<p>不过， 使用子进程也有一个问题需要解决： 因为子进程在进行 AOF 重写期间， 主进程还需要继续处理命令， 而新的命令可能对现有的数据进行修改， 这会让当前数据库的数据和重写后的 AOF 文件中的数据不一致。</p>
<p>为了解决这个问题， Redis 增加了一个 AOF 重写缓存， 这个缓存在 fork 出子进程之后开始启用， Redis 主进程在接到新的写命令之后， 除了会将这个写命令的协议内容追加到现有的 AOF 文件之外， 还会追加到这个缓存中。</p>
<p>换言之， 当子进程在执行 AOF 重写时， 主进程需要执行以下三个工作：</p>
<ol>
<li>处理命令请求。</li>
<li>将写命令追加到现有的 AOF 文件中。</li>
<li>将写命令追加到 AOF 重写缓存中。</li>
</ol>
<p>这样一来可以保证：</p>
<ol>
<li>现有的 AOF 功能会继续执行，即使在 AOF 重写期间发生停机，也不会有任何数据丢失。</li>
<li>所有对数据库进行修改的命令都会被记录到 AOF 重写缓存中。</li>
</ol>
<p>当子进程完成 AOF 重写之后， 它会向父进程发送一个完成信号， 父进程在接到完成信号之后， 会调用一个信号处理函数， 并完成以下工作：</p>
<ol>
<li>将 AOF 重写缓存中的内容全部写入到新 AOF 文件中。</li>
<li>对新的 AOF 文件进行改名，覆盖原有的 AOF 文件。</li>
</ol>
<p>当步骤 1 执行完毕之后， 现有 AOF 文件、新 AOF 文件和数据库三者的状态就完全一致了。</p>
<p>当步骤 2 执行完毕之后， 程序就完成了新旧两个 AOF 文件的交替。</p>
<p>这个信号处理函数执行完毕之后， 主进程就可以继续像往常一样接受命令请求了。 在整个 AOF 后台重写过程中， 只有最后的写入缓存和改名操作会造成主进程阻塞， 在其他时候， AOF 后台重写都不会对主进程造成阻塞， 这将 AOF 重写对性能造成的影响降到了最低。</p>
<h4 id="5-3-5-混合持久化"><a href="#5-3-5-混合持久化" class="headerlink" title="5.3.5 混合持久化"></a>5.3.5 混合持久化</h4><p>为了集成了两者的优点， Redis 4.0 提出了混合使用 AOF 日志和内存快照，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。</p>
<p>混合持久化工作在 AOF 日志重写过程，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。	</p>
<p>也就是说，使用了混合持久化，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1684770620104-4c8fc4d7-0964-4354-9ccf-ec35e2064483.jpeg" alt="img"></p>
<p>这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。</p>
<p>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失。</p>
<p>混合持久化优点：</p>
<p>混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。</p>
<p>混合持久化缺点：</p>
<p>AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；</p>
<p>兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。</p>
<h3 id="5-4-管道"><a href="#5-4-管道" class="headerlink" title="5.4 管道"></a>5.4 管道</h3><p>Redis 管道并不是 Redis 服务器直接提供的技术，这个技术实际是由客户端提供的，跟服务器没有本质关系。</p>
<p><strong>Redis 的消息交互：</strong></p>
<p>当我们使用客户端对 Redis 进行一次操作时。客户端将请求传送给服务器，服务器处理完成后，再将响应回复给客户端、这就需要花费一个网络数据包来回的时间。</p>
<p>如果连续执行多条指令，那就会花费多个网络数据包来回的时间。从客户端层面上来看，客户端时经历了 发送请求1-接受响应1-发送请求2-接受响应2— 这样。那么我们实际上可以调整一下，多个指令请求的请求响应顺序。即 发送请求1-发送请求2-接受请求1-接受请求2。这这样两个连续的发送请求操作和两个连续的等待请求响应操作 总共只会花费一次网络来回。</p>
<p>这便是管道操作的本质，服务器根本没有区别对待，还是收到一条消息，执行一条消息，回复一条消息的正常流程。客户端通过对管道中指令列表改变操作顺序就可以大幅节省 IO 时间。管道中的指令越多，效果越好。</p>
<h5 id="管道压力测试"><a href="#管道压力测试" class="headerlink" title="管道压力测试"></a>管道压力测试</h5><p>Redis 自带了一个压力测试工具 redis-benchmark，使用这个工具就可以进行管道测试。首先我们对一个普通的 set 指令进行压测，QPS大约 2.5w&#x2F;s。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@b7ba9713c11c:/data# redis-benchmark -t set -q</span><br><span class="line">SET: 24319.07 requests per second, p50=0.959 msec</span><br></pre></td></tr></table></figure>

<p>加入管道选项 -P 参数，它表示单个管道内并行的请求数量，看下面 P&#x3D;2时，QPS就可以达到 5w&#x2F;s</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@b7ba9713c11c:/data# redis-benchmark -t set -q -P 2</span><br><span class="line">SET: 50200.80 requests per second, p50=0.943 msec   </span><br><span class="line">root@b7ba9713c11c:/data# redis-benchmark -t set -q -P 40</span><br><span class="line">SET: 175131.36 requests per second, p50=10.391 msec </span><br><span class="line">root@b7ba9713c11c:/data# redis-benchmark -t set -q -P 100</span><br><span class="line">SET: 182149.36 requests per second, p50=26.671 msec</span><br></pre></td></tr></table></figure>

<p>发现到后面提高 P 参数，已经无法提高 QPS了，这一般都是因为 CPU 处理能力已经达到了瓶颈。</p>
<h5 id="管道本质"><a href="#管道本质" class="headerlink" title="管道本质"></a>管道本质</h5><p>下面就介绍一下一个请求的交互流程：</p>
<ol>
<li>客户端进行调用 write 将消息写到 操作系统内核 为套接字分配的 发送缓冲 sendbuffer</li>
<li>客户端操作系统内核将 发送缓冲的内容 发送到网卡，网卡硬件将数据通过 网际路由 送到服务器网卡。</li>
<li>服务器操作系统内核将 网卡的数据 放到内核为套接字分配的接受缓冲 recv buffer。</li>
<li>服务器进程调用 read 从接受缓冲区中 取出消息进行处理。</li>
<li>服务器进程调用 write 将响应消息写到 内核为套接字分配的发送缓冲 send buffer。</li>
<li>服务器操作系统内核 将发送缓冲的内容 发送到网卡，网卡硬件将数据通过 网际路由 发送到客户端的网卡。</li>
<li>客户端操作系统内核 将网卡的数据 放到内核为套接字分配的 接受缓冲 recv buffer</li>
<li>客户端进程调用 read 从接收缓冲区中 取出消息 返回给上层业务逻辑 进行处理。</li>
</ol>
<p>我们一开始可能以为 write 操作要等到对方收到消息才返回，但实际上不是这样的。write 操作只负责 将数据写到本地操作系统内核的 发送缓冲区然后就返回了。剩下的事 交给操作系统内核异步 将数据送到目标机器。但是如果发送缓冲区满了，那么就需要等待 缓冲区 空出，这个就是 写操作 IO 操作的真正耗时。</p>
<p>同理，read 操作并不是从目标机器拉取数据。read 操作只负责将 数据从本地操作系统内核的 接收缓冲区 取出来就了事。但是如果 缓冲区是空的，那么就需要等待数据到来，这个就是 读操作 IO 操作的真正耗时。</p>
<p>所以对于 客户端的 redis.get(key) 这样的命令来说，write 操作几乎没有耗时，直接写到 发送缓冲区就返回，而 read 操作比较耗时了，因为它要等待消息经过网络路由到目标机器处理后的响应消息，再发送到当前内核读缓冲 才可以返回。这才是一个网络来回的真正开销。</p>
<p>而对于管道来说，连续的 write 操作根本就没有耗时，之后第一个 read 操作会等待 一个网络的来回开销，然后响应信息到达 客户端系统内核的读缓冲了。因为 write 是连续发送，且几乎没有耗时，所以当 第一个read之后，后续所有read基本也同时随之到达 读缓冲。</p>
<h3 id="5-5-事务"><a href="#5-5-事务" class="headerlink" title="5.5 事务"></a>5.5 事务</h3><p>Redis 通过 MULTI、DISCARD 、EXEC 和 WATCH 四个命令来实现事务功能。事务提供了一种 “将多个命令打包，然后一次性、按顺序地执行”的机制，并且事务在执行的期间不会主动中断——服务器在执行完事务中的所有命令之后，才会继续处理其他客户端的命令。</p>
<p>例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379(TX)&gt; set name &quot;kxr&quot;</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379(TX)&gt; get name</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379(TX)&gt; sadd name-list &quot;kxr&quot; &quot;jyl&quot;</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379(TX)&gt; smembers name-list</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379(TX)&gt; exec</span><br><span class="line">1) OK</span><br><span class="line">2) &quot;kxr&quot;</span><br><span class="line">3) (integer) 2</span><br><span class="line">4) 1) &quot;jyl&quot;</span><br><span class="line">   2) &quot;kxr&quot;</span><br></pre></td></tr></table></figure>

<h4 id="5-5-1-事务流程"><a href="#5-5-1-事务流程" class="headerlink" title="5.5.1 事务流程"></a>5.5.1 事务流程</h4><p>一个事务从开始到执行会经历三个阶段：</p>
<ol>
<li>开始事务</li>
<li>命令入队</li>
<li>执行事务</li>
</ol>
<h5 id="开始事务"><a href="#开始事务" class="headerlink" title="开始事务"></a>开始事务</h5><p>MULTI 命令的执行 标记着事务的开始。这个命令唯一做的就是，将客户端的 REDIS_MULTI 选项打开，让客户端从非事务状态切换到事务状态。</p>
<h5 id="命令入队"><a href="#命令入队" class="headerlink" title="命令入队"></a>命令入队</h5><p>当客户端处于非事务状态下时，所有发送给服务端的命令都会立即被服务器执行。但是，当客户端进入事务状态之后，服务器在收到来自客户端的命令时，不会立即执行命令，而是将这些命令全部放进一个事务队列里，然后返回 QUEUED，表示命令已入队。</p>
<p>事务队列是一个数组，每个数组项是都包含三个属性：</p>
<ol>
<li>要执行的命令（cmd）</li>
<li>命令的参数（argv）</li>
<li>参数的个数（argc）</li>
</ol>
<h5 id="执行事务"><a href="#执行事务" class="headerlink" title="执行事务"></a>执行事务</h5><p>前面说到，当客户端进入事务状态之后，客户发送的命令就会被放进事务队列里。</p>
<p>但其实并不是所有的命令都会被放进事务队列，其中的例外就是 EXEC、DISCARD、MULTI 和 WATCH 这四个命令 —— 当这四个命令从客户端发送到服务器时，它们会像客户端处于非事务状态一样，直接被服务器执行。</p>
<p>如果客户端正处于事务状态，那么当 EXEC 命令执行时，服务器根据客户端所保存的事务队列，以先进先出（FIFO）的方式执行事务队列中的命令： 最先入队的命令最先执行，而最后入队的命令最后执行。</p>
<p>当事务队列里的 所有命令被执行完之后，EXEC 命令会将回复队列作为自己的执行结果返回给客户端，客户端从事务状态返回到非事务状态，至此，事务执行完毕。</p>
<p>事务的整个执行过程的伪代码表示：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def <span class="title function_">execute_transaction</span><span class="params">()</span>:</span><br><span class="line"></span><br><span class="line">    # 创建空白的回复队列</span><br><span class="line">    reply_queue = []</span><br><span class="line"></span><br><span class="line">    # 取出事务队列里的所有命令、参数和参数数量</span><br><span class="line">    <span class="keyword">for</span> cmd, argv, argc in client.transaction_queue:</span><br><span class="line"></span><br><span class="line">        # 执行命令，并取得命令的返回值</span><br><span class="line">        reply = execute_redis_command(cmd, argv, argc)</span><br><span class="line"></span><br><span class="line">    # 将返回值追加到回复队列末尾</span><br><span class="line">    reply_queue.append(reply)</span><br><span class="line"></span><br><span class="line">    # 清除客户端的事务状态</span><br><span class="line">    clear_transaction_state(client)</span><br><span class="line"></span><br><span class="line">    # 清空事务队列</span><br><span class="line">    clear_transaction_queue(client)</span><br><span class="line"></span><br><span class="line">    # 将事务的执行结果返回给客户端</span><br><span class="line">    send_reply_to_client(client, reply_queue)</span><br></pre></td></tr></table></figure>

<p>优化：上面的 Redis 事务在发送每个指令到事务缓存队列时都要经过一次网络读写，当一个事务内部的指令较多时，需要的网络 IO 时间也会线性增长。所以通常 Redis 客户端在执行事务时都会结合 pipline 一起使用，这样可以将多次 IO 操作压缩为单次 IO 操作。</p>
<h4 id="5-5-2-事务里的命令"><a href="#5-5-2-事务里的命令" class="headerlink" title="5.5.2 事务里的命令"></a>5.5.2 事务里的命令</h4><p>无论是在事务状态下，还是非事务状态下，Redis 命令都是由同一个函数执行，所有它们共享很多服务器的一般设置，比如 AOF 配置、RDB 的配置，以及内存限制等等。</p>
<p>事务中的命令执行和普通命令执行主要是两天区别：</p>
<ol>
<li>非事务状态下的命令以单个命令执行为单位，前一个命令和后一个命令不一定是同一个客户端。而事务状态则是以一个事务为单位，执行事务队列中的所有命令：除非当前事务执行完毕，否则服务器不会中断事务，也不会执行其他客户端的命令。</li>
<li>在非事务状态下，执行命令所得的结果会立即被返回给客户端。而事务则将所有命令所得返回结果集合到回复队列，再作为 EXEC 命令的结果返回给客户端。</li>
</ol>
<h4 id="5-5-3-DISCARD-、-MULTI-和-WATCH-命令"><a href="#5-5-3-DISCARD-、-MULTI-和-WATCH-命令" class="headerlink" title="5.5.3 DISCARD 、 MULTI 和 WATCH 命令"></a>5.5.3 DISCARD 、 MULTI 和 WATCH 命令</h4><p>除了 EXEC 之外，服务器在客户端处于事务状态下，不加入到事务队列而执行的另外三个命令是：DISCARD 、 MULTI 和 WATCH</p>
<ul>
<li>DISCARD：命令用于取消一个事务， 它清空客户端的整个事务队列， 然后将客户端从事务状态调整回非事务状态， 最后返回字符串 OK 给客户端， 说明事务已被取消。</li>
<li>MULTI：Redis 的事务是不可嵌套的， 当客户端已经处于事务状态， 而客户端又再向服务器发送 <a target="_blank" rel="noopener" href="http://redis.readthedocs.org/en/latest/transaction/multi.html#multi">MULTI</a> 时， 服务器只是简单地向客户端发送一个错误， 然后继续等待其他命令的入队。 <a target="_blank" rel="noopener" href="http://redis.readthedocs.org/en/latest/transaction/multi.html#multi">MULTI</a> 命令的发送不会造成整个事务失败， 也不会修改事务队列中已有的数据。</li>
<li>WATCH：只能在客户端进入事务状态之前执行， 在事务状态下发送 WATCH 命令会引发一个错误， 但它不会造成整个事务失败， 也不会修改事务队列中已有的数据（和前面处理 MULTI 的情况一样）</li>
</ul>
<h4 id="5-5-4-带-WATCH-的事务"><a href="#5-5-4-带-WATCH-的事务" class="headerlink" title="5.5.4 带 WATCH 的事务"></a>5.5.4 带 WATCH 的事务</h4><p>WATCH 命令用于在事务开始之前监视任意数量的键： 当调用 EXEC 命令执行事务时， 如果任意一个被监视的键已经被其他客户端修改了， 那么整个事务不再执行， 直接返回失败。</p>
<p>以下示例展示了一个执行失败的事务例子：</p>
<p>第一个客户端执行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; watch name</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379(TX)&gt; set name t</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379(TX)&gt; exec</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure>

<p>第二个客户端执行：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set name tt</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>

<p>在第一个客户端watch name 之后，事务执行之前，在第二个客户端中 修改 name 的值。这样当第一个客户端的执行事务时，Redis 会发现 name 整个被监视的键 已经被修改，因此客户端A的事务不会被执行，而是直接返回失败。</p>
<h5 id="WATCH-命令的实现"><a href="#WATCH-命令的实现" class="headerlink" title="WATCH 命令的实现"></a>WATCH 命令的实现</h5><p>在每个代表数据的 redis.h&#x2F;redisDb 结构类型中，都保存了一个 watched_keys 字典，字典的键这个数据库被监视的键，而字典的值则是一个链表，链表中保存了所有监视这个键的客户端。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779123785-9effddfb-dddd-4212-917f-061e49039521.svg" alt="img"></p>
<p>其中，键 key1 正在被 client2、client5 和 client1 三个客户端监视，其他一些键也分别被其他客户端监视着。</p>
<p>WATCH 命令的作用，就是将 当前客户端和要监视的键在 watched_keys 中进行关联。</p>
<p>举个例子， 如果当前客户端为 client10086 ， 那么当客户端执行 WATCH key1 key2 时， 前面展示的 watched_keys 将被修改成这个样子：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779124149-f5a1f0b8-25ae-428c-8927-910b8c86e485.svg" alt="img"></p>
<p>通过 watched_keys 字典， 如果程序想检查某个键是否被监视， 那么它只要检查字典中是否存在这个键即可； 如果程序要获取监视某个键的所有客户端， 那么只要取出键的值（一个链表）， 然后对链表进行遍历即可。</p>
<h5 id="WATCH-的触发"><a href="#WATCH-的触发" class="headerlink" title="WATCH 的触发"></a>WATCH 的触发</h5><p>在任何对数据库键空间（key space）进行修改的命令成功执行之后 （比如 FLUSHDB 、SET、DEL、LPUSH、SADD ，诸如此类）， multi.c&#x2F;touchWatchedKey 函数都会被调用 —— 它检查数据库的 watched_keys 字典， 看是否有客户端在监视已经被命令修改的键， 如果有的话， 程序将所有监视这个&#x2F;这些被修改键的客户端的 REDIS_DIRTY_CAS 选项打开：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779123291-8a135c71-3565-4c56-9dfe-533d255158e9.svg" alt="img"></p>
<p>当客户端发送 <a target="_blank" rel="noopener" href="http://redis.readthedocs.org/en/latest/transaction/exec.html#exec">EXEC</a> 命令、触发事务执行时， 服务器会对客户端的状态进行检查：</p>
<ul>
<li>如果客户端的 REDIS_DIRTY_CAS 选项已经被打开，那么说明被客户端监视的键至少有一个已经被修改了，事务的安全性已经被破坏。服务器会放弃执行这个事务，直接向客户端返回空回复，表示事务执行失败。</li>
<li>如果 REDIS_DIRTY_CAS 选项没有被打开，那么说明所有监视键都安全，服务器正式执行事务。</li>
</ul>
<p>举个例子，假设数据库的 watched_keys 字典如下图所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779124835-ac785dae-6d6d-4247-bd7f-8209ea924ea4.svg" alt="img"></p>
<p>如果某个客户端对 key1 进行了修改（比如执行 DEL key1 ）， 那么所有监视 key1 的客户端， 包括 client2 、 client5 和 client1 的 REDIS_DIRTY_CAS 选项都会被打开， 当客户端 client2 、 client5 和 client1 执行 <a target="_blank" rel="noopener" href="http://redis.readthedocs.org/en/latest/transaction/exec.html#exec">EXEC</a> 的时候， 它们的事务都会以失败告终。</p>
<p>最后，当一个客户端结束它的事务时，无论事务是成功执行，还是失败， watched_keys 字典中和这个客户端相关的资料都会被清除。</p>
<h4 id="5-5-6-事务的-ACID-性质"><a href="#5-5-6-事务的-ACID-性质" class="headerlink" title="5.5.6 事务的 ACID 性质"></a>5.5.6 事务的 ACID 性质</h4><p>传统数据库，常常用 ACID 性质来检验 事务是否安全。Redis 事务保证了 一致性（C）、隔离性（I），但并不能保证 原子性（A）和 持久性（D）。</p>
<h5 id="原子性（Atomicity）"><a href="#原子性（Atomicity）" class="headerlink" title="原子性（Atomicity）"></a>原子性（Atomicity）</h5><p>单个 Redis 命令执行肯定是 原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所有 Redis 事务的执行并不是原子性的。</p>
<p>如果一个事务队列中的所有命令都被成功地执行，那么称这个事务执行成功。另一方面，如果 Redis 服务器进程在执行事务的过程中被停止 —— 比如接到 KILL 信号、宿主机器停机，等等，那么事务执行失败。当事务失败时，Redis 也不会进行任何的重试或者回滚动作。</p>
<p>简单总结：</p>
<ul>
<li>命令入队时就报错，会放弃事务执行，保证原子性。</li>
<li>命令入队时没报错，实际执行时报错，不保证原子性。</li>
<li>EXEC 命令执行时实例故障，如果开启 AOF 日志，可以保证原子性。</li>
</ul>
<p>其保证的是部分原子性，<strong>可以保证多个命令要么就一起执行，要么就一起不执行</strong>。但是<strong>不能保证 多个命令要么一起执行成功，要么都不执行成功</strong>。入队后，如果有命令执行失败，其之前命令执行操作并不会回退，其之后命令也照常执行。</p>
<h5 id="一致性（Consistency）"><a href="#一致性（Consistency）" class="headerlink" title="一致性（Consistency）"></a>一致性（Consistency）</h5><p>一致性表示：事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后顺序都是合法数据状态。</p>
<ul>
<li>实体完整性(如行的主键存在且唯一);</li>
<li>列完整性(如字段的类型、大小、长度要符合要求)</li>
<li>外键约束;</li>
<li>用户自定义完整性(如转账前后，两个账户余额的和应该不变)。</li>
</ul>
<p>Redis 的一致性问题 可以分为三部分来讨论：入队错误、执行错误、Redis 进程被终结。</p>
<ol>
<li>入队错误：在命令入队的过程中，如果客户端向服务器发送了错误的命令，比如命令的参数数量不对，等等， 那么服务器将向客户端返回一个出错信息， 并且将客户端的事务状态设为 REDIS_DIRTY_EXEC 。当客户端执行 EXEC 命令时， Redis 会拒绝执行状态为 REDIS_DIRTY_EXEC 的事务， 并返回失败信息。因此，带有不正确入队命令的事务不会被执行，也不会影响数据库的一致性。</li>
<li>执行错误：如果命令在事务执行的过程中发生错误，比如说，对一个不同类型的 key 执行了错误的操作， 那么 Redis 只会将错误包含在事务的结果中， 这不会引起事务中断或整个失败，不会影响已执行事务命令的结果，也不会影响后面要执行的事务命令， 所以它对事务的一致性也没有影响。</li>
<li>Redis 进程被终结如果 Redis 服务器进程在执行事务的过程中被其他进程终结，或者被管理员强制杀死，那么根据 Redis 所使用的持久化模块，可能由以下情况出现：</li>
</ol>
<ul>
<li><ul>
<li>内存模块：如果 Redis 没有采取任何持久化机制，那么重启后的数据库总是空白的，所以数据总是一致的。</li>
<li>RDB 模块：在执行事务时，Redis 不会中断事务去执行保存 RDB 的工作，只有在事务执行之后，保存 RDB 的工作才可能开始。所以当RDB 模式下的 Redis 服务器进程在事务中途被杀死时，事务内执行的命令，不管成功了多少，都不会被保存到 RDB 文件里。恢复数据库需要使用现有的 RDB 文件，而这个 RDB 文件的数据保存的是最近一次的数据库快照（snapshot），所以它的数据可能不是最新的，但只要 RDB 文件本身没有因为其他问题而出错，那么还原后的数据库就是一致的。</li>
<li>AOF 模式：因为保存 AOF 文件的工作在后台线程进行，所以即使是在事务执行的中途，保存 AOF 文件的工作也可以继续进行，因此，根据事务语句是否被写入并保存到 AOF 文件，有以下两种情况发送：</li>
</ul>
</li>
<li><ul>
<li><ul>
<li>如果事务语句 未写入到 AOF 文件，或 AOF 未被 SYNC 调用保存到磁盘，那么当进程被杀死之后，Redis 可以根据 最近一次成功保存到 磁盘的 AOF 文件 来还原数据库，只要 AOF 文件本身没有因为其他问题而出错，那么还原后的数据库总是一致的，但其中的数据不一定是最新的。</li>
<li>如果事务的部分语句 被写入到 AOF 文件中，并且 AOF 文件被成功保存，那么不完整的事务执行信息就会遗留在 AOF 文件里，当重启 Redis 时，程序会检测到 AOF 文件并不完整，Redis 会退出，并报告错误。需要使用 redis-check-aof 工具将部分成功的事务命令移除之后，才能再次启动服务器。还原之后的数据总是一致的，而且数据也是最新的（直到事务执行之前为止）。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h5 id="隔离性（Isolation）"><a href="#隔离性（Isolation）" class="headerlink" title="隔离性（Isolation）"></a>隔离性（Isolation）</h5><p>Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。</p>
<h5 id="持久性（Durability）"><a href="#持久性（Durability）" class="headerlink" title="持久性（Durability）"></a>持久性（Durability）</h5><p>因为事务不过是用队列包裹了一组 Redis 命令，并没有提供任何额外的持久性功能，所以事务的持久性由 Redis 所使用的持久化模块决定</p>
<ul>
<li>单纯的内存模式下，事务肯定是不持久的。</li>
<li>在 RDB 模块下，服务器可能在事务执行之后、RDB 文件更新之前的这段时间失败，所以 RDB 模式下的 Redis 事务也不持久的。</li>
<li>在 AOF 的 “总是SYNC” 模式下，事务的每条命令在执行成功之后，都会立即调用 fsync 或 fdatasync 将事务数据写入到 AOF文件。但是，这种保存是由后台线程进行的，主线程不会堵塞直到保存成功。所以命令执行成功到数据保存到硬盘之间，还是有一段非常小的间隔，所以这种模式下的事务也是不持久的。</li>
</ul>
<p>其他 AOF 模式也和 “总是SYNC” 模式类似，所以它们都是不持久的。</p>
<h4 id="5-5-7-小结"><a href="#5-5-7-小结" class="headerlink" title="5.5.7 小结"></a>5.5.7 小结</h4><ul>
<li>事务提供了一种将多个命令打包，然后一次性、有序地执行的机制。</li>
<li>事务在执行过程中不会被中断，所有事务命令执行完之后，事务才能结束。</li>
<li>多个命令会被入队到事务队列中，然后按先进先出（FIFO）的顺序执行。</li>
<li>带 WATCH 命令的事务会将客户端和被监视的键在数据库的 watched_keys 字典中进行关联，当键被修改时，程序会将所有监视被修改键的客户端的 REDIS_DIRTY_CAS 选项打开。</li>
<li>只有在客户端的 REDIS_DIRTY_CAS 选项未被打开时，才能执行事务，否则事务直接返回失败。</li>
<li>Redis 的事务保证了 ACID 中的一致性（C）和隔离性（I），但并不保证原子性（A）和持久性（D）。</li>
</ul>
<h3 id="5-6-订阅与发布"><a href="#5-6-订阅与发布" class="headerlink" title="5.6 订阅与发布"></a>5.6 订阅与发布</h3><p>Redis 通过 PUBLISH、SUBSCRIBE等命令实现了订阅与发布模式， 这个功能提供两种信息机制， 分别是订阅&#x2F;发布到频道和订阅&#x2F;发布到模式， 下文先讨论订阅&#x2F;发布到频道的实现， 再讨论订阅&#x2F;发布到模式的实现。</p>
<h4 id="5-6-1-频道的订阅与信息发送"><a href="#5-6-1-频道的订阅与信息发送" class="headerlink" title="5.6.1 频道的订阅与信息发送"></a>5.6.1 频道的订阅与信息发送</h4><p>Redis 的 SUBSCRIBE 命令可以让客户端订阅任意数量的频道，每当有新消息发送到被订阅的频道时，信息就会被发送给所有订阅指定频道的客户端。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779124262-ac7f1f60-b21b-44a8-810f-6f10ac13eab1.svg" alt="img"></p>
<p>当有新消息通过 <a target="_blank" rel="noopener" href="http://redis.readthedocs.org/en/latest/pub_sub/publish.html#publish">PUBLISH</a> 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779126625-3d2dbe1a-b372-47b6-9a25-e937747ce3fa.svg" alt="img"></p>
<h5 id="订阅频道"><a href="#订阅频道" class="headerlink" title="订阅频道"></a>订阅频道</h5><p>每个 Redis 服务器进程都维持着一个表示服务器状态的 redis.h&#x2F;redisServer 结构，结构的 pubsub_channels 属性是一个字典，这个字典就用于保存订阅频道的信息。</p>
<p>其中，字典的键为正在被订阅的频道，而字典的值则是一个链表，链表中保存了所有订阅这个频道的客户端。</p>
<p>比如说，在下图展示的这个 pubsub_channels 示例中， client2 、 client5 和 client1 就订阅了 channel1 ， 而其他频道也分别被别的客户端所订阅：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779126861-01cd5b87-621a-4c11-8997-fd32e7124cde.svg" alt="img"></p>
<p>当客户端调用 <a target="_blank" rel="noopener" href="http://redis.readthedocs.org/en/latest/pub_sub/subscribe.html#subscribe">SUBSCRIBE</a> 命令时， 程序就将客户端和要订阅的频道在 pubsub_channels 字典中关联起来。</p>
<p>举个例子，如果客户端 client10086 执行命令 SUBSCRIBE channel1 channel2 channel3 ，那么前面展示的 pubsub_channels 将变成下面这个样子：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779127981-4b8e7194-f9c9-4e88-b812-b9f8594061e9.svg" alt="img"></p>
<p>通过 pubsub_channels 字典， 程序只要检查某个频道是否为字典的键， 就可以知道该频道是否正在被客户端订阅； 只要取出某个键的值， 就可以得到所有订阅该频道的客户端的信息。</p>
<h5 id="发送信息到频道"><a href="#发送信息到频道" class="headerlink" title="发送信息到频道"></a>发送信息到频道</h5><p>了解了 pubsub_channels 字典的结构之后， 解释 <a target="_blank" rel="noopener" href="http://redis.readthedocs.org/en/latest/pub_sub/publish.html#publish">PUBLISH</a> 命令的实现就非常简单了： 当调用 PUBLISH channel message 命令， 程序首先根据 channel 定位到字典的键， 然后将信息发送给字典值链表中的所有客户端。</p>
<p>比如说，对于以下这个 pubsub_channels 实例， 如果某个客户端执行命令 PUBLISH channel1 “hello moto” ，那么 client2 、 client5 和 client1 三个客户端都将接收到 “hello moto” 信息：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779127370-c53aa587-36b5-4a1e-8777-e74917f5ece7.svg" alt="img"></p>
<h5 id="退订频道"><a href="#退订频道" class="headerlink" title="退订频道"></a>退订频道</h5><p>使用 UNSUBSCRIBE 命令可以退订指定的频道， 这个命令执行的是订阅的反操作： 它从 pubsub_channels 字典的给定频道（键）中， 删除关于当前客户端的信息， 这样被退订频道的信息就不会再发送给这个客户端。</p>
<h4 id="5-6-2-模式的订阅与信息发送"><a href="#5-6-2-模式的订阅与信息发送" class="headerlink" title="5.6.2 模式的订阅与信息发送"></a>5.6.2 模式的订阅与信息发送</h4><p>当使用 PUBLISH 命令发送信息到某个频道时，不仅所有订阅该频道的客户端会收到信息，如果有 某个&#x2F;某些 模式和 这个频道匹配的话，那么所有订阅 这个&#x2F;这些 频道的客户端也同样会受到信息。</p>
<p>下图展示了一个带有频道和模式的例子， 其中 tweet.shop.* 模式匹配了 tweet.shop.kindle 频道和 tweet.shop.ipad 频道， 并且有不同的客户端分别订阅它们三个：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779128616-e784de68-42e6-4095-bcf0-60e9c43986ec.svg" alt="img"></p>
<p>当有信息发送到 tweet.shop.kindle 频道时， 信息除了发送给 clientX 和 clientY 之外， 还会发送给订阅 tweet.shop.* 模式的 client123 和 client256 ：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779128540-cc69dd3a-5458-471e-aaeb-84a2e7a04712.svg" alt="img"></p>
<p>另一方面， 如果接收到信息的是频道 tweet.shop.ipad ， 那么 client123 和 client256 同样会收到信息：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779131307-fa5396f0-9c11-438a-b6ed-492143caca5c.svg" alt="img"></p>
<h5 id="订阅模式"><a href="#订阅模式" class="headerlink" title="订阅模式"></a>订阅模式</h5><p>redisServer.pubsub_patterns 属性是一个链表，链表中保存着所有和模式相关的信息。</p>
<p>链表中的每个节点都包含一个 redis.h&#x2F;pubsubPattern 结构：</p>
<p>client 属性保存着订阅模式的客户端，而 pattern 属性则保存着被订阅的模式。</p>
<p>每当调用 PSUBSCRIBE 命令订阅一个模式时， 程序就创建一个包含客户端信息和被订阅模式的 pubsubPattern 结构， 并将该结构添加到 redisServer.pubsub_patterns 链表中。</p>
<p>作为例子，下图展示了一个包含两个模式的 pubsub_patterns 链表， 其中 client123 和 client256 都正在订阅 tweet.shop.* 模式：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779131253-176aab8f-481e-490a-8bdd-e31d5c0d0268.svg" alt="img"></p>
<p>如果这时客户端 client10086 执行 PSUBSCRIBE broadcast.list.* ， 那么 pubsub_patterns 链表将被更新成这样：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779133621-3a05dd6e-3664-4953-abb2-eca5a3de291e.svg" alt="img"></p>
<p>通过遍历整个 pubsub_patterns 链表，程序可以检查所有正在被订阅的模式，以及订阅这些模式的客户端。</p>
<h5 id="发送信息到模式"><a href="#发送信息到模式" class="headerlink" title="发送信息到模式"></a>发送信息到模式</h5><p>发送信息到模式的工作也是由 PUBLISH 命令进行的。 PUBLISH 除了将 message 发送到所有订阅 channel 的客户端之外，它还会将 channel 和 pubsub_pattern 中的模式进行对比，如果 channel 和某个模式匹配的话，那么也将 message 发送到订阅那个模式的客户端。</p>
<p>举个例子，如果 Redis 服务器的 pubsub_patterns 状态如下：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779131145-01a1aea3-c788-4cfa-aae6-91390a521463.svg" alt="img"></p>
<p>那么当某个客户端发送信息 “Amazon Kindle, $69.” 到 tweet.shop.kindle 频道时， 除了所有订阅了 tweet.shop.kindle 频道的客户端会收到信息之外， 客户端 client123 和 client256 也同样会收到信息， 因为这两个客户端订阅的 tweet.shop.* 模式和 tweet.shop.kindle 频道匹配。</p>
<h5 id="退订模式"><a href="#退订模式" class="headerlink" title="退订模式"></a>退订模式</h5><p>使用 PUNSUBSCRIBE 命令可以退订指定的模式， 这个命令执行的是订阅模式的反操作： 程序会删除 redisServer.pubsub_patterns 链表中， 所有和被退订模式相关联的 pubsubPattern 结构， 这样客户端就不会再收到和模式相匹配的频道发来的信息。</p>
<h4 id="5-6-3-小结"><a href="#5-6-3-小结" class="headerlink" title="5.6.3 小结"></a>5.6.3 小结</h4><p>要点：</p>
<ul>
<li>订阅信息由服务器进程维持的 redisServer.pubsub_channels 字典保存，字典的键为被订阅的频道，字典的值为订阅频道的所有客户端。</li>
<li>当有新消息发送到频道时，程序遍历频道（键）所对应的（值）所有客户端，然后将消息发送到所有订阅频道的客户端上。</li>
<li>订阅模式的信息由服务器进程维持的 redisServer.pubsub_patterns 链表保存，链表的每个节点都保存着一个 pubsubPattern 结构，结构中保存着被订阅的模式，以及订阅该模式的客户端。程序通过遍历链表来查找某个频道是否和某个模式匹配。</li>
<li>当有新消息发送到频道时，除了订阅频道的客户端会收到消息之外，所有订阅了匹配频道的模式的客户端，也同样会收到消息。</li>
<li>退订频道和退订模式分别是订阅频道和订阅模式的反操作。</li>
</ul>
<p>缺点：</p>
<p>PubSub 的生产者产地过来一个消息，Redis 会直接找到相应的消费者传递过去。如果一个消费者也没有，那么消息直接丢弃。如果开始有三个消费者，一个消费者突然挂掉了，生产者会继续发送消息，另外两个消费者可以持续受到消息。但是挂掉的消费者重新连上的时候，这断连期间生产者发送的消息，对于这个消费者来说就彻底消失了。</p>
<p>如果 Redis 停机重启，PubSub 的消息是不会持久化的，毕竟 Redis 宕机就相当于一个消费者都没有，所有的消息直接丢弃。</p>
<p>正是因为 PubSub 有这些缺点，它几乎找不到合适的应用场景。所以 Redis 的作者单独开启了一个项目 Disque 专门做 多播消息队列。</p>
<p>github地址：<a target="_blank" rel="noopener" href="https://github.com/antirez/disque-module%E3%80%82%E4%BD%86%E6%98%AF%E5%9C%A8">https://github.com/antirez/disque-module。但是在</a> Redis5.0 新增了 Stream 数据结构，这个功能给 Redis 带来了持久化消息队列，从此 PubSub 可以消失了，Disqueue 估计也不会发出它的正式版了。</p>
<h3 id="5-7-Redis集群模式—主从复制"><a href="#5-7-Redis集群模式—主从复制" class="headerlink" title="5.7 Redis集群模式—主从复制"></a>5.7 Redis集群模式—主从复制</h3><p><a target="_blank" rel="noopener" href="https://pdai.tech/md/db/nosql-redis/db-redis-x-copy.html">https://pdai.tech/md/db/nosql-redis/db-redis-x-copy.html</a></p>
<p>我们知道要避免单点故障，即保证高可用，便需要冗余（副本）方式提供集群服务。而 Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离 的方式。</p>
<h4 id="5-7-1-主从复制概述"><a href="#5-7-1-主从复制概述" class="headerlink" title="5.7.1 主从复制概述"></a>5.7.1 主从复制概述</h4><p>主从复制，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。前者称为 主节点（master），后者称为 从节点（slave）。数据的复制是单向的，只能从 主节点 到 从节点。</p>
<p><strong>主从复制的作用</strong>主要包括：</p>
<ul>
<li><strong>数据冗余</strong>：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li>
<li><strong>故障恢复</strong>：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li>
<li><strong>负载均衡</strong>：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li>
<li><strong>高可用基石</strong>：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</li>
</ul>
<p>主从库之间采用的是<strong>读写分离</strong>的方式。</p>
<ul>
<li>读操作：主库、从库都可以接收；</li>
<li>写操作：首先到主库执行，然后，主库将写操作同步给从库。</li>
</ul>
<p>在 2.8 版本之前，只有全量复制，而2.8版本之后有全量和增量复制</p>
<ul>
<li>全量（同步）复制：比如第一次同步时</li>
<li>增量（同步）复制：只会把主从库网络断连期间主库收到的命令，同步给从库。</li>
</ul>
<h4 id="5-7-2-全量复制"><a href="#5-7-2-全量复制" class="headerlink" title="5.7.2 全量复制"></a>5.7.2 全量复制</h4><p>当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步</p>
<ul>
<li>建立主从关系</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 这里我们创建了 两个 redis 实例</span><br><span class="line">[root@VM-4-9-centos ~]# docker run -it -d --name redis2 -p 6379:6379 redis</span><br><span class="line">9865ef807588457b05a4353a5c4a1699486343abab71d6682f98a6bc27497961</span><br><span class="line">[root@VM-4-9-centos ~]# docker run -it -d --name redis1 -p 6380:6379 redis</span><br><span class="line">f21ca2cacfea46f1b05baffffdafc9c46f76482cdea3d018ff7196469b75c6e9</span><br><span class="line"></span><br><span class="line"># 查看所有容器的 ip地址</span><br><span class="line">[root@VM-4-9-centos ~]# docker inspect -f &#x27;&#123;&#123;.Name&#125;&#125; - &#123;&#123;.NetworkSettings.IPAddress &#125;&#125;&#x27; $(docker ps -aq)</span><br><span class="line">/redis2 - 172.17.0.5</span><br><span class="line">/redis1 - 172.17.0.4</span><br><span class="line"></span><br><span class="line"># 使用 redis1 容器的 redis命令行，存入 key=name,value=kongxr</span><br><span class="line">[root@VM-4-9-centos ~]#  docker exec -it redis1 /bin/bash</span><br><span class="line">root@f21ca2cacfea:/data# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set name kongxr</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line"># 使用 reids2容器内的 redis命令行。查询key=name，未获取到值。</span><br><span class="line"># 然后使用同步命令将redis2 作为从库，建立主从关系，并同步数据</span><br><span class="line">[root@VM-4-9-centos ~]# docker exec -it redis2 /bin/bash</span><br><span class="line">root@9865ef807588:/data# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">(nil)</span><br><span class="line">127.0.0.1:6379&gt; replicaof 172.17.0.4 6379</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">(nil)</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">&quot;kongxr&quot;</span><br></pre></td></tr></table></figure>

<p>从上面的测试，可以看到 在建立主从关系后，从库会慢慢从主库中同步全量数据。</p>
<ul>
<li><p>全量复制的三个阶段</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779131543-769d79b6-8fbc-49bd-9f96-2cd53b6554a7-20250605100935711.jpeg" alt="img"></p>
</li>
</ul>
<ol>
<li><ol>
<li><strong>第一阶段是主从库间建立连接、协商同步的过程，主要是为了全量复制做准备。</strong>在这一步，从库和主库建立连接，并告诉主库即将开始进行同步，主库确认回复后，主从库间就可以开始同步了。具体的来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包括了主库的 runID 和 复制进度 offset 两个参数。runID，是每个 Redis 实例启动时都会自动生成的一个随机ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为 “?” 。offset，此时设为 -1，表示第一次复制。主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上 两个参数：主库 runID 和主库目前的复制进度 offset ，返回给从库。从库收到响应后，会记录下这两个参数。这里有个地方需要注意，FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。</li>
<li><strong>第二个阶段，主库将所有数据同步给从库。</strong>从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成 RDB 文件。具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发送给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。在主库将数据同步给从库的过程中，主库不会被堵塞，仍然可以正常接受请求。但是，请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。</li>
<li><strong>第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发给从库。</strong>具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样以来，主从库就实现同步了。</li>
</ol>
</li>
</ol>
<h4 id="5-7-3-增量复制"><a href="#5-7-3-增量复制" class="headerlink" title="5.7.3 增量复制"></a>5.7.3 增量复制</h4><p>在 Redis 2.8 版本引入了增量复制</p>
<ul>
<li><p>为什么会设计增量复制？如果主从库在命令传播时出现了网络闪断，那么从库就会和主库重新进行一次全量复制，开销非常大。从 Redis 2.8开始，网络断了之后，主从库会采用增量复制的方式继续同步。</p>
</li>
<li><p>增量复制流程</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779133615-180cf488-8310-45f7-9e35-8cea064b2119-20250605100916148.jpeg" alt="img"></p>
</li>
<li><p>先看两个概念： replication buffer 和 repl_backlog_bufferrepl_backlog_buffer：它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量复制带来的性能开销。如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量复制，所以<strong>repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量复制的概率</strong>。而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer。replication buffer：Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer。对于这个问题来说，有两个关键点：</p>
</li>
<li><ul>
<li><strong>如果在网络断开期间，repl_backlog_size环形缓冲区写满之后，从库是会丢失掉那部分被覆盖掉的数据，还是直接进行全量复制呢</strong>？</li>
</ul>
</li>
</ul>
<ol>
<li><ol>
<li>一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。</li>
<li>每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制。</li>
</ol>
</li>
</ol>
<h4 id="5-7-4-更多理解"><a href="#5-7-4-更多理解" class="headerlink" title="5.7.4 更多理解"></a>5.7.4 更多理解</h4><h5 id="1-当主服务器不进行持久化时-复制的安全性"><a href="#1-当主服务器不进行持久化时-复制的安全性" class="headerlink" title="1.当主服务器不进行持久化时 复制的安全性"></a>1.当主服务器不进行持久化时 复制的安全性</h5><p>强烈建议主服务器开启持久化。如果真的不能开启持久化，那么一定要禁止Redis实例自动重启。</p>
<p>为什么不持久化的主服务器自动重启非常危险呢？为了更好的理解这个问题，看下面这个失败的例子，其中主服务器和从服务器中数据库都被删除了。</p>
<ul>
<li>我们设置节点A为主服务器，关闭持久化，节点B和C从节点A复制数据。</li>
<li>这时出现了一个崩溃，但Redis具有自动重启系统，重启了进程，因为关闭了持久化，节点重启后只有一个空的数据集。</li>
<li>节点B和C从节点A进行复制，现在节点A是空的，所以节点B和C上的复制数据也会被删除。</li>
<li>当在高可用系统中使用Redis Sentinel，关闭了主服务器的持久化，并且允许自动重启，这种情况是很危险的。比如主服务器可能在很短的时间就完成了重启，以至于Sentinel都无法检测到这次失败，那么上面说的这种失败的情况就发生了。</li>
</ul>
<p>如果数据比较重要，并且在使用主从复制时关闭了主服务器持久化功能的场景中，都应该禁止实例自动重启。</p>
<h5 id="2-为什么主从全量复制使用-RDB-而不使用-AOF？"><a href="#2-为什么主从全量复制使用-RDB-而不使用-AOF？" class="headerlink" title="2.为什么主从全量复制使用 RDB 而不使用 AOF？"></a>2.为什么主从全量复制使用 RDB 而不使用 AOF？</h5><ul>
<li>RDB 文件内容时经过压缩的 二进制数据（不同数据类型数据做了针对性优化），文件很小。而 AOF 文件记录的是 每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个 key 的多次冗余操作。在主从全量数据同步时，传输 RDB 文件可以尽量降低对主库机器网络带宽的消耗，从库在加载 RDB 文件时，一是文件小，读取整个文件的速度会很快，二是因为RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比 RDB 会慢得多，所以使用 RDB 进行主从全量复制的成本最低。</li>
<li>假设要使用 AOF 做全量复制，意味着必须打开 AOF 功能，打开 AOF 功能就要选择文件的刷盘的策略，选择不当会严重影响 Redis 性能。而 RDB 只有在需要定时备份和主从全量复制数据时，才会触发生成一次快照。而在很多就是数据不敏感的业务场景，其实时不需要开启 AOF 的。</li>
</ul>
<h5 id="3-为什么有无磁盘复制模式？"><a href="#3-为什么有无磁盘复制模式？" class="headerlink" title="3.为什么有无磁盘复制模式？"></a>3.为什么有无磁盘复制模式？</h5><p>Redis 默认时磁盘复制，但是如果使用比较低速的磁盘，这种操作会给主服务器带来比较大的压力。Redis从2.8.18版本开始尝试支持无磁盘的复制。使用这种设置时，子进程直接将RDB通过网络发送给从服务器，不使用磁盘作为中间存储。</p>
<p><strong>无磁盘复制模式</strong>：master创建一个新进程直接dump RDB到slave的socket，不经过主进程，不经过硬盘。适用于disk较慢，并且网络较快的时候。</p>
<p>使用repl-diskless-sync配置参数来启动无磁盘复制。</p>
<p>使用repl-diskless-sync-delay 参数来配置传输开始的延迟时间；master等待一个repl-diskless-sync-delay的秒数，如果没slave来的话，就直接传，后来的得排队等了; 否则就可以一起传。</p>
<h5 id="4-为什么还有-从库的从库的设计？"><a href="#4-为什么还有-从库的从库的设计？" class="headerlink" title="4.为什么还有 从库的从库的设计？"></a>4.为什么还有 从库的从库的设计？</h5><p>通过分析主从库间第一次数据同步的过程，你可以看到，一次全量复制中，对于主库来说，需要完成两个耗时的操作：<strong>生成 RDB 文件和传输 RDB 文件</strong>。</p>
<p>如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量复制。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。那么，有没有好的解决方法可以分担主库压力呢？</p>
<p>其实是有的，这就是“主 - 从 - 从”模式。</p>
<p>在刚才介绍的主从库模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的。现在，我们可以通过“主 - 从 - 从”模式<strong>将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上</strong>。</p>
<p>简单来说，我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。</p>
<p>replicaof 所选从库的IP 6379</p>
<p>这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行了，这就可以减轻主库上的压力，如下图所示：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779133018-6c82f9a9-6735-48d3-953f-9a4410adf454-20250605100846437.jpeg" alt="img"></p>
<p>级联的“主-从-从”模式好了，到这里，我们了解了主从库间通过全量复制实现数据同步的过程，以及通过“主 - 从 - 从”模式分担主库压力的方式。那么，一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。</p>
<h5 id="5-读写分离及其中的问题"><a href="#5-读写分离及其中的问题" class="headerlink" title="5.读写分离及其中的问题"></a>5.读写分离及其中的问题</h5><p>在主从复制基础上实现的读写分离，可以实现 Redis 的读负载均衡：由主节点提供写服务，由一个或者多个从节点提供读服务（多个从节点既可以提供数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可以大大提高 Redis 服务器的并发量。下面介绍在使用 Redis 读写分离时，需要注意的问题：</p>
<ul>
<li><strong>延迟与不一致问题</strong></li>
</ul>
<p>前面已经讲到，由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；使用集群同时扩展写负载和读负载等。</p>
<p>在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。从节点的slave-serve-stale-data参数便与此有关：它控制这种情况下从节点的表现；如果为yes（默认值），则从节点仍能够响应客户端的命令，如果为no，则从节点只能响应info、slaveof等少数命令。该参数的设置与应用对数据一致性的要求有关；如果对数据一致性要求很高，则应设置为no。</p>
<ul>
<li><strong>数据过期问题</strong></li>
</ul>
<p>在单机版Redis中，存在两种删除策略：</p>
<ul>
<li>惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。</li>
<li>定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。</li>
</ul>
<p>在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。</p>
<p>Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。</p>
<ul>
<li><strong>故障切换问题</strong></li>
</ul>
<p>在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。</p>
<ul>
<li><strong>总结</strong></li>
</ul>
<p>在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。</p>
<h3 id="5-8-Redis集群模式—-哨兵机制（Redis-Sentinel）"><a href="#5-8-Redis集群模式—-哨兵机制（Redis-Sentinel）" class="headerlink" title="5.8 Redis集群模式— 哨兵机制（Redis Sentinel）"></a>5.8 Redis集群模式— 哨兵机制（Redis Sentinel）</h3><p>在上文主从复制的基础上，如果节点出现故障该怎么办？在 Redis 集群中，哨兵机制是实现主从库自动切换的关键机制，它有效的解决了主从复制模式下的故障转移的问题。其与Redis2.8版本开始引用。</p>
<p><a target="_blank" rel="noopener" href="https://xie.infoq.cn/article/f6a8c0c5218394d56f4ae329b">https://xie.infoq.cn/article/f6a8c0c5218394d56f4ae329b</a></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779133444-1385070f-a6ee-4915-83e1-ec451d704df0-20250605100839770.png" alt="img"></p>
<p><strong>哨兵是一个独立的进程，作为进程，它会独立运行其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个 Redis 实例</strong></p>
<p>哨兵实现了什么功能呢？下面是 Redis 官方文档的描述：</p>
<ul>
<li><strong>监控（Monitoring）</strong>：哨兵会不断地检查主节点和从节点是否运作正常。</li>
<li><strong>自动故障转移（Automatic failover）</strong>：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。</li>
<li><strong>配置提供者（Configuration provider）</strong>：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。</li>
<li><strong>通知（Notification）</strong>：哨兵可以将故障转移的结果发送给客户端。</li>
</ul>
<p>其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。</p>
<h4 id="5-8-1-哨兵集群的搭建"><a href="#5-8-1-哨兵集群的搭建" class="headerlink" title="5.8.1 哨兵集群的搭建"></a>5.8.1 哨兵集群的搭建</h4><p>上图中哨兵集群式如何组建起来的？哨兵实例之间相互发现，要归功于 Redis 提供的 pub&#x2F;sub 机制，即 发布&#x2F;订阅机制</p>
<p>在主从集群中，主库上由一个名为 <strong>sentinel</strong>:hello 的频道，不同哨兵就是通过它来相互发现，实现互相通信的。在下图，哨兵1把自己的 IP（172.16.19.3）和端口（26579）发布到__sentinel__:hello频道上，哨兵2和3订阅了该频道。那么此时，哨兵2和3就可以从这个频道直接获取哨兵1的 IP 地址和端口号。然后，哨兵2、3可以和哨兵1建立网络连接。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779137211-0ab99635-9d14-4bb2-a004-b883c255b4df-20250605100831797.jpeg" alt="img"></p>
<p>通过这个方式，哨兵2、3也可以建立网络连接，这样一来，哨兵集群就形成了。它们相互间可以通过网络连接进行通信，比如说对主库有没有下线这件事儿进行判断和协商。</p>
<h4 id="5-8-2-哨兵监控-Redis-库"><a href="#5-8-2-哨兵监控-Redis-库" class="headerlink" title="5.8.2 哨兵监控 Redis 库"></a>5.8.2 哨兵监控 Redis 库</h4><p>哨兵监控什么？并且如何完成监控的？</p>
<p>这是由哨兵向主库发送 INFO命令完成的。如下图，哨兵2给主库发送 INFO命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续的对从库进行监控。哨兵1和3 可以通过相同的方法和从库建立连接。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779137974-8096b7fe-4c89-4541-99ac-b892ab0c5489-20250605100826937.jpeg" alt="img"></p>
<p>哨兵的工作内容：</p>
<ul>
<li><strong>每个 Sentinel 以每秒钟一次的频率向它所知的 Master，Slave 以及其他 Sentinel 实例发送一个 PING 命令</strong>。(<strong>心跳机制</strong>)</li>
<li><strong>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel 标记为主观下线</strong>。</li>
<li><strong>如果一个 Master 被标记为主观下线，则正在监视这个 Master 的所有 Sentinel 要以每秒一次的频率确认 Master 的确进入了主观下线状态</strong>。（<strong>确认投票下线</strong>）</li>
<li><strong>当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认 Master 的确进入了主观下线状态， 则 Master 会被标记为客观下线</strong> 。</li>
<li><strong>在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 INFO 命令</strong>。（同步数据）</li>
<li><strong>当 Master 被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次</strong>。</li>
<li><strong>若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会被移除</strong>。</li>
<li><strong>若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除</strong>。</li>
</ul>
<h4 id="5-8-3-主库下线的判定"><a href="#5-8-3-主库下线的判定" class="headerlink" title="5.8.3 主库下线的判定"></a>5.8.3 主库下线的判定</h4><p>哨兵如何判断主库已经下线了？</p>
<p>首先要区别两个概念：</p>
<ul>
<li>主观下线：任何一个哨兵都是可以监控探测，并作出 Redis 下线的判断</li>
<li>客观下线：有哨兵集群共同决定 Redis 节点是否下线</li>
</ul>
<p>当某个哨兵 判断主库 “主观下线”后，就会给其他哨兵发送 is-master-down-by-addr命令。接着，其他哨兵会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y相当于赞成票，N相当于反对票。如果赞成票数是大于等于 哨兵配置文件中的 quorum 配置项（比如这里如果 quorum &#x3D; 2），则就可以判定 主库客观下线了。</p>
<h4 id="5-8-4-哨兵集群的选举"><a href="#5-8-4-哨兵集群的选举" class="headerlink" title="5.8.4 哨兵集群的选举"></a>5.8.4 哨兵集群的选举</h4><p>判断完主库下线后，由哪个哨兵节点来执行主从切换呢？这里就需要哨兵集群的选举机制了</p>
<ul>
<li>为什么必然会出现 选举&#x2F;共识 机制？为了避免哨兵的单点情况发生，所以需要一个哨兵的分布式集群。作为分布式集群，必然涉及到共识问题（即选举问题）</li>
<li>哨兵的选举机制是什么样的?</li>
</ul>
<ol>
<li><ol>
<li><strong>发现主库客观下线的哨兵节点（这里称为 A）向每个哨兵节点发送命令要求对方选举自己为领头哨兵（leader）</strong>；</li>
<li><strong>如果目标哨兵没有选举过其他人，则同意将 A 选举为领头哨兵</strong>；</li>
<li><strong>如果 A 发现有超过半数且超过 quorum 参数值的哨兵节点同意选自己成为领头哨兵，则 A 哨兵成功选举为领头哨兵</strong>。【<strong>sentinel 集群执行故障转移时需要选举 leader，此时涉及到 majority，majority 代表 sentinel 集群中大部分 sentinel 节点的个数，只有大于等于 max(quorum, majority) 个节点给某个 sentinel 节点投票，才能确定该 sentinel 节点为 leader，majority 的计算方式为：num(sentinels) &#x2F; 2 + 1</strong>】</li>
<li><strong>当有多个哨兵节点同时参与领头哨兵选举时，出现没有任何节点当选可能，此时每个参选节点等待一个随机时间进行下一轮选举，直到选出领头哨兵</strong>。</li>
</ol>
</li>
</ol>
<ul>
<li><p>任何一个想要 执行 主从切换操作的 哨兵，要满足两个条件：</p>
</li>
<li><ul>
<li>第一，拿到半数以上的赞成票；</li>
<li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li>
</ul>
</li>
</ul>
<p>以3个哨兵为例，假设此时的 quorum 设置为2，那么，任何一个想成为 Leader 的哨兵只要拿到 2张赞成票，就可以了。</p>
<p>更进一步理解</p>
<p>这里很多人会搞混 判定客观下线 和 是否能够主从切换（用到选举机制） 两个概念，我们再看一个例子。</p>
<p>Redis 1主4从，5个哨兵，哨兵配置quorum为2，如果3个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换</p>
<p>经过实际测试：</p>
<p>1、哨兵集群可以判定主库“主观下线”。由于quorum&#x3D;2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，<strong>哨兵集群可以判定主库为“客观下线”</strong>。</p>
<p>2、<strong>但哨兵不能完成主从切换</strong>。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5&#x2F;2+1&#x3D;3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到N&#x2F;2+1选票的结果。</p>
<h4 id="5-8-5-新主库的选出、故障转移"><a href="#5-8-5-新主库的选出、故障转移" class="headerlink" title="5.8.5 新主库的选出、故障转移"></a>5.8.5 新主库的选出、故障转移</h4><p>主库既然判定客观下线了，并且选举出了领头哨兵，那么如何从剩余的 slave节点（从库）中选择一个新的主库呢？</p>
<ul>
<li>过滤掉不健康的（下线或断线），没有回复过哨兵 ping 响应的从节点</li>
<li>选择 salve-priority从节点优先级最高的（redis.conf）</li>
<li>选择复制偏移量最大（即复制主节点最完整的从节点）</li>
</ul>
<p>新的主库选择出来了，就可以开始进行故障的转移了</p>
<p>假设根据我们一开始的图：（我们假设：判断主库客观下线了，同时选出sentinel 3是哨兵leader）</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779138232-d32bebb3-1e76-46dc-86d6-36e088a21802-20250605100820125.png" alt="img"></p>
<p><strong>故障转移流程如下</strong>：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779138529-f55bef09-55ec-4955-9c4d-5154ed2a03a3.png" alt="img"></p>
<p>将slave-1脱离原从节点（PS: 5.0 中应该是replicaof no one)，升级主节点，</p>
<p>将从节点slave-2指向新的主节点</p>
<p>通知客户端主节点已更换</p>
<p>将原主节点（oldMaster）变成从节点，指向新的主节点</p>
<h3 id="5-9-Redis集群模式-Redis-Cluster（高可用集群）"><a href="#5-9-Redis集群模式-Redis-Cluster（高可用集群）" class="headerlink" title="5.9 Redis集群模式-Redis Cluster（高可用集群）"></a>5.9 Redis集群模式-Redis Cluster（高可用集群）</h3><p>前面两节，主从复制和哨兵机制保障了高可用，就读写分离而言虽然 slave 节点扩展了主从的读并发能力，但是写能力和存储能力是没有得到扩展。如果面对海量数据写入，就必须构建 master（主节点分片）之间的集群，同时必然需要吸收高可用（主从复制和哨兵机制）能力，即每个 master 分片节点还需要由 slave 节点。这是分布式系统中典型的纵向扩展（集群的分片技术）</p>
<p>Redis Cluster是一种服务器Sharding技术(分片和路由都是在服务端实现)，采用多主多从，每一个分区都是由一个Redis主机和多个从机组成，片区和片区之间是相互平行的。Redis Cluster集群采用了P2P的模式，完全去中心化。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779161866-f0c18226-fd15-433e-9084-a07940689300-20250605100812167.jpeg" alt="img"></p>
<p>如上图，官方推荐，集群部署至少要 3 台以上的master节点，好使用 3 主 3 从六个节点的模式。Redis Cluster集群具有如下几个特点：</p>
<ul>
<li>集群完全去中心化，采用多主多从；所有的redis节点彼此互联(PING-PONG机制)，内部使用二进制协议优化传输速度和带宽。</li>
<li>客户端与 Redis 节点直连，不需要中间代理层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。</li>
<li>每一个分区都是由一个Redis主机和多个从机组成，分片和分片之间是相互平行的。</li>
<li>每一个master节点负责维护一部分槽，以及槽所映射的键值数据；集群中每个节点都有全量的槽信息，通过槽每个node都知道具体数据存储到哪个node上。</li>
</ul>
<h4 id="5-9-1-哈希槽"><a href="#5-9-1-哈希槽" class="headerlink" title="5.9.1 哈希槽"></a>5.9.1 哈希槽</h4><p>Redis-cluster 没有使用一致性 hash，而是引入了 哈希槽的概念。 Redis-cluster 中有 16384（2的14次方）个哈希槽，每个 key 通过 CRC16校验后对 16383取模 来决定放置在哪个槽。Cluster 中的每个节点负责一部分槽（hash slot）【一致性hash在算法章节说】</p>
<p>比如集群中存在三个节点，则可能存在下面类似分配：</p>
<ul>
<li>节点 A 包含0到5500号 哈希槽</li>
<li>节点 B 包含 5501到11000号 哈希槽</li>
<li>节点 C 包含 11001到16384 哈希槽</li>
</ul>
<p>哈希槽&#x3D;CRC16(key) % 16384，为什么不直接 哈希槽&#x3D;CRC16(key)？这样就可以有 2^16个值。</p>
<p>这是因为redis节点发送心跳包时，需要将所有的槽放到这个心跳包。如果slots&#x3D;2^16，需占用空间 &#x3D; 2^16 &#x2F; 8 &#x2F; 1024 &#x3D; 8KB。而 slots&#x3D;16384 只占用 2KB。并且一般情况下 Redis Cluster 集群主节点数量基本不可能超过1000个，超过1000个一般会导致网络堵塞。。如果slots更少，虽然能进一步降低心跳包大小，但是 会更容易出现碰撞概率（命中失效）。所以 slots &#x3D; 16384 比较合理</p>
<h4 id="5-9-2-Key-Hash-Tags"><a href="#5-9-2-Key-Hash-Tags" class="headerlink" title="5.9.2 Key Hash Tags"></a>5.9.2 Key Hash Tags</h4><p>因为 key 分布在不同节点，所以 Multi-Key 操作就会受限。实际场景比如：</p>
<ul>
<li>SUNION、mset、mget，这类命令会操作多个key</li>
<li>事务，在一个事务中会操作多个key</li>
<li>LUA脚本，在LUA脚本中也会操作多个key</li>
</ul>
<p>Hash Tags 提供了一种途径，用来将多个（key）分配到相同的 hash slot 中。这时 Redis Cluster中实现 multi-key 操作的基础。</p>
<ul>
<li>key包含一个{字符</li>
<li>并且 如果在这个{的右面有一个}字符</li>
<li>并且 如果在{和}之间存在至少一个字符</li>
</ul>
<p>例如：</p>
<ul>
<li>{user1000}.following和{user1000}.followers这两个key会被hash到相同的hash slot中，因为只有user1000会被用来计算hash slot值。</li>
<li>foo{}{bar}这个key不会启用hash tag因为第一个{和}之间没有字符。</li>
<li>foozap这个key中全部内容会被用来计算hash slot</li>
<li>foo{bar}{zap}这个key中的bar会被用来计算计算hash slot，而zap不会</li>
</ul>
<h4 id="5-9-3-请求重定向"><a href="#5-9-3-请求重定向" class="headerlink" title="5.9.3 请求重定向"></a>5.9.3 请求重定向</h4><p>Redis cluster 采用去中心化的架构，集群的主节点各自负责一部分槽，客户端如何确定 key 到底会映射到 哪个节点上呢？这就涉及到请求重定向</p>
<p>在 Cluster 模式下，节点对请求的处理过程如下：</p>
<ol>
<li>检查当前 key 是否存在于 当前 node</li>
</ol>
<ul>
<li><ul>
<li>通过key有效部分使用 CRC16函数计算散列值，再对16384 取余，计算出 slot 的编号。</li>
<li>Redis计算得到键对应的槽后，需要查找槽所对应的节点。集群内通过消息交换每个节点都会知道所有节点的槽信息。从而得到负责该槽的 节点指针。</li>
</ul>
</li>
</ul>
<ol>
<li>若 slot 不是由自身负责，则返回 MOVED 重定向。</li>
<li>若 slot 由自身负责，且 key 在 slot 中，则返回该 key 对应结果。</li>
<li>若 key 不存在此 slot中，检查该 slot 是否正在迁出（MIGRATING）？</li>
<li>slot 正在迁出，返回 ASK错误重定向客户端到 迁移的目的服务器上</li>
<li>若 slot 未迁出，检查 slot 是否在导入中 ？</li>
<li>若 slot 导入中且由 ASKING 标记，则直接操作</li>
<li>否则返回 MOVED 重定向</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779145349-c2ddfcdb-cc9b-4948-a6f2-00b3b740388c-20250605100802757.png" alt="img"></p>
<p>请求处理过程中，可能涉及到两个重定向，分别时 MOVED重定向、ASK重定向</p>
<h5 id="MOVED-重定向"><a href="#MOVED-重定向" class="headerlink" title="MOVED 重定向"></a>MOVED 重定向</h5><p>通过计算 key 和 本地 slot 缓存，得到负责 slot 的节点。一般就去请求了，但是可能有两种情况：</p>
<ul>
<li>槽命中：直接返回结果</li>
<li>槽不命中：即当前键命令所请求的键 不在当前请求的节点中，则当前节点会向客户端发送一个 MOVED 重定向。客户端根据 MOVED重定向所包含的内容找到目标节点，再一次发送命令。redis-cli会帮你自动重定向（如果没有集群方式启动，即没加参数 -c，redis-cli不会自动重定向）</li>
</ul>
<p>由于本地会缓存映射的存在，所以绝大部分时候都不会触发 MOVED，而MOVED是用来协助客户端更新 slot-node 映射。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779141290-b93974ae-08a7-4639-88d8-fec2f75f06ed-20250605100753660.png" alt="img"></p>
<h5 id="ASK-重定向"><a href="#ASK-重定向" class="headerlink" title="ASK 重定向"></a>ASK 重定向</h5><p>集群伸缩时，集群伸缩会导致槽迁移。槽迁移过程中，一个槽内的key 会分为多个批次，依次迁移。所以存在，一部分数据在源节点，一般部分数据在迁移的目标节点。ASK重定向由此诞生</p>
<p>出现上述情况，客户端的命令执行流程如下：</p>
<ol>
<li>客户端根据本地 slot 缓存发送命令到源节点，如果存在 键对象 则直接执行并返回结果给客户端。</li>
<li>如果键对象不存在，则可能存在于目标节点。这时源节点会回复 ASK 重定向异常。格式如下：（error）ASK{slot}{targetIP}：{targetPort}</li>
<li>客户端从 ASK 重定向异常中 提取目标节点信息，发送 asking命令到目标节点打开客户端连接标识，再执行键命令。如果存在则执，不存在则返回不存在信息。</li>
</ol>
<h5 id="两者的区别"><a href="#两者的区别" class="headerlink" title="两者的区别"></a>两者的区别</h5><p>ASK与MOVED虽然都是对客户端的重定向控制，但是有着本质区别。ASK 重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移完成，因此只能是<strong>临时性的重定向</strong>，客户端<strong>不会更新slots缓存</strong>。但是MOVED重定向说明键对应的槽已经明确指定到新的节点，因此<strong>需要更新slots缓存</strong>。</p>
<h4 id="5-9-4-故障转移"><a href="#5-9-4-故障转移" class="headerlink" title="5.9.4 故障转移"></a>5.9.4 故障转移</h4><p>Redis集群自身实现了高可用。高可用首先需要解决集群部分失败的场景：当集群内少量节点出现故障时通过自动故障转移保证集群可以正常对外提供服务。</p>
<p>Redis集群内节点通过ping&#x2F;pong消息实现节点通信，消息不但可以传播节点槽信息，还可以传播其他状态如：主从状态、节点故障等。因此故障发现也是通过消息传播机制实现的，主要环节包括：主观下线（pfail）和客观下线（fail）。</p>
<p>主观下线流程：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779141957-c4410066-51a8-40ed-9ae8-f17118aaa5fd-20250605100742339.png" alt="img"></p>
<p>当某个节点判断另一个节点主观下线后，相应的节点状态会跟随消息在集群内传播。ping&#x2F;pong消息的消息体会携带集群1&#x2F;10的其他节点状态数据，当接受节点发现消息体中含有主观下线的节点状态时，会在本地找到故障节点的ClusterNode结构，保存到<strong>下线报告链表</strong>中。</p>
<p>通过Gossip消息传播，集群内节点不断收集到故障节点的下线报告。当<strong>半数以上</strong>持有槽的主节点都标记某个节点是主观下线时，触发客观下线流程。</p>
<p><strong>故障恢复</strong></p>
<p>故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它的<strong>从节点</strong>中选出一个替换它，从而保证集群的高可用。下线主节点的所有从节点承担故障恢复的义务，当从节点通过内部定时任务发现自身复制的主节点进入客观下线时，将会触发故障恢复流程：</p>
<ul>
<li>从节点与主节点断线时间超过cluster-node-time*cluster-slave-validity-factor，则当前从节点不具备故障转移资格。参数cluster-slave-validity-factor用于从节点的有效因子，默认为10。</li>
<li>当从节点符合故障转移资格后，更新触发故障选举的时间，只有到达该时间后才能执行后续流程。这里之所以采用<strong>延迟触发机制</strong>，主要是通过对多个从节点使用不同的延迟选举时间来支持优先级问题。复制偏移量越大说明从节点延迟越低，那么它应该具有更高的优先级来替换故障主节点。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779142661-ccaf9622-687f-4fd7-bb0f-9b12dd307cfe-20250605100735532.png" alt="img"></p>
<ul>
<li>发起选举。Redis集群没有直接使用从节点进行领导者选举，主要因为从节点数必须大于等于3个才能保证凑够N&#x2F;2+1个节点，将导致从节点资源浪费。使用<strong>集群内所有持有槽的主节点进行领导者选举</strong>，即使只有一个从节点也可以完成选举过程。当从节点收集到N&#x2F;2+1个持有槽的主节点投票时，从节点可以执行替换主节点操作。</li>
</ul>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779143549-fe48adcb-3d12-4d75-9ec8-5b30473ab45e-20250605100730766.png" alt="img"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779143588-93b3d1eb-7667-4589-afc0-cb041b6046c3-20250605100725335.png" alt="img"></p>
<p><strong>预估故障转移时间</strong></p>
<p>failover-time(毫秒) ≤ cluster-node-timeout + cluster-node-timeout &#x2F; 2 + 1000</p>
<ul>
<li>主观下线识别时间：cluster-node-timeout</li>
<li>主观下线状态消息传播时间&lt;&#x3D;cluster-node-timeout&#x2F;2。消息通信机制对超过cluster-node-timeout&#x2F;2未通信节点会发起ping消息，消息体在选择包含哪些节点时会优先选取下线状态节点，所以通常这段时间内能够收集到半数以上主节点的pfail报告从而完成故障发现。</li>
<li>从节点转移时间&lt;&#x3D;1000毫秒。由于存在延迟发起选举机制，偏移量最大的从节点会<strong>最多延迟<strong><strong>1</strong></strong>秒发起选举</strong>。通常第一次选举就会成功。</li>
</ul>
<p>故障转移时间跟 cluster-node-timeout 参数息息相关，默认15秒。配置时可以根据业务容忍度做出适当调整，但不是越小越好。</p>
<h4 id="5-9-5-脑裂问题"><a href="#5-9-5-脑裂问题" class="headerlink" title="5.9.5 脑裂问题"></a>5.9.5 脑裂问题</h4><p>什么是脑裂？</p>
<p>在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。</p>
<p>这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— <strong>脑裂出现了</strong>。</p>
<p>脑裂可能会导致数据丢失？</p>
<p>然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，<strong>因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题</strong>。</p>
<p>总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</p>
<p>解决方案</p>
<p>当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。</p>
<p>在 Redis 的配置文件中有两个参数我们可以设置：</p>
<ul>
<li>min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。</li>
<li>min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。</li>
</ul>
<p>我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。</p>
<p>这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。</p>
<p>即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，<strong>原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了</strong>。</p>
<p><strong>等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。</strong></p>
<p>再来举个例子</p>
<p>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。</p>
<p>同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。</p>
<p>这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p>
<h4 id="5-9-6-状态检测及维护"><a href="#5-9-6-状态检测及维护" class="headerlink" title="5.9.6 状态检测及维护"></a>5.9.6 状态检测及维护</h4><p>Redis Cluster 中节点状态如何维护呢？这些就涉及 有哪些状态、底层协议Gossip及具体的通讯机制</p>
<p>Cluster 中 每个节点都维护一份在自己看来当前整个集群的状态，主要包括：</p>
<ul>
<li>当前集群的状态</li>
<li>集群中各节点所负责的 slots 信息及其 migrate 状态</li>
<li>集群中各节点的 master-slave 状态</li>
<li>集群中各节点的存活状态及不可达投票</li>
</ul>
<p>当集群状态发生变化，如：如新节点加入、slot迁移、节点宕机、slave提升为新Master，我们希望这些变化尽快的被发现，传播到整个集群的所有节点并达成一致。节点之间相互的<strong>心跳</strong>（PING，PONG，MEET）及其携带的数据是集群状态传播最主要的途径。</p>
<h5 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h5><p>Redis Cluster 通讯底层是 Gossip 协议，所以需要对 Gossip 协议有一定了解</p>
<p>gossip 协议（gossip protocol）又称 epidemic 协议（epidemic protocol），是基于流行病传播方式的节点或者进程之间信息交换的协议。 在分布式系统中被广泛使用，比如我们可以使用 gossip 协议来确保网络中所有节点的数据一样。</p>
<p>Gossip协议已经是P2P网络中比较成熟的协议了。Gossip协议的最大的好处是，<strong>即使集群节点的数量增加，每个节点的负载也不会增加很多，几乎是恒定的。这就允许Consul管理的集群规模能横向扩展到数千个节点</strong>。</p>
<p>Gossip算法又被称为反熵（Anti-Entropy），熵是物理学上的一个概念，代表杂乱无章，而反熵就是在杂乱无章中寻求一致，这充分说明了Gossip的特点：在一个有界网络中，每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，只要这些节可以通过网络连通，最终他们的状态都是一致的，当然这也是疫情传播的特点。<a target="_blank" rel="noopener" href="https://www.backendcloud.cn/2017/11/12/raft-gossip/">https://www.backendcloud.cn/2017/11/12/raft-gossip/</a></p>
<p>上面的描述都比较学术，其实Gossip协议对于我们吃瓜群众来说一点也不陌生，Gossip协议也成为流言协议，说白了就是八卦协议，这种传播规模和传播速度都是非常快的，你可以体会一下。所以计算机中的很多算法都是源自生活，而又高于生活的</p>
<h5 id="Gossip协议的使用"><a href="#Gossip协议的使用" class="headerlink" title="Gossip协议的使用"></a>Gossip协议的使用</h5><p>Redis 集群是去中心化的，彼此之间状态同步考 gossip 协议通讯，集群的消息有以下几种类型：</p>
<ul>
<li>Meet 通过 cluster meet ip port命令，已有集群的节点会向新的节点发送邀请，加入现有集群。</li>
<li>Ping 节点每秒会向集群中其他节点发送 ping 消息，消息中带有自己已知的两个节点的地址、槽、状态信息、最后一次通信时间等</li>
<li>Pong 节点收到 ping 消息后会回复 pong 消息，消息中同样带有自己已知的两个节点信息</li>
<li>Fail 节点 ping 不通某节点后，会向集群所有节点广播该节点挂掉的消息。其他节点收到消息后标记已下线。</li>
</ul>
<h5 id="基于Gossip-协议的故障检测"><a href="#基于Gossip-协议的故障检测" class="headerlink" title="基于Gossip 协议的故障检测"></a>基于Gossip 协议的故障检测</h5><p>集群中每个节点都会定期地向集群中其他节点发送 PING 消息，以此交换各个节点状态信息，检测各个节点状态：<strong>在线状态、疑似下线状态、PFAIL、已下线状态FAIL</strong></p>
<p><strong>自己保存信息</strong>：当主节点A通过消息得知主节点B认为主节点D进入了疑似下线(PFAIL)状态时,主节点A会在自己的clusterState.nodes字典中找到主节点D所对应的clusterNode结构，并将主节点B的下线报告添加到clusterNode结构的fail_reports链表中，并后续关于结点D疑似下线的状态通过Gossip协议通知其他节点。</p>
<p><strong>一起裁定</strong>：如果集群里面，半数以上的主节点都将主节点D报告为疑似下线，那么主节点D将被标记为已下线(FAIL)状态，将主节点D标记为已下线的节点会向集群广播主节点D的FAIL消息，所有收到FAIL消息的节点都会立即更新nodes里面主节点D状态标记为已下线。</p>
<p><strong>最终裁定</strong>：将 node 标记为 FAIL 需要满足以下两个条件：</p>
<ul>
<li>有半数以上的主节点将 node 标记为 PFAIL 状态。</li>
<li>当前节点也将 node 标记为 PFAIL 状态。</li>
</ul>
<h4 id="5-9-7-通讯状态和维护"><a href="#5-9-7-通讯状态和维护" class="headerlink" title="5.9.7 通讯状态和维护"></a>5.9.7 通讯状态和维护</h4><p>我们理解了Gossip协议基础后，就可以进一步理解Redis节点之间相互的通讯<strong>心跳</strong>（PING，PONG，MEET）实现和维护了</p>
<ol>
<li>什么时候进行心跳？Redis 节点会记录其向每个节点上次发出 ping 和收到 pong 的时间，心跳发送时机与这两个值有关。通过下面的方式既能保证及时更新集群状态，又不至于使心跳数过多：</li>
</ol>
<ul>
<li><ul>
<li>每次Cron向所有未建立链接的节点发送ping或meet</li>
<li>每1秒从所有已知节点中随机选取5个，向其中上次收到pong最久远的一个发送ping</li>
<li>每次Cron向收到pong超过timeout&#x2F;2的节点发送ping</li>
<li>收到ping或meet，立即回复pong</li>
</ul>
</li>
</ul>
<ol>
<li>发送那些心跳数据？</li>
</ol>
<ul>
<li><ul>
<li>Header，发送者自己的信息：所负责的 slots 的信息；主从信息；ip port 信息；状态信息</li>
<li>Gossip，发送者所了解的部分其他节点的信息：ping_sent、pong_received；ip port信息；状态信息（比如发送者认为该节点已经不可到达，会在状态信息中标记其为 PFAIL或FAIL）</li>
</ul>
</li>
</ul>
<ol>
<li>如何处理心跳</li>
</ol>
<ul>
<li><ul>
<li>新节点加入</li>
</ul>
</li>
</ul>
<ol>
<li><ol>
<li><ol>
<li>发送meet包加入集群</li>
<li>从pong包中的 gossip 得到未知的其他节点</li>
<li>循环上述过程，直到最终加入集群</li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><ul>
<li>Slots 信息</li>
</ul>
</li>
</ul>
<ol>
<li><ol>
<li><ol>
<li>判断发送者声明的 slots 信息，跟本地记录的是否不同</li>
<li>如果不同，且发送者 epoch较大，更新本地记录</li>
<li>如果不同，且发送者 epoch较小，发送 Update 信息通知发送者</li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><ul>
<li>Master slave信息发现发送者的master、slave信息变化，更新本地状态</li>
<li>节点Fail探测（故障发现）Gossip的存在使得集群状态的改变可以更快的达到整个集群。每个心跳包中会包含多个Gossip包，那么多少个才是合适的呢，redis的选择是N&#x2F;10，其中N是节点数，这样可以保证在PFAIL投票的过期时间内，节点可以收到80%机器关于失败节点的gossip，从而使其顺利进入FAIL状态。</li>
</ul>
</li>
</ul>
<ol>
<li><ol>
<li><ol>
<li>超过超时时间仍然没有收到 pong 包的节点会被当前节点标记为 PFAIL</li>
<li>PFAIL 标记会随着 gossip 传播</li>
<li>每次收到心跳包会检测其中对其他节点的 PFAIL 标记，当做对该节点的FAIL的投票维护在本机</li>
<li>对某个节点的 PFAIL标记达到大多数时，将其变为 FAIL 标记并广播 FAIL消息</li>
</ol>
</li>
</ol>
</li>
<li><p>只能通过 gossip + 心跳 传递信息？当需要发布一些非常重要需要立即发送的信息时，上述 心跳+Gossip的方式就显得捉襟见肘了。这时就需要向所有集群内机器广播信息，使用广播发的场景：</p>
</li>
</ol>
<ul>
<li><ul>
<li>节点的 Fail 信息：当发现某一个节点不可达时，探测节点会将其标记为 PFAIL状态，并通过心跳传播出去。当某一个节点发现这个节点的 PFAIL 超过半数时修改其为 FAIL 并发起广播。</li>
<li>Failover Request 信息：slave 尝试发起 FailOver时 广播其要求投票的信息</li>
<li>新 Master 信息：FailOver成功的节点向整个集群广播自己的信息</li>
</ul>
</li>
</ul>
<h4 id="5-9-8-扩容、缩容"><a href="#5-9-8-扩容、缩容" class="headerlink" title="5.9.8 扩容、缩容"></a>5.9.8 扩容、缩容</h4><p>当集群出现容量限制或者其他一些原因需要扩容时，redis cluster提供了比较优雅的集群扩容方案。</p>
<ol>
<li>首先将新节点加入到集群中，可以通过在集群中任何一个客户端执行cluster meet 新节点ip:端口，或者通过redis-trib add node添加，新添加的节点默认在集群中都是主节点。</li>
<li>迁移数据 迁移数据的大致流程是，首先需要确定哪些槽需要被迁移到目标节点，然后获取槽中key，将槽中的key全部迁移到目标节点，然后向集群所有主节点广播槽（数据）全部迁移到了目标节点。直接通过redis-trib工具做数据迁移很方便。 现在假设将节点A的槽10迁移到B节点，过程如下：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">B:cluster setslot 10 importing A.nodeId</span><br><span class="line">A:cluster setslot 10 migrating B.nodeId</span><br></pre></td></tr></table></figure>

<p>循环获取槽中key，将key迁移到B节点</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A:cluster getkeysinslot 10 100</span><br><span class="line">A:migrate B.ip B.port &quot;&quot; 0 5000 keys key1[ key2....]</span><br></pre></td></tr></table></figure>

<p>向集群广播槽已经迁移到B节点</p>
<p>cluster setslot 10 node B.nodeId</p>
<p>缩容的大致过程与扩容一致，需要判断下线的节点是否是主节点，以及主节点上是否有槽，若主节点上有槽，需要将槽迁移到集群中其他主节点，槽迁移完成之后，需要向其他节点广播该节点准备下线（cluster forget nodeId）。最后需要将该下线主节点的从节点指向其他主节点，当然最好是先将从节点下线</p>
<h4 id="5-9-9-Write-Safety-分析"><a href="#5-9-9-Write-Safety-分析" class="headerlink" title="5.9.9 Write Safety 分析"></a>5.9.9 Write Safety 分析</h4><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000039226390">https://segmentfault.com/a/1190000039226390</a></p>
<p>Redis Cluster 是 Redis 的分布式实现，就如同官方文档里强调的，其设计优先考虑的是 高性能和线性扩展能力，尽量保证 write safety。这里所说的 write 丢失是指，回复 客户端响应后，后续请求中出现未做变更或者丢失的情况。导致该问题，主要在 主从切换、实例重启、脑裂三种情况下。</p>
<ul>
<li><p>主从切换</p>
</li>
<li><ul>
<li>被动 failover情景：master c 为主节点，负责 slot 1-100，其对应的从节点是 slave c。当master c挂掉后，slave c 在 最多2倍 cluster_node_timeout 的时间 内把 master c 标记成 FALL,进而触发 failover 逻辑。在 slave c 成功切换为 master前，slot 1-100 仍然由 master c 负责，访问也会报错。当 slave c 切换为 master 后，gossip 广播路由变更，在这个过程中，client 访问 slave c，仍然可以得到正常回应，而访问其他持有老路由的 node，请求会被 moved 到挂掉的 master c，访问报错。问题：如果写到 master 上的数据还没来得及同步到 slave 就挂掉了，那么这部分数据就会丢失（重启后不存在 merge操作）。即写入的数据丢失。master 回复 client ack 于 同步 slave 几乎同时进行的，这种情况很少发生（时间窗口小），但是这存在这个风险</li>
<li>主动 failover主动 failover 通过 sysadmin 在 slave node 上执行 CLUSTER FAILOVER [FORCE|TAKEOVER] 命令触发。完整的 manual failover 可以概括为以下步骤：该命令的三个选项分别由不同的行为：</li>
</ul>
</li>
</ul>
<ol>
<li><ol>
<li><ol>
<li>slave 发起请求，gossip 消息携带 <strong>CLUSTERMSG_TYPE_MFSTART</strong> 标识。</li>
<li>master 阻塞 client，停服时间为 2 倍 <strong>CLUSTER_MF_TIMEOUT</strong>，目前版本为 10s。</li>
<li>slave 追赶主从复制 offset 数据。</li>
<li>slave 开始发起选举，并最终当选。</li>
<li>slave 切换自身 role，接管 slots，并广播新的路由信息。</li>
<li>其他节点更改路由，cluster 路由打平。</li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><ul>
<li><ul>
<li>默认选项：执行完整的 mf 流程，master 由停服行为，因此不存在write丢失问题。</li>
<li>FORCE选项：从第四步开始执行。在 slave c 统计选票阶段，master c 仍然可以正常接收用户请求，且主从异步复制，这些都可能导致 write 丢失。mf 将在未来的某个时间点开始执行，timeout 时间为 <strong>CLUSTER_MF_TIMEOUT</strong>（现版本为 5s），每次 clusterCron 都会检查。</li>
<li>TAKEOVER选项：从第五步开始执行。slave 直接增加自己的 configEpoch（无需其他node同意），接管 slots。从 slave c切换为 master 到 原 master c 更新路由 这段期间，发送到 原master 从的请求，都可能存在 write 丢失的可能。一般在一个 ping 的时间内完成，时间窗口很小。master c 和 slave c 以外节点更新路由滞后只会带来多一次的 moved 错误，不会导致 write 丢失。</li>
</ul>
</li>
</ul>
</li>
<li><p>master 重启clusterState 结构体中有一个 <strong>state</strong> 成员变量，表示 cluster 的全局状态，控制着当前 cluster 是否可以提供服务，有以下两种取值：</p>
</li>
<li><ul>
<li>cluster 状态初始化</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define CLUSTER_OK 0 /* Everything looks ok */</span><br><span class="line"> #define CLUSTER_FAIL 1 /* The cluster can&#x27;t work */</span><br></pre></td></tr></table></figure>

<p>server 重启后，state 被初始化为 <strong>CLUSTER_FAIL</strong>，此状态下的 cluster 是拒绝访问的。这对保证 write safety 是非常必要的！可以想象，如果 master A 挂掉后，对应的 slave A’ 通过选举成功当选为新 master。此时，A 重启，且恰好有一些 client 看到的路由没有更新，它们仍然会往 A 上写数据，如果接受这些 write，就会丢数据！A’ 才是这个 sharding 大家公认的 master。所以，A’ 重启后需要先禁用服务，直到路由变更完成。所以如果 <strong>CLUSTER_WRITABLE_DELAY</strong> 内，未能更新路由，可能就导致 write 丢失。</p>
<ul>
<li><ul>
<li>cluster 状态变更什么时候 cluster 才会出现 <strong>CLUSTER_FAIL</strong> -&gt; <strong>CLUSTER_OK</strong> 的状态变更呢。从 clusterCron 定时任务中，可以知道 clusterCron状态变更要延迟 <strong>CLUSTER_WRITABLE_DELAY</strong> 毫秒，当前版本是2s。访问延迟就是为等待 路由变更，那么什么时候触发路由变更呢？一个新 server 刚启动，它与其他 node 进行 gossip 通信的 link 都是 null，在 clusterCron 里检查出来后会依次连接，并发送 ping。作为一个路由过期的老节点，收到其他节点发来的 update 消息，更改自身路由。<strong>CLUSTER_WRITABLE_DELAY</strong> 毫秒后，A 节点恢复访问，我们认为 CLUSTER_WRITABLE_DELAY 的时间窗口足够更新路由。</li>
</ul>
</li>
<li><p>网络分区</p>
</li>
<li><ul>
<li>网络分区发生由于网络的不可靠，网络分区时一个必须要考虑的问题。当网络分区发生后，cluster 被割裂成 majority 和 minority 两部分，这里以分区中的 master 节点来区分。</li>
</ul>
</li>
</ul>
<ol>
<li><ol>
<li><ol>
<li>对于 minority 部分，slave 会发起选举，但是不能收到大多数 master 的选票，也就无法完成正常的 failover 流程。同时在 clusterCron 里的大部分节点会被标记为 <strong>CLUSTER_NODE_PFAIL</strong> 状态，进而触发集群状态更新。在 minority 中，cluster 状态在一段时间后，会被更改为 <strong>CLUSTER_FAIL</strong>。但，对于一个划分到 minority 的 master 节点，在状态更改前是一直可以访问的，这就有一个时间窗口，会导致 write 丢失。在 clusterCron 函数中可以计算出这个时间窗口大小：从 partition 时间开始算起，<strong>cluster_node_timeout</strong> 时间后才会有 node 标记为 PFAIL，加上 gossip 消息传播会偏向于携带 PFAIL 的节点，master节点 不必等到 <strong>cluster_node_timeout&#x2F;2</strong> 把 cluster nodes ping 遍，就可以把 cluster 标记为 <strong>CLUSTER_FAIL</strong>可以推算出，时间窗口大约为 <strong>cluster_node_timeout</strong>。另外，会记录下禁用服务的时间，即 among_minority_time</li>
<li>对于 majority 部分，slave 会发起选举，切换为新的master并提供服务。如果partition 时间小于 cluster_node_timeout,以至于没有 PFAIL 标识出现，就不会有 write 丢失。</li>
</ol>
</li>
</ol>
</li>
</ol>
<ul>
<li><ul>
<li>网络分区恢复当网络分区恢复后，minority 中 老的master 重新加进 cluster，master 要想提供服务，就必须先将 cluster 状态从 <strong>CLUSTER_FAIL</strong> 修改为 <strong>CLUSTER_OK</strong>，那么，应该什么时候改呢？我们知道 老master中应该是旧路由，此时它应该变更为 slave，所以，还是需要等待一段时间做路由变更，否则有可能出现 write 丢失的问题。从 clusterUpdateState 函数的逻辑里，可以看出时间窗口为 <strong>cluster_node_timeout</strong></li>
</ul>
</li>
</ul>
<p>总结：</p>
<p>failover 可能因为选举和主从异步复制数据偏差带来 write 丢失。master 重启通过 <strong>CLUSTER_WRITABLE_DELAY</strong> 延迟，等 cluster 状态变更为 <strong>CLUSTER_OK</strong>，可以重新访问，不存在 write 丢失。partition 中的 minority 部分，在 cluster 状态变更为 <strong>CLUSTER_FAIL</strong> 之前，可能存在 write 丢失。partition 恢复后，通过 rejoin_delay 延迟，等 cluster 状态变更为 <strong>CLUSTER_OK</strong>，可以重新访问，不存在 write 丢失。</p>
<h4 id="5-9-10-availability-分析"><a href="#5-9-10-availability-分析" class="headerlink" title="5.9.10 availability 分析"></a>5.9.10 availability 分析</h4><p><a target="_blank" rel="noopener" href="https://segmentfault.com/a/1190000039234661?utm_source=sf-similar-article">https://segmentfault.com/a/1190000039234661?utm_source=sf-similar-article</a></p>
<p>主要在三种情况下，出现不可用：</p>
<ul>
<li>网络故障Redis Cluster 在发生 网络分区后，minority 部分是不可用的。假设 majority 部分有 过半数 master 和 所有不在majority的master其下的一个slave。那么，经过 NODE_TIMEOUT 时间加额外几秒钟（给slave进行failover），cluster 恢复可用状态。</li>
<li>sharding 缺失故障默认情况下，当检测到有 slot 没有绑定，Redis Cluster 就会停止接受请求。在这种配置下（三主三从），如果 cluster 部分节点挂掉（一个主节点和其对应的从节点都挂了），也就是说一个范围内的 slot 不再有节点负责，最终整个 cluster 会变的不能提供服务。<strong>有时候，服务部分可用比整个不可用更有意义</strong>，因此，即使一部分 sharding 可用，也要让 cluster 提供服务。redis 将这种选择权交到了用户手中，conf 里提供 <strong>cluster-require-full-coverage</strong> 参数。如果该参数为false，那么有 slot 未绑定或者 sharding确实，server 也是可以接受请求的。</li>
<li>当集群节点宕机，出现集群Master节点个数小于3个的时候，或者集群可用节点个数为偶数的时候，基于 failover 这种选举机制的自动主从切换过程可能会不能正常工作。标记 fail、以及选举新master的过程，都可能异常。</li>
</ul>
<h5 id="replicas-migration-功能"><a href="#replicas-migration-功能" class="headerlink" title="replicas migration 功能"></a>replicas migration 功能</h5><p>举个例子，如果一个包含N个 master 的集群，每个Master 有唯一 slave。单个 node 出现故障，cluster必定仍然可用；第二个 node 再出现再出现故障。如果第二个节点正好是上面已经故障的master节点的slave，则此时集群不可用。如果第二个节点是其他节点，则集群仍然可用。所以集群不可用的概率是 1&#x2F;(N*2-1) </p>
<p>Redis Cluster 为了提高可用性，这个是用于在每次故障之后，重新布局集群的slave，给没有slave的master配备上slave，以此来更好应对下次故障。</p>
<p>具体实现：</p>
<p>这种负责 部分slot但是没有健康slave的 master，就称为 orphaned master。当slave检测到自己的 master 拥有不少于2个健康slave，且 cluster 中恰好有 orphan master 时，触发 clusterHandleSlaveMigration 函数逻辑，尝试进行 slave 漂移，slave步骤有如下四步</p>
<ol>
<li>CLUSTER_FAIL 集群漂移 if (server.cluster-&gt;state !&#x3D; CLUSTER_OK) return;非 CLUSTER_OK 集群本来旧无法正常接收请求，所以也不需要漂移。</li>
<li>检查 cluster-migration-barrier 参数<strong>redis conf 提供了cluster-migration-barrier 参数</strong>，用来决定 slave 数量达到多少个才会把冗余 slave 漂移出去。只有 master 健康 slave 的个数超过 cluster-migration-barrier 配置的数量时，才会漂移。</li>
<li>选出要漂移的 slave，以及漂移给谁。选择 node name 最小的slave，漂移给遍历到的第一个 orphaned master</li>
<li>执行漂移在 failover 期间，master 有一段时间是没有 slave，为了防止误漂，漂移必须有一定的延迟。时间为 CLUSTER_SLAVE_MIGRATION _DELAY 现版本为 5s。</li>
</ol>
<h2 id="六、Redisson"><a href="#六、Redisson" class="headerlink" title="六、Redisson"></a>六、Redisson</h2><h3 id="6-1-分布式锁"><a href="#6-1-分布式锁" class="headerlink" title="6.1 分布式锁"></a>6.1 分布式锁</h3><p>分布式锁，是控制分布式系统不同进程共同访问共享资源的一种锁的实现。秒杀下单、抢红包等等业务场景，都需要用到分布式锁。</p>
<h4 id="6-1-1-常见redis-分布式锁"><a href="#6-1-1-常见redis-分布式锁" class="headerlink" title="6.1.1 常见redis 分布式锁"></a>6.1.1 常见redis 分布式锁</h4><p>一般Redis分布式锁有如下几种实现方案：</p>
<ul>
<li>命令 setnx + expire 分开写</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">if(jedis.setnx(key,lock_value) == 1)&#123; // 加锁</span><br><span class="line">    expire(key,100);  // 设置过期时间</span><br><span class="line">    try&#123;</span><br><span class="line">        do something // 业务处理</span><br><span class="line">    &#125;catch()&#123;</span><br><span class="line">        </span><br><span class="line">    &#125;finally&#123; </span><br><span class="line">      jedis.del(key); // 释放锁</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果执行完 setnx 加锁，正要执行 expire 设置过期时间，进行crash或者重启维护，那么这个锁就一直被锁住了，别的线程永远获取不到锁了，所以分布式不能这种实现。</p>
<ul>
<li>setnx + value 值过期时间为了解决方案一，发生异常锁得不到释放的场景。</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">long expires = System.currentTimeMillis() + expireTime; // 系统时间 + 设置的过期时间</span><br><span class="line">if(jedis.setnx(key,expires) == 1)&#123;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br><span class="line">// 如果当前锁不存在，返回加锁成功</span><br><span class="line">if (jedis.setnx(key_resource_id, String.vaue(expires)) == 1) &#123;</span><br><span class="line">        return true;</span><br><span class="line">&#125; </span><br><span class="line">// 如果锁已经存在，获取锁的过期时间</span><br><span class="line">String currentValueStr = jedis.get(key_resource_id);</span><br><span class="line"></span><br><span class="line">// 如果获取到的过期时间，小于系统当前时间，表示已经过期</span><br><span class="line">if (currentValueStr != null &amp;&amp; Long.parseLong(currentValueStr) &lt; System.currentTimeMillis()) &#123;</span><br><span class="line"></span><br><span class="line">         // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间</span><br><span class="line">        String oldValueStr = jedis.getSet(key_resource_id, expiresStr);</span><br><span class="line"></span><br><span class="line">        if (oldValueStr != null &amp;&amp; oldValueStr.equals(currentValueStr)) &#123;</span><br><span class="line">             // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才可以加锁</span><br><span class="line">             return true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">        </span><br><span class="line">    //其他情况，均返回加锁失败</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这一方案巧妙移除了 expire 单独设置过期时间的操作，把过期时间放到了 setnx 的 value 值中。解决了 发生异常锁得不到释放的问题。但是此方案也有自己的缺点：</p>
<ul>
<li><ul>
<li>过期时间是客户端自己生成的（System.currentTimeMillis()是当前系统的时间），必须要求分布式环境下，每个客户端的时间必须同步。</li>
<li>如果锁过期的时候，并发多个客户端同时请求过来，都执行jedis.getSet()，最终只能有一个客户端加锁成功，但是该客户端锁的过期时间，可能被别的客户端覆盖</li>
<li>该锁没有保存持有者的唯一标识，可能被别的客户端释放&#x2F;解锁。</li>
</ul>
</li>
<li><p>set 的扩展命令（set ex px nx）Redis 的 set 扩展参数（SET key value[EX seconds][PX milliseconds][NX|XX]）是原子性的。EX seconds：设定key的过期时间，时间单位是秒。PX milliseconds：设定key的过期时间，单位是毫秒NX：表示key不存在的时候，才能set成功，也即保证只有第一个客户端请求才能获取锁，而其他客户端请求只能等起释放锁，才能获取。XX：仅当key存在时设置值</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if（jedis.set(key_resource_id, lock_value, &quot;NX&quot;, &quot;EX&quot;, 100s) == 1）&#123; //加锁</span><br><span class="line">    try &#123;</span><br><span class="line">        do something  //业务处理</span><br><span class="line">    &#125;catch()&#123;</span><br><span class="line">　　&#125;</span><br><span class="line">　　finally &#123;</span><br><span class="line">       jedis.del(key_resource_id); //释放锁</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但是呢，这个方案还是可能存在问题：问题一：<strong>锁过期释放了，业务还没执行完</strong>。假设线程a获取锁成功，一直在执行临界区的代码。但是100s过去后，它还没执行完。但是，这时候锁已经过期了，此时线程b又请求过来。显然线程b就可以获得锁成功，也开始执行临界区的代码。那么问题就来了，临界区的业务代码都不是严格串行执行的啦。问题二：<strong>锁被别的线程误删</strong>。假设线程a执行完后，去释放锁。但是它不知道当前的锁可能是线程b持有的（线程a去释放锁时，有可能过期时间已经到了，此时线程b进来占有了锁）。那线程a就把线程b的锁释放掉了，但是线程b临界区业务代码可能都还没执行完呢。</p>
<ul>
<li>set ex px nx + 校验唯一随机值 再删除既然锁可能被别的线程误删，那我们给value值设置一个标记当前线程唯一的随机数，在删除的时候，校验一下，不就OK了嘛。伪代码如下：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if（jedis.set(key_resource_id, uni_request_id, &quot;NX&quot;, &quot;EX&quot;, 100s) == 1）&#123; //加锁</span><br><span class="line">    try &#123;</span><br><span class="line">        do something  //业务处理</span><br><span class="line">    &#125;catch()&#123;</span><br><span class="line">　　&#125;</span><br><span class="line">　　finally &#123;</span><br><span class="line">       //判断是不是当前线程加的锁,是才释放</span><br><span class="line">       if (uni_request_id.equals(jedis.get(key_resource_id))) &#123;</span><br><span class="line">        jedis.del(lockKey); //释放锁</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在这里，<strong>判断是不是当前线程加的锁</strong>和<strong>释放锁</strong>不是一个原子操作。如果调用jedis.del()释放锁的时候，可能这把锁已经不属于当前客户端，会解除他人加的锁。因为 finally 部分执行时不能保证原子性，一般也是用 lua脚本代替。</p>
<h4 id="6-1-2-Redisson-的解决方案"><a href="#6-1-2-Redisson-的解决方案" class="headerlink" title="6.1.2 Redisson 的解决方案"></a>6.1.2 Redisson 的解决方案</h4><p><strong>1. 单机方案</strong></p>
<p>其实上面的方案还是会存在 锁过期释放，业务没有执行完的问题。所以其实我们可以开启一个定时守护线程，每隔一段时间检查锁是否还存在，存在则对锁过期时间延长，防止锁过期提前释放。</p>
<p>只要线程1加锁成功，就会启动一个 watch dog，它是一个后台线程，会每隔10秒检查一下锁。如果线程1还持有锁，那么就会不断的延长锁key的过期时间。因此 Redission 解决了 业务还没执行完 锁就过期释放的 问题。</p>
<p><strong>2. 基于故障转移的RedLock算法</strong></p>
<p>上面的所有的方案都是基于单机版的，然而实际上生产环境redis都是集群部署。</p>
<p>直接在 redis 主从集群中使用上面的方案，会有如下问题：</p>
<p>客户端在 Redis 的 master 节点上拿到了 锁，但是这个锁还没有同步到 slave 节点上，master节点就发生了故障。然后进行了故障转移，slave节点升级为 master节点。因此 客户端 加的锁丢失了。</p>
<p>因此Redis作者antirez基于分布式环境下提出了一种更高级的分布式锁的实现方式：<strong>Redlock</strong>。</p>
<p><strong>Redlock架构图</strong></p>
<p>应用前提：在Redis的分布式环境中，我们假设有N个Redis master。这些节点<strong>完全互相独立，不存在主从复制或者其他集群协调机制</strong>。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。</p>
<p>实现步骤：</p>
<ol>
<li>获取当前的时间戳</li>
<li>依次尝试向5个实例，使用相同的 key 和 具有唯一性的value（例如UUID）获取锁。客户端请求各实例获取锁时，应有设置响应超时时间。并且这个响应超时时间尽量远小于锁的失效时间。如此设计的原因，是因为我们不能在已经挂掉的master上花费太多时间。如果花费太多时间，会造成还没向全部master请求完，锁的失效时间就已经到了。因此 如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。</li>
<li>客户端使用当前时间减去开始获取锁的时间（步骤1记录的时间），就可以得到 获取锁 所用的时间。<strong>当且仅当从大多数（N&#x2F;2+1，这里是3个节点）的Redis节点都取到锁，并且整个过程使用的时间小于锁失效时间时，锁才算获取成功</strong>。</li>
<li>如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。</li>
<li>如果因为某些原因，获取锁失败（没有在至少N&#x2F;2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在<strong>所有的Redis实例上进行解锁</strong>（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。</li>
</ol>
<h2 id="七、Redis应用问题"><a href="#七、Redis应用问题" class="headerlink" title="七、Redis应用问题"></a>七、Redis应用问题</h2><h3 id="7-1-Redis与MySQL双写一致性如何保证？"><a href="#7-1-Redis与MySQL双写一致性如何保证？" class="headerlink" title="7.1 Redis与MySQL双写一致性如何保证？"></a>7.1 Redis与MySQL双写一致性如何保证？</h3><p>一旦出现数据更新，redis与数据库之间的数据一致性问题就会出现。</p>
<p>一致性就是数据保持一致，在分布式系统中，可以理解为多个节点中数据的值是一致的。</p>
<ul>
<li><strong>强一致性</strong>：这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大</li>
<li><strong>弱一致性</strong>：这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态</li>
<li><strong>最终一致性</strong>：最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型</li>
</ul>
<p><strong>是选择更新缓存还是删除缓存？</strong></p>
<p>如果 线程A先更新数据库，之后线程B也向数据库中更新同一值，但是B请求快，先写入了缓存，A后写入了缓存。那么实际上 缓存中还是旧值，而数据库中是B更改后的新值。导致数据最终不一致。</p>
<p>但是你选择的是删除缓存。那么在最后一次删除缓存后，请求再来时会查询数据库最新数据。那么就避免了这个问题。所以 我们选择 删除缓存。</p>
<p>不管是先删除缓存再更新数据库，还是先更新数据库再删除缓存，都有可能存在数据不一致的情况。</p>
<ol>
<li><strong>先删除缓存再更新数据库</strong>：在删除缓存后，更新数据库前。就可能会有个请求获取缓存，此时缓存没有，它就去查数据库了，就得到了脏数据。并将脏数据塞入了缓存中。这就导致了 缓存与数据库 最终不一致。</li>
<li><strong>先更新数据库再删除缓存</strong>：在删除缓存之前，去读到的都是 脏数据。在并发写不高、redis删除失败概率不大时，可以一定程度实现 最终一致性。但是在并发写较高，就会出现下面的情况：</li>
</ol>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682815161357-87e6efce-ca8a-4ce3-a1d2-592d9d2c7a6c-20250605100709115.png" alt="img"></p>
<p>此时 再有线程进来读取缓存，就会读取到就是a&#x3D;2，但是实际 数据库中 a&#x3D;3。这就导致了数据最终不一致。</p>
<p>此方案可以考虑在写并发极低的情况下使用。</p>
<p>但是综合来看，上面两个方案即使在不考虑 删除key 可能失败的情况，也不能保证 缓存和数据库 数据最终一致。</p>
<p><strong>3.延迟双删：</strong> </p>
<p>延迟双删再上面方案1 的基础上，增加了一步 延迟一定时间后 再删除缓存。从而避免方案1，造成的脏数据存在缓存中。达到下面左图到效果</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1684856079904-9a8380f7-4d84-40fc-88aa-a1efe58412d1-20250605100653159.png" alt="img"></p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1684856140846-5f64616b-c627-4b51-90e2-7cf9943c770d-20250605100659576.png" alt="img"></p>
<p>这样就可以实现 数据最终一致性。但是我们也可以清楚的发现，如果延迟时间不够，很有可能会出现 Thread-2 的写入缓存操作 在Thread-1第二次删除缓存 之后发生。那么此时，数据又会出现不一致的情况。</p>
<p>所以我们应当设置一个合理的 延迟时间，但是即使合理，也不能说 一定能保证在任何情况下 Thread-2 写入操作都在 Thread-1 第二次删缓存 之后。</p>
<p><strong>4.异步更新缓存（基于CDC的同步机制）</strong></p>
<p>通过CDC（数据变更跟踪）将缓存与数据库的一致性同步从业务中独立出来统一处理，保证数据一致性。</p>
<p>整体思路：</p>
<ol>
<li>更新、写 数据库后，会产生数据变更记录。（MySQL中有binlog日志，SQLServer中有CDC变更表）</li>
<li>通过数据变更记录来更新 Redis中数据</li>
</ol>
<p>这里可以使用：1. FlinkCDC 来实现 对数据库变更数据的追踪、处理；2. 数据变更记录 存入 消息队列，消费者有序实现 Redis 更新。</p>
<p>上面的所有方案中，都没有考虑 删除缓存失败 的可能，如果考虑删除缓存失败，可能所有方案都保证不了 数据最终一致性。所以在 删除缓存 这一操作，可以考虑 失败重试 或者 将需要删除的key存入消息队列中，依次保证 删除缓存的成功。</p>
<p>从整个大局来看，我们会发现 如果缓存不设置过期时间，是比较容易造成 redis与数据库 最终一致性难以保证的。最简单的方法就是 设置过期时间，这样即使脏数据在缓存中，也不会存在很久。</p>
<p>个人看法：小团队或者小项目可以考虑 使用方案2+设置key过期时间，较大项目可以考虑 使用方案4</p>
<h4 id=""><a href="#" class="headerlink" title=""></a></h4><h3 id="7-2-Redis-的大key如何处理？"><a href="#7-2-Redis-的大key如何处理？" class="headerlink" title="7.2 Redis 的大key如何处理？"></a>7.2 Redis 的大key如何处理？</h3><p>什么是 Redis 大key ？</p>
<p>大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。</p>
<p>一般而言，下面这两种情况被称为大 key：</p>
<ul>
<li>String 类型的值大于 10 KB；</li>
<li>Hash、List、Set、ZSet 类型的元素的个数超过 5000个；</li>
</ul>
<p>大key会造成什么问题？</p>
<p>大 key 会带来以下四种影响：</p>
<ul>
<li><strong>客户端超时阻塞。</strong>由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li>
<li><strong>引发网络阻塞。</strong>每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li>
<li><strong>阻塞工作线程。</strong>如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li>
<li><strong>内存分布不均。</strong>集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li>
</ul>
<p>如何找到大key？</p>
<ol>
<li>redis-cli –bigkeys 查找大key</li>
</ol>
<p>可以通过 redis-cli –bigkeys 命令查找大 key：</p>
<p>使用的时候注意事项：</p>
<ul>
<li><ul>
<li>最好选择在从节点上执行该命令。因为主节点上执行时，会阻塞主节点；</li>
<li>如果没有从节点，那么可以选择在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；或者可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。</li>
</ul>
</li>
</ul>
<p>该方式的不足之处：</p>
<ul>
<li><ul>
<li>这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey；</li>
<li>对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是，一个集合中的元素个数多，并不一定占用的内存就多。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大；</li>
</ul>
</li>
</ul>
<ol>
<li>使用 SCAN 命令查找大 key</li>
</ol>
<p>使用 SCAN 命令对数据库扫描，然后用 TYPE 命令获取返回的每一个 key 的类型。</p>
<p>对于 String 类型，可以直接使用 STRLEN 命令获取字符串的长度，也就是占用的内存空间字节数。</p>
<p>对于集合类型来说，有两种方法可以获得它占用的内存大小：</p>
<ul>
<li><ul>
<li>如果能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。List 类型：LLEN 命令；Hash 类型：HLEN 命令；Set 类型：SCARD 命令；Sorted Set 类型：ZCARD 命令；</li>
<li>如果不能提前知道写入集合的元素大小，可以使用 MEMORY USAGE 命令（需要 Redis 4.0 及以上版本），查询一个键值对占用的内存空间。</li>
</ul>
</li>
</ul>
<ol>
<li>使用 RdbTools 工具查找大 key</li>
</ol>
<p>使用 RdbTools 第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key。</p>
<p>比如，下面这条命令，将大于 10 kb 的  key  输出到一个表格文件。</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdb dump.rdb -c memory --bytes 10240 -f redis.csv</span><br></pre></td></tr></table></figure>



<p>如何优化大key？</p>
<ul>
<li>对大key进行拆分和压缩</li>
</ul>
<p>例如将含有数万成员的一个HASH Key拆分为多个HASH Key，<strong>使用multiGet方法获得值，</strong>并确保每个Key的成员数量在合理范围。<strong>这样的拆分主要是为了减少单台操作的压力，而是将压力平摊到集群各个实例中，降低单台机器的IO操作。</strong></p>
<ul>
<li>对大key可以进行清理</li>
</ul>
<p>将不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。</p>
<ul>
<li>在Redis集群架构中对热Key进行复制</li>
</ul>
<p>在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。此时，可以将对应热Key进行复制并迁移至其他数据分片，例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。</p>
<ul>
<li>使用读写分离架构</li>
</ul>
<p>如果热Key的产生来自于读请求，您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。</p>
<h3 id="7-3-如何选择持久化策略？"><a href="#7-3-如何选择持久化策略？" class="headerlink" title="7.3 如何选择持久化策略？"></a>7.3 如何选择持久化策略？</h3><p>RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。</p>
<p>AOF 优点是丢失数据少，但是数据恢复不快。</p>
<p>为了集成了两者的优点， Redis 4.0 提出了<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。</p>
<p>混合持久化工作在 <strong>AOF 日志重写过程</strong>，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p>
<p>也就是说，使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。</strong></p>
<p>这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。</p>
<p>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得<strong>数据更少的丢失。</strong></p>
<p><strong>混合持久化优点：</strong></p>
<ul>
<li>混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。</li>
</ul>
<p><strong>混合持久化缺点：</strong></p>
<ul>
<li>AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；</li>
<li>兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。</li>
</ul>
<h2 id="八、Redis-涉及的算法"><a href="#八、Redis-涉及的算法" class="headerlink" title="八、Redis 涉及的算法"></a>八、Redis 涉及的算法</h2><h3 id="1-一致性Hash"><a href="#1-一致性Hash" class="headerlink" title="1.一致性Hash"></a>1.一致性Hash</h3><p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779145889-e62ed280-3191-42c2-904d-1c8c373415eb-20250605100643333.png" alt="img"></p>
<h4 id="1-1-问题的由来"><a href="#1-1-问题的由来" class="headerlink" title="1.1 问题的由来"></a>1.1 问题的由来</h4><p>大多数应用，背后肯定不只有一台服务器提供服务。因为高可用或并发量的需要，都会使用多台服务器组成集群对外提供服务。那么问题来了，这么多服务器，要如何分配客户端请求呢？其实这个问题，就是 负载均衡问题了。解决负载均衡问题的算法很多，不同的负载均衡算法，适用于不同的应用场景和需求。一般，最简单的方式，就是引入一个中间的负载均衡层，让它将外界的请求 “轮流” 转发给内部的集群。比如集群有三个节点，并收到了3个请求，那么每个节点都会处理一个请求。</p>
<p>考虑到每个节点的硬件配置有区别，一般引用权重值。按不同节点的权重值，来分配请求，让处理能力更抢的节点，分担更多请求。</p>
<p>但是这种加权轮询使用场景是建立前提——每个节点存储的数据都是相同的。这样，访问任意一个节点都可以获取相同的结果。但是，这就无法应对 分布式系统。因为分布式系统，每个节点存储的数据是不同的。</p>
<p>比如：分布式存储系统，一般为了提高系统的容量，就会把数据水平切分到不同的节点来存储。比如 Redis，某个key应该到哪个或者那些节点上获的，应该是确定的。而不是任意访问一个节点都可以获取 key 对应的 value。</p>
<h4 id="1-2-直接使用哈希算法？"><a href="#1-2-直接使用哈希算法？" class="headerlink" title="1.2 直接使用哈希算法？"></a>1.2 直接使用哈希算法？</h4><p>很容易就会想到 hash算法，其可以通过一个 key 进行 哈希计算，每次都可以得到相同的值。这样就可以将某个 key 确定到一个节点了，可以满足分布式系统的负载均衡需求。</p>
<p>哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 hash(key) % 3 公式对数据进行了映射。如果客户端要获取指定 key 的数据，通过上面的公式定位节点。</p>
<p>但是这有一个很致命的问题：如果节点数据发生了变化，也就是在对系统做扩容或者缩容时，可能造成大部分映射关系改变。并且必须迁移改变了映射关系的数据，否则会查询不到数据的问题。假设总数据条数为 M，哈希算法在面对节点数量变化时，最坏情况下所有数据都需要迁移，所以它的数据迁移规模时 O（M），这样数据迁移成本太高。</p>
<h4 id="1-3-使用一致性哈希算法有什么问题"><a href="#1-3-使用一致性哈希算法有什么问题" class="headerlink" title="1.3 使用一致性哈希算法有什么问题?"></a>1.3 使用一致性哈希算法有什么问题?</h4><p>一致性哈希算法就很好地解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。一致哈希算法也用了取模运算，但于哈希算法不同的是，哈希算法是对节点数量进行取模，而一致哈希算法是对 2^32 进行取模运算&#x3D;</p>
<p>们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环。这个圆想可以想象成由 2^32 个点组成的圆，这个圆环被称为<strong>哈希环</strong>，如下图：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779145911-113a608a-7f26-4b41-8eff-464c49c5cdb4-20250605100626223.png" alt="img"></p>
<p>一致性哈希要进行两步哈希：</p>
<ul>
<li>第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；</li>
<li>第二步：当对数据进行存储或访问时，对数据进行哈希映射；</li>
</ul>
<p>所以，<strong>一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上</strong>。</p>
<p>问题来了，对「数据」进行哈希映射得到一个结果要怎么找到存储该数据的节点呢？</p>
<p>答案是，映射的结果值往<strong>顺时针的方向的找到第一个节点</strong>，就是存储该数据的节点。</p>
<p>举个例子，有 3 个节点经过哈希计算，映射到了如下图的位置：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779146288-40a6a0f2-c9c1-402e-b0b0-d5e849e93c80.png" alt="img"></p>
<p>接着，对要查询的 key-01 进行哈希计算，确定此 key-01 映射在哈希环的位置，然后从这个位置往顺时针的方向找到第一个节点，就是存储该 key-01 数据的节点。</p>
<p>比如，下图中的 key-01 映射的位置，往顺时针的方向找到第一个节点就是节点 A。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779148088-70cf5d37-5c2c-4798-9017-0b922282dfde-20250605100619239.png" alt="img"></p>
<p>所以，当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：</p>
<ul>
<li>首先，对 key 进行哈希计算，确定此 key 在环上的位置；</li>
<li>然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。</li>
</ul>
<p>知道了一致哈希寻址的方式，我们来看看，如果增加一个节点或者减少一个节点会发生大量的数据迁移吗？</p>
<p>假设节点数量从 3 增加到了 4，新的节点 D 经过哈希计算后映射到了下图中的位置：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779148190-0c1b592b-c7fe-48c2-b1a3-809ba82d18c4-20250605100611637.png" alt="img"></p>
<p>你可以看到，key-01、key-03 都不受影响，只有 key-02 需要被迁移节点 D。</p>
<p>假设节点数量从 3 减少到了 2，比如将节点 A 移除：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779149035-52942a34-67f3-4b3c-b460-711a9a5e35f8-20250605100604477.png" alt="img"></p>
<p>你可以看到，key-02 和 key-03 不会受到影响，只有 key-01 需要被迁移节点 B。</p>
<p>因此，<strong>在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响</strong>。</p>
<p>上面这些图中 3 个节点映射在哈希环还是比较分散的，所以看起来请求都会「均衡」到每个节点。</p>
<p>但是<strong>一致性哈希算法并不保证节点能够在哈希环上分布均匀</strong>，这样就会带来一个问题，会有大量的请求集中在一个节点上。</p>
<p>比如，下图中 3 个节点的映射位置都在哈希环的右半边：</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779150974-f47dbce4-1f4a-4de3-a89c-46fe115a7c6e-20250605100557936.png" alt="img"></p>
<p>这时候有一半以上的数据的寻址都会找节点 A，也就是访问请求主要集中的节点 A 上，这肯定不行的呀，说好的负载均衡呢，这种情况一点都不均衡。</p>
<p>另外，在这种节点分布不均匀的情况下，进行容灾与扩容时，哈希环上的相邻节点容易受到过大影响，容易发生雪崩式的连锁反应。</p>
<p>比如，上图中如果节点 A 被移除了，当节点 A 宕机后，根据一致性哈希算法的规则，其上数据应该全部迁移到相邻的节点 B 上，这样，节点 B 的数据量、访问量都会迅速增加很多倍，一旦新增的压力超过了节点 B 的处理能力上限，就会导致节点 B 崩溃，进而形成雪崩式的连锁反应。</p>
<p>所以，<strong>一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题</strong>。</p>
<h4 id="1-3-通过虚拟节点提高均衡度"><a href="#1-3-通过虚拟节点提高均衡度" class="headerlink" title="1.3 通过虚拟节点提高均衡度"></a>1.3 通过虚拟节点提高均衡度</h4><p>要想解决节点能在 哈希环上 分配不均匀的问题，就是要有大量的节点，节点越多，哈希环上的节点分布就越均匀。但问题是，实际上我们没有那么多节点，所以这个时候我们就加入虚拟节点，也就是对一个真实节点做多个副本。</p>
<p>具体做法是，不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点。所以这里有 两层 映射关系。</p>
<p>比如对每个节点分别设置 3 个虚拟节点：</p>
<ul>
<li>对节点 A 加上编号来作为虚拟节点：A-01、A-02、A-03</li>
<li>对节点 B 加上编号来作为虚拟节点：B-01、B-02、B-03</li>
<li>对节点 C 加上编号来作为虚拟节点：C-01、C-02、C-03</li>
</ul>
<p>引入虚拟节点后，原本哈希环上只有 3 个节点的情况，就会变成有 9 个虚拟节点映射到哈希环上，哈希环上的节点数量多了 3 倍。</p>
<p><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779151776-aaf4acdf-2263-4845-8949-6bcf82659d50-20250605100548993.png" alt="img"></p>
<p>你可以看到，<strong>节点数量多了后，节点在哈希环上的分布就相对均匀了</strong>。这时候，如果有访问请求寻址到「A-01」这个虚拟节点，接着再通过「A-01」虚拟节点找到真实节点 A，这样请求就能访问到真实节点 A 了。</p>
<p>上面为了方便你理解，每个真实节点仅包含 3 个虚拟节点，这样能起到的均衡效果其实很有限。而在实际的工程中，虚拟节点的数量会大很多，比如 Nginx 的一致性哈希算法，每个权重为 1 的真实节点就含有160 个虚拟节点。</p>
<p>另外，虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。<strong>当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高</strong>。比如，当某个节点被移除时，对应 该节点的多个虚拟节点均会移除，而这些虚拟节点按顺时针方向的下一个虚拟节点，可能会对应不同的真实节点，即这些不同的真实节点共同分担了 节点被移除 导致的压力。</p>
<p>而且有虚拟节点的概念也方便了，对不同节点进行权重区分。硬件配置更好的节点，增加更多虚拟节点。</p>
<h4 id="1-4-总结"><a href="#1-4-总结" class="headerlink" title="1.4 总结"></a>1.4 总结</h4><p>轮训这类的策略只能适用与每个节点的数据都是相同的场景，访问任意节点都能请求到数据。但是不适用分布式系统，因为分布式系统意味着数据水平切分到了不同的节点上，访问数据的时候，一定要寻址存储该数据的节点。</p>
<p>哈希算法虽然能建立数据和节点的映射关系，但是每次在节点数量发生变化的时候，最坏情况下所有数据都需要迁移，这样太麻烦了，所以不适用节点数量变化的场景。</p>
<p>为了减少迁移的数据量，就出现了一致性哈希算法。</p>
<p>一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。</p>
<p>但是一致性哈希算法不能够均匀的分布节点，会出现大量请求都集中在一个节点的情况，在这种情况下进行容灾与扩容时，容易出现雪崩的连锁反应。</p>
<p>为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。</p>
<p>引入虚拟节点后，可以会提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。</p>
<hr>
<p>摘录文章：</p>
<p>Redis 设计与实现（第一版）：<a target="_blank" rel="noopener" href="https://redisbook.readthedocs.io/en/latest/index.html">https://redisbook.readthedocs.io/en/latest/index.html</a></p>
<p><a target="_blank" rel="noopener" href="https://juejin.cn/post/6964531365643550751">美团二面：Redis与MySQL双写一致性如何保证？</a></p>
</article><div class="post-copyright"><div class="copyright-cc-box"><i class="anzhiyufont anzhiyu-icon-copyright"></i></div><div class="post-copyright__author_box"><a class="post-copyright__author_img" href="/" title="头像"><img class="post-copyright__author_img_back" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" title="头像" alt="头像"><img class="post-copyright__author_img_front" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" title="头像" alt="头像"></a><div class="post-copyright__author_name">XR</div><div class="post-copyright__author_desc">一片叶、一朵云</div></div><div class="post-copyright__post__info"><a class="post-copyright__original" title="该文章为原创文章，注意版权协议" href="http://example.com/2025/06/07/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">原创</a><a class="post-copyright-title"><span onclick="rm.copyPageUrl('http://example.com/2025/06/07/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/')">Redis学习笔记</span></a></div><div class="post-tools" id="post-tools"><div class="post-tools-left"><div class="rewardLeftButton"><div class="post-reward" onclick="anzhiyu.addRewardMask()"><div class="reward-button button--animated" title="赞赏作者"><i class="anzhiyufont anzhiyu-icon-hand-heart-fill"></i>打赏作者</div><div class="reward-main"><div class="reward-all"><span class="reward-title">感谢你赐予我前进的力量</span><ul class="reward-group"><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231130275.png" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png" target="_blank"><img class="post-qr-code-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226231143327.png" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul><a class="reward-main-btn" href="/about/#about-reward" target="_blank"><div class="reward-text">赞赏者名单</div><div class="reward-dec">因为你们的支持让我意识到写文章的价值🙏</div></a></div></div></div><div id="quit-box" onclick="anzhiyu.removeRewardMask()" style="display: none"></div></div><div class="shareRight"><div class="share-link mobile"><div class="share-qrcode"><div class="share-button" title="使用手机访问这篇文章"><i class="anzhiyufont anzhiyu-icon-qrcode"></i></div><div class="share-main"><div class="share-main-all"><div id="qrcode" title="http://example.com/2025/06/07/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"></div><div class="reward-dec">使用手机访问这篇文章</div></div></div></div></div><div class="share-link weibo"><a class="share-button" target="_blank" href="https://service.weibo.com/share/share.php?title=Redis学习笔记&amp;url=http://example.com/2025/06/07/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/&amp;pic=https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250607204045262.png" rel="external nofollow noreferrer noopener"><i class="anzhiyufont anzhiyu-icon-weibo"></i></a></div><script>function copyCurrentPageUrl() {
  var currentPageUrl = window.location.href;
  var input = document.createElement("input");
  input.setAttribute("value", currentPageUrl);
  document.body.appendChild(input);
  input.select();
  input.setSelectionRange(0, 99999);
  document.execCommand("copy");
  document.body.removeChild(input);
}</script><div class="share-link copyurl"><div class="share-button" id="post-share-url" title="复制链接" onclick="copyCurrentPageUrl()"><i class="anzhiyufont anzhiyu-icon-link"></i></div></div></div></div></div><div class="post-copyright__notice"><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://example.com" target="_blank">凌霄博客</a>！</span></div></div><div class="post-tools-right"><div class="tag_share"><div class="post-meta__box"><div class="post-meta__box__tag-list"></div></div></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226224350520.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"/><script src="https://cdn.cbd.int/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer="defer"></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2025/06/07/%E6%96%B0%E7%94%9F%E4%BB%A3%E5%8F%AA%E6%9C%89%E4%B8%80%E4%B8%AAEden+S0%20%E5%8F%AF%E4%BB%A5%E5%90%97/"><img class="prev-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250608162900884.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">JVM新生代只有一个Eden+S0 可以吗</div></div></a></div><div class="next-post pull-right"><a href="/2025/06/07/%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92%20%E7%9C%9F%E7%9A%84%E6%9C%89%E7%82%B9%E9%98%B4/"><img class="next-cover" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250607203155245.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">指令重排 真的有点阴</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="anzhiyufont anzhiyu-icon-comments"></i><span> 评论</span></div><div class="comment-randomInfo"><a onclick="anzhiyu.addRandomCommentInfo()" href="javascript:void(0)">匿名评论</a><a href="/privacy" style="margin-left: 4px">隐私政策</a></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div><div class="comment-barrage"></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-content"><div class="author-info__sayhi" id="author-info__sayhi" onclick="anzhiyu.changeSayHelloText()"></div><div class="author-info-avatar"><img class="avatar-img" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/04/27/64496e511b09c.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/><div class="author-status"><img class="g-status" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://bu.dusays.com/2023/08/24/64e6ce9c507bb.png" alt="status"/></div></div><div class="author-info__description"></div><div class="author-info__bottom-group"><a class="author-info__bottom-group-left" href="/"><h1 class="author-info__name">XR</h1><div class="author-info__desc">一片叶、一朵云</div></a><div class="card-info-social-icons is-center"><a class="social-icon faa-parent animated-hover" href="https://github.com/kongxiaoran" target="_blank" title="Github"></a></div></div></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-bars"></i><span>文章目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0"><span class="toc-number">1.</span> <span class="toc-text">Redis学习笔记</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%80%E3%80%81Redis-%E7%9A%84%E5%AE%89%E8%A3%85"><span class="toc-number">1.1.</span> <span class="toc-text">一、Redis 的安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-Redis-%E5%AE%89%E8%A3%85%EF%BC%88window%EF%BC%89"><span class="toc-number">1.1.1.</span> <span class="toc-text">1.1 Redis 安装（window）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-2-Redis-%E5%AE%89%E8%A3%85%EF%BC%88docker%EF%BC%89"><span class="toc-number">1.1.2.</span> <span class="toc-text">1.2 Redis 安装（docker）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#1-3-Redis-%E9%85%8D%E7%BD%AE"><span class="toc-number">1.1.3.</span> <span class="toc-text">1.3 Redis 配置</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%8C%E3%80%81Redis-%E7%9A%84%E5%9F%BA%E7%A1%80%E7%AF%87"><span class="toc-number">1.2.</span> <span class="toc-text">二、Redis 的基础篇</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-%E4%BA%94%E7%A7%8D%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">1.2.0.1.</span> <span class="toc-text">2.1 五种基本数据结构</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-1-String"><span class="toc-number">1.2.0.1.1.</span> <span class="toc-text">2.1.1 String</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-2-List"><span class="toc-number">1.2.0.1.2.</span> <span class="toc-text">2.1.2 List</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-3-Hash"><span class="toc-number">1.2.0.1.3.</span> <span class="toc-text">2.1.3 Hash</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-4-Set"><span class="toc-number">1.2.0.1.4.</span> <span class="toc-text">2.1.4 Set</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-1-5-SortSet"><span class="toc-number">1.2.0.2.</span> <span class="toc-text">2.1.5 SortSet</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-%E4%B8%89%E7%A7%8D%E7%89%B9%E6%AE%8A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="toc-number">1.2.0.3.</span> <span class="toc-text">2.2 三种特殊数据结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-Redis%E5%91%BD%E4%BB%A4"><span class="toc-number">1.2.0.4.</span> <span class="toc-text">2.3 Redis命令</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-1-%E9%80%9A%E7%94%A8%E5%91%BD%E4%BB%A4"><span class="toc-number">1.2.0.4.1.</span> <span class="toc-text">2.1.1 通用命令</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-2-String%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.2.0.4.2.</span> <span class="toc-text">2.1.2 String类型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-3-Key%E7%9A%84%E5%B1%82%E7%BA%A7%E6%A0%BC%E5%BC%8F"><span class="toc-number">1.2.0.4.3.</span> <span class="toc-text">2.1.3 Key的层级格式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-4-Hash%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.2.0.4.4.</span> <span class="toc-text">2.1.4 Hash类型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-4-List%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.2.0.4.5.</span> <span class="toc-text">2.1.4 List类型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-5-Set%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.2.0.4.6.</span> <span class="toc-text">2.1.5 Set类型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-1-6-SortedSet%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.2.0.4.7.</span> <span class="toc-text">2.1.6 SortedSet类型</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-2-Redis%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-number">1.2.0.5.</span> <span class="toc-text">2.2 Redis客户端</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-1-Jedis-%E5%AE%A2%E6%88%B7%E7%AB%AF"><span class="toc-number">1.2.0.5.1.</span> <span class="toc-text">2.2.1 Jedis 客户端</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-2-2-SpringDataRedis"><span class="toc-number">1.2.0.5.2.</span> <span class="toc-text">2.2.2 SpringDataRedis</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-3-SpringDataRedis-%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8"><span class="toc-number">1.2.0.6.</span> <span class="toc-text">2.3 SpringDataRedis 客户端使用</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-1-SpringDataRedis-%E7%9A%84%E9%BB%98%E8%AE%A4%E5%BA%8F%E5%88%97%E5%8C%96"><span class="toc-number">1.2.0.6.1.</span> <span class="toc-text">2.3.1 SpringDataRedis 的默认序列化</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-2-SpringDataRedis-%E6%8F%90%E4%BE%9B%E7%9A%84%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8"><span class="toc-number">1.2.0.6.2.</span> <span class="toc-text">2.3.2 SpringDataRedis 提供的序列化器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-3-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8"><span class="toc-number">1.2.0.6.3.</span> <span class="toc-text">2.3.3 自定义序列化器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-4-%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E5%BA%8F%E5%88%97%E5%8C%96%E5%99%A8%E5%AD%98%E5%82%A8%E5%AF%B9%E8%B1%A1"><span class="toc-number">1.2.0.6.4.</span> <span class="toc-text">2.3.4 使用自定义序列化器存储对象</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-5-%E4%BD%BF%E7%94%A8StringRedisTemplate%E5%AD%98%E5%82%A8JSON%E5%AF%B9%E8%B1%A1"><span class="toc-number">1.2.0.6.5.</span> <span class="toc-text">2.3.5 使用StringRedisTemplate存储JSON对象</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-3-6-RedisTemplate-%E6%93%8D%E4%BD%9C-Hash-%E7%B1%BB%E5%9E%8B"><span class="toc-number">1.2.0.6.6.</span> <span class="toc-text">2.3.6 RedisTemplate 操作 Hash 类型</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%89%E3%80%81Redis-%E5%AE%9E%E6%88%98"><span class="toc-number">1.3.</span> <span class="toc-text">三、Redis 实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Redis%E4%B8%8EMySQL%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%EF%BC%9F"><span class="toc-number">1.3.1.</span> <span class="toc-text">3.1 Redis与MySQL双写一致性如何保证？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-1-%E4%B8%80%E8%87%B4%E6%80%A7"><span class="toc-number">1.3.1.1.</span> <span class="toc-text">3.1.1 一致性</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-2-%E4%B8%89%E7%A7%8D%E7%BB%8F%E5%85%B8%E7%9A%84%E7%BC%93%E5%AD%98%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.3.1.2.</span> <span class="toc-text">3.1.2 三种经典的缓存模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-3-%E6%93%8D%E4%BD%9C%E7%BC%93%E5%AD%98%E7%9A%84%E6%97%B6%E5%80%99%EF%BC%8C%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98%E5%91%A2%EF%BC%8C%E8%BF%98%E6%98%AF%E6%9B%B4%E6%96%B0%E7%BC%93%E5%AD%98%EF%BC%9F"><span class="toc-number">1.3.1.3.</span> <span class="toc-text">3.1.3 操作缓存的时候，删除缓存呢，还是更新缓存？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-3-%E5%8F%8C%E5%86%99%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8C%E5%85%88%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE%E5%BA%93%E8%BF%98%E6%98%AF%E5%85%88%E6%93%8D%E4%BD%9C%E7%BC%93%E5%AD%98%EF%BC%9F"><span class="toc-number">1.3.1.4.</span> <span class="toc-text">3.1.3 双写的情况下，先操作数据库还是先操作缓存？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-4-%E7%BC%93%E5%AD%98%E5%BB%B6%E6%97%B6%E5%8F%8C%E5%88%A0"><span class="toc-number">1.3.1.5.</span> <span class="toc-text">3.1.4 缓存延时双删</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-1-5-%E5%88%A0%E9%99%A4%E7%BC%93%E5%AD%98%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6"><span class="toc-number">1.3.1.6.</span> <span class="toc-text">3.1.5 删除缓存重试机制</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%98%9F%E5%88%97-%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6"><span class="toc-number">1.3.1.6.1.</span> <span class="toc-text">队列+重试机制</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E8%AE%A2%E9%98%85binlog%E7%9A%84%E5%90%8C%E6%AD%A5%E6%9C%BA%E5%88%B6"><span class="toc-number">1.3.1.6.2.</span> <span class="toc-text">基于订阅binlog的同步机制</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E3%80%81%E7%A9%BF%E9%80%8F%E3%80%81%E5%87%BB%E7%A9%BF%E3%80%81%E6%B1%A1%E6%9F%93"><span class="toc-number">1.3.2.</span> <span class="toc-text">3.2 缓存雪崩、穿透、击穿、污染</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9"><span class="toc-number">1.3.2.1.</span> <span class="toc-text">3.2.1 缓存雪崩</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-2-%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F"><span class="toc-number">1.3.2.2.</span> <span class="toc-text">3.2.2 缓存穿透</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-3-%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF"><span class="toc-number">1.3.2.3.</span> <span class="toc-text">3.2.3 缓存击穿</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-4-%E7%BC%93%E5%AD%98%E6%B1%A1%E6%9F%93"><span class="toc-number">1.3.2.4.</span> <span class="toc-text">3.2.4 缓存污染</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E6%B7%98%E6%B1%B0%E7%AD%96%E7%95%A5"><span class="toc-number">1.3.2.4.1.</span> <span class="toc-text">缓存淘汰策略</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8"><span class="toc-number">1.3.3.</span> <span class="toc-text">3.3 I&#x2F;O多路复用</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-1-%E6%9C%89%E5%93%AA%E5%87%A0%E7%A7%8DI-O%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.3.3.1.</span> <span class="toc-text">3.3.1 有哪几种I&#x2F;O模型</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-2-Reactor%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.3.3.2.</span> <span class="toc-text">3.3.2 Reactor设计模式</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-3-3-I-O%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8%E6%A8%A1%E5%9D%97"><span class="toc-number">1.3.3.3.</span> <span class="toc-text">3.3.3 I&#x2F;O多路复用模块</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.4.</span> <span class="toc-text">3.4 脑裂问题</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-1-%E5%93%A8%E5%85%B5%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E8%84%91%E8%A3%82"><span class="toc-number">1.3.4.1.</span> <span class="toc-text">3.4.1 哨兵模式下的脑裂</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-4-2-cluster-%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84%E8%84%91%E8%A3%82"><span class="toc-number">1.3.4.2.</span> <span class="toc-text">3.4.2 cluster 模式下的脑裂</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%89%8B%E5%8A%A8%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.4.2.1.</span> <span class="toc-text">手动解决问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%87%AA%E5%8A%A8%E8%A7%A3%E5%86%B3%E9%97%AE%E9%A2%98"><span class="toc-number">1.3.4.2.2.</span> <span class="toc-text">自动解决问题</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%A6%82%E4%BD%95%E9%81%BF%E5%85%8D%E8%84%91%E8%A3%82"><span class="toc-number">1.3.4.2.3.</span> <span class="toc-text">如何避免脑裂</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-%E6%90%AD%E5%BB%BA%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4"><span class="toc-number">1.3.5.</span> <span class="toc-text">3.4 搭建哨兵集群</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9B%9B%E3%80%81Redis%E5%BA%94%E7%94%A8"><span class="toc-number">1.4.</span> <span class="toc-text">四、Redis应用</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">1.4.1.</span> <span class="toc-text">4.1 分布式锁</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E5%BB%B6%E6%97%B6%E9%98%9F%E5%88%97"><span class="toc-number">1.4.2.</span> <span class="toc-text">4.2 延时队列</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-1-%E5%BC%82%E6%AD%A5%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97"><span class="toc-number">1.4.2.1.</span> <span class="toc-text">4.2.1 异步消息队列</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-%E5%BB%B6%E8%BF%9F%E9%98%9F%E5%88%97%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.4.2.2.</span> <span class="toc-text">4.2.2 延迟队列的实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E4%BD%8D%E5%9B%BE"><span class="toc-number">1.4.3.</span> <span class="toc-text">4.3 位图</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-1-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-number">1.4.3.1.</span> <span class="toc-text">4.3.1 基本使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-2-%E7%BB%9F%E8%AE%A1%E5%92%8C%E6%9F%A5%E6%89%BE"><span class="toc-number">1.4.3.2.</span> <span class="toc-text">4.3.2 统计和查找</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-3-3-%E9%AD%94%E6%9C%AF%E6%8C%87%E4%BB%A4-bitfield"><span class="toc-number">1.4.3.3.</span> <span class="toc-text">4.3.3 魔术指令 bitfield</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-4-HyperLogLog"><span class="toc-number">1.4.4.</span> <span class="toc-text">4.4 HyperLogLog</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-1-%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95"><span class="toc-number">1.4.4.1.</span> <span class="toc-text">4.4.1 使用方法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-2-%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86"><span class="toc-number">1.4.4.2.</span> <span class="toc-text">4.4.2 数学原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-4-3-redis%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.4.4.3.</span> <span class="toc-text">4.4.3 redis实现</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-5-%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8"><span class="toc-number">1.4.5.</span> <span class="toc-text">4.5 布隆过滤器</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5-1-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-number">1.4.5.1.</span> <span class="toc-text">4.5.1 基本使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5-2-%E5%8E%9F%E7%90%86"><span class="toc-number">1.4.5.2.</span> <span class="toc-text">4.5.2 原理</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-5-3-%E7%A9%BA%E9%97%B4%E5%8D%A0%E7%94%A8%E4%BC%B0%E8%AE%A1"><span class="toc-number">1.4.5.3.</span> <span class="toc-text">4.5.3 空间占用估计</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-6-%E7%AE%80%E5%8D%95%E9%99%90%E6%B5%81"><span class="toc-number">1.4.6.</span> <span class="toc-text">4.6 简单限流</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-7-%E6%BC%8F%E6%96%97%E9%99%90%E6%B5%81"><span class="toc-number">1.4.7.</span> <span class="toc-text">4.7 漏斗限流</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-8-%E8%BF%91%E6%B0%B4%E6%A5%BC%E5%8F%B0-GeoHash"><span class="toc-number">1.4.8.</span> <span class="toc-text">4.8 近水楼台-GeoHash</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-8-1-%E7%94%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E6%9D%A5%E7%AE%97%E9%99%84%E8%BF%91%E7%9A%84%E4%BA%BA"><span class="toc-number">1.4.8.1.</span> <span class="toc-text">4.8.1 用数据库来算附近的人</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-8-2-GeoHash%E7%AE%97%E6%B3%95"><span class="toc-number">1.4.8.2.</span> <span class="toc-text">4.8.2 GeoHash算法</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-8-3-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8"><span class="toc-number">1.4.8.3.</span> <span class="toc-text">4.8.3 基本使用</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-9-%E5%A4%A7%E6%B5%B7%E6%8D%9E%E9%92%88-scan"><span class="toc-number">1.4.9.</span> <span class="toc-text">4.9 大海捞针 scan</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-9-1-scan-%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8"><span class="toc-number">1.4.9.1.</span> <span class="toc-text">4.9.1 scan 基础使用</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-9-2-%E5%AD%97%E5%85%B8%E7%9A%84%E7%BB%93%E6%9E%84"><span class="toc-number">1.4.9.2.</span> <span class="toc-text">4.9.2 字典的结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-9-3-scan-%E9%81%8D%E5%8E%86%E9%A1%BA%E5%BA%8F"><span class="toc-number">1.4.9.3.</span> <span class="toc-text">4.9.3 scan 遍历顺序</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-9-4-%E5%AD%97%E5%85%B8%E6%89%A9%E5%AE%B9"><span class="toc-number">1.4.9.4.</span> <span class="toc-text">4.9.4 字典扩容</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-9-5-scan-%E8%80%83%E8%99%91-%E6%B8%90%E8%BF%9B%E5%BC%8F-rehash"><span class="toc-number">1.4.9.5.</span> <span class="toc-text">4.9.5 scan 考虑 渐进式 rehash</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-9-6-%E6%9B%B4%E5%A4%9A-scan-%E6%8C%87%E4%BB%A4"><span class="toc-number">1.4.9.6.</span> <span class="toc-text">4.9.6 更多 scan 指令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-9-7-%E5%A4%A7Key%E7%9A%84%E6%89%AB%E6%8F%8F"><span class="toc-number">1.4.9.7.</span> <span class="toc-text">4.9.7 大Key的扫描</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BA%94%E3%80%81Redis-%E5%8E%9F%E7%90%86"><span class="toc-number">1.5.</span> <span class="toc-text">五、Redis 原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E7%BA%BF%E7%A8%8B-IO-%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.5.1.</span> <span class="toc-text">5.1 线程 IO 模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E9%80%9A%E4%BF%A1%E5%8D%8F%E8%AE%AE"><span class="toc-number">1.5.2.</span> <span class="toc-text">5.2 通信协议</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-1-RESP-%EF%BC%88Redis-Serialization-Protocol%EF%BC%89"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">5.2.1 RESP （Redis Serialization Protocol）</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-2-2-%E5%B0%8F%E7%BB%93"><span class="toc-number">1.5.2.2.</span> <span class="toc-text">5.2.2 小结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">1.5.3.</span> <span class="toc-text">5.3 持久化</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-1-%E5%BF%AB%E7%85%A7"><span class="toc-number">1.5.3.1.</span> <span class="toc-text">5.3.1 快照</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-2-AOF%E7%9A%84%E5%86%99%E5%85%A5"><span class="toc-number">1.5.3.2.</span> <span class="toc-text">5.3.2 AOF的写入</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4%E4%BC%A0%E6%92%AD"><span class="toc-number">1.5.3.2.1.</span> <span class="toc-text">命令传播</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%BC%93%E5%AD%98%E8%BF%BD%E5%8A%A0"><span class="toc-number">1.5.3.2.2.</span> <span class="toc-text">缓存追加</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%96%87%E4%BB%B6%E5%86%99%E5%85%A5%E5%92%8C%E4%BF%9D%E5%AD%98"><span class="toc-number">1.5.3.2.3.</span> <span class="toc-text">文件写入和保存</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#AOF-%E4%BF%9D%E5%AD%98%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.5.3.2.4.</span> <span class="toc-text">AOF 保存模式</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-3-AOF-%E6%96%87%E4%BB%B6%E7%9A%84%E8%AF%BB%E5%8F%96%E5%92%8C%E6%95%B0%E6%8D%AE%E8%BF%98%E5%8E%9F"><span class="toc-number">1.5.3.3.</span> <span class="toc-text">5.3.3 AOF 文件的读取和数据还原</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-4-AOF-%E9%87%8D%E5%86%99"><span class="toc-number">1.5.3.4.</span> <span class="toc-text">5.3.4 AOF 重写</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#AOF-%E9%87%8D%E5%86%99%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.5.3.4.1.</span> <span class="toc-text">AOF 重写的实现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#AOF-%E5%90%8E%E5%8F%B0%E9%87%8D%E5%86%99"><span class="toc-number">1.5.3.4.2.</span> <span class="toc-text">AOF 后台重写</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-3-5-%E6%B7%B7%E5%90%88%E6%8C%81%E4%B9%85%E5%8C%96"><span class="toc-number">1.5.3.5.</span> <span class="toc-text">5.3.5 混合持久化</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E7%AE%A1%E9%81%93"><span class="toc-number">1.5.4.</span> <span class="toc-text">5.4 管道</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AE%A1%E9%81%93%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95"><span class="toc-number">1.5.4.0.1.</span> <span class="toc-text">管道压力测试</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%AE%A1%E9%81%93%E6%9C%AC%E8%B4%A8"><span class="toc-number">1.5.4.0.2.</span> <span class="toc-text">管道本质</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-5-%E4%BA%8B%E5%8A%A1"><span class="toc-number">1.5.5.</span> <span class="toc-text">5.5 事务</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-5-1-%E4%BA%8B%E5%8A%A1%E6%B5%81%E7%A8%8B"><span class="toc-number">1.5.5.1.</span> <span class="toc-text">5.5.1 事务流程</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%BC%80%E5%A7%8B%E4%BA%8B%E5%8A%A1"><span class="toc-number">1.5.5.1.1.</span> <span class="toc-text">开始事务</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%91%BD%E4%BB%A4%E5%85%A5%E9%98%9F"><span class="toc-number">1.5.5.1.2.</span> <span class="toc-text">命令入队</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%89%A7%E8%A1%8C%E4%BA%8B%E5%8A%A1"><span class="toc-number">1.5.5.1.3.</span> <span class="toc-text">执行事务</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-5-2-%E4%BA%8B%E5%8A%A1%E9%87%8C%E7%9A%84%E5%91%BD%E4%BB%A4"><span class="toc-number">1.5.5.2.</span> <span class="toc-text">5.5.2 事务里的命令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-5-3-DISCARD-%E3%80%81-MULTI-%E5%92%8C-WATCH-%E5%91%BD%E4%BB%A4"><span class="toc-number">1.5.5.3.</span> <span class="toc-text">5.5.3 DISCARD 、 MULTI 和 WATCH 命令</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-5-4-%E5%B8%A6-WATCH-%E7%9A%84%E4%BA%8B%E5%8A%A1"><span class="toc-number">1.5.5.4.</span> <span class="toc-text">5.5.4 带 WATCH 的事务</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#WATCH-%E5%91%BD%E4%BB%A4%E7%9A%84%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.5.5.4.1.</span> <span class="toc-text">WATCH 命令的实现</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#WATCH-%E7%9A%84%E8%A7%A6%E5%8F%91"><span class="toc-number">1.5.5.4.2.</span> <span class="toc-text">WATCH 的触发</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-5-6-%E4%BA%8B%E5%8A%A1%E7%9A%84-ACID-%E6%80%A7%E8%B4%A8"><span class="toc-number">1.5.5.5.</span> <span class="toc-text">5.5.6 事务的 ACID 性质</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8E%9F%E5%AD%90%E6%80%A7%EF%BC%88Atomicity%EF%BC%89"><span class="toc-number">1.5.5.5.1.</span> <span class="toc-text">原子性（Atomicity）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%80%E8%87%B4%E6%80%A7%EF%BC%88Consistency%EF%BC%89"><span class="toc-number">1.5.5.5.2.</span> <span class="toc-text">一致性（Consistency）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%9A%94%E7%A6%BB%E6%80%A7%EF%BC%88Isolation%EF%BC%89"><span class="toc-number">1.5.5.5.3.</span> <span class="toc-text">隔离性（Isolation）</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E6%8C%81%E4%B9%85%E6%80%A7%EF%BC%88Durability%EF%BC%89"><span class="toc-number">1.5.5.5.4.</span> <span class="toc-text">持久性（Durability）</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-5-7-%E5%B0%8F%E7%BB%93"><span class="toc-number">1.5.5.6.</span> <span class="toc-text">5.5.7 小结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-6-%E8%AE%A2%E9%98%85%E4%B8%8E%E5%8F%91%E5%B8%83"><span class="toc-number">1.5.6.</span> <span class="toc-text">5.6 订阅与发布</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-6-1-%E9%A2%91%E9%81%93%E7%9A%84%E8%AE%A2%E9%98%85%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%8F%91%E9%80%81"><span class="toc-number">1.5.6.1.</span> <span class="toc-text">5.6.1 频道的订阅与信息发送</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%A2%E9%98%85%E9%A2%91%E9%81%93"><span class="toc-number">1.5.6.1.1.</span> <span class="toc-text">订阅频道</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E4%BF%A1%E6%81%AF%E5%88%B0%E9%A2%91%E9%81%93"><span class="toc-number">1.5.6.1.2.</span> <span class="toc-text">发送信息到频道</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%80%80%E8%AE%A2%E9%A2%91%E9%81%93"><span class="toc-number">1.5.6.1.3.</span> <span class="toc-text">退订频道</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-6-2-%E6%A8%A1%E5%BC%8F%E7%9A%84%E8%AE%A2%E9%98%85%E4%B8%8E%E4%BF%A1%E6%81%AF%E5%8F%91%E9%80%81"><span class="toc-number">1.5.6.2.</span> <span class="toc-text">5.6.2 模式的订阅与信息发送</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%A2%E9%98%85%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.5.6.2.1.</span> <span class="toc-text">订阅模式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%8F%91%E9%80%81%E4%BF%A1%E6%81%AF%E5%88%B0%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.5.6.2.2.</span> <span class="toc-text">发送信息到模式</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E9%80%80%E8%AE%A2%E6%A8%A1%E5%BC%8F"><span class="toc-number">1.5.6.2.3.</span> <span class="toc-text">退订模式</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-6-3-%E5%B0%8F%E7%BB%93"><span class="toc-number">1.5.6.3.</span> <span class="toc-text">5.6.3 小结</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-7-Redis%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E2%80%94%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6"><span class="toc-number">1.5.7.</span> <span class="toc-text">5.7 Redis集群模式—主从复制</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-7-1-%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%A6%82%E8%BF%B0"><span class="toc-number">1.5.7.1.</span> <span class="toc-text">5.7.1 主从复制概述</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-7-2-%E5%85%A8%E9%87%8F%E5%A4%8D%E5%88%B6"><span class="toc-number">1.5.7.2.</span> <span class="toc-text">5.7.2 全量复制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-7-3-%E5%A2%9E%E9%87%8F%E5%A4%8D%E5%88%B6"><span class="toc-number">1.5.7.3.</span> <span class="toc-text">5.7.3 增量复制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-7-4-%E6%9B%B4%E5%A4%9A%E7%90%86%E8%A7%A3"><span class="toc-number">1.5.7.4.</span> <span class="toc-text">5.7.4 更多理解</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#1-%E5%BD%93%E4%B8%BB%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8D%E8%BF%9B%E8%A1%8C%E6%8C%81%E4%B9%85%E5%8C%96%E6%97%B6-%E5%A4%8D%E5%88%B6%E7%9A%84%E5%AE%89%E5%85%A8%E6%80%A7"><span class="toc-number">1.5.7.4.1.</span> <span class="toc-text">1.当主服务器不进行持久化时 复制的安全性</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#2-%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%BB%E4%BB%8E%E5%85%A8%E9%87%8F%E5%A4%8D%E5%88%B6%E4%BD%BF%E7%94%A8-RDB-%E8%80%8C%E4%B8%8D%E4%BD%BF%E7%94%A8-AOF%EF%BC%9F"><span class="toc-number">1.5.7.4.2.</span> <span class="toc-text">2.为什么主从全量复制使用 RDB 而不使用 AOF？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#3-%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%97%A0%E7%A3%81%E7%9B%98%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%BC%8F%EF%BC%9F"><span class="toc-number">1.5.7.4.3.</span> <span class="toc-text">3.为什么有无磁盘复制模式？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#4-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E6%9C%89-%E4%BB%8E%E5%BA%93%E7%9A%84%E4%BB%8E%E5%BA%93%E7%9A%84%E8%AE%BE%E8%AE%A1%EF%BC%9F"><span class="toc-number">1.5.7.4.4.</span> <span class="toc-text">4.为什么还有 从库的从库的设计？</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#5-%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E5%8F%8A%E5%85%B6%E4%B8%AD%E7%9A%84%E9%97%AE%E9%A2%98"><span class="toc-number">1.5.7.4.5.</span> <span class="toc-text">5.读写分离及其中的问题</span></a></li></ol></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-8-Redis%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F%E2%80%94-%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6%EF%BC%88Redis-Sentinel%EF%BC%89"><span class="toc-number">1.5.8.</span> <span class="toc-text">5.8 Redis集群模式— 哨兵机制（Redis Sentinel）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-8-1-%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E7%9A%84%E6%90%AD%E5%BB%BA"><span class="toc-number">1.5.8.1.</span> <span class="toc-text">5.8.1 哨兵集群的搭建</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-8-2-%E5%93%A8%E5%85%B5%E7%9B%91%E6%8E%A7-Redis-%E5%BA%93"><span class="toc-number">1.5.8.2.</span> <span class="toc-text">5.8.2 哨兵监控 Redis 库</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-8-3-%E4%B8%BB%E5%BA%93%E4%B8%8B%E7%BA%BF%E7%9A%84%E5%88%A4%E5%AE%9A"><span class="toc-number">1.5.8.3.</span> <span class="toc-text">5.8.3 主库下线的判定</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-8-4-%E5%93%A8%E5%85%B5%E9%9B%86%E7%BE%A4%E7%9A%84%E9%80%89%E4%B8%BE"><span class="toc-number">1.5.8.4.</span> <span class="toc-text">5.8.4 哨兵集群的选举</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-8-5-%E6%96%B0%E4%B8%BB%E5%BA%93%E7%9A%84%E9%80%89%E5%87%BA%E3%80%81%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="toc-number">1.5.8.5.</span> <span class="toc-text">5.8.5 新主库的选出、故障转移</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-9-Redis%E9%9B%86%E7%BE%A4%E6%A8%A1%E5%BC%8F-Redis-Cluster%EF%BC%88%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%EF%BC%89"><span class="toc-number">1.5.9.</span> <span class="toc-text">5.9 Redis集群模式-Redis Cluster（高可用集群）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#5-9-1-%E5%93%88%E5%B8%8C%E6%A7%BD"><span class="toc-number">1.5.9.1.</span> <span class="toc-text">5.9.1 哈希槽</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-9-2-Key-Hash-Tags"><span class="toc-number">1.5.9.2.</span> <span class="toc-text">5.9.2 Key Hash Tags</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-9-3-%E8%AF%B7%E6%B1%82%E9%87%8D%E5%AE%9A%E5%90%91"><span class="toc-number">1.5.9.3.</span> <span class="toc-text">5.9.3 请求重定向</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#MOVED-%E9%87%8D%E5%AE%9A%E5%90%91"><span class="toc-number">1.5.9.3.1.</span> <span class="toc-text">MOVED 重定向</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#ASK-%E9%87%8D%E5%AE%9A%E5%90%91"><span class="toc-number">1.5.9.3.2.</span> <span class="toc-text">ASK 重定向</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E4%B8%A4%E8%80%85%E7%9A%84%E5%8C%BA%E5%88%AB"><span class="toc-number">1.5.9.3.3.</span> <span class="toc-text">两者的区别</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-9-4-%E6%95%85%E9%9A%9C%E8%BD%AC%E7%A7%BB"><span class="toc-number">1.5.9.4.</span> <span class="toc-text">5.9.4 故障转移</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-9-5-%E8%84%91%E8%A3%82%E9%97%AE%E9%A2%98"><span class="toc-number">1.5.9.5.</span> <span class="toc-text">5.9.5 脑裂问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-9-6-%E7%8A%B6%E6%80%81%E6%A3%80%E6%B5%8B%E5%8F%8A%E7%BB%B4%E6%8A%A4"><span class="toc-number">1.5.9.6.</span> <span class="toc-text">5.9.6 状态检测及维护</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#Gossip%E5%8D%8F%E8%AE%AE"><span class="toc-number">1.5.9.6.1.</span> <span class="toc-text">Gossip协议</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#Gossip%E5%8D%8F%E8%AE%AE%E7%9A%84%E4%BD%BF%E7%94%A8"><span class="toc-number">1.5.9.6.2.</span> <span class="toc-text">Gossip协议的使用</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8EGossip-%E5%8D%8F%E8%AE%AE%E7%9A%84%E6%95%85%E9%9A%9C%E6%A3%80%E6%B5%8B"><span class="toc-number">1.5.9.6.3.</span> <span class="toc-text">基于Gossip 协议的故障检测</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-9-7-%E9%80%9A%E8%AE%AF%E7%8A%B6%E6%80%81%E5%92%8C%E7%BB%B4%E6%8A%A4"><span class="toc-number">1.5.9.7.</span> <span class="toc-text">5.9.7 通讯状态和维护</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-9-8-%E6%89%A9%E5%AE%B9%E3%80%81%E7%BC%A9%E5%AE%B9"><span class="toc-number">1.5.9.8.</span> <span class="toc-text">5.9.8 扩容、缩容</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-9-9-Write-Safety-%E5%88%86%E6%9E%90"><span class="toc-number">1.5.9.9.</span> <span class="toc-text">5.9.9 Write Safety 分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#5-9-10-availability-%E5%88%86%E6%9E%90"><span class="toc-number">1.5.9.10.</span> <span class="toc-text">5.9.10 availability 分析</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#replicas-migration-%E5%8A%9F%E8%83%BD"><span class="toc-number">1.5.9.10.1.</span> <span class="toc-text">replicas migration 功能</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AD%E3%80%81Redisson"><span class="toc-number">1.6.</span> <span class="toc-text">六、Redisson</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">1.6.1.</span> <span class="toc-text">6.1 分布式锁</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#6-1-1-%E5%B8%B8%E8%A7%81redis-%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81"><span class="toc-number">1.6.1.1.</span> <span class="toc-text">6.1.1 常见redis 分布式锁</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#6-1-2-Redisson-%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">1.6.1.2.</span> <span class="toc-text">6.1.2 Redisson 的解决方案</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%83%E3%80%81Redis%E5%BA%94%E7%94%A8%E9%97%AE%E9%A2%98"><span class="toc-number">1.7.</span> <span class="toc-text">七、Redis应用问题</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-Redis%E4%B8%8EMySQL%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%EF%BC%9F"><span class="toc-number">1.7.1.</span> <span class="toc-text">7.1 Redis与MySQL双写一致性如何保证？</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link"><span class="toc-number">1.7.1.1.</span> <span class="toc-text"></span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-Redis-%E7%9A%84%E5%A4%A7key%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%EF%BC%9F"><span class="toc-number">1.7.2.</span> <span class="toc-text">7.2 Redis 的大key如何处理？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E6%8C%81%E4%B9%85%E5%8C%96%E7%AD%96%E7%95%A5%EF%BC%9F"><span class="toc-number">1.7.3.</span> <span class="toc-text">7.3 如何选择持久化策略？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%85%AB%E3%80%81Redis-%E6%B6%89%E5%8F%8A%E7%9A%84%E7%AE%97%E6%B3%95"><span class="toc-number">1.8.</span> <span class="toc-text">八、Redis 涉及的算法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%B8%80%E8%87%B4%E6%80%A7Hash"><span class="toc-number">1.8.1.</span> <span class="toc-text">1.一致性Hash</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-1-%E9%97%AE%E9%A2%98%E7%9A%84%E7%94%B1%E6%9D%A5"><span class="toc-number">1.8.1.1.</span> <span class="toc-text">1.1 问题的由来</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-2-%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%EF%BC%9F"><span class="toc-number">1.8.1.2.</span> <span class="toc-text">1.2 直接使用哈希算法？</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-%E4%BD%BF%E7%94%A8%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C%E7%AE%97%E6%B3%95%E6%9C%89%E4%BB%80%E4%B9%88%E9%97%AE%E9%A2%98"><span class="toc-number">1.8.1.3.</span> <span class="toc-text">1.3 使用一致性哈希算法有什么问题?</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-3-%E9%80%9A%E8%BF%87%E8%99%9A%E6%8B%9F%E8%8A%82%E7%82%B9%E6%8F%90%E9%AB%98%E5%9D%87%E8%A1%A1%E5%BA%A6"><span class="toc-number">1.8.1.4.</span> <span class="toc-text">1.3 通过虚拟节点提高均衡度</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#1-4-%E6%80%BB%E7%BB%93"><span class="toc-number">1.8.1.5.</span> <span class="toc-text">1.4 总结</span></a></li></ol></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="anzhiyufont anzhiyu-icon-history"></i><span>最近发布</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/06/12/Linux%E5%86%85%E6%A0%B8%E7%9A%84netfilter%E8%AF%A6%E8%A7%A31/" title="Linux内核的netfilter详解"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226224350520.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Linux内核的netfilter详解"/></a><div class="content"><a class="title" href="/2025/06/12/Linux%E5%86%85%E6%A0%B8%E7%9A%84netfilter%E8%AF%A6%E8%A7%A31/" title="Linux内核的netfilter详解">Linux内核的netfilter详解</a><time datetime="2025-06-11T16:00:00.000Z" title="发表于 2025-06-12 00:00:00">2025-06-12</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/07/JDK%20%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%87%8C%E7%9C%9F%E7%9A%84%E5%8C%BA%E5%88%86%20%E6%A0%B8%E5%BF%83%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%9D%9E%E6%A0%B8%E5%BF%83%E7%BA%BF%E7%A8%8B%E5%90%97%EF%BC%9F/" title="JDK 线程池里真的区分 核心线程与非核心线程吗？"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://cdn.jsdelivr.net/gh/kongxiaoran/image-repo/blog20241226224350520.jpeg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="JDK 线程池里真的区分 核心线程与非核心线程吗？"/></a><div class="content"><a class="title" href="/2025/06/07/JDK%20%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%87%8C%E7%9C%9F%E7%9A%84%E5%8C%BA%E5%88%86%20%E6%A0%B8%E5%BF%83%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%9D%9E%E6%A0%B8%E5%BF%83%E7%BA%BF%E7%A8%8B%E5%90%97%EF%BC%9F/" title="JDK 线程池里真的区分 核心线程与非核心线程吗？">JDK 线程池里真的区分 核心线程与非核心线程吗？</a><time datetime="2025-06-06T16:00:00.000Z" title="发表于 2025-06-07 00:00:00">2025-06-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/07/MySQL%20%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E5%9C%BA%E6%99%AF/" title="MySQL 索引失效场景"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250607204936123.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="MySQL 索引失效场景"/></a><div class="content"><a class="title" href="/2025/06/07/MySQL%20%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E5%9C%BA%E6%99%AF/" title="MySQL 索引失效场景">MySQL 索引失效场景</a><time datetime="2025-06-06T16:00:00.000Z" title="发表于 2025-06-07 00:00:00">2025-06-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/07/Redis%20%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="Redis 底层数据结构"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250607204045262.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Redis 底层数据结构"/></a><div class="content"><a class="title" href="/2025/06/07/Redis%20%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/" title="Redis 底层数据结构">Redis 底层数据结构</a><time datetime="2025-06-06T16:00:00.000Z" title="发表于 2025-06-07 00:00:00">2025-06-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/06/07/%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92%20%E7%9C%9F%E7%9A%84%E6%9C%89%E7%82%B9%E9%98%B4/" title="指令重排 真的有点阴"><img src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/20250607203155245.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="指令重排 真的有点阴"/></a><div class="content"><a class="title" href="/2025/06/07/%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92%20%E7%9C%9F%E7%9A%84%E6%9C%89%E7%82%B9%E9%98%B4/" title="指令重排 真的有点阴">指令重排 真的有点阴</a><time datetime="2025-06-06T16:00:00.000Z" title="发表于 2025-06-07 00:00:00">2025-06-07</time></div></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"></div><div id="footer-bar"><div class="footer-bar-links"><div class="footer-bar-left"><div id="footer-bar-tips"><div class="copyright">&copy;2024 - 2025 By <a class="footer-bar-link" href="/" title="XR" target="_blank">XR</a></div></div><div id="footer-type-tips"></div></div><div class="footer-bar-right"><a class="footer-bar-link" target="_blank" rel="noopener" href="https://github.com/anzhiyu-c/hexo-theme-anzhiyu" title="主题">主题</a></div></div></div></footer></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="sidebar-site-data site-data is-center"><a href="/archives/" title="archive"><div class="headline">文章</div><div class="length-num">9</div></a><a href="/tags/" title="tag"><div class="headline">标签</div><div class="length-num">0</div></a><a href="/categories/" title="category"><div class="headline">分类</div><div class="length-num">3</div></a></div><span class="sidebar-menu-item-title">功能</span><div class="sidebar-menu-item"><a class="darkmode_switchbutton menu-child" href="javascript:void(0);" title="显示模式"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span>显示模式</span></a></div><div class="back-menu-list-groups"><div class="back-menu-list-group"><div class="back-menu-list-title">网页</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://blog.anheyu.com/" title="博客"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="/img/favicon.ico" alt="博客"/><span class="back-menu-item-text">博客</span></a></div></div><div class="back-menu-list-group"><div class="back-menu-list-title">项目</div><div class="back-menu-list"><a class="back-menu-item" target="_blank" rel="noopener" href="https://image.anheyu.com/" title="安知鱼图床"><img class="back-menu-item-icon" src= "data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" onerror="this.onerror=null,this.src=&quot;/img/404.jpg&quot;" data-lazy-src="https://image.anheyu.com/favicon.ico" alt="安知鱼图床"/><span class="back-menu-item-text">安知鱼图床</span></a></div></div></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 文章</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/archives/"><i class="anzhiyufont anzhiyu-icon-box-archive faa-tada" style="font-size: 0.9em;"></i><span> 隧道</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/categories/"><i class="anzhiyufont anzhiyu-icon-shapes faa-tada" style="font-size: 0.9em;"></i><span> 分类</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags faa-tada" style="font-size: 0.9em;"></i><span> 标签</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 友链</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/link/"><i class="anzhiyufont anzhiyu-icon-link faa-tada" style="font-size: 0.9em;"></i><span> 友人帐</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/fcircle/"><i class="anzhiyufont anzhiyu-icon-artstation faa-tada" style="font-size: 0.9em;"></i><span> 朋友圈</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/comments/"><i class="anzhiyufont anzhiyu-icon-envelope faa-tada" style="font-size: 0.9em;"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 我的</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/music/"><i class="anzhiyufont anzhiyu-icon-music faa-tada" style="font-size: 0.9em;"></i><span> 音乐馆</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/bangumis/"><i class="anzhiyufont anzhiyu-icon-bilibili faa-tada" style="font-size: 0.9em;"></i><span> 追番页</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/album/"><i class="anzhiyufont anzhiyu-icon-images faa-tada" style="font-size: 0.9em;"></i><span> 相册集</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/air-conditioner/"><i class="anzhiyufont anzhiyu-icon-fan faa-tada" style="font-size: 0.9em;"></i><span> 小空调</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><span> 关于</span></a><ul class="menus_item_child"><li><a class="site-page child faa-parent animated-hover" href="/about/"><i class="anzhiyufont anzhiyu-icon-paper-plane faa-tada" style="font-size: 0.9em;"></i><span> 关于本人</span></a></li><li><a class="site-page child faa-parent animated-hover" href="/essay/"><i class="anzhiyufont anzhiyu-icon-lightbulb faa-tada" style="font-size: 0.9em;"></i><span> 闲言碎语</span></a></li><li><a class="site-page child faa-parent animated-hover" href="javascript:toRandomPost()"><i class="anzhiyufont anzhiyu-icon-shoe-prints1 faa-tada" style="font-size: 0.9em;"></i><span> 随便逛逛</span></a></li></ul></div></div><span class="sidebar-menu-item-title">标签</span></div></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="anzhiyufont anzhiyu-icon-book-open"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="anzhiyufont anzhiyu-icon-arrows-left-right"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="anzhiyufont anzhiyu-icon-gear"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="anzhiyufont anzhiyu-icon-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="anzhiyufont anzhiyu-icon-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></button></div></div><div id="nav-music"><a id="nav-music-hoverTips" onclick="anzhiyu.musicToggle()" accesskey="m">播放音乐</a><div id="console-music-bg"></div><meting-js id="8152976493" server="netease" type="playlist" mutex="true" preload="none" theme="var(--anzhiyu-main)" data-lrctype="0" order="random" volume="0.7"></meting-js></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="anzhiyufont anzhiyu-icon-xmark"></i></button></nav><div class="is-center" id="loading-database"><i class="anzhiyufont anzhiyu-icon-spinner anzhiyu-pulse-icon"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div id="rightMenu"><div class="rightMenu-group rightMenu-small"><div class="rightMenu-item" id="menu-backward"><i class="anzhiyufont anzhiyu-icon-arrow-left"></i></div><div class="rightMenu-item" id="menu-forward"><i class="anzhiyufont anzhiyu-icon-arrow-right"></i></div><div class="rightMenu-item" id="menu-refresh"><i class="anzhiyufont anzhiyu-icon-arrow-rotate-right" style="font-size: 1rem;"></i></div><div class="rightMenu-item" id="menu-top"><i class="anzhiyufont anzhiyu-icon-arrow-up"></i></div></div><div class="rightMenu-group rightMenu-line rightMenuPlugin"><div class="rightMenu-item" id="menu-copytext"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制选中文本</span></div><div class="rightMenu-item" id="menu-pastetext"><i class="anzhiyufont anzhiyu-icon-paste"></i><span>粘贴文本</span></div><a class="rightMenu-item" id="menu-commenttext"><i class="anzhiyufont anzhiyu-icon-comment-medical"></i><span>引用到评论</span></a><div class="rightMenu-item" id="menu-newwindow"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开</span></div><div class="rightMenu-item" id="menu-copylink"><i class="anzhiyufont anzhiyu-icon-link"></i><span>复制链接地址</span></div><div class="rightMenu-item" id="menu-copyimg"><i class="anzhiyufont anzhiyu-icon-images"></i><span>复制此图片</span></div><div class="rightMenu-item" id="menu-downloadimg"><i class="anzhiyufont anzhiyu-icon-download"></i><span>下载此图片</span></div><div class="rightMenu-item" id="menu-newwindowimg"><i class="anzhiyufont anzhiyu-icon-window-restore"></i><span>新窗口打开图片</span></div><div class="rightMenu-item" id="menu-search"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>站内搜索</span></div><div class="rightMenu-item" id="menu-searchBaidu"><i class="anzhiyufont anzhiyu-icon-magnifying-glass"></i><span>百度搜索</span></div><div class="rightMenu-item" id="menu-music-toggle"><i class="anzhiyufont anzhiyu-icon-play"></i><span>播放音乐</span></div><div class="rightMenu-item" id="menu-music-back"><i class="anzhiyufont anzhiyu-icon-backward"></i><span>切换到上一首</span></div><div class="rightMenu-item" id="menu-music-forward"><i class="anzhiyufont anzhiyu-icon-forward"></i><span>切换到下一首</span></div><div class="rightMenu-item" id="menu-music-playlist" onclick="window.open(&quot;https://y.qq.com/n/ryqq/playlist/8802438608&quot;, &quot;_blank&quot;);" style="display: none;"><i class="anzhiyufont anzhiyu-icon-radio"></i><span>查看所有歌曲</span></div><div class="rightMenu-item" id="menu-music-copyMusicName"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制歌名</span></div></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item menu-link" id="menu-randomPost"><i class="anzhiyufont anzhiyu-icon-shuffle"></i><span>随便逛逛</span></a><a class="rightMenu-item menu-link" href="/categories/"><i class="anzhiyufont anzhiyu-icon-cube"></i><span>博客分类</span></a><a class="rightMenu-item menu-link" href="/tags/"><i class="anzhiyufont anzhiyu-icon-tags"></i><span>文章标签</span></a></div><div class="rightMenu-group rightMenu-line rightMenuOther"><a class="rightMenu-item" id="menu-copy" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-copy"></i><span>复制地址</span></a><a class="rightMenu-item" id="menu-commentBarrage" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-message"></i><span class="menu-commentBarrage-text">关闭热评</span></a><a class="rightMenu-item" id="menu-darkmode" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-circle-half-stroke"></i><span class="menu-darkmode-text">深色模式</span></a><a class="rightMenu-item" id="menu-translate" href="javascript:void(0);"><i class="anzhiyufont anzhiyu-icon-language"></i><span>轉為繁體</span></a></div></div><div id="rightmenu-mask"></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.cbd.int/@fancyapps/ui@5.0.28/dist/fancybox/fancybox.umd.js"></script><script src="https://cdn.cbd.int/instant.page@5.2.0/instantpage.js" type="module"></script><script src="https://cdn.cbd.int/vanilla-lazyload@17.8.5/dist/lazyload.iife.min.js"></script><script src="https://cdn.cbd.int/node-snackbar@0.1.16/dist/snackbar.min.js"></script><canvas id="universe"></canvas><script async src="https://npm.elemecdn.com/anzhiyu-theme-static@1.0.0/dark/dark.js"></script><script>// 消除控制台打印
var HoldLog = console.log;
console.log = function () {};
let now1 = new Date();
queueMicrotask(() => {
  const Log = function () {
    HoldLog.apply(console, arguments);
  }; //在恢复前输出日志
  const grt = new Date("12/26/2024 00:00:00"); //此处修改你的建站时间或者网站上线时间
  now1.setTime(now1.getTime() + 250);
  const days = (now1 - grt) / 1000 / 60 / 60 / 24;
  const dnum = Math.floor(days);
  const ascll = [
    `欢迎使用安知鱼!`,
    `生活明朗, 万物可爱`,
    `
        
       █████╗ ███╗   ██╗███████╗██╗  ██╗██╗██╗   ██╗██╗   ██╗
      ██╔══██╗████╗  ██║╚══███╔╝██║  ██║██║╚██╗ ██╔╝██║   ██║
      ███████║██╔██╗ ██║  ███╔╝ ███████║██║ ╚████╔╝ ██║   ██║
      ██╔══██║██║╚██╗██║ ███╔╝  ██╔══██║██║  ╚██╔╝  ██║   ██║
      ██║  ██║██║ ╚████║███████╗██║  ██║██║   ██║   ╚██████╔╝
      ╚═╝  ╚═╝╚═╝  ╚═══╝╚══════╝╚═╝  ╚═╝╚═╝   ╚═╝    ╚═════╝
        
        `,
    "已上线",
    dnum,
    "天",
    "©2024 By 安知鱼 V1.6.14",
  ];
  const ascll2 = [`NCC2-036`, `调用前置摄像头拍照成功，识别为【小笨蛋】.`, `Photo captured: `, `🤪`];

  setTimeout(
    Log.bind(
      console,
      `\n%c${ascll[0]} %c ${ascll[1]} %c ${ascll[2]} %c${ascll[3]}%c ${ascll[4]}%c ${ascll[5]}\n\n%c ${ascll[6]}\n`,
      "color:#425AEF",
      "",
      "color:#425AEF",
      "color:#425AEF",
      "",
      "color:#425AEF",
      ""
    )
  );
  setTimeout(
    Log.bind(
      console,
      `%c ${ascll2[0]} %c ${ascll2[1]} %c \n${ascll2[2]} %c\n${ascll2[3]}\n`,
      "color:white; background-color:#4fd953",
      "",
      "",
      'background:url("https://npm.elemecdn.com/anzhiyu-blog@1.1.6/img/post/common/tinggge.gif") no-repeat;font-size:450%'
    )
  );

  setTimeout(Log.bind(console, "%c WELCOME %c 你好，小笨蛋.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(
      console,
      "%c ⚡ Powered by 安知鱼 %c 你正在访问 XR 的博客.",
      "color:white; background-color:#f0ad4e",
      ""
    )
  );

  setTimeout(Log.bind(console, "%c W23-12 %c 你已打开控制台.", "color:white; background-color:#4f90d9", ""));

  setTimeout(
    console.warn.bind(console, "%c S013-782 %c 你现在正处于监控中.", "color:white; background-color:#d9534f", "")
  );
});</script><script async src="/anzhiyu/random.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>(() => {
  const initValine = () => {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'cbSQtAqs68yENzUQ5wpQK826-MdYXbMMI',
      appKey: 'MR93sqmbPdh7Zm1bZzjXNvlm',
      avatar: 'mp',
      serverURLs: 'https://cbsqtaqs.api.lncldglobal.com',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: false
    }, null))
  }

  const loadValine = async () => {
    if (typeof Valine === 'function') initValine()
    else {
      await getScript('https://cdn.cbd.int/valine@1.5.1/dist/Valine.min.js')
      initValine()
    }
  }

  if ('Valine' === 'Valine' || !false) {
    if (false) anzhiyu.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><input type="hidden" name="page-type" id="page-type" value="post"></div><script src="https://cdn.cbd.int/blueimp-md5@2.19.0/js/md5.min.js"></script><script>window.addEventListener('load', () => {
  const changeContent = (content) => {
    if (content === '') return content

    content = content.replace(/<img.*?src="(.*?)"?[^\>]+>/ig, '[图片]') // replace image link
    content = content.replace(/<a[^>]+?href=["']?([^"']+)["']?[^>]*>([^<]+)<\/a>/gi, '[链接]') // replace url
    content = content.replace(/<pre><code>.*?<\/pre>/gi, '[代码]') // replace code
    content = content.replace(/<[^>]+>/g,"") // remove html tag

    if (content.length > 150) {
      content = content.substring(0,150) + '...'
    }
    return content
  }

  const getIcon = (icon, mail) => {
    if (icon) return icon
    let defaultIcon = '?d=mp'
    let iconUrl = `https://gravatar.loli.net/avatar/${md5(mail.toLowerCase()) + defaultIcon}`
    return iconUrl
  }

  const generateHtml = array => {
    let result = ''

    if (array.length) {
      for (let i = 0; i < array.length; i++) {
        result += '<div class=\'aside-list-item\'>'

        if (true) {
          const name = 'data-lazy-src'
          result += `<a href='${array[i].url}' class='thumbnail'><img ${name}='${array[i].avatar}' alt='${array[i].nick}'></a>`
        }

        result += `<div class='content'>
        <a class='comment' href='${array[i].url}' title='${array[i].content}'>${array[i].content}</a>
        <div class='name'><span>${array[i].nick} / </span><time datetime="${array[i].date}">${anzhiyu.diffDate(array[i].date, true)}</time></div>
        </div></div>`
      }
    } else {
      result += '没有评论'
    }

    let $dom = document.querySelector('#card-newest-comments .aside-list')
    $dom && ($dom.innerHTML= result)
    window.lazyLoadInstance && window.lazyLoadInstance.update()
    window.pjax && window.pjax.refresh($dom)
  }

  const getComment = () => {
    const serverURL = 'https://cbsqtaqs.api.lncldglobal.com'

    var settings = {
      "method": "GET",
      "headers": {
        "X-LC-Id": 'cbSQtAqs68yENzUQ5wpQK826-MdYXbMMI',
        "X-LC-Key": 'MR93sqmbPdh7Zm1bZzjXNvlm',
        "Content-Type": "application/json"
      },
    }

    fetch(`${serverURL}/1.1/classes/Comment?limit=6&order=-createdAt`,settings)
      .then(response => response.json())
      .then(data => {
        const valineArray = data.results.map(function (e) {
          return {
            'avatar': getIcon(e.QQAvatar, e.mail),
            'content': changeContent(e.comment),
            'nick': e.nick,
            'url': e.url + '#' + e.objectId,
            'date': e.updatedAt,
          }
        })
        saveToLocal.set('valine-newest-comments', JSON.stringify(valineArray), 10/(60*24))
        generateHtml(valineArray)
      }).catch(e => {
        const $dom = document.querySelector('#card-newest-comments .aside-list')
        $dom.textContent= "无法获取评论，请确认相关配置是否正确"
      }) 
  }

  const newestCommentInit = () => {
    if (document.querySelector('#card-newest-comments .aside-list')) {
      const data = saveToLocal.get('valine-newest-comments')
      if (data) {
        generateHtml(JSON.parse(data))
      } else {
        getComment()
      }
    }
  }

  newestCommentInit()
  document.addEventListener('pjax:complete', newestCommentInit)
})</script><script>var visitorMail = "";
</script><script async data-pjax src="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/waterfall/waterfall.js"></script><script src="https://lf3-cdn-tos.bytecdntp.com/cdn/expire-1-M/qrcodejs/1.0.0/qrcode.min.js"></script><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.1.9/icon/ali_iconfont_css.css"><link rel="stylesheet" href="https://cdn.cbd.int/anzhiyu-theme-static@1.0.0/aplayer/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.cbd.int/anzhiyu-blog-static@1.0.1/js/APlayer.min.js"></script><script src="https://cdn.cbd.int/hexo-anzhiyu-music@1.0.1/assets/js/Meting2.min.js"></script><script src="https://cdn.cbd.int/pjax@0.2.8/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]
var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {
  // removeEventListener scroll 
  anzhiyu.removeGlobalFnEvent('pjax')
  anzhiyu.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script charset="UTF-8" src="https://cdn.cbd.int/anzhiyu-theme-static@1.1.5/accesskey/accesskey.js"></script></div><div id="popup-window"><div class="popup-window-title">通知</div><div class="popup-window-divider"></div><div class="popup-window-content"><div class="popup-tip">你好呀</div><div class="popup-link"><i class="anzhiyufont anzhiyu-icon-arrow-circle-right"></i></div></div></div></body></html>