<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title></title>
      <link href="/2025/06/20/TPM%E9%9A%8F%E7%AC%94/"/>
      <url>/2025/06/20/TPM%E9%9A%8F%E7%AC%94/</url>
      
        <content type="html"><![CDATA[<p>TPM随笔</p><p><a href="https://learn.microsoft.com/zh-cn/windows/security/hardware-security/tpm/tpm-fundamentals">https://learn.microsoft.com/zh-cn/windows/security/hardware-security/tpm/tpm-fundamentals</a></p><p><a href="https://zuopeng.blog.csdn.net/article/details/123302249">https://zuopeng.blog.csdn.net/article/details/123302249</a></p><p><a href="https://trustedcomputinggroup.org/work-groups/trusted-platform-module/">https://trustedcomputinggroup.org/work-groups/trusted-platform-module/</a></p><p><a href="https://trustedcomputinggroup.org/resources/?workgroups=Trusted%20Platform%20Module%20(TPM)&">https://trustedcomputinggroup.org/resources/?workgroups=Trusted%20Platform%20Module%20(TPM)&amp;</a></p><p><a href="https://zhuanlan.zhihu.com/p/607975183">https://zhuanlan.zhihu.com/p/607975183</a></p><p><a href="https://github.com/tpm2-software/tpm2-tss">https://github.com/tpm2-software/tpm2-tss</a></p>]]></content>
      
      
      
    </entry>
    
    
    
    <entry>
      <title>关于隐私集合求交 (PSI) 的认识</title>
      <link href="/2025/06/19/%E9%9A%90%E7%A7%81%E6%B1%82%E4%BA%A4%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%80%9D%E8%80%83/"/>
      <url>/2025/06/19/%E9%9A%90%E7%A7%81%E6%B1%82%E4%BA%A4%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<h1 id="关于隐私集合求交-PSI-的认识"><a href="#关于隐私集合求交-PSI-的认识" class="headerlink" title="关于隐私集合求交 (PSI) 的认识"></a>关于隐私集合求交 (PSI) 的认识</h1><p>隐私集合求交（Private Set Intersection, PSI）是密码学和数据工程交叉领域中的一个经典问题：<strong>两个或多个参与方，如何在不泄露各自私有数据的前提下，计算出他们数据集的交集？</strong></p><p>这个需求在现实世界中非常普遍，例如：</p><ul><li><strong>广告归因</strong>：广告平台和广告主需要知道哪些观看了广告的用户最终完成了购买，但双方都不想直接暴露自己的全部用户列表。</li><li><strong>联系人发现</strong>：手机应用想知道你的通讯录里有哪些人也注册了该应用，但你不想上传整个通讯录。</li><li><strong>安全情报共享</strong>：多个情报机构希望找出共同的嫌疑人名单，但各自的名单都是高度机密的。</li></ul><p>本文将梳理几种主流的 PSI 实现方案，分析它们的设计思路、性能、安全性，以及各自的适用场景。</p><hr><h2 id="核心密码学概念：安全模型"><a href="#核心密码学概念：安全模型" class="headerlink" title="核心密码学概念：安全模型"></a>核心密码学概念：安全模型</h2><p>在深入了解各种 PSI 协议之前，我们必须先理解评估其安全性的两个基本模型。这决定了一个协议能抵御什么样的攻击者。</p><ul><li><p><strong>半诚实模型 (Semi-Honest &#x2F; Honest-but-Curious)</strong></p><ul><li><strong>定义</strong>：这是密码学协议中最常见的威胁模型。在此模型中，参与方会<strong>完全遵守</strong>协议的每一步指令，如同一个诚实的学生。但是，他们会保留协议执行过程中收到的所有信息（例如，中间计算结果），并试图在协议结束后，通过分析这些信息来推断出超出协议规定泄露范围的、对方的额外隐私。</li><li><strong>类比</strong>：一个“好奇的”合作伙伴。他会按合同办事，但会试图从你给他的文件中分析出你的商业秘密。</li><li><strong>意义</strong>：绝大多数高性能的 PSI 协议（如 OT-PSI）都是在半诚实模型下被证明安全的。这意味着，只要大家都遵守规则，就不可能泄露交集之外的任何信息。</li></ul></li><li><p><strong>恶意模型 (Malicious)</strong></p><ul><li><strong>定义</strong>：这是一个更强大、更符合现实世界某些场景的威胁模型。恶意攻击者<strong>不遵守</strong>协议，他们可以采取任何行动来破坏协议或窃取信息，例如：发送伪造的数据、提前中止协议、或者根据自己的输入来改变协议流程。</li><li><strong>类比</strong>：一个“不择手段的”商业间谍。他不仅想分析文件，还可能伪造文件、贿赂你的员工，以达到目的。</li><li><strong>意义</strong>：防御恶意攻击者需要引入更复杂的密码学工具，如**零知识证明 (Zero-Knowledge Proofs)**，来强制验证每一步的正确性。这通常会导致协议性能大幅下降。因此，恶意安全的 PSI 协议通常用在金融、政府等高风险领域。</li></ul></li></ul><p><strong>结论</strong>：在选择 PSI 方案时，首先要评估你的安全需求。对于大多数商业合作场景，半诚实模型下的安全通常已经足够。</p><hr><h2 id="方案一：基础哈希方案-简单但脆弱"><a href="#方案一：基础哈希方案-简单但脆弱" class="headerlink" title="方案一：基础哈希方案 - 简单但脆弱"></a>方案一：基础哈希方案 - 简单但脆弱</h2><p>最直观的想法是避免明文传输，利用哈希函数的单向性。</p><p><strong>核心原理</strong></p><ul><li>**单向哈希函数 (One-way Hash Function)**：如 SHA-256，可以将任意输入数据转换成一个固定长度的、独一无二的“指纹”。关键在于，从指纹反推出原始输入在计算上是不可行的。</li></ul><p><strong>协议流程</strong></p><ol><li><strong>约定哈希</strong>: A 和 B 双方约定一个标准的哈希函数（如 SHA-256）。</li><li><strong>本地计算</strong>: A 将自己的数据集内每个元素进行哈希，得到哈希列表 <code>Hash(A)</code>。B 也同样计算出 <code>Hash(B)</code>。</li><li><strong>交换与比较</strong>: 双方交换哈希列表，然后本地比较 <code>Hash(A)</code> 和 <code>Hash(B)</code>，找出相同的哈希值，这些就代表了原始数据的交集。</li></ol><p><strong>实现伪代码 (Python)</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">hash_items</span>(<span class="params">items</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;hashlib.sha256(item.encode()).hexdigest() <span class="keyword">for</span> item <span class="keyword">in</span> items&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Client A&#x27;s data</span></span><br><span class="line">data_A = &#123;<span class="string">&quot;apple&quot;</span>, <span class="string">&quot;banana&quot;</span>, <span class="string">&quot;cherry&quot;</span>&#125;</span><br><span class="line"><span class="comment"># Client B&#x27;s data</span></span><br><span class="line">data_B = &#123;<span class="string">&quot;banana&quot;</span>, <span class="string">&quot;date&quot;</span>, <span class="string">&quot;grape&quot;</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. Both parties hash their data</span></span><br><span class="line">hashed_A = hash_items(data_A)</span><br><span class="line">hashed_B = hash_items(data_B)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. They exchange these hashed sets</span></span><br><span class="line"><span class="comment"># 3. B finds the intersection of the hashed sets</span></span><br><span class="line">intersection_hashes = hashed_A.intersection(hashed_B)</span><br><span class="line"></span><br><span class="line"><span class="comment"># B might send these back to A for final confirmation, or if hashes are identifiers,</span></span><br><span class="line"><span class="comment"># the process might end here.</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;Intersection Hashes: <span class="subst">&#123;intersection_hashes&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><p><strong>分析</strong></p><ul><li><strong>优点</strong>：实现极其简单，计算速度飞快，网络通信只有一轮。</li><li><strong>缺点</strong>：安全性极低。如果元素的空间有限且已知（如手机号、身份证号、日期），攻击者可以轻松构建一个“彩虹表”，通过预计算的哈希值反推出原始输入。即使对每个元素加盐（Salt），也只能增加暴力破解的难度，无法从根本上解决问题。</li></ul><p><strong>结论</strong>：该方案仅适用于内部系统或完全可信的环境，<strong>绝对不能</strong>用于对抗任何有动机的外部攻击者。</p><hr><h2 id="方案二：布隆过滤器-高性能的概率方案"><a href="#方案二：布隆过滤器-高性能的概率方案" class="headerlink" title="方案二：布隆过滤器 - 高性能的概率方案"></a>方案二：布隆过滤器 - 高性能的概率方案</h2><p>布隆过滤器（Bloom Filter）是一种空间效率极高的概率型数据结构，它以牺牲一小部分准确性为代价，换取了巨大的性能和空间优势。</p><p><strong>核心原理</strong></p><ul><li><strong>位数组与哈希函数</strong>: 布隆过滤器由一个很长的位数组（初始化全为0）和多个独立的哈希函数组成。</li><li><strong>添加元素</strong>: 当你向过滤器中添加一个元素时，你会用所有哈希函数对这个元素进行计算，得到多个不同的位置索引，然后将位数组中这些位置的比特值设为 1。</li><li><strong>查询元素</strong>: 查询一个元素是否存在时，你用同样的哈希函数再次计算出所有位置索引。只有当所有这些位置的比特值都为 1 时，过滤器才报告“元素<strong>可能</strong>存在”。只要有一个位置是 0，那么该元素<strong>绝对不</strong>存在。</li><li><strong>假阳性 (False Positive)</strong>: 当一个本不存在的元素，其哈希到的所有位置恰好都被其他元素置为 1 时，就会发生误判。假阳性率可以通过调整位数组大小和哈希函数数量来控制。</li></ul><p><strong>协议流程</strong></p><ol><li><p><strong>阶段一：A 构建并发送过滤器</strong></p><ul><li>数据量较小的一方（A），根据自己的数据集创建一个布隆过滤器。</li><li>A 将这个紧凑的位数组发送给数据量较大的一方（B）。通信量极小，一个几MB的过滤器就能代表上亿条数据。</li></ul></li><li><p><strong>阶段二：B 查询并返回候选集</strong></p><ul><li>B 遍历自己的数据集，用与 A 相同的哈希函数去查询收到的布隆过滤器。</li><li>B 将所有在布隆过滤器中显示“可能存在”的元素，构成一个<strong>候选交集</strong>。这个集合由于假阳性的存在，会比真实交集更大。</li><li>B 将这个<strong>候选集的原始 ID</strong>（或其哈希）发回给 A。</li></ul></li><li><p><strong>阶段三：A 确认最终交集</strong></p><ul><li>A 收到候选集后，在自己的原始数据中进行精确匹配，剔除掉所有假阳性成员，得到最终的真实交集。</li></ul></li></ol><p><strong>分析</strong></p><ul><li><strong>优点</strong>:<ul><li><strong>性能极高</strong>：计算哈希和位操作非常快，是所有方案中速度最快的之一。</li><li><strong>通信效率极高</strong>：A 只需要发送一个紧凑的位数组，通信成本是其最大亮点。</li></ul></li><li><strong>缺点</strong>:<ul><li><strong>有误报</strong>：必须有一个额外的交互步骤（B -&gt; A）来剔除误报结果。</li><li><strong>安全性有限</strong>：过滤器本身虽然不是明文，但仍然泄露了关于数据集的统计学特征。如果 B 是恶意的，它可以利用过滤器测试它猜测的元素是否存在于 A 的集合中。因此，它只在半诚实模型下提供有限的隐私保护。</li></ul></li></ul><p><strong>结论</strong>：在追求极致性能、能接受多轮交互、且安全要求不是最高级别的场景下，布隆过滤器是业界大规模数据求交的常用方案。它是性能和隐私之间一个出色的工程平衡。</p><hr><h2 id="方案三：基于公钥密码学的安全方案"><a href="#方案三：基于公钥密码学的安全方案" class="headerlink" title="方案三：基于公钥密码学的安全方案"></a>方案三：基于公钥密码学的安全方案</h2><p>为了实现数学上可证明的安全性（即除了交集本身，不泄露任何额外信息），我们需要引入公钥密码学工具。这些方案通常在半诚实模型下是安全的。</p><h3 id="3-1-基于-Diffie-Hellman-的-PSI"><a href="#3-1-基于-Diffie-Hellman-的-PSI" class="headerlink" title="3.1 基于 Diffie-Hellman 的 PSI"></a>3.1 基于 Diffie-Hellman 的 PSI</h3><p>该方案巧妙地利用了 Diffie-Hellman 密钥交换协议的交换律，构建了一个优雅的 PSI 协议。</p><p><strong>前置知识：Diffie-Hellman 密钥交换</strong><br>该协议的核心是让两个互不信任的人（Alice 和 Bob）通过公开信道协商出一个共享的秘密密钥。</p><ol><li>双方约定公共参数 <code>g</code> 和 <code>p</code>。</li><li>Alice 生成私钥 <code>a</code>，计算公钥 <code>A = g^a mod p</code>，发送给 Bob。</li><li>Bob 生成私钥 <code>b</code>，计算公钥 <code>B = g^b mod p</code>，发送给 Alice。</li><li>Alice 计算共享密钥 <code>S = B^a mod p = (g^b)^a mod p</code>。</li><li>Bob 计算共享密钥 <code>S = A^b mod p = (g^a)^b mod p</code>。<br>由于幂运算的交换律，双方得到了完全相同的密钥 <code>S</code>，而窃听者无法从公开的 <code>A</code> 和 <code>B</code> 中计算出它。</li></ol><p><strong>协议流程</strong><br>此 PSI 协议将每个数据项都视作一次独立的密钥交换。</p><ol><li><strong>各自准备</strong>: A 和 B 各自生成一个私钥（随机数 <code>a</code> 和 <code>b</code>）。</li><li><strong>A 方计算与发送</strong>: A 对自己的每个元素 <code>x</code>，先哈希到椭圆曲线上的一个点 <code>H(x)</code>，然后用私钥 <code>a</code> 计算“公钥” <code>P_x = a * H(x)</code>。A 将所有 <code>P_x</code> 组成的列表发送给 B。</li><li><strong>B 方计算与发送</strong>: B 收到列表后，用自己的私钥 <code>b</code> 对列表中的每个元素进行二次“加密”，得到 <code>S_x = b * P_x = b * a * H(x)</code>。同时，B 对自己的每个元素 <code>y</code> 计算 <code>P_y = b * H(y)</code>。B 将所有 <code>P_y</code> 组成的列表发送给 A。</li><li><strong>A 方计算</strong>: A 收到 B 发送的 <code>P_y</code> 列表后，用自己的私钥 <code>a</code> 对每个元素计算，得到 <code>S_y = a * P_y = a * b * H(y)</code>。</li><li><strong>找出交集</strong>: 此时，如果 A 和 B 有一个共同元素 <code>z</code>，那么在 A 的本地，她计算出了 <code>S_z = a*b*H(z)</code>；在 B 的本地，他计算出了 <code>S_z = b*a*H(z)</code>。由于交换律，这两个值是相等的。A 将自己计算出的 <code>S_y</code> 集合与 B 发回的 <code>S_x</code> 集合（A可以在本地重新计算）求交，即可找出交集对应的秘密值，从而确定交集。通常，为了不让 B 也知道交集，最后一步比较只在 A 方进行。</li></ol><p><strong>分析</strong></p><ul><li><strong>优点</strong>：安全性高，基于成熟的公钥密码体系，无误报。在半诚实模型下是安全的。</li><li><strong>缺点</strong>：计算开销大，涉及大量的椭圆曲线点乘运算（比模幂更快，但仍是重计算），比简单哈希慢得多。通信成本也较高，需要交换两轮数据。</li></ul><p><strong>结论</strong>：一个优雅的、教科书式的 PSI 方案。适合中等大小数据集，或作为理解更复杂协议的起点。</p><h3 id="3-2-基于不经意传输-OT-的-PSI"><a href="#3-2-基于不经意传输-OT-的-PSI" class="headerlink" title="3.2 基于不经意传输 (OT) 的 PSI"></a>3.2 基于不经意传输 (OT) 的 PSI</h3><p>这是当前兼顾<strong>顶级安全</strong>和<strong>顶级性能</strong>的黄金标准，是现代隐私计算框架（如 FATE, SecretFlow）的核心。它虽然复杂，但理解其构件是理解现代密码学的关键。</p><p><strong>核心构件一：不经意传输 (Oblivious Transfer, OT)</strong></p><ul><li><strong>是什么</strong>：一个两方协议，其中发送方 (Sender) 有 <code>N</code> 个消息 <code>(m_1, m_2, ..., m_n)</code>，接收方 (Receiver) 有一个索引 <code>i</code>。协议结束后，接收方只得到了消息 <code>m_i</code>，而发送方完全不知道接收方取走了第几个消息。</li><li><strong>“邮局信箱”类比</strong>: Bob 想从邮递员 Alice 那里拿到 N 封信中的第 <code>i</code> 封，但他不想让 Alice 知道他取了哪封。Bob 有一把只能打开第 <code>i</code> 号信箱的钥匙。他把这把锁（已打开状态，但钥匙不给 Alice）交给 Alice。Alice 拿到后，用它和其他 N-1 把她自己准备的锁，分别锁上对应的 N 封信，然后把所有 N 个信箱都交给 Bob。Bob 只能用自己的钥匙打开第 <code>i</code> 号信箱，拿到信件。Alice 始终不知道 Bob 的选择。</li><li>**不经意传输扩展 (OTe)**：基础的 OT 协议执行一次开销很大。OTe 技术可以用很少的“种子”OT 实例，以极低的成本生成海量的 OT 实例，这使得 OT 在大数据场景下变得实用。</li></ul><p><strong>核心构件二：布谷鸟哈希 (Cuckoo Hashing)</strong></p><ul><li><strong>是什么</strong>：一种特殊的哈希表，它为每个元素分配<strong>两个或多个</strong>备选存储位置。</li><li><strong>“布谷鸟占巢”类比</strong>: 想象一排鸟巢（一个大数组）和一群布谷鸟（数据项）。每只鸟都有两个固定的巢可以去（由两个哈希函数 <code>h1(x)</code>, <code>h2(x)</code> 决定）。当一只新鸟飞来，它检查第一个家 <code>h1(x)</code>。如果空着，就住进去。如果被占了，它就把里面的“原住民”踢出去，自己住进去。被踢出去的鸟，现在飞向它的<em>另一个</em>备选家 <code>h2(x)</code>… 这个过程会像链式反应一样继续下去，直到所有鸟都找到家。</li><li><strong>在PSI中的作用</strong>: 服务端（大数据方）将自己的数据存入布谷鸟哈希表。这样，客户端（小数据方）想查询一个元素 <code>x</code>，它就<strong>明确地知道</strong> <code>x</code> 只可能存在于 <code>h1(x)</code> 和 <code>h2(x)</code> 这两个位置。这避免了全表扫描，将查询范围缩小到常数级别，是 OT-PSI 高性能的关键。</li></ul><p><strong>协议流程 (高度简化)</strong><br>我们将参与方称为客户端 C (数据量小)和服务端 S (数据量大)。目标是客户端得到交集，服务端一无所知。</p><ol><li><p><strong>服务端准备 (离线)</strong>:</p><ul><li>S 将自己的数据集 <code>Y</code> 存入一个布谷鸟哈希表中。表的每个槽位要么是 <code>y</code>，要么是空。</li><li>S 对布谷鸟哈希表中的每个位置，都填充一个随机生成的秘密值。</li></ul></li><li><p><strong>交互与查询 (在线)</strong>:</p><ul><li>C 对于自己的每个元素 <code>x</code>，也用相同的哈希函数计算出它在布谷鸟表中的所有可能位置（如 <code>h1(x)</code>, <code>h2(x)</code>）。</li><li>C 作为 OT 协议的接收方，S 作为发送方，双方执行 OTe 协议。C 将上一步计算出的所有位置作为查询索引。</li><li>通过 OTe，C “不经意地”从 S 获取了它想查询的所有位置上的秘密值。整个过程 S 不知道 C 查询了哪些位置，C 也不知道其他位置的值。</li></ul></li><li><p><strong>客户端计算 (离线)</strong>:</p><ul><li>为了找出交集，协议有一个巧妙的设计：客户端不仅获取秘密值，还能通过另一个函数 <code>F</code> 计算出自己元素的“期望秘密值”。</li><li>客户端检查取回的秘密值中，是否存在一个与它为 <code>x</code> 计算出的期望值相匹配。如果匹配，<code>x</code> 就属于交集。</li><li>客户端在本地完成所有匹配，最终得到完整的交集，而服务端对结果一无所知。</li></ul></li></ol><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  sequenceDiagram    participant Server as 服务端 (大数据集 Y)    participant Client as 客户端 (小数据集 X)    Note over Server: 阶段一：离线准备 (Cuckoo Hashing)    Server-&gt;&gt;Server: 1. 将数据集 Y 存入布谷鸟哈希表    Server-&gt;&gt;Server: 2. 为哈希表中每个槽位填充随机秘密值    Note over Client,Server: 阶段二：在线交互 (OTe)    loop 对客户端每个元素 x        Client-&gt;&gt;Client: 3. 计算 x 的两个查询地址 h1(x), h2(x)    end    Note over Client,Server: 4. 执行 OTe 协议批量查询    Client-&gt;&gt;Server: 作为接收方，将 h1(x), h2(x)... 作为选择比特    Server--&gt;&gt;Client: 作为发送方，返回加密的秘密值    Note over Client: 阶段三：本地计算    Client-&gt;&gt;Client: 5. 将获取的秘密值与本地期望值比对    Client-&gt;&gt;Client: 6. 找出所有匹配成功的元素，构成交集  </pre></div><p><strong>分析</strong></p><ul><li><strong>优点</strong>：通过复杂的密码学工程，实现了极高的安全（半诚实模型）和极高的性能，通信轮次少（基本一轮），计算速度远超其他公钥方案。</li><li><strong>缺点</strong>：实现极为复杂，个人难以从零开始正确构建，必须依赖成熟的、经过同行评审的密码学库。</li></ul><p><strong>结论</strong>：这是业界前沿的选择，适用于对安全和性能都有着严苛要求的大规模场景。</p><h3 id="3-3-关于同态加密-HE-的说明"><a href="#3-3-关于同态加密-HE-的说明" class="headerlink" title="3.3 关于同态加密 (HE) 的说明"></a>3.3 关于同态加密 (HE) 的说明</h3><p>同态加密允许在密文上进行计算，得到的结果解密后与在明文上计算的结果相同。</p><p><strong>核心原理</strong></p><ul><li><p>一个函数 <code>f</code> 和加密算法 <code>Enc</code>，满足 <code>Dec(f(Enc(a), Enc(b))) = f(a, b)</code>。</p></li><li><p><strong>实现思路</strong>: A 将自己的集合 <code>&#123;x&#125;</code> 每个元素加密 <code>Enc(x)</code> 并发送给 B。B 利用同态性质，在密文上执行一个“比较”操作，找出哪些 <code>Enc(x)</code> 与自己的某个 <code>Enc(y)</code> 相等。这个过程非常复杂，远不止是简单的 <code>==</code> 比较。</p></li><li><p><strong>优点</strong>：安全性极高，理论上可以支持非常复杂的数据分析。</p></li><li><p><strong>缺点</strong>：性能极差。同态运算比明文运算慢数个数量级，且密文膨胀严重。对于简单的集合求交任务，其开销远大于专用的 OT-PSI 等协议，如同“用大炮打蚊子”。</p></li></ul><p><strong>结论</strong>：HE 是解决更复杂隐私计算问题的强大工具（如隐私联邦学习中的模型聚合），但对于单纯的 PSI 任务，通常不是性价比最高的选择。</p><hr><h2 id="PSI-协议变种"><a href="#PSI-协议变种" class="headerlink" title="PSI 协议变种"></a>PSI 协议变种</h2><p>标准的 PSI 解决的是“找出交集成员”的问题，但在现实中，我们常常有更细化的需求。</p><ul><li><p><strong>PSI-Cardinality (交集基数计算)</strong></p><ul><li><strong>目标</strong>：只计算交集的大小 <code>|X ∩ Y|</code>，不暴露任何交集成员。</li><li><strong>场景</strong>：两家公司想知道他们有多少共同客户，但不想知道具体是哪些客户。</li><li><strong>实现</strong>：通常比标准 PSI 更高效，因为需要泄露的信息更少。可以基于布隆过滤器（A 发送过滤器，B 查询后返回一个计数值）、或专用的密码学协议构建。</li></ul></li><li><p><strong>Labeled PSI (带标签的 PSI)</strong></p><ul><li><strong>目标</strong>：一方（通常是客户端 A）拥有数据集 <code>X</code>，另一方（服务端 B）拥有带标签的数据集 <code>&#123;(y, l_y)&#125;</code>。协议结束后，A 得到与交集相关的标签 <code>&#123; (x, l_x) | x ∈ X ∩ Y &#125;</code>。B 除了数据集大小外，一无所知。</li><li><strong>场景</strong>：广告归因。广告平台（B）有<code>（用户ID, 转化价值）</code>数据，广告主（A）有<code>（用户ID）</code>数据。通过 Labeled PSI，广告主可以知道自己哪些用户产生了转化，以及具体的价值，而平台方无需暴露所有用户的价值信息。</li><li><strong>实现</strong>：通常是 OT-PSI 的一个扩展。</li></ul></li><li><p><strong>Multi-Party PSI (多方 PSI)</strong></p><ul><li><strong>目标</strong>：三个或更多参与方，共同计算他们数据集的交集 <code>X1 ∩ X2 ∩ ... ∩ Xn</code>。</li><li><strong>场景</strong>：多个安全机构希望找出他们共同的嫌疑人名单，但任何两方之间都不想暴露自己的私有名单。</li><li><strong>实现</strong>：复杂度显著提高。常见的方法有两类：<ol><li><strong>基于中心协调者</strong>：所有参与方都与一个（可信或不可信的）中心服务器进行两方 PSI。</li><li><strong>去中心化</strong>：参与方形成一个环，例如 <code>P1 -&gt; P2 -&gt; ... -&gt; Pn -&gt; P1</code>，每一方都将自己与上一方计算的中间结果传递给下一方，最终完成计算。</li></ol></li></ul></li></ul><hr><h2 id="方案对比与选择"><a href="#方案对比与选择" class="headerlink" title="方案对比与选择"></a>方案对比与选择</h2><table><thead><tr><th align="left">方案</th><th align="left">安全模型</th><th align="left">性能</th><th align="left">通信成本</th><th align="left">核心原理</th><th align="left">实现复杂度</th><th align="left">核心场景</th></tr></thead><tbody><tr><td align="left"><strong>简单哈希</strong></td><td align="left">不安全</td><td align="left">极高</td><td align="left">中</td><td align="left">单向哈希</td><td align="left">低</td><td align="left">内部或完全可信环境</td></tr><tr><td align="left"><strong>布隆过滤器</strong></td><td align="left">弱&#x2F;半诚实</td><td align="left">极高</td><td align="left"><strong>极低</strong></td><td align="left">概率数据结构</td><td align="left">中</td><td align="left">性能敏感，能接受额外交互</td></tr><tr><td align="left"><strong>DH-PSI</strong></td><td align="left"><strong>半诚实</strong></td><td align="left">中</td><td align="left">高</td><td align="left">密钥交换</td><td align="left">高</td><td align="left">安全要求高，数据集不大，教学</td></tr><tr><td align="left"><strong>OT-PSI</strong></td><td align="left"><strong>半诚实</strong></td><td align="left"><strong>高</strong></td><td align="left">中</td><td align="left">不经意传输</td><td align="left"><strong>极高</strong></td><td align="left">兼顾高性能和高安全的前沿选择</td></tr><tr><td align="left"><strong>HE-PSI</strong></td><td align="left"><strong>半诚实</strong></td><td align="left">极低</td><td align="left">极高</td><td align="left">同态加密</td><td align="left">极高</td><td align="left">学术研究或复杂计算场景</td></tr></tbody></table><h3 id="如何选择？一份决策指南"><a href="#如何选择？一份决策指南" class="headerlink" title="如何选择？一份决策指南"></a>如何选择？一份决策指南</h3><ol><li><p><strong>第一步：评估安全威胁与信任模型</strong></p><ul><li>你的对手是会遵守规则的“好奇宝宝”（半诚实），还是可能作弊的“破坏者”（恶意）？</li><li>对于绝大多数商业应用，<strong>半诚实安全</strong>已经足够。如果需要对抗恶意攻击，你需要寻找明确支持<code>Malicious Secure</code>的库，并接受显著的性能下降。</li></ul></li><li><p><strong>第二步：明确你的输出需求</strong></p><ul><li>你真的需要交集的<strong>具体成员</strong>吗？还是只需要它的<strong>数量</strong>（-&gt; PSI-Cardinality）？</li><li>你是否需要在求交的同时，从对方获取关联<strong>数据</strong>（-&gt; Labeled PSI）？</li><li>参与方是两个还是多个（-&gt; Multi-Party PSI）？</li></ul></li><li><p><strong>第三步：评估性能、成本与数据规模</strong></p><ul><li><strong>性能和通信成本是唯一瓶颈</strong>：数据量巨大，但安全要求不高，且可以容忍多一轮交互来消除误报 -&gt; <strong>布隆过滤器</strong>。</li><li><strong>安全是首要考虑，但数据规模不大</strong>：数据集在十万到百万级别，希望有一个可靠、易于理解的强安全方案 -&gt; <strong>DH-PSI</strong>。</li><li><strong>安全和性能缺一不可</strong>：数据规模在百万级以上，需要半诚实安全保证，并且对性能有很高要求 -&gt; <strong>OT-PSI</strong> (并使用现有库)。</li></ul></li><li><p><strong>第四步：考虑工程实现</strong></p><ul><li>对于所有公钥方案，<strong>永远不要自己从零实现</strong>。密码学实现中的任何微小错误都可能导致灾难性的安全漏洞。</li><li><strong>优先使用封装好的高级库</strong>：如 <code>OpenPSI</code>, <code>FALCON-PSI</code>，它们提供了易于使用的接口。</li><li><strong>需要极致定制或研究</strong>：可以深入更底层的库，如 <code>libOTe</code>。</li></ul></li></ol><hr><h2 id="未来展望"><a href="#未来展望" class="headerlink" title="未来展望"></a>未来展望</h2><p>隐私集合求交是一个活跃的研究领域，仍在不断演进。</p><ul><li>**抗量子密码 (Post-Quantum PSI)**：当前主流的公钥方案（DH, OT）都基于传统数论难题，在未来可能受到量子计算机的威胁。学术界正在积极研究基于格密码（Lattices）等抗量子困难问题的 PSI 新范式。</li><li>**硬件加速 (Hardware Acceleration)**：为了进一步突破性能瓶颈，研究者们正在探索使用 GPU、FPGA 等专用硬件来加速底层复杂的密码学运算（如OTe、椭圆曲线点乘），以满足更大规模、更低延迟的实时计算需求。</li></ul><hr><h2 id="资源与库"><a href="#资源与库" class="headerlink" title="资源与库"></a>资源与库</h2><p>要亲手实现安全的 PSI 协议，建议直接使用经过同行评审和社区考验的开源库，而不是自己造轮子。</p><ul><li><strong>libOTe (C++)</strong>: 目前最知名和最高性能的 OT 库之一，是许多其他库的基础。</li><li><strong>OpenPSI (C++)</strong>: 一个封装了多种 PSI 协议（包括基于 OT 的）的开源库，相对易于使用。</li><li><strong>FALCON-PSI (Python&#x2F;C++)</strong>: 微软研究院等机构推出的高性能 PSI 库。</li></ul><h2 id="业界产品"><a href="#业界产品" class="headerlink" title="业界产品"></a>业界产品</h2><p><a href="https://m.jrj.com.cn/toutiao/2022/3/17/34839331.shtml">https://m.jrj.com.cn/toutiao/2022/3/17/34839331.shtml</a></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop生态：YARN、HDFS、Hive、Spark、HBase是如何协同工作的？</title>
      <link href="/2025/06/18/hadoop-ecosystem-explained/"/>
      <url>/2025/06/18/hadoop-ecosystem-explained/</url>
      
        <content type="html"><![CDATA[<p>我想刚接触大数据领域的同学，常常被一堆名词砸晕：Hadoop、HDFS、YARN、Hive、Spark、HBase… 【东西也太多了吧】，个个看起来都很有用，但彼此之间到底是什么关系？跑一个作业的时候，数据和指令又是在它们之间如何流转的？</p><p>这篇文章不打算讲原理讲概念，我们就从一个开发者的角度，用一个好理解的类比，把这几位的关系捋清楚。</p><h3 id="一个公司运作的类比"><a href="#一个公司运作的类比" class="headerlink" title="一个公司运作的类比"></a>一个公司运作的类比</h3><p>想象一下，我们开了一家大型的互联网公司，这家公司就是我们的 <strong>Hadoop集群</strong>。</p><ul><li><p><strong>HDFS (Hadoop Distributed File System)<strong>：这是公司的</strong>巨型中央仓库</strong>。所有部门的数据、资料、历史文档（也就是我们的数据，各种结构化或者半结构化的数据都可以）都堆在这里。这个仓库非常大，由很多个普通的货架（服务器硬盘）组成，但对外看起来是一个整体。它有个管理员（NameNode），知道每个资料（数据块）放在了哪个货架的哪个位置，还做了备份，防止资料丢失。它的特点是：存东西和整批取东西很方便，但你要是想在某个文件中间改个字，就太难了。</p></li><li><p><strong>YARN (Yet Another Resource Negotiator)<strong>：这是公司的</strong>行政和人力资源部</strong>。它不负责具体的业务，但掌管着公司所有的资源：座位（CPU）、网络（内存）、会议室（计算槽位）等。哪个项目组（比如Spark或MapReduce作业）需要多少人手和地方来干活，都得向YARN申请。YARN批准，然后项目组才能拿到资源开工。它让公司的资源能够被不同项目组共享，大大提高了利用率。</p></li><li><p><strong>计算引擎 (MapReduce&#x2F;Spark)<strong>：这些就是公司里的各个</strong>项目组&#x2F;业务线</strong>。它们是真正干活的。</p><ul><li><strong>MapReduce</strong>：可以看作是公司的<strong>传统业务线</strong>。它做事手法很简单，只有 “分拣（Map）”和”汇总（Reduce）”两个固定步骤，处理海量数据没问题，但就是流程有点死板，速度也比较慢（中间结果要频繁写入仓库HDFS导致速度不行）</li><li><strong>Spark</strong>：这是新来的<strong>项目组</strong>。脑子快（基于内存计算），十八般武艺样样精通（支持批处理、流计算、机器学习等）。它干活效率极高，因为很多中间过程在内存上就完成了，不用总是走HDFS【磁盘】，比较类似flink。</li></ul></li><li><p><strong>Hive</strong>：这是公司的<strong>数据分析部</strong>。数据分析师们擅长用SQL写报表，但他们不了解生产线（MapReduce&#x2F;Spark）上复杂的处理。于是Hive就诞生了，它提供了一个SQL查询的窗口。分析师把SQL报表需求给Hive，Hive就会把这个SQL翻译成生产线能听懂的”指令”（MapReduce或Spark任务），然后交给YARN去调度资源执行。所以，<strong>Hive本身不计算，它是个翻译官和任务提交工具</strong>。</p></li><li><p><strong>HBase</strong>：这是公司的<strong>前台实时查询系统&#x2F;档案室</strong>。当客服需要在一秒内查到某个客户的详细信息时，你总不能让数据分析部（Hive）去仓库（HDFS）里把所有客户数据翻一遍吧？那得等到猴年马月。HBase就是解决这个问题的，它也把数据存在HDFS大仓库里，但它用一种特殊的方式（列式存储、索引）整理了这些数据，让你能像查数据库一样，毫秒级地找到你想要的那一行或那几行数据。它专门负责<strong>实时、高并发的随机读写</strong>。</p></li></ul><h3 id="它们的关系图"><a href="#它们的关系图" class="headerlink" title="它们的关系图"></a>它们的关系图</h3><p>用一张图来表示它们的关系，会更清晰：</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    subgraph &quot;Hadoop Cluster (基础设施)&quot;        YARN(&quot;YARN (资源调度中心)&quot;)        HDFS(&quot;HDFS (统一数据存储)&quot;)    end    subgraph &quot;Computing Engines (计算引擎)&quot;        Spark(&quot;Spark (快速通用计算)&quot;)        MapReduce(&quot;MapReduce (传统批处理)&quot;)    end    subgraph &quot;Applications (上层应用)&quot;        Hive(&quot;Hive (数据仓库&#x2F;SQL接口)&quot;)        HBase(&quot;HBase (NoSQL实时数据库)&quot;)        OtherApps(&quot;其他应用 Flink, etc.&quot;)    end    Hive -- &quot;翻译成&quot; --&gt; Spark    Hive -- &quot;翻译成&quot; --&gt; MapReduce    Spark -- &quot;读写数据&quot; --&gt; HDFS    MapReduce -- &quot;读写数据&quot; --&gt; HDFS    HBase -- &quot;底层存储&quot; --&gt; HDFS    Spark -- &quot;申请资源运行于&quot; --&gt; YARN    MapReduce -- &quot;申请资源运行于&quot; --&gt; YARN    HBase -- &quot;服务运行于&quot; --&gt; YARN    subgraph User        Developer(&quot;开发者&#x2F;分析师&quot;)    end    Developer -- &quot;写SQL&quot; --&gt; Hive    Developer -- &quot;写代码&quot; --&gt; Spark    Developer -- &quot;实时读写&quot; --&gt; HBase  </pre></div><h3 id="一个作业的旅程：当你在Hive里敲下回车"><a href="#一个作业的旅程：当你在Hive里敲下回车" class="headerlink" title="一个作业的旅程：当你在Hive里敲下回车"></a>一个作业的旅程：当你在Hive里敲下回车</h3><p>现在，我们把上面的所有东西串起来，看看当一个数据分析师执行一个Hive SQL查询时，到底发生了什么。</p><p><strong>场景</strong>：分析师想统计每个国家的用户数量。</p><p><strong>SQL</strong>: <code>SELECT country, COUNT(*) FROM user_logs GROUP BY country;</code></p><ol><li><p><strong>提交查询</strong>: 分析师在Hive的客户端（比如Beeline）里输入SQL，敲下回车。</p></li><li><p><strong>Hive处理</strong>: Hive Server接收到这个SQL。它首先会检查语法对不对，然后查询它的元数据（Metastore，记录了<code>user_logs</code>表在哪，什么格式等），生成一个执行计划。这个计划本质上是一个有向无环图（DAG），描述了需要几步、每步干什么才能完成这个计算。</p></li><li><p><strong>向YARN申请”包工头”</strong>: Hive（或者说它配置的执行引擎，比如Tez或Spark）作为一个YARN客户端，向YARN的<strong>ResourceManager（资源总管）</strong> 发起请求：”我有个大活儿，需要启动一个’包工头’（ApplicationMaster），请给我分配点资源。”</p></li><li><p><strong>YARN启动”包工头”</strong>: ResourceManager一看有名额，就在集群里找一个不那么忙的节点（NodeManager），在上面启动一个Container（容器，可以理解为一个隔离的进程空间），并把ApplicationMaster（AM）给运行起来。</p></li><li><p><strong>包工头申请工人</strong>: 这个AM就是本次作业的总指挥。它会分析刚才Hive生成的执行计划，看看具体需要多少”工人”（计算任务），每个工人需要多少资源。然后它会分批向ResourceManager去申请：”老板，我需要10个工人，每人分配1GB内存和1个CPU。”</p></li><li><p><strong>YARN分配工人</strong>: ResourceManager再次在集群的各个NodeManager上分配Container作为”工位”给这些工人。</p></li><li><p><strong>工人开工</strong>: AM拿到”工位”列表后，直接跟对应的NodeManager通信，让它们在这些Container里启动真正的计算任务（Task）。这些任务会从<strong>HDFS</strong>上读取<code>user_logs</code>表的数据块。YARN会尽可能地让任务在数据所在的节点上运行，这就是所谓的”计算向数据移动”，以减少网络传输开销。</p></li><li><p><strong>数据处理与汇总</strong>:</p><ul><li><strong>Map阶段</strong>：各个任务（工人）读取自己分到的数据，解析出<code>country</code>，然后输出 <code>(country, 1)</code> 这样的键值对。</li><li><strong>Shuffle&#x2F;Reduce阶段</strong>：YARN和执行引擎负责将相同<code>country</code>的数据拉到一起，然后交给Reduce任务去做最终的<code>COUNT(*)</code>汇总。</li></ul></li><li><p><strong>输出结果</strong>: 最终的统计结果，可能会被写回到HDFS的一个新文件里，或者直接通过网络返回给分析师的Hive客户端。</p></li><li><p><strong>释放资源</strong>: 作业完成后，AM向ResourceManager注销自己，所有它申请的Container也都被YARN回收，资源被释放出来给其他作业使用。</p></li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>好了，现在我们再回顾一下：</p><ul><li><strong>HDFS</strong>是地基，负责存。</li><li><strong>YARN</strong>是管家，负责调度资源。</li><li><strong>Spark</strong>和<strong>MapReduce</strong>是工人，负责算。</li><li><strong>Hive</strong>是项目经理，把大领导的意图（SQL）翻译成工人能懂的语言，然后交给管家去安排。</li><li><strong>HBase</strong>是档案管理员，负责快速查找和存取特定记录。</li></ul><p>它们共同构成了 常见的离线大数据处理平台。 </p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hadoop </tag>
            
            <tag> Spark </tag>
            
            <tag> Hive </tag>
            
            <tag> HDFS </tag>
            
            <tag> YARN </tag>
            
            <tag> HBase </tag>
            
            <tag> 大数据 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初学Hive</title>
      <link href="/2025/06/18/hive%20%E5%AD%A6%E4%B9%A0/"/>
      <url>/2025/06/18/hive%20%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p>聊到大数据处理，Hadoop 是绕不开的话题，而提到 Hadoop 生态，就不得不说 Hive。这玩意儿到底是啥？简单来说，Hive 就是一个能让你用类似 SQL 的语言（叫 HQL）去查 HDFS 上海量数据的工具。对于熟悉 SQL 的人来说，这极大降低了数据分析的门槛，不用上来就手写复杂的 MapReduce 程序了。</p><p>但这并不意味着 Hive 是万能的。它跑的是 MapReduce（或者 Tez、Spark），天生就是为批处理设计的，所以别指望它能有毫秒级的实时查询响应，那不是它的活。</p><h3 id="Hive-能干啥？"><a href="#Hive-能干啥？" class="headerlink" title="Hive 能干啥？"></a>Hive 能干啥？</h3><p>Hive 本身不存储数据，它更像一个数据目录和查询引擎。它能处理的数据和文件类型其实非常灵活：</p><ul><li><strong>数据源</strong>: 主要处理存储在 HDFS 上的结构化或半结构化数据。</li><li><strong>文件格式</strong>: 默认可以直接加载文本文件（TEXTFILE），你只需要在建表时告诉 Hive 数据的列分隔符和行分隔符。除此之外，它也支持更高效的列式存储格式，如 <strong>ORC</strong> 和 <strong>Parquet</strong>，以及 <strong>SequenceFile</strong>、<strong>RCFile</strong> 等。用好这些格式对性能提升有很大帮助。</li></ul><p>核心思想是 **”Schema on Read”**。数据可以就是一堆普普通通的文本文件，在你查询的时候，Hive 才根据表的定义（元数据）来解析这些文件，而不是在写入时就强制校验格式。</p><h3 id="运行架构"><a href="#运行架构" class="headerlink" title="运行架构"></a>运行架构</h3><p>Hive 的架构可以拆成客户端和服务端两部分。我们可以用下面这张图来理解它的核心组件：</p><pre class="mermaid">graph TD    subgraph Client [客户端]        A[CLI]        B[JDBC/ODBC]        C[Web UI]    end    subgraph HiveServer [Hive 服务端]        D[Thrift Server]        E[Driver]        F[Metastore]    end    subgraph HadoopEcosystem [Hadoop 生态]        G[HDFS]        H[YARN / MapReduce]    end    Client --> D    D --> E    E --> H    E -- "元数据请求" --> F    F -- "元数据存储" --> RDB[(MySQL/Postgres)]    H -- "读写数据" --> G</pre><p><strong>服务端组件 (Server-side Components):</strong></p><ul><li><strong>Driver</strong>: 这是 Hive 的大脑，负责把你的 HQL 搞定。它里面又包含几个小弟：<ul><li><strong>Complier (编译器)</strong>: 把 HQL 语句解析成语法树，然后生成一个执行计划。</li><li><strong>Optimizer (优化器)</strong>: 对执行计划进行优化，比如怎么做 Join 更快。</li><li><strong>Executor (执行器)</strong>: 把最终的执行计划交给 Hadoop 去运行。</li></ul></li><li><strong>Metastore (元数据存储)</strong>: 这是 Hive 的核心，存着所有表的信息，比如表名、列、数据类型、分区信息、数据在 HDFS 的哪个位置等等。它通常会用一个正经的关系型数据库（比如 MySQL）来存这些信息，保证稳定可靠。把 Metastore 独立出来，也让 Hive 变得更健壮。</li><li><strong>Thrift Server</strong>: 这玩意儿提供了一个 RPC 接口，让各种语言（Java, Python 等）的客户端都能远程连接到 Hive 并提交查询。</li></ul><p><strong>客户端组件 (Client-side Components):</strong></p><ul><li><strong>CLI (命令行接口)</strong>: 就是我们最常用的 <code>hive</code> 命令，直接在终端里写 HQL。</li><li><strong>JDBC&#x2F;ODBC</strong>: 提供了标准的数据库连接方式，让 BI 工具或者 Java 程序能像连 MySQL 一样连接 Hive。</li><li><strong>Web GUI</strong>: 提供一个网页界面来操作 Hive。</li></ul><h3 id="一次查询的执行流程"><a href="#一次查询的执行流程" class="headerlink" title="一次查询的执行流程"></a>一次查询的执行流程</h3><p>当我们敲下一行 HQL 回车后，背后发生了什么？</p><pre class="mermaid">sequenceDiagram    participant Client as 客户端    participant Driver as 驱动器    participant Compiler as 编译器    participant Optimizer as 优化器    participant Executor as 执行器    participant Metastore as 元数据中心    participant Hadoop as "Hadoop(YARN/HDFS)"    Client->>Driver: 提交 HQL 查询    Driver->>Compiler: 解析/编译查询    Compiler->>Metastore: 获取表结构等元数据    Metastore-->>Compiler: 返回元数据    Compiler->>Optimizer: 生成优化的执行计划(DAG)    Optimizer-->>Driver: 返回最终执行计划    Driver->>Executor: 执行    Executor->>Hadoop: 提交 MapReduce/Tez/Spark 作业    Hadoop->>Hadoop: 在集群上执行作业, 从 HDFS 读数据    Hadoop->>Executor: 返回作业结果/状态    Executor-->>Driver: 返回执行结果    Driver-->>Client: 返回最终查询结果</pre><p>简单总结一下步骤：</p><ol><li>客户端把 HQL 发给 Driver。</li><li>Driver 里的编译器和优化器开始工作，它们会去 Metastore 查询这张表到底长啥样（比如字段、分区），然后生成一个最优的执行计划。</li><li>执行器拿到计划，把它翻译成一个或多个 MapReduce（或 Tez&#x2F;Spark）作业。</li><li>执行器把这些作业扔给 Hadoop 的 YARN 去调度执行。</li><li>作业在 Hadoop 集群上运行，从 HDFS 读取数据进行计算。</li><li>计算结果可能会写回 HDFS，或者直接返回给客户端。</li></ol><h3 id="数据模型"><a href="#数据模型" class="headerlink" title="数据模型"></a>数据模型</h3><p>Hive 是怎么组织数据的呢？主要有这么几个概念：</p><ul><li><strong>Database</strong>: 和传统数据库一样，就是个命名空间，用来组织和隔离表。</li><li><strong>Table</strong>: 表。分为两种：<ul><li><strong>内部表 (Managed&#x2F;Internal Table)</strong>: Hive 全权管理。数据会被移动到 Hive 的数据仓库目录（通常是 <code>/user/hive/warehouse</code>）。你 <code>DROP</code> 这张表的时候，它的元数据和 HDFS 上的数据文件会一起被删掉。适合存放只给 Hive 用的临时表或中间表。</li><li><strong>外部表 (External Table)</strong>: Hive 只管理元数据，数据文件存放在你指定的 HDFS 路径下。<code>DROP</code> 外部表时，只会删除元数据，HDFS 上的文件安然无恙。这对于多工具（比如 Spark、Presto 也会用）共享数据源的场景非常有用。</li></ul></li><li><strong>Partition (分区)</strong>: 这是 Hive 一个非常重要的性能优化机制。你可以根据一个或多个列的值把一张表的数据分成不同的部分来存储。在文件系统层面，每个分区就是一个独立的文件夹。<ul><li>比如，一张日志表 <code>logs</code> 按天分区（<code>dt</code> 列），那么 <code>dt=&#39;2023-10-27&#39;</code> 的所有数据都会存放在 HDFS 的 <code>.../logs/dt=2023-10-27/</code> 目录下。</li><li>当你查询时带上 <code>WHERE dt=&#39;2023-10-27&#39;</code>，Hive 就只需要扫描这个文件夹下的数据，而不用全表扫描，速度自然就快了。</li></ul></li><li><strong>Bucket (分桶)</strong>: 如果说分区是”宏观”上的切分（分文件夹），那分桶就是”微观”上的切分（分文件）。它会在一个分区内，根据某列的哈希值把数据再切分成固定数量的文件（桶）。这对于高效的采样（sampling）和某些 Join 操作有奇效。</li></ul><h3 id="常用数据类型"><a href="#常用数据类型" class="headerlink" title="常用数据类型"></a>常用数据类型</h3><p>Hive 的数据类型跟标准 SQL 差不多。</p><ul><li><strong>基本类型</strong>:<ul><li>数值型: <code>TINYINT</code>, <code>SMALLINT</code>, <code>INT</code>, <code>BIGINT</code>, <code>FLOAT</code>, <code>DOUBLE</code>, <code>DECIMAL</code></li><li>布尔型: <code>BOOLEAN</code></li><li>字符串: <code>STRING</code>, <code>VARCHAR</code>, <code>CHAR</code></li><li>时间戳: <code>TIMESTAMP</code>, <code>DATE</code></li></ul></li><li><strong>复杂类型</strong>:<ul><li><code>ARRAY&lt;data_type&gt;</code>: 数组，比如 <code>ARRAY&lt;STRING&gt;</code>。</li><li><code>MAP&lt;primitive_type, data_type&gt;</code>: Key-Value 对，比如 <code>MAP&lt;STRING, INT&gt;</code>。</li><li><code>STRUCT&lt;col_name: data_type, ...&gt;</code>: 结构体，可以把多个字段包在一起，类似 C 语言的 struct。比如 <code>STRUCT&lt;name:STRING, age:INT&gt;</code>。</li></ul></li></ul><h3 id="Hive-与-HDFS-的关系"><a href="#Hive-与-HDFS-的关系" class="headerlink" title="Hive 与 HDFS 的关系"></a>Hive 与 HDFS 的关系</h3><p>最后再捋一捋 Hive 和 HDFS 的关系：</p><ul><li>**Hive 是”上层建筑”，HDFS 是”经济基础”**。</li><li><strong>数据存储</strong>: Hive 不负责存数据，它表里的数据实际上都是 HDFS 上的文件。Hive 的元数据（Metastore）里记录了表的数据对应 HDFS 的哪个路径。</li><li><strong>数据处理</strong>: Hive 把用户的 HQL 查询转换成底层的计算任务（如 MapReduce），这些任务在 Hadoop 集群上运行，直接操作 HDFS 上的数据文件。</li></ul><p>所以，你可以把 Hive 理解成一个翻译官 + 指挥官。它把我们写的 SQL “翻译” 成 Hadoop 能听懂的语言（MapReduce 作业），然后 “指挥” Hadoop 集群去 HDFS 上搬砖干活。 </p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入哈希函数：SHA-256的数学之旅</title>
      <link href="/2025/06/18/%E6%B7%B1%E5%85%A5%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0%EF%BC%9ASHA-256%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%97%85/"/>
      <url>/2025/06/18/%E6%B7%B1%E5%85%A5%E5%93%88%E5%B8%8C%E5%87%BD%E6%95%B0%EF%BC%9ASHA-256%E7%9A%84%E6%95%B0%E5%AD%A6%E4%B9%8B%E6%97%85/</url>
      
        <content type="html"><![CDATA[<h1 id="深入哈希函数：SHA-256的数学之旅"><a href="#深入哈希函数：SHA-256的数学之旅" class="headerlink" title="深入哈希函数：SHA-256的数学之旅"></a>深入哈希函数：SHA-256的数学之旅</h1><p>上次我们聊了哈希是干啥的，说它是个”单向搅拌机”。那今天，咱们就把这台搅拌机的盖子掀开，看看里面的齿轮和刀片（也就是数学原理）到底是怎么工作的。</p><p>我们拿大名鼎鼎的 SHA-256 来开刀。放心，这篇文章不是让你去当数学家，也不是让你自己去实现一个。而是用一个开发者的视角，去理解我们每天都在用的工具，它背后那些精妙的设计。</p><p><strong>理解原理是为了更好地使用它，而不是让你自己去实现一个！</strong> 专业的事交给密码学家，我们负责把它用对。</p><h2 id="宏观视角：Merkle–Damgard-结构"><a href="#宏观视角：Merkle–Damgard-结构" class="headerlink" title="宏观视角：Merkle–Damgård 结构"></a>宏观视角：Merkle–Damgård 结构</h2><p>在我们一头扎进 SHA-256 的细节之前，得先了解大部分哈希函数（包括 MD5、SHA-1、SHA-256）的通用设计蓝图——<strong>Merkle–Damgård 结构</strong>。</p><p>这结构思想很简单：既然我一次性处理不了无限长的数据，那我把它切成一块一块的，不就行了？</p><p>它就像一个链式反应炉：</p><ol><li>把你的输入数据（比如”hello world”）切成固定大小的块（Block）。</li><li>定义一个初始的哈希值（IV - Initial Value），这可以看作是反应炉的”种子”。</li><li>把第一个数据块和”种子”一起扔进一个叫做”压缩函数（Compression Function）”的黑盒里。</li><li>这个黑盒会输出一个新的哈希值。</li><li>把这个新的哈希值作为新的”种子”，和下一个数据块一起，再次扔进那个黑盒里。</li><li>如此循环，直到最后一个数据块被处理完毕。</li><li>最后输出的那个哈希值，就是你整个数据的最终哈希结果。</li></ol><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    IV(初始哈希值) --&gt; C1(压缩函数);    B1(数据块1) --&gt; C1;    C1 --&gt; H1(中间哈希值1);    H1 --&gt; C2(压缩函数);    B2(数据块2) --&gt; C2;    C2 --&gt; H2(中间哈希值2);    H2 --&gt; Cn(压缩函数);    Bn(数据块n) --&gt; Cn;    Cn --&gt; FinalHash(最终哈希值);    style IV fill:#f9f,stroke:#333,stroke-width:2px    style FinalHash fill:#ccf,stroke:#333,stroke-width:2px  </pre></div><p>这个结构的核心就是那个”压缩函数”。SHA-256 的所有魔法，都发生在这个函数里。</p><h2 id="SHA-256-的解剖过程"><a href="#SHA-256-的解剖过程" class="headerlink" title="SHA-256 的解剖过程"></a>SHA-256 的解剖过程</h2><p>现在，我们正式开始解剖 SHA-256。</p><h3 id="第一步：消息填充（Padding）"><a href="#第一步：消息填充（Padding）" class="headerlink" title="第一步：消息填充（Padding）"></a>第一步：消息填充（Padding）</h3><p>反应炉要求每个数据块大小都得一样，SHA-256 要求是 <strong>512 位（64 字节）</strong>。可我们的输入数据千奇百怪，怎么办？</p><p><strong>填充！</strong> 规则如下：</p><ol><li>在你的原始数据末尾，先补一个 <code>1</code>。</li><li>然后，一直补 <code>0</code>，直到消息的总长度距离”512的倍数”只差 64 位为止。</li><li>最后这 64 位，用来存放你<strong>原始数据</strong>的长度（用二进制表示）。</li></ol><p>举个例子，假设我们要哈希字符串 “abc”。</p><ul><li>“abc” 的 ASCII 编码是 <code>01100001 01100010 01100011</code>，共 24 位。</li><li><strong>补 1</strong>：变成 25 位。</li><li><strong>补 0</strong>：我们需要补到 <code>512 - 64 = 448</code> 位。所以要补 <code>448 - 25 = 423</code> 个 0。</li><li><strong>补长度</strong>：最后 64 位，填入原始长度 24 的二进制。</li></ul><p>这样一来，任何长度的输入，都会被处理成一个或多个精确的 512 位数据块。这个填充方案确保了不同长度的原始消息，不会产生相同的填充后消息。</p><h3 id="第二步：初始化哈希值（H）"><a href="#第二步：初始化哈希值（H）" class="headerlink" title="第二步：初始化哈希值（H）"></a>第二步：初始化哈希值（H）</h3><p>还记得上面说的”种子”吗？SHA-256 的”种子”是 8 个 32 位的整数，我们称之为 <code>H0</code> 到 <code>H7</code>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">H0 = 0x6a09e667</span><br><span class="line">H1 = 0xbb67ae85</span><br><span class="line">H2 = 0x3c6ef372</span><br><span class="line">H3 = 0xa54ff53a</span><br><span class="line">H4 = 0x510e527f</span><br><span class="line">H5 = 0x9b05688c</span><br><span class="line">H6 = 0x1f83d9ab</span><br><span class="line">H7 = 0x5be0cd19</span><br></pre></td></tr></table></figure><p>这些”魔法数字”可不是随便拍脑袋想的。它们是自然界最纯粹的 8 个素数（2, 3, 5, 7, 11, 13, 17, 19）的平方根的小数部分，取前 32 位。这么做的目的是为了消除任何可能的后门或人为偏见，保证其初始状态的”随机性”。</p><h3 id="第三步：处理数据块（核心压缩函数）"><a href="#第三步：处理数据块（核心压缩函数）" class="headerlink" title="第三步：处理数据块（核心压缩函数）"></a>第三步：处理数据块（核心压缩函数）</h3><p>终于到了最核心的部分。对于每一个 512 位的数据块，SHA-256 会执行一个包含 64 “轮”计算的循环。</p><p>在循环开始前，会先初始化 8 个”工作变量”，用当前的哈希值（对于第一个块，就是初始 H 值）来赋值：<br><code>a, b, c, d, e, f, g, h = H0, H1, H2, H3, H4, H5, H6, H7</code></p><p>然后，开始 64 轮的”搅拌”：</p><p><strong>1. 消息调度（Message Schedule）</strong></p><p>首先，SHA-256 不会直接用 512 位的数据块，而是会把它扩展成 64 个 32 位的”字”（word），我们称之为 <code>W[0]</code> 到 <code>W[63]</code>。</p><ul><li>前 16 个字 <code>W[0]</code> 到 <code>W[15]</code> 就是把 512 位数据块直接切开得到的。</li><li>后面的 48 个字 <code>W[16]</code> 到 <code>W[63]</code> 是通过一个公式，由前面的字生成的：<br><code>W[t] = σ1(W[t-2]) + W[t-7] + σ0(W[t-15]) + W[t-16]</code></li></ul><p>这里的 <code>σ0</code> 和 <code>σ1</code> 是一些”小魔法”，它们包含了按位<strong>循环右移（ROTR）</strong>和<strong>右移（SHR）</strong>操作。</p><ul><li><code>σ0(x) = ROTR(x, 7) ^ ROTR(x, 18) ^ SHR(x, 3)</code></li><li><code>σ1(x) = ROTR(x, 17) ^ ROTR(x, 19) ^ SHR(x, 10)</code><br>(注：<code>^</code> 是异或 XOR)</li></ul><p>这个过程的目的是<strong>制造雪崩效应</strong>。输入的微小变化，会通过这个扩展过程，迅速扩散到整个消息调度数组中。</p><p><strong>2. 64 轮循环</strong></p><p>接下来就是长达 64 轮的循环。在每一轮（我们称之为第 <code>t</code> 轮），都会进行如下计算：</p><p><code>T1 = h + Σ1(e) + Ch(e, f, g) + K[t] + W[t]</code><br><code>T2 = Σ0(a) + Maj(a, b, c)</code></p><p><code>h = g</code><br><code>g = f</code><br><code>f = e</code><br><code>e = d + T1</code><br><code>d = c</code><br><code>c = b</code><br><code>b = a</code><br><code>a = T1 + T2</code></p><p>是不是看着有点头大？我们拆解一下里面的”大魔法”：</p><ul><li><code>W[t]</code>: 上一步消息调度中生成的第 <code>t</code> 个字。</li><li><code>K[t]</code>: 第 <code>t</code> 轮的常量。和初始 H 值一样，这些也是”魔法数字”，来自前 64 个素数的立方根的小数部分。它们为每一轮的计算引入了不同的扰动。</li><li><code>Σ0(a)</code> 和 <code>Σ1(e)</code>: 又是两个循环移位和异或的组合，目的是进一步混淆数据。<ul><li><code>Σ0(a) = ROTR(a, 2) ^ ROTR(a, 13) ^ ROTR(a, 22)</code></li><li><code>Σ1(e) = ROTR(e, 6) ^ ROTR(e, 11) ^ ROTR(e, 25)</code></li></ul></li><li><code>Ch(e, f, g)</code>: “Choose” 函数。<code>Ch(e, f, g) = (e AND f) ^ ((NOT e) AND g)</code>。如果 <code>e</code> 的某一位是 1，则结果的对应位取 <code>f</code> 的，否则取 <code>g</code> 的。这引入了<strong>非线性</strong>。</li><li><code>Maj(a, b, c)</code>: “Majority” 函数。<code>Maj(a, b, c) = (a AND b) ^ (a AND c) ^ (b AND c)</code>。对每一位看 <code>a, b, c</code> 中哪一个（0 或 1）占多数，结果就取哪个。同样是为了引入非线性。</li></ul><p><strong>为什么要做这些奇怪的操作？</strong></p><p>所有这些眼花缭乱的移位、异或、与非操作，核心目的只有一个：<strong>混淆（Confusion）与扩散（Diffusion）</strong>。</p><ul><li><strong>混淆</strong>：让密钥（在这里是输入数据）和最终密文（哈希值）之间的关系变得尽可能复杂。<code>Ch</code>、<code>Maj</code> 等非线性函数是主力。</li><li><strong>扩散</strong>：输入数据的任何一点微小改动，都能迅速地、大范围地影响到输出的每一位。这就是所谓的”雪崩效应”。各种循环移位 <code>ROTR</code> 就是干这个的。</li></ul><p>这 64 轮疯狂”搅拌”之后，我们得到了 8 个新的 <code>a, b, c, d, e, f, g, h</code> 值。</p><h3 id="第四步：更新哈希值"><a href="#第四步：更新哈希值" class="headerlink" title="第四步：更新哈希值"></a>第四步：更新哈希值</h3><p>循环结束后，将这一轮计算得到的”工作变量”和该数据块处理之前的”哈希值”进行相加（模 2^32 加法）：</p><p><code>H0 = H0 + a</code><br><code>H1 = H1 + b</code><br><code>...</code><br><code>H7 = H7 + h</code></p><p>好了，一个数据块处理完毕。这个新生成的 <code>H0</code> 到 <code>H7</code>，将作为下一个数据块的”种子”，重复第三步。</p><h3 id="第五步：生成最终结果"><a href="#第五步：生成最终结果" class="headerlink" title="第五步：生成最终结果"></a>第五步：生成最终结果</h3><p>当所有的数据块都被处理完毕后，最后得到的 <code>H0</code> 到 <code>H7</code> 这 8 个 32 位整数，按顺序拼接在一起，就形成了最终的 256 位 SHA-256 哈希值。</p><p>大功告成！</p><h2 id="终极问题：为什么我们找不到碰撞？"><a href="#终极问题：为什么我们找不到碰撞？" class="headerlink" title="终极问题：为什么我们找不到碰撞？"></a>终极问题：为什么我们找不到碰撞？</h2><p>在理解了 SHA-256 的内部构造后，一个非常核心的问题浮出水面：”既然哈希函数的输入是无限的，输出是有限的，那必然存在碰撞。为什么我们还说它是安全的，而且找不到碰撞呢？”</p><p>这是一个绝佳的问题，它触及了哈希函数安全性的根基。要回答它，我们得从两个层面来看：<strong>理论层面</strong>和<strong>现实层面</strong>。</p><h3 id="理论上：碰撞必然存在（鸽巢原理）"><a href="#理论上：碰撞必然存在（鸽巢原理）" class="headerlink" title="理论上：碰撞必然存在（鸽巢原理）"></a>理论上：碰撞必然存在（鸽巢原理）</h3><p>首先，一个残酷但必须承认的事实是：<strong>哈希碰撞是 100% 存在的。</strong></p><p>这可以用一个我们初中就学过的数学知识来解释，叫”<strong>鸽巢原理</strong>“（Pigeonhole Principle）：如果你有 10 只鸽子，但只有 9 个鸽巢，那么无论你怎么放，至少有 1 个鸽巢里得挤着 2 只或更多的鸽子。</p><p>我们把这个原理套在 SHA-256 上：</p><ul><li><strong>鸽巢（输出空间）</strong>：SHA-256 的输出长度是固定的 256 位。所以，它能产生的不同哈希值的总数是 <code>2^256</code> 个。这是一个天文数字，但它是<strong>有限的</strong>。</li><li><strong>鸽子（输入空间）</strong>：哈希函数的输入可以是任意长度的数据。字符串 “a”、”b”、”hello world”、一部电影、整个互联网的数据…… 输入的可能性是<strong>无限的</strong>。</li></ul><p>好了，现在我们用一个<strong>有限</strong>的鸽巢，去装<strong>无限</strong>的鸽子。结果不言而喻：<strong>必然会有无数个不同的输入，最终挤在同一个哈希值的”鸽巢”里。</strong></p><p>所以，从理论上讲，绝对存在 <code>x != y</code>，但 <code>sha(x) = sha(y)</code>。我们管这种情况叫做”<strong>碰撞</strong>“（Collision）。</p><h3 id="现实中：为什么你就是找不到它"><a href="#现实中：为什么你就是找不到它" class="headerlink" title="现实中：为什么你就是找不到它"></a>现实中：为什么你就是找不到它</h3><p>既然碰撞必然存在，那为什么我们还每天放心地用着它，并认为它是安全的？</p><p>答案是：<strong>因为从理论上的”存在”，到实际上的”找到”，中间隔着一道名为”计算上不可行”的天堑。</strong></p><p>这道天堑，就是由 SHA-256 内部那些复杂的设计精心构建的。我们刚刚拆解的那些眼花缭乱的操作，就是为了达到这个目的：</p><p><strong>1. 雪崩效应（Avalanche Effect）</strong></p><p>这是最核心的一点。一个设计良好的哈希算法，输入的任何一点微小变化（哪怕只改动 1 个 bit），都会导致输出结果天翻地覆、完全不同（理想情况下会有一半的 bit 位发生反转）。</p><p>这意味着什么？</p><ul><li><strong>没有规律可循</strong>：你无法通过观察 <code>hash(&quot;abc&quot;)</code> 和 <code>hash(&quot;abd&quot;)</code> 的结果，来推测如何修改输入才能让它们的哈希值更”接近”。两个结果之间看起来是完全随机的关系。</li><li><strong>无法”逼近”目标</strong>：寻找碰撞不是一个可以逐步优化的过程。你不能像猜数字游戏那样，根据”大了”或”小了”来调整下一次猜测。每一次尝试都是一次独立的、全新的”盲猜”。</li></ul><p>这让寻找碰撞变成了一场纯粹的、暴力的、运气差到极点的”抽奖”。</p><p><strong>2. 非线性操作（Non-linearity）</strong></p><p>我们刚刚分析过的 <code>Ch</code> (Choose) 和 <code>Maj</code> (Majority) 函数是关键。如果整个哈希过程都是线性的（比如只有加法、异或、移位），那密码学家就可以构建一套巨大的线性方程组，然后用计算机”解方程”的方式来找到碰撞。</p><p>但这些非线性函数的引入，彻底打乱了这种可能性。它让整个系统变得无法用简单的数学方程来描述和求解。就好像你没法通过分析一块蛋糕的成分，来精确反推出烤箱的温度和烘焙时间一样。</p><p><strong>3. 生日攻击（Birthday Attack）与恐怖的 <code>2^128</code></strong></p><p>黑客们也不是只会”盲猜”。他们能用的最有效的寻找碰撞的捷径，叫做”<strong>生日攻击</strong>“。</p><p>这个名字来源于”生日悖论”：一个 23 人的房间里，有两个人同一天生日的概率就超过了 50%。这比直觉要高得多。</p><p>应用到哈希碰撞上：我们不需要尝试 <code>2^256</code> 次才能找到一个碰撞。根据概率学，我们只需要计算大约 <code>sqrt(2^256) = 2^128</code> 个不同输入的哈希值，就有很大概率在这些结果中找到一对碰撞。</p><p><code>2^128</code> 次！这看起来比 <code>2^256</code> 小多了，对吧？</p><p>但它依然是个无法想象的数字。这么说吧：</p><blockquote><p>假设你拥有当前地球上最强的算力，用全世界所有的计算机一起来算。要想完成 <code>2^128</code> 次 SHA-256 计算，所需要的时间，可能比宇宙的年龄（约 138 亿年）还要长得多得多。</p></blockquote><p>这就是我们说它”<strong>计算上不可行</strong>“（Computationally Infeasible）的真正含义。它在理论上可行，但在可预见的未来，以人类已知的任何技术，都无法完成。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我们再回顾一下这趟旅程：</p><ol><li><strong>打包行李（填充）</strong>：把任意长度的数据，按照严格规定打包成一或多个 512 位的行李箱。</li><li><strong>设定起点（初始H值）</strong>：拿出密码学家给我们的、源于素数平方根的”魔法数字”作为起点。</li><li><strong>循环搅拌（压缩函数）</strong>：对每一个行李箱，都用一套包含 64 道工序的复杂流程（消息调度、移位、异或、非线性函数）进行搅拌，并把搅拌结果和上一轮的结果混合。</li><li><strong>得出终点（最终哈希）</strong>：当所有行李箱都搅拌完毕，最后输出的结果就是最终的哈希值。</li></ol><p>这套流程被设计得如此复杂和精妙，充满了各种非线性和扩散操作，目的就是为了让它成为一个真正的”单向”过程，让任何试图从结果反推输入的努力，都淹没在计算量的汪洋大海之中。</p><p>而正是因为这种”计算上不可行”的特性，我们才能在理论上承认碰撞必然存在的同时，在现实中放心地依赖 SHA-256 来确保数据的完整性。我们不是在和数学博弈，我们是在和宇宙的物理定律、能量和时间本身博弈。</p><p>现在，当你再在代码里调用 <code>sha256(data)</code> 时，希望你能会心一笑，因为你已经知道了这台”搅拌机”内部的秘密。 </p><h2 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h2><p>如果你想亲眼看看哈希的计算过程，其实有一个在线可视化网站：<a href="https://sha256algorithm.com/%EF%BC%8C%E5%8F%AF%E4%BB%A5%E6%8F%90%E4%BE%9B">https://sha256algorithm.com/，可以提供</a> sha256的全过程展示，非常的直观。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 哈希 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聊聊双重检查锁定（Double-Checked Locking）这点事</title>
      <link href="/2025/06/17/%E8%AF%A6%E7%BB%86%E8%AF%B4%E8%AF%B4%E5%8F%8C%E9%87%8D%E6%A3%80%E6%9F%A5%E9%94%81%E5%AE%9A/"/>
      <url>/2025/06/17/%E8%AF%A6%E7%BB%86%E8%AF%B4%E8%AF%B4%E5%8F%8C%E9%87%8D%E6%A3%80%E6%9F%A5%E9%94%81%E5%AE%9A/</url>
      
        <content type="html"><![CDATA[<p>在多线程编程中，我们经常需要延迟初始化（Lazy Initialization）某个对象，特别是在实现单例模式时。最简单粗暴的方法当然是直接上 <code>synchronized</code>，但由此带来的性能问题也让我们不得不寻找更优的方案。今天，我们就来深入聊聊大名鼎鼎的双重检查锁定（Double-Checked Locking, DCL），看看它到底牛在哪里，又有哪些坑需要我们注意。</p><h3 id="问题在哪？无脑-synchronized-的性能瓶颈"><a href="#问题在哪？无脑-synchronized-的性能瓶颈" class="headerlink" title="问题在哪？无脑 synchronized 的性能瓶颈"></a>问题在哪？无脑 <code>synchronized</code> 的性能瓶颈</h3><p>咱们先看一个最直观的单例实现：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 直接在方法上加锁</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">            instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>代码简单明了，<code>synchronized</code> 关键字确保了 <code>getInstance()</code> 方法在同一时间只会被一个线程执行，从而保证了线程安全。</p><p>但问题也随之而来。<code>synchronized</code> 是一把”重锁”，一旦实例被创建之后，实际上我们不再需要任何同步了，因为 <code>instance</code> 不再是 <code>null</code>，后续的所有 <code>if</code> 判断都是 <code>false</code>，直接返回即可。可 <code>synchronized</code> 会让所有调用 <code>getInstance()</code> 的线程，无论实例是否已创建，都得排队等待获取锁。在高并发场景下，这里会成为一个巨大的性能瓶颈，大量的线程都在做无意义的等待。</p><h3 id="更聪明的玩法：双重检查锁定（DCL）"><a href="#更聪明的玩法：双重检查锁定（DCL）" class="headerlink" title="更聪明的玩法：双重检查锁定（DCL）"></a>更聪明的玩法：双重检查锁定（DCL）</h3><p>为了解决上述问题，前辈们想出了一个更巧妙的办法——双重检查锁定。它的核心思想是：<strong>只有在实例未被创建时才进行同步，一旦创建成功，就再也不用锁了。</strong></p><p>直接上代码：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">    <span class="comment">// 关键点1: volatile</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">volatile</span> Singleton instance;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// 关键点2: 第一次检查（无锁）</span></span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 关键点3: 同步块</span></span><br><span class="line">            <span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">                <span class="comment">// 关键点4: 第二次检查（有锁）</span></span><br><span class="line">                <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;</span><br><span class="line">                    instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个实现看起来复杂了一些，但逻辑非常清晰：</p><ol><li><strong>第一次检查（无锁）</strong>：<code>if (instance == null)</code>。这是一个无锁的读操作。如果实例已经存在，线程就直接返回，完全避免了锁的开销。这是 DCL 高性能的关键。</li><li><strong>同步块</strong>：只有当 <code>instance</code> 为 <code>null</code> 时，线程才会尝试进入 <code>synchronized</code> 代码块。这确保了同一时间只有一个线程能执行实例的创建逻辑。</li><li><strong>第二次检查（有锁）</strong>：<code>if (instance == null)</code>。这是 DCL 的精髓所在。它防止了多个线程在第一次检查都通过后，重复创建实例。</li></ol><p>你可能会问，既然外面已经检查过一次了，为什么进了同步块还要再检查一次？</p><p>想象一下这个场景：线程 A 和 B 同时执行到第一次检查，都发现 <code>instance</code> 是 <code>null</code>。它们都想进入同步块，假设线程 A 抢到了锁，进入代码块，创建了实例，然后释放锁。此时线程 B 拿到了锁，如果同步块里没有第二层检查，线程 B 就会毫不知情地再次创建一个新的实例，这就破坏了单例的初衷。第二次检查正是为了防止这种情况发生。</p><p>下面这个流程图能帮你更好地理解这个过程：</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[开始] --&gt; B{instance &#x3D;&#x3D; null?}    B --&gt;|否| G[返回实例]    B --&gt;|是| C[进入同步块]    C --&gt; D{instance &#x3D;&#x3D; null?}    D --&gt;|否| E[退出同步块]    D --&gt;|是| F[创建新实例]    F --&gt; E    E --&gt; G  </pre></div><h3 id="灵魂拷问：volatile-到底在干嘛？"><a href="#灵魂拷问：volatile-到底在干嘛？" class="headerlink" title="灵魂拷问：volatile 到底在干嘛？"></a>灵魂拷问：<code>volatile</code> 到底在干嘛？</h3><p>在 DCL 的实现中，<code>volatile</code> 关键字是绝对不能少的。如果少了它，看似正常的代码在多线程环境下可能会出现致命问题。这就要提到 JVM 的<strong>指令重排序</strong>了。</p><p><code>instance = new Singleton()</code> 这行代码，在我们看来是一步操作，但在 JVM 内部，它大致分为三个步骤：</p><ol><li><strong>分配内存</strong>：为 <code>Singleton</code> 对象分配一块内存空间。</li><li><strong>初始化对象</strong>：调用 <code>Singleton</code> 的构造函数，对对象进行初始化。</li><li><strong>建立连接</strong>：将 <code>instance</code> 引用指向分配好的内存地址。</li></ol><p>正常情况下，顺序是 <code>1 -&gt; 2 -&gt; 3</code>。但为了性能优化，JVM 可能会对指令进行重排序，把顺序变成 <code>1 -&gt; 3 -&gt; 2</code>。</p><p>这时候问题就来了：</p><ol><li>线程 A 执行 <code>instance = new Singleton()</code>。</li><li>由于指令重排序，JVM 先执行了步骤 1 和 3，<code>instance</code> 引用被赋值，不再是 <code>null</code>。</li><li>此时，线程 B 调用 <code>getInstance()</code>，执行第一次检查 <code>if (instance == null)</code>。它会发现 <code>instance</code> 已经不是 <code>null</code> 了，于是直接返回 <code>instance</code>。</li><li>但实际上，线程 A 的步骤 2 (初始化对象) 还没执行完。线程 B 拿到的 <code>instance</code> 是一个<strong>未完全初始化的对象</strong>。如果此时去使用这个对象，就可能引发各种诡异的错误。</li></ol><p>而 <code>volatile</code> 关键字有两大作用：</p><ol><li><strong>禁止指令重排序</strong>：确保 <code>instance = new Singleton()</code> 的操作按照 <code>1 -&gt; 2 -&gt; 3</code> 的顺序执行，不会出现上面那种”半成品”对象的情况。</li><li><strong>保证可见性</strong>：当一个线程修改了 <code>instance</code> 的值，这个新值会立刻对其他线程可见。</li></ol><p>所以，<code>volatile</code> 是确保 DCL 线程安全的最后一道，也是最关键的一道防线。</p><h3 id="还有没有更好的选择？"><a href="#还有没有更好的选择？" class="headerlink" title="还有没有更好的选择？"></a>还有没有更好的选择？</h3><p>当然有！DCL 虽然高效，但写法相对复杂，容易出错。在现代 Java 中，我们有更简洁、更安全的实现方式。</p><h4 id="静态内部类（Lazy-Initialization-Holder-Class）"><a href="#静态内部类（Lazy-Initialization-Holder-Class）" class="headerlink" title="静态内部类（Lazy Initialization Holder Class）"></a>静态内部类（Lazy Initialization Holder Class）</h4><p>这是目前最受推荐的单例实现方式之一。它利用了 JVM 类加载机制来保证线程安全。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">    <span class="comment">// 私有构造</span></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 静态内部类</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">class</span> <span class="title class_">Holder</span> &#123;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Singleton</span> <span class="variable">INSTANCE</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Singleton</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> Holder.INSTANCE;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>当 <code>getInstance()</code> 方法第一次被调用时，<code>Holder</code> 类才会被加载，此时 JVM 会保证 <code>INSTANCE</code> 只被初始化一次，并且这个过程是线程安全的。这种方式既实现了懒加载，又无需任何同步锁，代码也更简单。</p><h4 id="枚举单例"><a href="#枚举单例" class="headerlink" title="枚举单例"></a>枚举单例</h4><p>这是《Effective Java》作者 Joshua Bloch 极力推崇的方式。它不仅写法超级简单，还能天然防止反射和反序列化攻击。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">enum</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">    INSTANCE;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">someMethod</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="comment">// ...</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>调用时直接使用 <code>Singleton.INSTANCE</code> 即可。如果你不需要懒加载，这无疑是最佳选择。</p><h3 id="总结一下"><a href="#总结一下" class="headerlink" title="总结一下"></a>总结一下</h3><p>我们来对比一下这几种方案的优劣：</p><table><thead><tr><th>方案</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td><strong>直接 <code>synchronized</code></strong></td><td>实现简单，绝对线程安全</td><td>性能差，无论是否需要都会加锁</td></tr><tr><td><strong>双重检查锁定 (DCL)</strong></td><td>性能高，只在首次初始化时加锁</td><td>写法复杂，必须正确使用 <code>volatile</code></td></tr><tr><td><strong>静态内部类</strong></td><td>无锁、线程安全、写法简单、懒加载</td><td>相对DCL代码稍多一点</td></tr><tr><td><strong>枚举单例</strong></td><td>极简、防反射、防序列化</td><td>非懒加载</td></tr></tbody></table><p>总的来说，双重检查锁定（DCL）是一个在特定场景下（例如需要懒加载且追求极致性能）非常经典的解决方案，但我们必须深刻理解其背后的 <code>volatile</code> 和指令重排序原理，才能正确地使用它。</p><p>不过，在大多数情况下，<strong>静态内部类</strong>和<strong>枚举</strong>通常是更推荐、更安全的选择。作为开发者，了解 DCL 不仅是为了在面试中脱颖而出，更是为了加深我们对并发编程底层原理的理解。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 并发 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解密 Spring MVC：从 Tomcat 到 Controller 的一次完整请求之旅</title>
      <link href="/2025/06/17/%E8%A7%A3%E5%AF%86%20Spring%20MVC%EF%BC%9A%E4%BB%8E%20Tomcat%20%E5%88%B0%20Controller%20%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E8%AF%B7%E6%B1%82%E4%B9%8B%E6%97%85/"/>
      <url>/2025/06/17/%E8%A7%A3%E5%AF%86%20Spring%20MVC%EF%BC%9A%E4%BB%8E%20Tomcat%20%E5%88%B0%20Controller%20%E7%9A%84%E4%B8%80%E6%AC%A1%E5%AE%8C%E6%95%B4%E8%AF%B7%E6%B1%82%E4%B9%8B%E6%97%85/</url>
      
        <content type="html"><![CDATA[<h1 id="解密-Spring-MVC：从-Tomcat-到-Controller-的一次完整请求之旅"><a href="#解密-Spring-MVC：从-Tomcat-到-Controller-的一次完整请求之旅" class="headerlink" title="解密 Spring MVC：从 Tomcat 到 Controller 的一次完整请求之旅"></a>解密 Spring MVC：从 Tomcat 到 Controller 的一次完整请求之旅</h1><p>今天，想和你聊一个我们每天都在打交道，但可能不曾深入思考的话题：当一个 HTTP 请求从浏览器发出，到最终被我们的 Spring Controller 处理，它到底经历了一场怎样的旅程？</p><p>理解这个流程，不仅仅是为了应付面试，更是为了在遇到棘手问题时，能像庖丁解牛一样，精准定位问题所在。这趟旅程，我们可以清晰地划分为两大站：<strong>Tomcat 处理阶段</strong>和 <strong>Spring MVC 处理阶段</strong>。</p><hr><h2 id="第一站：Tomcat-的守门与引导"><a href="#第一站：Tomcat-的守门与引导" class="headerlink" title="第一站：Tomcat 的守门与引导"></a>第一站：Tomcat 的守门与引导</h2><p>在请求进入 Spring 的世界之前，Tomcat 作为”前哨站”，需要完成一系列的接待和引导工作。</p><h3 id="1-门口的接待员：Connector"><a href="#1-门口的接待员：Connector" class="headerlink" title="1. 门口的接待员：Connector"></a>1. 门口的接待员：Connector</h3><p>当一个请求，比如 <code>http://localhost:8080/user/info</code>，敲响 8080 端口的大门时，Tomcat 的 <strong>Connector</strong> 组件第一个站出来迎接。它的职责就是监听网络端口，接收原始的 TCP 连接，并将其解析成一个标准的 <code>HttpServletRequest</code> 对象。</p><p>同时，为了高效处理并发，Tomcat 会从一个线程池（比如 <code>http-nio-8080-exec-1</code>）中取出一个工作线程，专门为这个请求服务，直到响应完成。</p><h3 id="2-容器的层层路由"><a href="#2-容器的层层路由" class="headerlink" title="2. 容器的层层路由"></a>2. 容器的层层路由</h3><p>请求对象创建好后，就进入了 Tomcat 的容器内部。这个过程就像一个俄罗斯套娃，请求会依次经过 <code>Engine</code> → <code>Host</code> → <code>Context</code> → <code>Wrapper</code> 这几层。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 伪代码：感受一下这个调用链</span></span><br><span class="line">connector.getService().getContainer().getPipeline().getFirst().invoke(request, response);</span><br></pre></td></tr></table></figure><ul><li><strong>Engine</strong>: 全局引擎，服务于整个 Tomcat 实例。</li><li><strong>Host</strong>: 虚拟主机，对应一个域名，比如 <code>localhost</code>。</li><li><strong>Context</strong>: Web 应用，对应我们的项目。Tomcat 在这里根据 <code>/</code> 之后的 URL 路径，匹配到处理该路径的 <code>Context</code>。</li><li><strong>Wrapper</strong>: Servlet 包装器。最终，<code>Context</code> 会根据 <code>web.xml</code> 中配置的 <code>servlet-mapping</code>，找到处理这个请求的最终 Servlet。在 Spring Boot 应用中，这个 Servlet 通常就是大名鼎鼎的 <code>DispatcherServlet</code>。</li></ul><h3 id="3-第一道安检：过滤器链-Filter-Chain"><a href="#3-第一道安检：过滤器链-Filter-Chain" class="headerlink" title="3. 第一道安检：过滤器链 (Filter Chain)"></a>3. 第一道安检：过滤器链 (Filter Chain)</h3><p>在请求被正式交给 <code>DispatcherServlet</code> 之前，它必须先通过一系列”安检”——这就是<strong>过滤器（Filter）</strong>。</p><p>过滤器是 Servlet 规范的一部分，像一道道关卡，按顺序执行。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 过滤器链执行伪代码</span></span><br><span class="line"><span class="comment">// 只有当所有 Filter 都放行，请求才会最终到达 Servlet</span></span><br><span class="line"><span class="keyword">for</span> (Filter filter : filters) &#123;</span><br><span class="line">    filter.doFilter(request, response, chain);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 链的末端，触发 Servlet 的 service 方法</span></span><br><span class="line">chain.doFilter(request, response);</span><br></pre></td></tr></table></figure><p><strong>实战场景</strong>:</p><ul><li><code>CharacterEncodingFilter</code>: 确保全站请求和响应的字符集统一，防止乱码。</li><li><code>CorsFilter</code>: 解决跨域问题，允许特定来源的前端应用访问。</li><li>自定义的 <code>JwtAuthFilter</code>: 对受保护的 API 进行身份验证，解析 Token，并将用户信息存入 <code>SecurityContext</code>。</li><li><code>LoggingFilter</code>: 记录所有请求的详细日志，便于审计和调试。</li></ul><p>只有通过了所有过滤器的”盘问”，请求才算完成了在 Tomcat 阶段的旅程，正式敲响了 Spring MVC 的大门。</p><hr><h2 id="第二站：Spring-MVC-的调度中心-DispatcherServlet"><a href="#第二站：Spring-MVC-的调度中心-DispatcherServlet" class="headerlink" title="第二站：Spring MVC 的调度中心 - DispatcherServlet"></a>第二站：Spring MVC 的调度中心 - DispatcherServlet</h2><p><code>DispatcherServlet</code> 是 Spring MVC 的绝对核心，堪称”中央调度员”。它接管请求后，会在其 <code>doDispatch</code> 方法内， orchestrate（精心安排）后续所有操作。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// DispatcherServlet.doDispatch 精简核心逻辑</span></span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">doDispatch</span><span class="params">(HttpServletRequest request, HttpServletResponse response)</span> &#123;</span><br><span class="line">    <span class="comment">// 1. 根据请求查找 Handler（即 Controller 方法）</span></span><br><span class="line">    <span class="type">HandlerExecutionChain</span> <span class="variable">mappedHandler</span> <span class="operator">=</span> getHandler(request);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2. 获取能执行这个 Handler 的适配器 HandlerAdapter</span></span><br><span class="line">    <span class="type">HandlerAdapter</span> <span class="variable">ha</span> <span class="operator">=</span> getHandlerAdapter(mappedHandler.getHandler());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3. 执行拦截器的 preHandle() 方法，这是进入 Controller 前的最后一道关卡</span></span><br><span class="line">    <span class="keyword">if</span> (!mappedHandler.applyPreHandle(request, response)) &#123;</span><br><span class="line">        <span class="keyword">return</span>; <span class="comment">// 如果 preHandle 返回 false，请求被中断</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4. 真正调用 Controller 方法</span></span><br><span class="line">    <span class="type">ModelAndView</span> <span class="variable">mv</span> <span class="operator">=</span> ha.handle(request, response, mappedHandler.getHandler());</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 5. 执行拦截器的 postHandle() 方法</span></span><br><span class="line">    mappedHandler.applyPostHandle(request, response, mv);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 6. 处理派发结果（如渲染视图或处理异常）</span></span><br><span class="line">    processDispatchResult(request, response, mappedHandler, mv, <span class="literal">null</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>让我们一步步拆解这个过程：</p><h3 id="1-HandlerMapping：找到对的人"><a href="#1-HandlerMapping：找到对的人" class="headerlink" title="1. HandlerMapping：找到对的人"></a>1. HandlerMapping：找到对的人</h3><p><code>DispatcherServlet</code> 首先会询问 <code>HandlerMapping</code>：”嘿，这个 URL (<code>/user/info</code>) 应该由哪个 Controller 的哪个方法来处理？”。<br><code>RequestMappingHandlerMapping</code> 会扫描所有被 <code>@RequestMapping</code>、<code>@GetMapping</code> 等注解标记的方法，构建一个 URL 与 <code>HandlerMethod</code> 的映射关系，然后精准地找到匹配项。</p><h3 id="2-Interceptor-preHandle：Controller-前的最后机会"><a href="#2-Interceptor-preHandle：Controller-前的最后机会" class="headerlink" title="2. Interceptor preHandle：Controller 前的最后机会"></a>2. Interceptor preHandle：Controller 前的最后机会</h3><p>找到目标 <code>Controller</code> 方法后，并不会立刻执行。而是先执行所有匹配该路径的<strong>拦截器（Interceptor）</strong>的 <code>preHandle</code> 方法。</p><p>这是一个关键的切入点。<code>preHandle</code> 返回 <code>true</code> 则放行，返回 <code>false</code> 则请求被直接中断。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 拦截器 preHandle 示例</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">preHandle</span><span class="params">(HttpServletRequest request, HttpServletResponse response, Object handler)</span> &#123;</span><br><span class="line">    <span class="comment">// 比如，进行更细粒度的权限校验</span></span><br><span class="line">    <span class="keyword">if</span> (!checkAuth(request, handler)) &#123; <span class="comment">// 甚至可以拿到 handler 信息做更复杂的判断</span></span><br><span class="line">        response.sendError(<span class="number">403</span>, <span class="string">&quot;权限不足&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>; <span class="comment">// 中断请求</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>; <span class="comment">// 放行</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="3-参数解析与-Controller-方法执行"><a href="#3-参数解析与-Controller-方法执行" class="headerlink" title="3. 参数解析与 Controller 方法执行"></a>3. 参数解析与 Controller 方法执行</h3><p>通过了所有拦截器的 <code>preHandle</code> 后，<code>HandlerAdapter</code> 开始工作。它会借助 <code>HandlerMethodArgumentResolver</code> 等一系列”参数解析器”，神奇地将 HTTP 请求中的各种信息（如 <code>@RequestBody</code> 的 JSON、<code>@RequestParam</code> 的查询参数、<code>@PathVariable</code> 的路径变量）转换并注入到你 <code>Controller</code> 方法的参数列表中。</p><p>然后，通过<strong>反射</strong>，你的 <code>Controller</code> 方法终于被执行了！</p><h3 id="4-AOP-切面：无感知的逻辑增强"><a href="#4-AOP-切面：无感知的逻辑增强" class="headerlink" title="4. AOP 切面：无感知的逻辑增强"></a>4. AOP 切面：无感知的逻辑增强</h3><p>就在你的 <code>Controller</code> 方法执行前后，AOP（面向切面编程）可能会”神不知鬼不觉”地介入。如果你的方法上加了 <code>@Transactional</code>、<code>@Cacheable</code> 或是自定义的 AOP 注解，那么相关的切面逻辑（如环绕通知）会在这里执行。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 环绕通知示例：在 Controller 方法执行前后织入逻辑</span></span><br><span class="line"><span class="meta">@Around(&quot;@annotation(com.example.MyCustomLog)&quot;)</span></span><br><span class="line"><span class="keyword">public</span> Object <span class="title function_">logExecutionTime</span><span class="params">(ProceedingJoinPoint joinPoint)</span> <span class="keyword">throws</span> Throwable &#123;</span><br><span class="line">    <span class="type">long</span> <span class="variable">start</span> <span class="operator">=</span> System.currentTimeMillis();</span><br><span class="line">    <span class="comment">// 执行 Controller 方法</span></span><br><span class="line">    <span class="type">Object</span> <span class="variable">result</span> <span class="operator">=</span> joinPoint.proceed();</span><br><span class="line">    <span class="type">long</span> <span class="variable">duration</span> <span class="operator">=</span> System.currentTimeMillis() - start;</span><br><span class="line">    log.info(<span class="string">&quot;&#123;&#125; 执行耗时: &#123;&#125; ms&quot;</span>, joinPoint.getSignature(), duration);</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>AOP 的美妙之处在于，它让你的业务代码保持纯净，同时又能附加额外的通用功能。</p><h3 id="5-Interceptor-postHandle-视图渲染"><a href="#5-Interceptor-postHandle-视图渲染" class="headerlink" title="5. Interceptor postHandle &amp; 视图渲染"></a>5. Interceptor postHandle &amp; 视图渲染</h3><p>Controller 方法执行完毕，并返回了一个结果（比如一个 <code>ModelAndView</code> 对象或者一个被 <code>@ResponseBody</code> 标记的对象）。<br>此时，拦截器的 <code>postHandle</code> 方法会被调用。你可以在这里对 <code>ModelAndView</code> 进行修改，或者在响应提交前做一些额外操作。</p><p>如果返回的是 <code>ModelAndView</code>，<code>DispatcherServlet</code> 会通过 <code>ViewResolver</code>（视图解析器）找到对应的视图模板（如 Thymeleaf 或 JSP），并用模型数据进行渲染，最终生成 HTML 响应。</p><h3 id="6-Interceptor-afterCompletion：最后的清理工作"><a href="#6-Interceptor-afterCompletion：最后的清理工作" class="headerlink" title="6. Interceptor afterCompletion：最后的清理工作"></a>6. Interceptor afterCompletion：最后的清理工作</h3><p>无论请求处理过程中是否发生异常，只要它经过了拦截器的 <code>preHandle</code> 并返回 <code>true</code>，那么在整个请求完成（视图渲染完毕或响应已提交）后，拦截器的 <code>afterCompletion</code> 方法就一定会被调用。</p><p>这里是执行资源清理工作的最佳地点，比如清理线程绑定的变量等。</p><hr><h2 id="全景图：一张图看懂执行顺序"><a href="#全景图：一张图看懂执行顺序" class="headerlink" title="全景图：一张图看懂执行顺序"></a>全景图：一张图看懂执行顺序</h2><p>为了更直观地理解整个流程，我为你绘制了一张流程图：</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD;    subgraph &quot;客户端&quot;        A[发起 HTTP 请求]    end    subgraph &quot;Tomcat 服务器&quot;        A --&gt; B(Connector 监听端口);        B --&gt; C{线程池分配线程};        C --&gt; D[Tomcat 容器路由];        D --&gt; E(过滤器链 Filter Chain);    end    subgraph &quot;Spring MVC 框架&quot;        E --&gt; F(DispatcherServlet);        F -- 1. 查找 Handler --&gt; G{HandlerMapping};        G -- 2. 获得 HandlerExecutionChain --&gt; H(拦截器 preHandle);        H -- 3. 放行 --&gt; I{参数解析&#x2F;AOP};        I -- 4. 调用 --&gt; J[Controller 方法执行];        J -- 5. 返回 ModelAndView&#x2F;结果 --&gt; K(拦截器 postHandle);        K -- 6. 视图处理 --&gt; L{视图渲染 ViewResolver};        L -- 7. 响应完成后 --&gt; M(拦截器 afterCompletion);    end    subgraph &quot;响应&quot;        M --&gt; N[返回 HTTP 响应];    end    style F fill:#f9f,stroke:#333,stroke-width:2px    style J fill:#ccf,stroke:#333,stroke-width:2px  </pre></div><p><strong>调试技巧</strong>：在 <code>DispatcherServlet</code> 的 <code>doDispatch</code> 方法里打上一个断点，然后单步调试。你会清晰地看到 <code>getHandler</code>、<code>applyPreHandle</code>、<code>ha.handle</code> 等关键步骤的调用过程，这是理解整个流程最快的方式。</p><hr><h2 id="实战排雷：常见问题与调试技巧"><a href="#实战排雷：常见问题与调试技巧" class="headerlink" title="实战排雷：常见问题与调试技巧"></a>实战排雷：常见问题与调试技巧</h2><h3 id="1-灵魂拷问：Filter-vs-Interceptor？"><a href="#1-灵魂拷问：Filter-vs-Interceptor？" class="headerlink" title="1. 灵魂拷问：Filter vs. Interceptor？"></a>1. 灵魂拷问：Filter vs. Interceptor？</h3><p>这是个老生常谈但至关重要的问题。</p><table><thead><tr><th align="left">特性</th><th align="left">过滤器 (Filter)</th><th align="left">拦截器 (Interceptor)</th></tr></thead><tbody><tr><td align="left"><strong>出身</strong></td><td align="left">Servlet 规范，J2EE 标准，任何 Web 框架都能用</td><td align="left">Spring MVC 框架特有，高度集成于 Spring 上下文</td></tr><tr><td align="left"><strong>执行时机</strong></td><td align="left">在 <code>DispatcherServlet</code> 之前，无法触及 Controller</td><td align="left">在 <code>DispatcherServlet</code> 之后，Controller 执行前后</td></tr><tr><td align="left"><strong>依赖注入</strong></td><td align="left">默认不支持 <code>@Autowired</code>，需特殊配置（如 <code>FilterRegistrationBean</code>）</td><td align="left">由 Spring IoC 容器管理，可直接 <code>@Autowired</code> 注入任何 Bean</td></tr><tr><td align="left"><strong>能力范围</strong></td><td align="left">能处理所有进入 Tomcat 的请求，包括静态资源</td><td align="left">只能拦截进入 <code>DispatcherServlet</code> 的请求</td></tr><tr><td align="left"><strong>获取信息</strong></td><td align="left">无法直接获取即将执行的 Controller 方法信息</td><td align="left">可以获取 <code>HandlerMethod</code>，知道具体是哪个方法在处理</td></tr></tbody></table><p><strong>一句话总结</strong>：<code>Filter</code> 是粗粒度的全局”门卫”，适合做认证、编码等通用工作；<code>Interceptor</code> 是细粒度的”警卫”，适合做权限、日志等与业务逻辑相关的校验。</p><h3 id="2-为何静态资源不经过我的拦截器？"><a href="#2-为何静态资源不经过我的拦截器？" class="headerlink" title="2. 为何静态资源不经过我的拦截器？"></a>2. 为何静态资源不经过我的拦截器？</h3><p>因为 Spring Boot 默认配置下，对于 <code>/static</code>、<code>/public</code> 等目录下的静态资源请求，会由一个名为 <code>DefaultServletHttpRequestHandler</code> 的处理器直接处理，它会绕过 <code>DispatcherServlet</code>，直接将资源以流的形式返回。因此，你的拦截器自然也就不会被触发。</p><h3 id="3-如何优雅地跳过某些路径的拦截器？"><a href="#3-如何优雅地跳过某些路径的拦截器？" class="headerlink" title="3. 如何优雅地跳过某些路径的拦截器？"></a>3. 如何优雅地跳过某些路径的拦截器？</h3><p>在配置拦截器时，使用 <code>excludePathPatterns</code> 方法。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">WebMvcConfig</span> <span class="keyword">implements</span> <span class="title class_">WebMvcConfigurer</span> &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">addInterceptors</span><span class="params">(InterceptorRegistry registry)</span> &#123;</span><br><span class="line">        registry.addInterceptor(<span class="keyword">new</span> <span class="title class_">MyAuthInterceptor</span>())</span><br><span class="line">                .addPathPatterns(<span class="string">&quot;/**&quot;</span>) <span class="comment">// 拦截所有</span></span><br><span class="line">                .excludePathPatterns(<span class="string">&quot;/login&quot;</span>, <span class="string">&quot;/error&quot;</span>, <span class="string">&quot;/static/**&quot;</span>); <span class="comment">// 排除特定路径</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="4-如何捕获全局异常？"><a href="#4-如何捕获全局异常？" class="headerlink" title="4. 如何捕获全局异常？"></a>4. 如何捕获全局异常？</h3><p>使用 <code>@ControllerAdvice</code> 和 <code>@ExceptionHandler</code> 的组合拳，可以优雅地处理全局异常，避免 <code>try-catch</code> 遍地开花。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@ControllerAdvice</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GlobalExceptionHandler</span> &#123;</span><br><span class="line">    <span class="meta">@ExceptionHandler(Exception.class)</span></span><br><span class="line">    <span class="keyword">public</span> ResponseEntity&lt;String&gt; <span class="title function_">handleGenericException</span><span class="params">(Exception e)</span> &#123;</span><br><span class="line">        <span class="comment">// 记录日志</span></span><br><span class="line">        log.error(<span class="string">&quot;系统发生未知异常&quot;</span>, e);</span><br><span class="line">        <span class="comment">// 返回一个对用户友好的错误信息</span></span><br><span class="line">        <span class="keyword">return</span> ResponseEntity.status(<span class="number">500</span>).body(<span class="string">&quot;服务器开小差了，请稍后再试～&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@ExceptionHandler(IllegalArgumentException.class)</span></span><br><span class="line">    <span class="keyword">public</span> ResponseEntity&lt;String&gt; <span class="title function_">handleIllegalArgumentException</span><span class="params">(IllegalArgumentException e)</span> &#123;</span><br><span class="line">        <span class="keyword">return</span> ResponseEntity.status(<span class="number">400</span>).body(<span class="string">&quot;请求参数不合法: &quot;</span> + e.getMessage());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h2 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h2><p>好了，这次从 Tomcat 到 Controller 的请求之旅就到这里。我们一起梳理了其中的每一个关键节点和核心组件。</p><p>掌握这条核心路径，你就能：</p><ol><li><strong>清晰定位问题</strong>：到底是 Filter 拦了，还是 Interceptor 没过？是参数解析错了，还是 AOP 出了异常？</li><li><strong>优雅设计系统</strong>：合理地在 Filter、Interceptor、AOP、ControllerAdvice 中放置你的逻辑，让代码结构更清晰，职责更分明。</li><li><strong>提升性能</strong>：理解了流程，才能更好地进行性能分析和优化。</li></ol><p>这次的深度剖析，能让我们都对 Spring MVC 的请求处理有更深刻的理解，也是日常学习的一个记录📝。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring AOP 与循环依赖：揭秘提前暴露代理的底层原理</title>
      <link href="/2025/06/17/Spring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E4%B8%8EAOP/"/>
      <url>/2025/06/17/Spring%E5%BE%AA%E7%8E%AF%E4%BE%9D%E8%B5%96%E4%B8%8EAOP/</url>
      
        <content type="html"><![CDATA[<h3 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h3><p>在Spring开发中，AOP和循环依赖是两个我们经常打交道的话题。通常的认知是，Spring会在一个Bean完全初始化（属性填充、<code>init</code>方法执行完毕）之后，才为其创建AOP代理。但当一个需要被代理的Bean，恰好又陷入了循环依赖，情况就变得棘手起来：Spring必须在这个Bean尚未”完工”时，就将它暴露给依赖方。</p><p>这就带来一个很自然的问题：一个尚未完全初始化的Bean，如何能以它最终的代理形态被提前暴露？这样做不会有状态不一致的风险吗？本文将以开发者的视角，深入Spring内部，看看它是如何通过精妙的三级缓存设计，解决这个看似矛盾的问题的。</p><hr><h3 id="1-循环依赖的解决机制：三级缓存"><a href="#1-循环依赖的解决机制：三级缓存" class="headerlink" title="1. 循环依赖的解决机制：三级缓存"></a>1. <strong>循环依赖的解决机制：三级缓存</strong></h3><p>要理解循环依赖的解决方案，核心就是要弄懂Spring的三级缓存。这三级缓存，本质上是Spring在Bean生命周期中，为了管理不同状态的Bean实例而设的三层存储空间：</p><ol><li><strong>一级缓存（singletonObjects）</strong>：一个Map，存放的是<strong>完全初始化好</strong>的单例Bean。可以把它看作是”成品仓”，里面的Bean随时可以取用。</li><li><strong>二级缓存（earlySingletonObjects）</strong>：也是一个Map，存放的是<strong>提前暴露</strong>的单例Bean的早期引用。这些Bean已经实例化，但可能还没完成属性注入和初始化。它们是”半成品”，用于解开循环依赖。</li><li><strong>三级缓存（singletonFactories）</strong>：还是一个Map，但它存放的不是Bean，而是创建Bean的<strong>工厂</strong>（<code>ObjectFactory</code>）。这是解决AOP循环依赖的关键，当Bean需要被代理时，这个工厂负责创建出代理对象，而不是原始对象。</li></ol><p>当Bean A依赖Bean B，同时Bean B又依赖Bean A时，这个机制就开始运转：</p><ul><li>Spring在创建Bean A时，首先会实例化A，然后将一个能够创建A的早期引用（可能是代理）的<code>ObjectFactory</code>放入三级缓存。</li><li>接着Spring为A填充属性，发现它依赖B，于是去创建B。</li><li>在创建B的过程中，Spring发现B又依赖A，此时需要获取A。</li><li>Spring依次检查一级、二级缓存，都找不到A。最后在三级缓存中找到了A的<code>ObjectFactory</code>。</li><li>通过这个工厂，Spring创建出A的早期引用（如果需要AOP，此时就会生成代理对象），并将其放入二级缓存，然后从三级缓存中移除工厂。这个早期引用被注入到B中，B顺利完成初始化，并被放入一级缓存。</li><li>最后，Spring回到A的创建流程，将已经完成的B注入A，A也顺利完成初始化，最终被放入一级缓存。</li></ul><hr><h3 id="2-流程可视化"><a href="#2-流程可视化" class="headerlink" title="2. 流程可视化"></a>2. <strong>流程可视化</strong></h3><p>为了更直观地理解上述过程，尤其是AOP代理的创建时机，下面的流程图展示了完整的交互：</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  sequenceDiagram    participant Client as 客户端    participant Spring as Spring容器    participant L3Cache as &quot;三级缓存 (singletonFactories)&quot;    participant L2Cache as &quot;二级缓存 (earlySingletonObjects)&quot;    participant L1Cache as &quot;一级缓存 (singletonObjects)&quot;    participant InstanceA as &quot;Bean A 实例&quot;    participant InstanceB as &quot;Bean B 实例&quot;    Client-&gt;&gt;+Spring: getBean(&quot;a&quot;)    Spring-&gt;&gt;Spring: 1. 创建Bean A    Spring-&gt;&gt;InstanceA: new ServiceA()    Spring-&gt;&gt;L3Cache: 2. 放入A的ObjectFactory    Spring-&gt;&gt;Spring: 3. 填充A的属性 (发现依赖B)    Spring-&gt;&gt;+Spring: 4. getBean(&quot;b&quot;)    Spring-&gt;&gt;InstanceB: new ServiceB()    Spring-&gt;&gt;L3Cache: 5. 放入B的ObjectFactory    Spring-&gt;&gt;Spring: 6. 填充B的属性 (发现依赖A)    Spring-&gt;&gt;Spring: 7. 尝试获取Bean A (为B注入)    Spring-&gt;&gt;L1Cache: 检查&quot;a&quot; (未命中)    Spring-&gt;&gt;L2Cache: 检查&quot;a&quot; (未命中)    Spring-&gt;&gt;L3Cache: 检查&quot;a&quot; (命中, 获取ObjectFactory)    Spring-&gt;&gt;Spring: 8. 调用A的ObjectFactory.getObject()    Note right of Spring: 此刻通过getEarlyBeanReference&lt;br&gt;为A创建代理对象    Spring-&gt;&gt;L2Cache: 9. 将A的早期引用(代理)放入二级缓存    Spring-&gt;&gt;L3Cache: 从三级缓存移除A的Factory    Spring--&gt;&gt;InstanceB: 10. 将A的早期引用注入B    Spring-&gt;&gt;Spring: 11. 完成B的初始化    Spring-&gt;&gt;L1Cache: 12. 放入B的完整实例    Spring--&gt;&gt;Spring: 返回B的实例    Spring-&gt;&gt;InstanceA: 13. 将B实例注入A    Spring-&gt;&gt;Spring: 14. 完成A的初始化    Spring-&gt;&gt;L1Cache: 15. 放入A的完整实例(代理)    Spring--&gt;&gt;Client: 返回A的实例(代理)  </pre></div><hr><h3 id="3-为什么需要提前生成代理？"><a href="#3-为什么需要提前生成代理？" class="headerlink" title="3. 为什么需要提前生成代理？"></a>3. <strong>为什么需要提前生成代理？</strong></h3><p>我们已经清楚了三级缓存的流程，但一个关键问题是：为什么必须在这么早的阶段就创建代理对象？</p><p>原因很直接：<strong>为了保证依赖注入的一致性，防止AOP失效。</strong></p><p>设想一下，如果Spring在解决B对A的依赖时，从缓存里取出了一个<strong>原始的、未被代理的A对象</strong>并注入给了B，那么B就持有了一个指向原始A对象的引用。即使后续A对象走完了所有流程并被成功代理，B对此也一无所知。当B调用A的方法时，它会直接访问原始对象，从而完美绕过AOP代理，导致事务、日志等切面功能全部失效。</p><p>因此，Spring必须在依赖注入发生时，就确保注入的是正确的对象——如果这个Bean未来需要被代理，那么此时注入的就必须是代理对象。三级缓存中的<code>ObjectFactory</code>就承担了这个职责，它在提供早期引用时，会检查并应用AOP，返回一个代理对象。</p><hr><h3 id="4-提前生成代理的潜在问题与解决方案"><a href="#4-提前生成代理的潜在问题与解决方案" class="headerlink" title="4. 提前生成代理的潜在问题与解决方案"></a>4. <strong>提前生成代理的潜在问题与解决方案</strong></h3><p>这种”提前暴露”的机制虽然巧妙，但作为开发者，我们很自然会关心它是否存在风险。</p><h4 id="问题-1：提前暴露的”半成品”Bean状态可靠吗？"><a href="#问题-1：提前暴露的”半成品”Bean状态可靠吗？" class="headerlink" title="问题 1：提前暴露的”半成品”Bean状态可靠吗？"></a><strong>问题 1：提前暴露的”半成品”Bean状态可靠吗？</strong></h4><ul><li><strong>风险</strong>：这个提前生成的代理对象，其内部包裹的目标对象在当时尚未完成属性注入和初始化（如<code>@PostConstruct</code>）。此时若有方法调用，会不会导致空指针或数据不一致？</li><li><strong>解决方案</strong>：<br>这得益于代理对象的工作模式。无论是JDK动态代理还是CGLIB，代理对象内部都只维护了一个对<strong>目标对象的引用</strong>。当外部通过代理调用方法时，代理对象会将调用<strong>实时转发</strong>给它持有的目标对象。在循环依赖的场景下，虽然代理暴露得很早，但真正的外部方法调用通常发生在所有Bean都初始化完成之后。届时，目标对象的状态已经完整，因此通过代理的调用是安全的。</li></ul><h4 id="问题-2：后来的BeanPostProcessor会不会失效？"><a href="#问题-2：后来的BeanPostProcessor会不会失效？" class="headerlink" title="问题 2：后来的BeanPostProcessor会不会失效？"></a><strong>问题 2：后来的BeanPostProcessor会不会失效？</strong></h4><ul><li><strong>风险</strong>：如果代理对象过早生成，那排在后面的 <code>BeanPostProcessor</code> 对原始 Bean 的修改，还能否体现在代理对象上？</li><li><strong>解决方案</strong>：<br>Spring通过<code>BeanPostProcessor</code>的执行顺序来保证。负责AOP的<code>AnnotationAwareAspectJAutoProxyCreator</code>会在一个非常早的时间点（<code>getEarlyBeanReference</code>阶段）介入。一旦它生成了代理对象，这个代理的AOP逻辑就基本固定了。后续其他的<code>BeanPostProcessor</code>仍然可以对原始Bean的属性等进行修改，但无法改变已经织入的代理逻辑。</li></ul><blockquote><p>当然，这也意味着如果你的某个后置处理器需要影响到代理的生成逻辑，你需要确保它的执行顺序在AOP处理器之前。</p></blockquote><hr><h3 id="5-Spring-的权衡：一种务实的设计哲学"><a href="#5-Spring-的权衡：一种务实的设计哲学" class="headerlink" title="5. Spring 的权衡：一种务实的设计哲学"></a>5. <strong>Spring 的权衡：一种务实的设计哲学</strong></h3><p>Spring在这里的设计，体现了一种非常务实的设计哲学：在保证核心功能的前提下，做出聪明的权衡。</p><ol><li><strong>利用代理的转发机制</strong>：<br>代理对象的核心是”转发”，而非”存储状态”。这为”先创建代理，后完善对象”的异步操作提供了理论基础。只要保证在方法被真正调用时，目标对象是完整的即可。</li><li><strong>明确的边界条件</strong>：<br>这个机制并非万能。Spring官方也指出，应当<strong>避免在初始化方法（如<code>@PostConstruct</code>）中，调用本类中需要被AOP拦截的方法</strong>。因为在那个时间点，代理可能尚未完全应用到当前Bean的自我引用上，导致调用绕过代理。</li></ol><hr><h3 id="6-总结"><a href="#6-总结" class="headerlink" title="6. 总结"></a>6. <strong>总结</strong></h3><p>现在我们再来梳理一下。当Spring”打破常规”提前暴露代理时，背后是一套严谨的机制在支撑：</p><ol><li><strong>循环依赖靠三级缓存解耦</strong>：这套缓存机制确保了Bean之间即使相互依赖，也能顺利完成装配。</li><li><strong>AOP有效性靠提前代理</strong>：在三级缓存的<code>ObjectFactory</code>中提前生成代理，保证了注入到其他Bean中的引用是正确的代理对象，从而让AOP功能不失效。</li><li><strong>数据一致性靠引用转发</strong>：代理对象通过持有对目标对象的引用，确保了任何时候的调用都能访问到目标对象的最新状态，避免了数据不一致的问题。</li></ol><p>总而言之，这套方案是Spring在框架的健壮性和功能的完备性之间，做出的一个非常精彩的工程决策，体现了设计的灵活性和实用性。</p><hr><h3 id="7-设计启示：从Spring身上学到的"><a href="#7-设计启示：从Spring身上学到的" class="headerlink" title="7. 设计启示：从Spring身上学到的"></a>7. <strong>设计启示：从Spring身上学到的</strong></h3><p>从Spring处理循环依赖的方式中，我们作为开发者可以得到一些启发：</p><ol><li><strong>问题驱动，务实取舍</strong>：面对复杂问题（如循环依赖），不拘泥于单一原则，优先保证核心功能可用，再通过精巧的设计规避潜在风险。</li><li><strong>分层与延迟</strong>：通过分层（三级缓存）和延迟计算（<code>ObjectFactory</code>），将复杂问题分解，在真正需要时才执行关键步骤（如创建代理），降低了耦合。</li><li><strong>对用户透明</strong>：尽管内部机制复杂，但对于开发者而言，使用<code>@Autowired</code>和AOP注解的体验是无缝的。一个优秀的框架，就应该将复杂性留在内部。</li></ol><hr><h3 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h3><p>Spring 在解决循环依赖时”违背”延迟生成代理的原则，实则是<strong>通过三级缓存和代理对象的设计，在特定场景下做出的合理权衡</strong>。这样既支持了循环依赖，又通过技术手段（如目标对象引用委托）避免了状态不一致问题，我感觉体现了Spring框架设计的灵活性。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MinIO 学习指南</title>
      <link href="/2025/06/16/minio-learning-guide/"/>
      <url>/2025/06/16/minio-learning-guide/</url>
      
        <content type="html"><![CDATA[<h1 id="MinIO-学习指南"><a href="#MinIO-学习指南" class="headerlink" title="MinIO 学习指南"></a>MinIO 学习指南</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>MinIO 是一个高性能的分布式对象存储系统，专为云原生应用而设计。它完全兼容 Amazon S3 API，可以用于存储非结构化数据，如图片、视频、日志文件、备份和容器镜像等。</p><h2 id="文档结构"><a href="#文档结构" class="headerlink" title="文档结构"></a>文档结构</h2><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[MinIO学习指南] --&gt; B[1.核心概念]    A --&gt; C[2.整体架构]    A --&gt; D[3.核心流程]    A --&gt; E[4.存储系统对比]    A --&gt; F[5.命令使用指南]    A --&gt; G[6.最佳实践]    A --&gt; H[7.总结]        B --&gt; B1[基本概念]    B --&gt; B2[高级概念]        C --&gt; C1[系统架构图]    C --&gt; C2[架构特点]    C --&gt; C3[无主架构原理]        D --&gt; D1[数据写入流程]    D --&gt; D2[数据读取流程]    D --&gt; D3[故障恢复流程]        E --&gt; E1[存储类型对比]    E --&gt; E2[MinIO vs HDFS]    E --&gt; E3[选型决策框架]        F --&gt; F1[安装部署]    F --&gt; F2[基本命令]    F --&gt; F3[高级功能]        G --&gt; G1[部署建议]    G --&gt; G2[性能优化]    G --&gt; G3[安全建议]        H --&gt; H1[技术特色]    H --&gt; H2[适用场景]    H --&gt; H3[最佳实践]  </pre></div><h2 id="1-MinIO-核心概念"><a href="#1-MinIO-核心概念" class="headerlink" title="1. MinIO 核心概念"></a>1. MinIO 核心概念</h2><h3 id="1-1-基本概念"><a href="#1-1-基本概念" class="headerlink" title="1.1 基本概念"></a>1.1 基本概念</h3><h4 id="Object（对象）"><a href="#Object（对象）" class="headerlink" title="Object（对象）"></a>Object（对象）</h4><ul><li>MinIO 中的基本存储单元</li><li>包含数据本身和相关的元数据</li><li>对象大小可以从几 KB 到 5TB</li></ul><h4 id="Bucket（存储桶）"><a href="#Bucket（存储桶）" class="headerlink" title="Bucket（存储桶）"></a>Bucket（存储桶）</h4><ul><li>用于组织对象的容器</li><li>类似于文件系统中的顶级目录</li><li>每个 MinIO 部署可以有多个 bucket</li><li>Bucket 名称在同一 MinIO 集群内必须唯一</li></ul><h4 id="Key（键）"><a href="#Key（键）" class="headerlink" title="Key（键）"></a>Key（键）</h4><ul><li>对象在 bucket 中的唯一标识符</li><li>类似于文件路径</li><li>支持层次结构（使用 <code>/</code> 分隔符）</li></ul><h4 id="Node（节点）"><a href="#Node（节点）" class="headerlink" title="Node（节点）"></a>Node（节点）</h4><ul><li>MinIO 集群中的单个服务器实例</li><li>可以是物理机器或虚拟机</li><li>每个节点运行 MinIO 服务器进程</li></ul><h4 id="Drive（驱动器）"><a href="#Drive（驱动器）" class="headerlink" title="Drive（驱动器）"></a>Drive（驱动器）</h4><ul><li>节点上的存储设备</li><li>可以是硬盘、SSD 或网络存储</li><li>MinIO 使用纠删码将数据分布在多个驱动器上</li></ul><h3 id="1-2-高级概念"><a href="#1-2-高级概念" class="headerlink" title="1.2 高级概念"></a>1.2 高级概念</h3><h4 id="Erasure-Coding（纠删码）"><a href="#Erasure-Coding（纠删码）" class="headerlink" title="Erasure Coding（纠删码）"></a>Erasure Coding（纠删码）</h4><ul><li>MinIO 的核心数据保护机制</li><li>将数据分割成多个数据片和校验片</li><li>即使部分驱动器故障也能恢复数据</li><li>提供比副本更高的存储效率</li></ul><h4 id="Tenant（租户）"><a href="#Tenant（租户）" class="headerlink" title="Tenant（租户）"></a>Tenant（租户）</h4><ul><li>多租户环境中的隔离单元</li><li>每个租户有独立的存储空间和权限</li><li>支持细粒度的访问控制</li></ul><h2 id="2-MinIO-整体架构"><a href="#2-MinIO-整体架构" class="headerlink" title="2. MinIO 整体架构"></a>2. MinIO 整体架构</h2><h3 id="2-1-系统架构图"><a href="#2-1-系统架构图" class="headerlink" title="2.1 系统架构图"></a>2.1 系统架构图</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TB    subgraph &quot;客户端层&quot;        A1[Web浏览器]        A2[SDK应用]        A3[CLI工具]        A4[S3兼容客户端]    end    subgraph &quot;接入层&quot;        B1[DNS]        B2[负载均衡器]    end    subgraph &quot;MinIO集群 (示例: 4节点, 16驱动器)&quot;        C1[节点1]        C2[节点2]        C3[节点3]        C4[节点4]    end    subgraph &quot;存储层 (每个节点管理自己的驱动器)&quot;        subgraph &quot;节点1驱动器&quot;            D1_1[Drive]            D1_2[Drive]            D1_3[Drive]            D1_4[Drive]        end        subgraph &quot;节点2驱动器&quot;            D2_1[Drive]            D2_2[Drive]            D2_3[Drive]            D2_4[Drive]        end        subgraph &quot;节点3驱动器&quot;            D3_1[Drive]            D3_2[Drive]            D3_3[Drive]            D3_4[Drive]        end        subgraph &quot;节点4驱动器&quot;            D4_1[Drive]            D4_2[Drive]            D4_3[Drive]            D4_4[Drive]        end    end    A1 --&gt; B1    A2 --&gt; B1    A3 --&gt; B1    A4 --&gt; B1    B1 --&gt; B2    B2 --&gt; C1    B2 --&gt; C2    B2 --&gt; C3    B2 --&gt; C4    C1 --&gt; D1_1    C1 --&gt; D1_2    C1 --&gt; D1_3    C1 --&gt; D1_4    C2 --&gt; D2_1    C2 --&gt; D2_2    C2 --&gt; D2_3    C2 --&gt; D2_4    C3 --&gt; D3_1    C3 --&gt; D3_2    C3 --&gt; D3_3    C3 --&gt; D3_4    C4 --&gt; D4_1    C4 --&gt; D4_2    C4 --&gt; D4_3    C4 --&gt; D4_4  </pre></div><h3 id="2-2-架构特点"><a href="#2-2-架构特点" class="headerlink" title="2.2 架构特点"></a>2.2 架构特点</h3><h4 id="2-2-1-S3兼容性"><a href="#2-2-1-S3兼容性" class="headerlink" title="2.2.1 S3兼容性"></a>2.2.1 S3兼容性</h4><ul><li><strong>API兼容</strong>：完全兼容Amazon S3 API</li><li><strong>SDK支持</strong>：支持所有主流编程语言的S3 SDK</li><li><strong>工具兼容</strong>：支持S3兼容的工具和客户端</li><li><strong>功能对等</strong>：支持S3的主要功能，如：<ul><li>存储桶操作</li><li>对象操作</li><li>版本控制</li><li>生命周期管理</li><li>加密</li><li>访问控制</li></ul></li></ul><h4 id="2-2-2-无主架构"><a href="#2-2-2-无主架构" class="headerlink" title="2.2.2 无主架构"></a>2.2.2 无主架构</h4><ul><li>所有节点都是对等的</li><li>没有单点故障</li><li>自动故障转移和恢复</li></ul><h4 id="2-2-3-横向扩展"><a href="#2-2-3-横向扩展" class="headerlink" title="2.2.3 横向扩展"></a>2.2.3 横向扩展</h4><ul><li>支持从单节点到数千节点的扩展</li><li>线性性能增长</li><li>热添加新节点</li></ul><h4 id="2-2-4-高可用性"><a href="#2-2-4-高可用性" class="headerlink" title="2.2.4 高可用性"></a>2.2.4 高可用性</h4><ul><li>支持多数据中心部署</li><li>自动故障检测和恢复</li><li>数据一致性保证</li></ul><h3 id="2-3-无主架构技术原理"><a href="#2-3-无主架构技术原理" class="headerlink" title="2.3 无主架构技术原理"></a>2.3 无主架构技术原理</h3><p>MinIO的无主架构是其实现高可用和高性能的核心。这套架构依赖于几个关键的技术机制：确定性哈希算法、纠删码、自描述的元数据管理以及智能的故障检测与自愈。</p><h4 id="2-3-1-核心机制：确定性哈希与纠删码"><a href="#2-3-1-核心机制：确定性哈希与纠删码" class="headerlink" title="2.3.1 核心机制：确定性哈希与纠删码"></a>2.3.1 核心机制：确定性哈希与纠删码</h4><h5 id="确定性哈希分布算法"><a href="#确定性哈希分布算法" class="headerlink" title="确定性哈希分布算法"></a>确定性哈希分布算法</h5><p>MinIO不使用传统的一致性哈希环。它采用基于对象名称（Bucket + Object）的确定性哈希算法（HighwayHash）来决定对象应存放在哪个纠删码集合（Erasure Set）中。一个纠删码集合是一组驱动器的组合。因为算法是确定性的，任何一个节点都可以独立计算出任意对象的存放位置，从而无需中心节点协调。</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph LR    subgraph &quot;确定性哈希分布&quot;        A[对象A名称] --&gt; H1[确定性哈希]        B[对象B名称] --&gt; H2[确定性哈希]                H1 --&gt; ES1[&quot;纠删码集合1 (驱动器组合A)&quot;]        H2 --&gt; ES2[&quot;纠删码集合2 (驱动器组合B)&quot;]    end  </pre></div><h5 id="Reed-Solomon-纠删码"><a href="#Reed-Solomon-纠删码" class="headerlink" title="Reed-Solomon 纠删码"></a>Reed-Solomon 纠删码</h5><p>纠删码是MinIO数据保护的基石，它取代了传统的多副本方式，提供了更高的存储效率。</p><p><strong>基本原理</strong>:</p><ul><li><strong>编码</strong>: 将原始数据分割成K个数据分片，并基于这些数据分片生成M个校验分片。总共得到K+M个分片。</li><li><strong>存储</strong>: 将这K+M个分片存储在不同的驱动器上。</li><li><strong>恢复</strong>: 系统最多可以容忍M个分片（即M个驱动器）丢失。只要有不少于K个分片存在（无论是数据分片还是校验分片），就可以通过Reed-Solomon解码算法完整地恢复出原始数据。</li></ul><p><strong>纠删码配置示例</strong>:<br>MinIO会根据集群中驱动器的总数自动选择最合适的纠删码配置（K+M）。用户也可以手动指定。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 常用纠删码配置 (N个驱动器，EC:M表示M个校验分片)</span></span><br><span class="line"><span class="comment"># 数据分片K = N - M</span></span><br><span class="line"></span><br><span class="line">1. 8个驱动器, EC:4 (4+4)</span><br><span class="line">   - 存储效率: 50%, 可容忍4个驱动器故障。</span><br><span class="line">   - 适用场景: 高可靠性要求。</span><br><span class="line"></span><br><span class="line">2. 16个驱动器, EC:4 (12+4)</span><br><span class="line">   - 存储效率: 75%, 可容忍4个驱动器故障。</span><br><span class="line">   - 适用场景: 平衡效率和可靠性。</span><br><span class="line"></span><br><span class="line">3. 16个驱动器, EC:8 (8+8)</span><br><span class="line">   - 存储效率: 50%, 可容忍8个驱动器故障。</span><br><span class="line">   - 适用场景: 最高可靠性要求。</span><br></pre></td></tr></table></figure><p><strong>性能优化</strong>：<br>为了加速纠删码的编解码计算，MinIO使用了SIMD指令集（如Intel AVX512），大幅提升了CPU处理效率，使得纠删码的性能开销降到最低。</p><h4 id="2-3-2-数据读写机制"><a href="#2-3-2-数据读写机制" class="headerlink" title="2.3.2 数据读写机制"></a>2.3.2 数据读写机制</h4><h5 id="并行读写真相：并非所有节点参与"><a href="#并行读写真相：并非所有节点参与" class="headerlink" title="并行读写真相：并非所有节点参与"></a>并行读写真相：并非所有节点参与</h5><p>一个常见的误解是MinIO会将数据写入到所有节点。实际上，MinIO只向当前对象所属的纠删码集合（Erasure Set）所包含的驱动器（及对应节点）进行并行读写。</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TB    subgraph &quot;16节点集群, 8+8纠删码配置&quot;        A[客户端请求] --&gt; B[确定性哈希计算]        B --&gt; C{选择16个驱动器组成纠删码集合}                C --&gt; D[8个数据分片]        C --&gt; E[8个校验分片]                D --&gt; N_Data[并行写入8个驱动器]        E --&gt; N_Parity[并行写入8个驱动器]                subgraph &quot;对象A的存储&quot;            N_Data --&gt; NA[&quot;节点1,3,5,...&quot;]            N_Parity --&gt; PA[&quot;节点2,4,6,...&quot;]        end                subgraph &quot;对象B的存储 (不同分布)&quot;            style NB fill:#cce5ff            style PB fill:#fff2cc            B --&gt; NB[&quot;节点2,5,8,...&quot;]            B --&gt; PB[&quot;节点1,4,7,...&quot;]        end    end  </pre></div><p><strong>关键点</strong>:</p><ol><li><strong>精确并行</strong>：读写操作只涉及构成纠删码集合的节点和驱动器，而非整个集群。</li><li><strong>负载均衡</strong>：由于不同对象的哈希值不同，它们会被分散到集群内不同的驱动器组合上，从而自然实现了负载均衡。</li></ol><h5 id="读写Quorum机制"><a href="#读写Quorum机制" class="headerlink" title="读写Quorum机制"></a>读写Quorum机制</h5><p>MinIO的读写成功与否依赖于一个”Quorum”机制，这个机制基于纠删码的特性。</p><ul><li><strong>写入Quorum</strong>：对于K+M的配置，一次写入操作必须成功写入至少K个分片才算成功。这保证了数据至少有足够的”基础”可以被恢复。在实际实现中，MinIO要求所有K+M个分片都写入成功，如果某个驱动器暂时不可用，写操作会报错，由客户端重试。</li><li><strong>读取Quorum</strong>：一个读取操作只需要成功读取任意K个分片（数据或校验），就可以在内存中重构出完整的原始数据。MinIO会并行向所有K+M个分片发起读取，并采用最先返回的K个分片。</li></ul><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    subgraph &quot;写入流程&quot;        A[写请求] --&gt; B[&quot;计算哈希, 定位K+M个驱动器&quot;]        B --&gt; C[&quot;并行写入K+M个分片&quot;]        C --&gt; D{成功写入分片数}        D --&gt;|&gt;&#x3D; K+M| E[写入成功]        D --&gt;|&lt; K+M| F[写入失败]    end    subgraph &quot;读取流程&quot;        G[读请求] --&gt; H[&quot;计算哈希, 定位K+M个驱动器&quot;]        H --&gt; I[并行读取所有分片]        I --&gt; J{成功返回分片数}        J --&gt;|&gt;&#x3D; K| K[数据重构成功]        J --&gt;|&lt; K| L[读取失败]    end  </pre></div><h4 id="2-3-3-分布式元数据管理"><a href="#2-3-3-分布式元数据管理" class="headerlink" title="2.3.3 分布式元数据管理"></a>2.3.3 分布式元数据管理</h4><p>MinIO的元数据管理是其无主架构设计的精髓之一，它没有中心化的元数据服务器。其元数据分为两类：对象元数据和配置元数据。</p><h5 id="对象元数据-Object-Metadata"><a href="#对象元数据-Object-Metadata" class="headerlink" title="对象元数据 (Object Metadata)"></a>对象元数据 (Object Metadata)</h5><ul><li><strong>自描述格式</strong>：每个对象在磁盘上都包含一个 <code>xl.json</code> 文件。这个文件与对象的数据分片（<code>part.1</code>）存储在一起。</li><li><strong>内容</strong>: <code>xl.json</code> 包含了关于该对象的所有元信息，例如纠删码配置（算法、K值、M值）、分片分布、校验和、创建时间等。</li><li><strong>保护机制</strong>: <code>xl.json</code> 文件本身也被视为对象的一部分，与数据分片一样，它会被复制并分布到纠删码集合的所有驱动器上。这意味着元数据和数据享有同等级别的纠删码保护。</li><li><strong>优势</strong>: 这种设计使得每个对象都是”自包含”和”自描述”的。恢复数据时，系统无需查询外部的元数据服务，只需读取对象自身的 <code>xl.json</code> 文件即可了解如何重构它。这极大地简化了系统设计和故障恢复流程。</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对象在磁盘上的实际存储格式示例</span></span><br><span class="line"><span class="comment"># 桶 MyBucket, 对象 MyObject, 存储在4个驱动器的纠删码集合中</span></span><br><span class="line">/path/to/drive1/MyBucket/MyObject/</span><br><span class="line">├── xl.json        <span class="comment"># 元数据文件</span></span><br><span class="line">└── part.1         <span class="comment"># 该驱动器上的数据/校验分片</span></span><br><span class="line"></span><br><span class="line">/path/to/drive2/MyBucket/MyObject/</span><br><span class="line">├── xl.json        <span class="comment"># 元数据文件的副本</span></span><br><span class="line">└── part.2         <span class="comment"># 该驱动器上的数据/校验分片</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><h5 id="配置元数据-Configuration-Metadata"><a href="#配置元数据-Configuration-Metadata" class="headerlink" title="配置元数据 (Configuration Metadata)"></a>配置元数据 (Configuration Metadata)</h5><ul><li><strong>范围</strong>: 这类元数据包括存储桶策略、版本控制设置、生命周期规则（ILM）、IAM用户和策略等。</li><li><strong>存储位置</strong>: 这些配置信息存储在每个节点的数据目录下名为 <code>.minio.sys/</code> 的隐藏目录中。</li><li><strong>同步机制</strong>: MinIO集群内的所有节点会通过一个内部的分布式共识（consensus）算法来保证 <code>.minio.sys/</code> 目录下的内容在所有节点间是最终一致的。当管理员在一个节点上创建用户或修改存储桶策略时，这个变更会被同步到所有其他节点。</li><li><strong>高可用性</strong>: 即使部分节点宕机，只要集群的多数节点存活，配置信息就不会丢失，并且可以在新节点加入时同步给它。这确保了集群管理操作的高可用性。</li></ul><h4 id="2-3-4-故障检测与自愈机制"><a href="#2-3-4-故障检测与自愈机制" class="headerlink" title="2.3.4 故障检测与自愈机制"></a>2.3.4 故障检测与自愈机制</h4><h5 id="实时故障监控"><a href="#实时故障监控" class="headerlink" title="实时故障监控"></a>实时故障监控</h5><ul><li><strong>心跳机制</strong>：节点间通过心跳包（默认30秒一次）相互探测健康状态。</li><li><strong>多维度检测</strong>：监控不仅限于节点存活，还包括网络延迟、磁盘健康（SMART信息）、IO性能等。</li><li><strong>渐进式判断</strong>：系统不会因为短暂的网络抖动就立即判定节点故障，而是采用”可疑”到”故障”的渐进式策略，避免误判。</li></ul><h5 id="自动数据重建（自愈）"><a href="#自动数据重建（自愈）" class="headerlink" title="自动数据重建（自愈）"></a>自动数据重建（自愈）</h5><p>当一个驱动器被确认故障后，MinIO的自愈（Healing）过程会自动启动：</p><ol><li><strong>降级模式</strong>：包含故障驱动器的纠删码集合会进入降级（degraded）模式。此时读写请求仍可正常服务（只要剩余驱动器数量大于等于K）。</li><li><strong>后台扫描</strong>：系统会扫描所有受该故障驱动器影响的对象。</li><li><strong>数据重构</strong>：对于每个受影响的对象，MinIO会读取其剩余的K个可用分片，重构出丢失的分片。</li><li><strong>写入新位置</strong>：将重构好的分片写入到集群中的一个健康的、可用的新驱动器上。</li><li><strong>更新元数据</strong>：更新相关对象的<code>xl.json</code>文件，记录新的分片位置。</li><li><strong>恢复正常</strong>：一旦所有受影响的数据都完成重建，系统就恢复到正常状态。</li></ol><p>这个过程完全在后台自动进行，对前台应用透明。</p><h4 id="2-3-5-无主架构的优缺点"><a href="#2-3-5-无主架构的优缺点" class="headerlink" title="2.3.5 无主架构的优缺点"></a>2.3.5 无主架构的优缺点</h4><h5 id="优势"><a href="#优势" class="headerlink" title="优势"></a>优势</h5><ol><li>**高可用性 (无单点故障)**：所有节点对等，没有主节点。任何节点的故障都不会导致整个服务中断，只要满足纠删码的最小可用驱动器数。</li><li><strong>线性扩展</strong>：增加节点或驱动器可以带来近乎线性的性能和容量增长。确定性哈希算法保证了新加入的资源会被自动利用起来。</li><li><strong>运维简化</strong>：所有节点配置相同，部署和维护都非常简单。扩容（通过服务器池）也无需复杂的数据重分布操作。</li><li><strong>成本效益</strong>：纠删码相比3副本等机制，在同等或更高可靠性下，存储空间利用率更高，从而降低了硬件成本。</li></ol><h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ol><li><strong>最终一致性</strong>：在某些场景下，比如配置信息的变更，节点间的同步存在短暂延迟，属于最终一致性。但对于对象数据IO，MinIO通过其Quorum机制保证了强一致性。</li><li><strong>网络开销</strong>：无主架构下，节点间的通信（心跳、数据修复等）会比主从架构更频繁，对网络质量要求较高。</li><li><strong>扩容限制</strong>：单个服务器池的扩容（增加驱动器）需要重启。虽然支持通过添加新服务器池（Server Pool）的方式在线扩容，但这增加了架构的逻辑层次。同时，官方建议单个集群规模不宜过大（如超过32个节点），超大规模推荐使用联邦模式。</li></ol><h3 id="2-4-集群扩容机制"><a href="#2-4-集群扩容机制" class="headerlink" title="2.4 集群扩容机制"></a>2.4 集群扩容机制</h3><p>MinIO 支持两种主要的扩容方式，每种方式都有其特定的使用场景和限制。</p><h4 id="2-4-1-对等扩容（Server-Pool扩容）"><a href="#2-4-1-对等扩容（Server-Pool扩容）" class="headerlink" title="2.4.1 对等扩容（Server Pool扩容）"></a>2.4.1 对等扩容（Server Pool扩容）</h4><p><strong>基本原理</strong>：</p><ul><li>MinIO 采用服务器池（Server Pool）的概念进行扩容</li><li>要求新增的节点数和磁盘数与原集群保持对等关系</li><li>新老数据保持在各自的服务器池中，不进行重新分布</li></ul><p><strong>扩容流程</strong>：</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TB    subgraph &quot;扩容前&quot;        SP1[服务器池1]        SP1 --&gt; N1[节点1-4]        SP1 --&gt; D1[原有数据]    end        subgraph &quot;扩容后&quot;        SP1_FINAL[服务器池1]        SP2_FINAL[服务器池2]                SP1_FINAL --&gt; N1_FINAL[节点1-4]        SP1_FINAL --&gt; D1_FINAL[原有数据]                SP2_FINAL --&gt; N2_FINAL[节点5-8]        SP2_FINAL --&gt; D2_FINAL[新数据]                APP[新对象写入] --&gt; BALANCE{负载均衡}        BALANCE --&gt;|基于可用空间| SP1_FINAL        BALANCE --&gt;|基于可用空间| SP2_FINAL    end  </pre></div><p><strong>技术限制</strong>：</p><ul><li><strong>对等要求</strong>：新增的服务器池必须与现有池具有完全相同的节点数和每节点的驱动器数。</li><li><strong>数据不重分布</strong>：旧数据停留在旧池，新数据根据负载均衡策略写入到所有池中。</li><li><strong>重启需求</strong>：扩容操作需要重启整个集群以应用新的服务器池配置。</li></ul><h4 id="2-4-2-联邦扩容（Federation）"><a href="#2-4-2-联邦扩容（Federation）" class="headerlink" title="2.4.2 联邦扩容（Federation）"></a>2.4.2 联邦扩容（Federation）</h4><p><strong>基本原理</strong>：</p><ul><li>通过 etcd 将多个独立的 MinIO 集群（或称为租户）组成一个逻辑上的大集群。</li><li>联邦提供统一的命名空间，但各租户集群在物理上和管理上是独立的。</li><li>etcd 负责维护存储桶到具体租户集群的映射关系。</li></ul><p><strong>联邦架构</strong>：</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TB    subgraph &quot;MinIO联邦集群&quot;        CLIENT[客户端] --&gt; |请求bucket-A| LB[&quot;统一入口&#x2F;网关&quot;]        LB --&gt;|查询etcd| ETCD[etcd集群]        ETCD --&gt;|bucket-A 在 Cluster1| LB                LB --&gt; CLUSTER1[租户集群1]                subgraph &quot;独立租户集群&quot;            CLUSTER1            CLUSTER2[租户集群2]            CLUSTER3[租户集群N]        end                CLUSTER1 -- &quot;注册&#x2F;心跳&quot; --&gt; ETCD        CLUSTER2 -- &quot;注册&#x2F;心跳&quot; --&gt; ETCD        CLUSTER3 -- &quot;注册&#x2F;心跳&quot; --&gt; ETCD    end  </pre></div><p><strong>联邦扩容优势</strong>：</p><ul><li><strong>无限扩展</strong>：理论上可以无限连接新的租户集群，打破单集群的节点数限制。</li><li><strong>故障隔离</strong>：一个租户集群的故障不会影响其他集群。</li><li><strong>灵活性</strong>：不同租户集群可以有不同的规模和配置。</li></ul><p><strong>联邦扩容缺点</strong>：</p><ul><li><strong>引入外部依赖</strong>：需要部署和维护一个高可用的etcd集群。</li><li><strong>配置与管理更复杂</strong>：增加了系统的整体复杂度。</li></ul><h4 id="2-4-3-扩容方式选择建议"><a href="#2-4-3-扩容方式选择建议" class="headerlink" title="2.4.3 扩容方式选择建议"></a>2.4.3 扩容方式选择建议</h4><table><thead><tr><th>扩容方式</th><th>适用场景</th><th>优势</th><th>劣势</th></tr></thead><tbody><tr><td><strong>对等扩容</strong></td><td>中小型集群（&lt;32节点）</td><td>配置简单，无外部依赖</td><td>有节点数建议上限，需要重启</td></tr><tr><td><strong>联邦扩容</strong></td><td>超大规模环境，多租户场景</td><td>无限扩展，故障隔离</td><td>配置复杂，依赖etcd</td></tr></tbody></table><h3 id="2-5-MinIO技术澄清与问题解答"><a href="#2-5-MinIO技术澄清与问题解答" class="headerlink" title="2.5 MinIO技术澄清与问题解答"></a>2.5 MinIO技术澄清与问题解答</h3><p>基于对MinIO架构的深入理解，我们可以澄清一些常见的技术误解，并回答一些核心问题。</p><h4 id="重要技术澄清"><a href="#重要技术澄清" class="headerlink" title="重要技术澄清"></a>重要技术澄清</h4><ul><li><strong>MinIO不使用传统的一致性哈希环</strong>: 它使用基于对象名称的确定性哈希算法，这与需要维护哈希环状态的系统有本质区别。</li><li><strong>MinIO的Quorum机制基于纠删码</strong>: 其读写Quorum由Reed-Solomon算法的数学特性（K&#x2F;M值）决定，而非传统的基于多数派投票的Quorum。</li><li><strong>MinIO的元数据管理是自描述和分布式的</strong>: 对象元数据随对象本身存储和保护，不存在集中式的元数据瓶颈。</li></ul><h4 id="核心技术问题解答"><a href="#核心技术问题解答" class="headerlink" title="核心技术问题解答"></a>核心技术问题解答</h4><h5 id="问题1：MinIO读写文件会并行写到所有节点吗？"><a href="#问题1：MinIO读写文件会并行写到所有节点吗？" class="headerlink" title="问题1：MinIO读写文件会并行写到所有节点吗？"></a>问题1：MinIO读写文件会并行写到所有节点吗？</h5><p><strong>答案：不会，这是一个常见误解。</strong></p><p><strong>正确理解</strong>：</p><ul><li>MinIO只向当前对象所属的纠删码集合所包含的节点&#x2F;驱动器并行写入，而非集群中的所有节点。</li><li>例如，在一个100节点的集群中，如果使用8+8的纠删码配置，那么任何一个对象的读写操作都只涉及其中的16个节点&#x2F;驱动器。</li><li>通过确定性哈希算法，不同的对象会被智能地分配到不同的纠删码集合上，这就在宏观上实现了整个集群的负载均衡，避免了不必要的网络和IO开销。</li></ul><h5 id="问题2：分布式元数据在扩容-缩容和节点宕机时如何处理？"><a href="#问题2：分布式元数据在扩容-缩容和节点宕机时如何处理？" class="headerlink" title="问题2：分布式元数据在扩容&#x2F;缩容和节点宕机时如何处理？"></a>问题2：分布式元数据在扩容&#x2F;缩容和节点宕机时如何处理？</h5><p><strong>答案</strong>：需要区分对象元数据和配置元数据。</p><p>**对象元数据 (<code>xl.json</code>)**：</p><ul><li><strong>节点宕机</strong>：由于 <code>xl.json</code> 和数据分片一样，在纠删码集合的所有驱动器上都有副本，因此它的可用性和恢复机制与对象数据完全相同。只要满足读取Quorum（K个可用分片），对象及其元数据就可以被访问和恢复。</li><li><strong>扩容</strong>：在服务器池扩容模式下，现有对象的元数据和数据都保留在原有的服务器池中，不会发生变动。新对象及其元数据将被写入到包括新池在内的所有可用池中。</li></ul><p>**配置元数据 (<code>.minio.sys/</code>)**：</p><ul><li><strong>节点宕机</strong>：由于配置信息在所有节点间通过共识算法同步，少数节点的宕机不会影响配置的可用性。存活的节点仍然拥有完整的配置信息。</li><li><strong>扩容&#x2F;新节点加入</strong>：新加入的节点会自动从集群中的其他节点同步最新的配置信息，从而快速融入集群。</li></ul><p><strong>总结</strong>：MinIO的无主架构通过精巧的技术设计（确定性哈希、纠删码、自描述元数据），成功地解决了分布式系统中的经典难题，实现了高可用、高性能、易扩展的存储系统。</p><h2 id="3-MinIO-核心流程"><a href="#3-MinIO-核心流程" class="headerlink" title="3. MinIO 核心流程"></a>3. MinIO 核心流程</h2><h3 id="3-1-数据写入流程"><a href="#3-1-数据写入流程" class="headerlink" title="3.1 数据写入流程"></a>3.1 数据写入流程</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  sequenceDiagram    participant C as 客户端    participant LB as 负载均衡器    participant M as 任一MinIO节点    participant DSet as 驱动器纠删码集合        C-&gt;&gt;LB: PUT对象请求 (携带数据)    LB-&gt;&gt;M: 路由到任一可用节点    M-&gt;&gt;M: 1. 根据对象名计算哈希, 确定驱动器集合    M-&gt;&gt;M: 2. 对数据进行纠删码编码(K+M分片)    M-&gt;&gt;DSet: 3. 并行将K+M分片写入对应驱动器    DSet--&gt;&gt;M: 确认写入完成    M--&gt;&gt;C: 4. 返回成功响应 (200 OK)  </pre></div><h3 id="3-2-数据读取流程"><a href="#3-2-数据读取流程" class="headerlink" title="3.2 数据读取流程"></a>3.2 数据读取流程</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  sequenceDiagram    participant C as 客户端    participant LB as 负载均衡器    participant M as 任一MinIO节点    participant DSet as 驱动器纠删码集合        C-&gt;&gt;LB: GET对象请求    LB-&gt;&gt;M: 路由到任一可用节点    M-&gt;&gt;M: 1. 根据对象名计算哈希, 确定驱动器集合    M-&gt;&gt;DSet: 2. 并行向所有K+M个驱动器请求分片    DSet--&gt;&gt;M: 3. 最先返回的K个分片到达    M-&gt;&gt;M: 4. 在内存中重构原始数据    M--&gt;&gt;C: 5. 将数据流式传输给客户端  </pre></div><h3 id="3-3-故障恢复流程"><a href="#3-3-故障恢复流程" class="headerlink" title="3.3 故障恢复流程"></a>3.3 故障恢复流程</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[检测到驱动器故障] --&gt; B{&quot;检查冗余是否充足&quot;}    B -- &quot;是 (剩余驱动器 &gt;&#x3D; K)&quot; --&gt; C[&quot;集群进入降级模式, 服务不中断&quot;]    B -- &quot;否 (剩余驱动器 &lt; K)&quot; --&gt; D[&quot;部分数据不可用, 告警管理员&quot;]        C --&gt; E[&quot;后台自愈(Healing)进程启动&quot;]    E --&gt; F[扫描受影响的对象]    F --&gt; G[&quot;对每个对象, 读取K个可用分片&quot;]    G --&gt; H[重构丢失的分片]    H --&gt; I[&quot;将新分片写入健康的备用驱动器&quot;]    I --&gt; J[&quot;更新对象的元数据(xl.json)&quot;]    J --&gt; K[&quot;所有数据恢复后, 集群恢复正常模式&quot;]  </pre></div><h2 id="4-MinIO-与其他存储系统对比"><a href="#4-MinIO-与其他存储系统对比" class="headerlink" title="4. MinIO 与其他存储系统对比"></a>4. MinIO 与其他存储系统对比</h2><h3 id="4-1-对象存储-vs-文件存储-vs-块存储"><a href="#4-1-对象存储-vs-文件存储-vs-块存储" class="headerlink" title="4.1 对象存储 vs 文件存储 vs 块存储"></a>4.1 对象存储 vs 文件存储 vs 块存储</h3><h4 id="存储类型架构对比"><a href="#存储类型架构对比" class="headerlink" title="存储类型架构对比"></a>存储类型架构对比</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TB    subgraph &quot;对象存储 (MinIO)&quot;        OBJ1[应用程序] --&gt; OBJ2[&quot;REST API (HTTP)&quot;]        OBJ2 --&gt; OBJ3[对象存储引擎]        OBJ3 --&gt; OBJ4[&quot;扁平化命名空间 + 元数据&quot;]        OBJ4 --&gt; OBJ5[分布式存储池]    end        subgraph &quot;文件存储 (NFS&#x2F;HDFS)&quot;        FILE1[应用程序] --&gt; FILE2[&quot;文件系统接口 (POSIX)&quot;]        FILE2 --&gt; FILE3[层级目录树结构]        FILE3 --&gt; FILE4[元数据服务器]        FILE4 --&gt; FILE5[数据节点]    end        subgraph &quot;块存储 (SAN)&quot;        BLOCK1[操作系统] --&gt; BLOCK2[&quot;文件系统 (ext4&#x2F;xfs)&quot;]        BLOCK2 --&gt; BLOCK3[&quot;块设备接口 (SCSI&#x2F;iSCSI)&quot;]        BLOCK3 --&gt; BLOCK4[存储控制器]        BLOCK4 --&gt; BLOCK5[&quot;物理磁盘阵列 (RAID)&quot;]    end  </pre></div><h3 id="4-2-MinIO-vs-HDFS-详细对比"><a href="#4-2-MinIO-vs-HDFS-详细对比" class="headerlink" title="4.2 MinIO vs HDFS 详细对比"></a>4.2 MinIO vs HDFS 详细对比</h3><h4 id="4-2-1-架构差异"><a href="#4-2-1-架构差异" class="headerlink" title="4.2.1 架构差异"></a>4.2.1 架构差异</h4><table><thead><tr><th>对比维度</th><th>MinIO</th><th>HDFS</th></tr></thead><tbody><tr><td><strong>架构模式</strong></td><td>无主架构，所有节点对等</td><td>主从架构，NameNode + DataNode</td></tr><tr><td><strong>单点故障</strong></td><td>无单点故障</td><td>NameNode 是潜在单点故障 (需HA方案)</td></tr><tr><td><strong>数据保护</strong></td><td>Reed-Solomon纠删码</td><td>多副本机制（通常3副本）</td></tr><tr><td><strong>存储效率</strong></td><td>高 (如EC:4为75%)</td><td>低 (3副本为33.3%)</td></tr><tr><td><strong>访问接口</strong></td><td>S3 API (HTTP)</td><td>HDFS API, WebHDFS</td></tr><tr><td><strong>小文件处理</strong></td><td>较优</td><td>NameNode压力大，性能较差</td></tr></tbody></table><h4 id="4-2-2-技术实现对比"><a href="#4-2-2-技术实现对比" class="headerlink" title="4.2.2 技术实现对比"></a>4.2.2 技术实现对比</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TB    subgraph &quot;MinIO 架构&quot;        M1[客户端] --&gt; M2[&quot;任意节点 (无主)&quot;]        M2 --&gt; M3[确定性哈希计算]        M3 --&gt; M4[纠删码分片]        M4 --&gt; M5[纠删码集合存储]    end        subgraph &quot;HDFS 架构&quot;        H1[客户端] --&gt; H2[&quot;NameNode (主节点)&quot;]        H2 --&gt; H3[&quot;元数据查询&#x2F;管理&quot;]        H1 --&gt; H4[&quot;DataNode (从节点)&quot;]        H2 --&gt; H4[指令下发]        H4 --&gt; H5[3副本存储]    end  </pre></div><h4 id="4-2-3-性能与可靠性对比"><a href="#4-2-3-性能与可靠性对比" class="headerlink" title="4.2.3 性能与可靠性对比"></a>4.2.3 性能与可靠性对比</h4><h5 id="读写性能"><a href="#读写性能" class="headerlink" title="读写性能"></a>读写性能</h5><ul><li><strong>MinIO</strong>：<ul><li>擅长处理混合负载，对大文件和小文件都有良好的性能表现。</li><li>通过智能并行读写，吞吐量可达纠删码节点组的总带宽。</li></ul></li><li><strong>HDFS</strong>：<ul><li>为大文件顺序读写优化，流式处理能力强。</li><li>小文件场景下，NameNode成为瓶颈，性能下降严重。</li></ul></li></ul><h5 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h5><ul><li><strong>MinIO</strong>：<ul><li>自动检测、自动修复（自愈）。</li><li>可容忍的故障数取决于纠删码配置，更灵活。</li><li>恢复过程对业务透明。</li></ul></li><li><strong>HDFS</strong>：<ul><li>依赖NameNode协调块的复制。</li><li>NameNode故障需要复杂的HA切换（如JournalNode+ZKFC）。</li><li>恢复过程管理相对复杂。</li></ul></li></ul><h4 id="4-2-4-使用场景对比"><a href="#4-2-4-使用场景对比" class="headerlink" title="4.2.4 使用场景对比"></a>4.2.4 使用场景对比</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph LR    subgraph &quot;MinIO 适用场景&quot;        MINIO1[云原生应用存储]        MINIO2[CDN及静态资源]        MINIO3[备份归档]        MINIO4[AI&#x2F;ML数据湖]        MINIO5[容器镜像仓库]    end        subgraph &quot;HDFS 适用场景&quot;        HDFS1[&quot;海量数据批处理 (MapReduce&#x2F;Spark)&quot;]        HDFS2[数据仓库]        HDFS3[日志存储与分析]        HDFS4[传统大数据生态]    end  </pre></div><h3 id="4-3-MinIO-vs-其他对象存储"><a href="#4-3-MinIO-vs-其他对象存储" class="headerlink" title="4.3 MinIO vs 其他对象存储"></a>4.3 MinIO vs 其他对象存储</h3><h4 id="4-3-1-MinIO-vs-AWS-S3"><a href="#4-3-1-MinIO-vs-AWS-S3" class="headerlink" title="4.3.1 MinIO vs AWS S3"></a>4.3.1 MinIO vs AWS S3</h4><table><thead><tr><th>特性</th><th>MinIO</th><th>AWS S3</th></tr></thead><tbody><tr><td><strong>部署方式</strong></td><td>私有云&#x2F;混合云&#x2F;边缘</td><td>公有云服务</td></tr><tr><td><strong>API兼容性</strong></td><td>100% S3兼容</td><td>原生S3 API标准</td></tr><tr><td><strong>成本</strong></td><td>硬件+运维成本，可控</td><td>按使用量付费，易超支</td></tr><tr><td><strong>数据主权</strong></td><td>完全自主控制</td><td>依赖云服务商政策</td></tr><tr><td><strong>性能</strong></td><td>取决于硬件，可极致优化</td><td>服务等级限制，有吞吐量上限</td></tr><tr><td><strong>定制化</strong></td><td>高度可定制</td><td>黑盒，不可定制</td></tr></tbody></table><h4 id="4-3-2-MinIO-vs-Ceph"><a href="#4-3-2-MinIO-vs-Ceph" class="headerlink" title="4.3.2 MinIO vs Ceph"></a>4.3.2 MinIO vs Ceph</h4><table><thead><tr><th>对比项</th><th>MinIO</th><th>Ceph</th></tr></thead><tbody><tr><td><strong>设计哲学</strong></td><td>简洁、高性能</td><td>统一、功能全面</td></tr><tr><td><strong>存储类型</strong></td><td>纯对象存储</td><td>统一存储（对象+块+文件）</td></tr><tr><td><strong>复杂度</strong></td><td>非常简单，易于部署和运维</td><td>非常复杂，学习曲线陡峭</td></tr><tr><td><strong>性能</strong></td><td>对象存储场景下性能极致</td><td>通用性强，但为对象存储的调优复杂</td></tr><tr><td><strong>资源占用</strong></td><td>轻量级</td><td>重量级</td></tr><tr><td><strong>适用场景</strong></td><td>需要高性能、易于管理的对象存储</td><td>需要统一存储平台，有强大运维团队</td></tr></tbody></table><h3 id="4-4-选型决策框架"><a href="#4-4-选型决策框架" class="headerlink" title="4.4 选型决策框架"></a>4.4 选型决策框架</h3><h4 id="4-4-1-技术选型矩阵"><a href="#4-4-1-技术选型矩阵" class="headerlink" title="4.4.1 技术选型矩阵"></a>4.4.1 技术选型矩阵</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[存储需求分析] --&gt; B{&quot;主要数据访问模式?&quot;}    B -- &quot;HTTP&#x2F;S3 API&quot; --&gt; C[选择对象存储]    B -- &quot;文件&#x2F;POSIX API&quot; --&gt; D[选择文件存储]    B -- &quot;iSCSI&#x2F;块设备&quot; --&gt; E[选择块存储]        C --&gt; F{&quot;部署环境?&quot;}    F -- &quot;私有云&#x2F;混合云&quot; --&gt; G{&quot;运维复杂度要求?&quot;}    F -- &quot;公有云&quot; --&gt; H[&quot;AWS S3&#x2F;阿里云OSS等&quot;]        G -- &quot;追求简洁、高性能&quot; --&gt; I[MinIO]    G -- &quot;需要统一存储平台&quot; --&gt; J[Ceph]        D --&gt; K{&quot;主要应用场景?&quot;}    K -- &quot;大数据分析&quot; --&gt; L[HDFS]    K -- &quot;通用文件共享&quot; --&gt; M[&quot;NFS&#x2F;GlusterFS&quot;]        E --&gt; N[&quot;SAN&#x2F;iSCSI&#x2F;Ceph RBD&quot;]  </pre></div><h4 id="4-4-2-决策要素权重"><a href="#4-4-2-决策要素权重" class="headerlink" title="4.4.2 决策要素权重"></a>4.4.2 决策要素权重</h4><table><thead><tr><th>要素</th><th align="center">MinIO</th><th align="center">HDFS</th><th align="center">Ceph</th></tr></thead><tbody><tr><td><strong>易用性</strong></td><td align="center">⭐⭐⭐⭐⭐</td><td align="center">⭐⭐⭐</td><td align="center">⭐⭐</td></tr><tr><td><strong>对象存储性能</strong></td><td align="center">⭐⭐⭐⭐⭐</td><td align="center">⭐⭐</td><td align="center">⭐⭐⭐⭐</td></tr><tr><td><strong>可靠性</strong></td><td align="center">⭐⭐⭐⭐⭐</td><td align="center">⭐⭐⭐⭐</td><td align="center">⭐⭐⭐⭐</td></tr><tr><td><strong>扩展性</strong></td><td align="center">⭐⭐⭐⭐⭐</td><td align="center">⭐⭐⭐⭐</td><td align="center">⭐⭐⭐⭐⭐</td></tr><tr><td><strong>运维成本</strong></td><td align="center">⭐⭐⭐⭐⭐</td><td align="center">⭐⭐⭐</td><td align="center">⭐⭐</td></tr><tr><td><strong>功能全面性</strong></td><td align="center">⭐⭐⭐</td><td align="center">⭐⭐⭐</td><td align="center">⭐⭐⭐⭐⭐</td></tr></tbody></table><h3 id="4-5-实际应用案例分析"><a href="#4-5-实际应用案例分析" class="headerlink" title="4.5 实际应用案例分析"></a>4.5 实际应用案例分析</h3><h4 id="4-5-1-电商平台存储架构"><a href="#4-5-1-电商平台存储架构" class="headerlink" title="4.5.1 电商平台存储架构"></a>4.5.1 电商平台存储架构</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TB    subgraph &quot;电商平台存储层次&quot;        APP[电商应用] --&gt; CDN[CDN缓存层]        CDN --&gt; HOT[&quot;热数据层(商品图片&#x2F;视频) - MinIO&quot;]        HOT --&gt; WARM[&quot;温数据层(历史订单快照) - MinIO&quot;]        WARM --&gt; COLD[&quot;冷数据层(归档日志) - 磁带&#x2F;云归档存储&quot;]                DB[数据库] --&gt; BACKUP[&quot;数据库备份 - MinIO&quot;]        LOG[业务日志系统] --&gt; LOG_ANALYZE[&quot;日志分析平台 - HDFS&#x2F;ClickHouse&quot;]    end  </pre></div><h4 id="4-5-2-AI-ML平台存储设计"><a href="#4-5-2-AI-ML平台存储设计" class="headerlink" title="4.5.2 AI&#x2F;ML平台存储设计"></a>4.5.2 AI&#x2F;ML平台存储设计</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph LR    subgraph &quot;AI&#x2F;ML数据流&quot;        RAW[原始数据采集] --&gt; MINIO1[&quot;MinIO - 数据湖(统一存储)&quot;]        MINIO1 --&gt;|数据预处理| SPARK[&quot;Spark&#x2F;Dask&quot;]        SPARK --&gt; TRAIN_SET[&quot;训练&#x2F;验证数据集&quot;]        TRAIN_SET --&gt; MINIO1                MINIO1 --&gt;|读取训练数据| TRAIN[&quot;模型训练集群 (GPU)&quot;]        TRAIN --&gt; MINIO2[&quot;MinIO - 模型仓库&quot;]        MINIO2 --&gt; DEPLOY[&quot;模型部署&#x2F;推理服务&quot;]    end  </pre></div><h2 id="5-MinIO-命令使用指南"><a href="#5-MinIO-命令使用指南" class="headerlink" title="5. MinIO 命令使用指南"></a>5. MinIO 命令使用指南</h2><h3 id="5-1-安装和部署"><a href="#5-1-安装和部署" class="headerlink" title="5.1 安装和部署"></a>5.1 安装和部署</h3><h4 id="单机部署"><a href="#单机部署" class="headerlink" title="单机部署"></a>单机部署</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载 MinIO 服务器</span></span><br><span class="line">wget https://dl.min.io/server/minio/release/linux-amd64/minio</span><br><span class="line"><span class="built_in">chmod</span> +x minio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动 MinIO 服务器</span></span><br><span class="line"><span class="comment"># MINIO_ROOT_USER 和 MINIO_ROOT_PASSWORD 是启动所必需的环境变量</span></span><br><span class="line"><span class="built_in">export</span> MINIO_ROOT_USER=minioadmin</span><br><span class="line"><span class="built_in">export</span> MINIO_ROOT_PASSWORD=minioadmin</span><br><span class="line">./minio server /data --console-address <span class="string">&quot;:9001&quot;</span></span><br></pre></td></tr></table></figure><h4 id="集群部署-示例"><a href="#集群部署-示例" class="headerlink" title="集群部署 (示例)"></a>集群部署 (示例)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在4个节点上分别设置环境变量和启动命令</span></span><br><span class="line"><span class="comment"># 假设节点IP为 192.168.1.101 到 192.168.1.104</span></span><br><span class="line"><span class="comment"># 在所有节点上执行:</span></span><br><span class="line"><span class="built_in">export</span> MINIO_ROOT_USER=myminioadmin</span><br><span class="line"><span class="built_in">export</span> MINIO_ROOT_PASSWORD=minioadmin_secret</span><br><span class="line">minio server http://192.168.1.10&#123;1...4&#125;/data&#123;1...4&#125; --console-address <span class="string">&quot;:9001&quot;</span></span><br></pre></td></tr></table></figure><h3 id="5-2-MinIO-Client-mc-命令"><a href="#5-2-MinIO-Client-mc-命令" class="headerlink" title="5.2 MinIO Client (mc) 命令"></a>5.2 MinIO Client (mc) 命令</h3><h4 id="基本配置"><a href="#基本配置" class="headerlink" title="基本配置"></a>基本配置</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装 mc 客户端</span></span><br><span class="line">wget https://dl.min.io/client/mc/release/linux-amd64/mc</span><br><span class="line"><span class="built_in">chmod</span> +x mc</span><br><span class="line"><span class="built_in">sudo</span> <span class="built_in">mv</span> mc /usr/local/bin/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加 MinIO 服务器别名</span></span><br><span class="line">mc <span class="built_in">alias</span> <span class="built_in">set</span> myminio http://localhost:9000 minioadmin minioadmin</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有别名</span></span><br><span class="line">mc <span class="built_in">alias</span> list</span><br></pre></td></tr></table></figure><h4 id="Bucket-操作"><a href="#Bucket-操作" class="headerlink" title="Bucket 操作"></a>Bucket 操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 bucket</span></span><br><span class="line">mc mb myminio/mybucket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有 buckets</span></span><br><span class="line">mc <span class="built_in">ls</span> myminio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除 bucket（必须为空）</span></span><br><span class="line">mc rb myminio/mybucket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 强制删除非空 bucket</span></span><br><span class="line">mc rb myminio/mybucket --force</span><br></pre></td></tr></table></figure><h4 id="对象操作"><a href="#对象操作" class="headerlink" title="对象操作"></a>对象操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 上传文件</span></span><br><span class="line">mc <span class="built_in">cp</span> localfile.txt myminio/mybucket/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 上传目录</span></span><br><span class="line">mc <span class="built_in">cp</span> --recursive localdir/ myminio/mybucket/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载文件</span></span><br><span class="line">mc <span class="built_in">cp</span> myminio/mybucket/file.txt .</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载目录</span></span><br><span class="line">mc <span class="built_in">cp</span> --recursive myminio/mybucket/dir/ .</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出对象</span></span><br><span class="line">mc <span class="built_in">ls</span> myminio/mybucket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 递归列出所有对象</span></span><br><span class="line">mc <span class="built_in">ls</span> --recursive myminio/mybucket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除对象</span></span><br><span class="line">mc <span class="built_in">rm</span> myminio/mybucket/file.txt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 批量删除</span></span><br><span class="line">mc <span class="built_in">rm</span> --recursive --force myminio/mybucket/dir/</span><br></pre></td></tr></table></figure><h4 id="同步操作"><a href="#同步操作" class="headerlink" title="同步操作"></a>同步操作</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将本地目录的更改同步到 MinIO</span></span><br><span class="line">mc mirror localdir/ myminio/mybucket/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 MinIO 目录的更改同步到本地</span></span><br><span class="line">mc mirror myminio/mybucket/ localdir/</span><br></pre></td></tr></table></figure><h3 id="5-3-权限和策略管理"><a href="#5-3-权限和策略管理" class="headerlink" title="5.3 权限和策略管理"></a>5.3 权限和策略管理</h3><h4 id="用户管理"><a href="#用户管理" class="headerlink" title="用户管理"></a>用户管理</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建用户</span></span><br><span class="line">mc admin user add myminio newuser password123</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出用户</span></span><br><span class="line">mc admin user list myminio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 禁用用户</span></span><br><span class="line">mc admin user <span class="built_in">disable</span> myminio newuser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用用户</span></span><br><span class="line">mc admin user <span class="built_in">enable</span> myminio newuser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除用户</span></span><br><span class="line">mc admin user remove myminio newuser</span><br></pre></td></tr></table></figure><h4 id="策略管理"><a href="#策略管理" class="headerlink" title="策略管理"></a>策略管理</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 列出内置策略</span></span><br><span class="line">mc admin policy list myminio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建自定义策略文件</span></span><br><span class="line"><span class="built_in">cat</span> &gt; readonly-policy.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;Version&quot;: &quot;2012-10-17&quot;,</span></span><br><span class="line"><span class="string">  &quot;Statement&quot;: [</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      &quot;Effect&quot;: &quot;Allow&quot;,</span></span><br><span class="line"><span class="string">      &quot;Action&quot;: [&quot;s3:GetObject&quot;],</span></span><br><span class="line"><span class="string">      &quot;Resource&quot;: [&quot;arn:aws:s3:::mybucket/*&quot;]</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加策略</span></span><br><span class="line">mc admin policy add myminio readonly-policy readonly-policy.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将策略分配给用户</span></span><br><span class="line">mc admin policy <span class="built_in">set</span> myminio readonly-policy user=newuser</span><br></pre></td></tr></table></figure><h4 id="组管理"><a href="#组管理" class="headerlink" title="组管理"></a>组管理</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建组</span></span><br><span class="line">mc admin group add myminio mygroup newuser</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出组</span></span><br><span class="line">mc admin group list myminio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将策略分配给组</span></span><br><span class="line">mc admin policy <span class="built_in">set</span> myminio readwrite group=mygroup</span><br></pre></td></tr></table></figure><h3 id="5-4-监控和管理"><a href="#5-4-监控和管理" class="headerlink" title="5.4 监控和管理"></a>5.4 监控和管理</h3><h4 id="服务器信息"><a href="#服务器信息" class="headerlink" title="服务器信息"></a>服务器信息</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看服务器信息 (包含存储、版本、运行时间等)</span></span><br><span class="line">mc admin info myminio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启服务</span></span><br><span class="line">mc admin service restart myminio</span><br></pre></td></tr></table></figure><h4 id="性能测试"><a href="#性能测试" class="headerlink" title="性能测试"></a>性能测试</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 运行 S3 基准性能测试</span></span><br><span class="line">mc admin speedtest myminio</span><br></pre></td></tr></table></figure><h4 id="日志管理"><a href="#日志管理" class="headerlink" title="日志管理"></a>日志管理</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看服务器日志</span></span><br><span class="line">mc admin logs myminio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看审计日志</span></span><br><span class="line">mc admin logs myminio --<span class="built_in">type</span> audit --follow</span><br></pre></td></tr></table></figure><h3 id="5-5-高级功能"><a href="#5-5-高级功能" class="headerlink" title="5.5 高级功能"></a>5.5 高级功能</h3><h4 id="版本控制"><a href="#版本控制" class="headerlink" title="版本控制"></a>版本控制</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用版本控制</span></span><br><span class="line">mc version <span class="built_in">enable</span> myminio/mybucket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看版本控制状态</span></span><br><span class="line">mc version info myminio/mybucket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出对象所有版本</span></span><br><span class="line">mc <span class="built_in">ls</span> --versions myminio/mybucket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除特定版本</span></span><br><span class="line">mc <span class="built_in">rm</span> --vid <span class="string">&quot;version-id&quot;</span> myminio/mybucket/file.txt</span><br></pre></td></tr></table></figure><h4 id="生命周期管理-ILM"><a href="#生命周期管理-ILM" class="headerlink" title="生命周期管理 (ILM)"></a>生命周期管理 (ILM)</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建生命周期规则 (30天后过期对象)</span></span><br><span class="line"><span class="built_in">cat</span> &gt; lifecycle.json &lt;&lt; <span class="string">EOF</span></span><br><span class="line"><span class="string">&#123;</span></span><br><span class="line"><span class="string">  &quot;Rules&quot;: [</span></span><br><span class="line"><span class="string">    &#123;</span></span><br><span class="line"><span class="string">      &quot;ID&quot;: &quot;ExpireAfter30Days&quot;,</span></span><br><span class="line"><span class="string">      &quot;Status&quot;: &quot;Enabled&quot;,</span></span><br><span class="line"><span class="string">      &quot;Filter&quot;: &#123; &quot;Prefix&quot;: &quot;&quot; &#125;,</span></span><br><span class="line"><span class="string">      &quot;Expiration&quot;: &#123; &quot;Days&quot;: 30 &#125;</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  ]</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">EOF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用生命周期规则</span></span><br><span class="line">mc ilm import myminio/mybucket &lt; lifecycle.json</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看生命周期规则</span></span><br><span class="line">mc ilm <span class="built_in">ls</span> myminio/mybucket</span><br></pre></td></tr></table></figure><h4 id="加密"><a href="#加密" class="headerlink" title="加密"></a>加密</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用服务器端加密 (SSE-S3)</span></span><br><span class="line">mc encrypt <span class="built_in">set</span> sse-s3 myminio/mybucket</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看加密状态</span></span><br><span class="line">mc encrypt info myminio/mybucket</span><br></pre></td></tr></table></figure><h3 id="5-6-联邦扩容配置"><a href="#5-6-联邦扩容配置" class="headerlink" title="5.6 联邦扩容配置"></a>5.6 联邦扩容配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 启动 etcd 集群 (示例)</span></span><br><span class="line"><span class="comment"># 节点1:</span></span><br><span class="line">etcd --name etcd-1 --initial-advertise-peer-urls http://192.168.1.107:2380 \</span><br><span class="line">  --listen-peer-urls http://192.168.1.107:2380 \</span><br><span class="line">  --listen-client-urls http://192.168.1.107:2379,http://127.0.0.1:2379 \</span><br><span class="line">  --advertise-client-urls http://192.168.1.107:2379 \</span><br><span class="line">  --initial-cluster-token etcd-cluster-1 \</span><br><span class="line">  --initial-cluster etcd-1=http://192.168.1.107:2380,etcd-2=http://192.168.1.108:2380 \</span><br><span class="line">  --initial-cluster-state new</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 配置并启动 MinIO 租户集群</span></span><br><span class="line"><span class="comment"># 在所有 MinIO 节点上设置环境变量</span></span><br><span class="line"><span class="built_in">export</span> MINIO_ETCD_ENDPOINTS=<span class="string">&quot;http://192.168.1.107:2379,http://192.168.1.108:2379&quot;</span></span><br><span class="line"><span class="built_in">export</span> MINIO_PUBLIC_IPS=<span class="string">&quot;192.168.1.103,192.168.1.104&quot;</span> <span class="comment"># 租户集群的公共IP</span></span><br><span class="line"><span class="built_in">export</span> MINIO_DOMAIN=minio.example.com</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动集群1 (租户1)</span></span><br><span class="line">minio server http://192.168.1.&#123;103...104&#125;/data&#123;1...2&#125; --console-address <span class="string">&quot;:9001&quot;</span></span><br></pre></td></tr></table></figure><h3 id="5-7-故障排除命令"><a href="#5-7-故障排除命令" class="headerlink" title="5.7 故障排除命令"></a>5.7 故障排除命令</h3><h4 id="健康检查"><a href="#健康检查" class="headerlink" title="健康检查"></a>健康检查</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查集群健康状况并修复</span></span><br><span class="line">mc admin heal myminio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 递归地检查所有对象</span></span><br><span class="line">mc admin heal --recursive myminio/mybucket</span><br></pre></td></tr></table></figure><h4 id="配置管理"><a href="#配置管理" class="headerlink" title="配置管理"></a>配置管理</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看当前配置</span></span><br><span class="line">mc admin config get myminio</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置配置 (例如，区域)</span></span><br><span class="line">mc admin config <span class="built_in">set</span> myminio region name=us-east-1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重置配置为默认值</span></span><br><span class="line">mc admin config reset myminio</span><br></pre></td></tr></table></figure><h2 id="6-最佳实践"><a href="#6-最佳实践" class="headerlink" title="6. 最佳实践"></a>6. 最佳实践</h2><h3 id="6-1-部署建议"><a href="#6-1-部署建议" class="headerlink" title="6.1 部署建议"></a>6.1 部署建议</h3><h4 id="6-1-1-硬件配置建议"><a href="#6-1-1-硬件配置建议" class="headerlink" title="6.1.1 硬件配置建议"></a>6.1.1 硬件配置建议</h4><ul><li><strong>存储设备</strong>：强烈推荐使用同质化的 NVMe SSD，以避免慢盘效应。使用JBOD（Just a Bunch of Disks）模式，避免使用硬件RAID。</li><li><strong>网络带宽</strong>：为发挥极致性能，建议节点间使用 25Gbps 到 100Gbps 的高速网络。</li><li><strong>CPU要求</strong>：为最大化纠删码性能，推荐使用支持 Intel AVX512 指令集的CPU。</li><li><strong>内存配置</strong>：内存使用与并发请求数和纠删码配置相关。官方建议，对于100TB以下的小规模部署，每节点至少配置32GB内存。对于更大规模的部署，应根据监控的实际内存使用情况进行规划，以支持高并发连接和元数据缓存。</li></ul><h4 id="6-1-2-集群规划建议"><a href="#6-1-2-集群规划建议" class="headerlink" title="6.1.2 集群规划建议"></a>6.1.2 集群规划建议</h4><ul><li><strong>纠删码集合大小</strong>：每个纠删码集合（Erasure Set）的驱动器数量建议为4到16块。</li><li><strong>节点数量限制</strong>：对于单个MinIO集群，为保证通信效率和一致性，建议节点数不要超过32个。更大规模请使用联邦模式。</li><li><strong>可用区部署</strong>：为实现高可用性，应将节点和驱动器分布在不同的物理机架、数据中心可用区中。</li><li><strong>DNS轮询</strong>：配置DNS轮询或使用负载均衡器将客户端请求分发到所有MinIO节点。</li></ul><h4 id="6-1-3-连续IP规划"><a href="#6-1-3-连续IP规划" class="headerlink" title="6.1.3 连续IP规划"></a>6.1.3 连续IP规划</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 推荐使用连续的节点IP和相似的目录结构，便于模板化配置和管理</span></span><br><span class="line">minio server http://192.168.1.&#123;10...13&#125;/data&#123;1...4&#125; --console-address <span class="string">&quot;:9001&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 而非分散的IP和不规则的目录</span></span><br><span class="line"><span class="comment"># minio server http://192.168.1.10/disk_a http://192.168.2.20/drive_1 ...</span></span><br></pre></td></tr></table></figure><h3 id="6-2-性能优化"><a href="#6-2-性能优化" class="headerlink" title="6.2 性能优化"></a>6.2 性能优化</h3><h4 id="6-2-1-纠删码配置优化"><a href="#6-2-1-纠删码配置优化" class="headerlink" title="6.2.1 纠删码配置优化"></a>6.2.1 纠删码配置优化</h4><ul><li><strong>可靠性与效率的平衡</strong>：根据业务对数据可靠性的要求和成本预算，选择合适的纠删码配置。<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># EC:4 (例如 12+4) - 存储效率 75%，可容忍4个驱动器故障，是性能和可靠性的良好平衡点。</span></span><br><span class="line"><span class="comment"># EC:8 (例如 8+8) - 存储效率 50%，可容忍8个驱动器故障，提供极高的可靠性，但成本较高。</span></span><br></pre></td></tr></table></figure></li><li><strong>默认配置推荐</strong>：对于大多数场景，MinIO自动选择的默认纠删码配置（通常是EC:4）是一个很好的起点。</li></ul><h4 id="6-2-2-硬件性能优化"><a href="#6-2-2-硬件性能优化" class="headerlink" title="6.2.2 硬件性能优化"></a>6.2.2 硬件性能优化</h4><ul><li><strong>启用AVX512</strong>：确保CPU支持并启用了AVX512指令集。</li><li><strong>使用NVMe SSD</strong>：充分利用其高IOPS和低延迟特性。</li><li><strong>避免RAID</strong>：硬件RAID会与MinIO自身的纠删码和数据保护机制冲突，并引入性能瓶颈。</li></ul><h4 id="6-2-3-网络优化"><a href="#6-2-3-网络优化" class="headerlink" title="6.2.3 网络优化"></a>6.2.3 网络优化</h4><ul><li><strong>高速网络</strong>：使用25&#x2F;100Gbps网络以支持线速读写。</li><li><strong>负载均衡策略</strong>：使用支持最小连接数或轮询的负载均衡策略。</li><li><strong>网络拓扑</strong>：设计扁平化的网络拓扑，最小化节点间的网络跳数和延迟。</li></ul><h4 id="6-2-4-关键监控指标"><a href="#6-2-4-关键监控指标" class="headerlink" title="6.2.4 关键监控指标"></a>6.2.4 关键监控指标</h4><ul><li>**吞吐量 (Throughput)**：监控集群的读&#x2F;写吞吐量是否符合预期。</li><li>**延迟 (Latency)**：监控S3 API请求的平均和P99延迟。</li><li><strong>驱动器健康</strong>：监控驱动器的SMART数据、IO等待时间、错误率等。</li><li><strong>纠删码状态</strong>：监控是否有降级的纠删码集合，以及数据重建（Healing）的进度和速度。</li></ul><h3 id="6-3-安全建议"><a href="#6-3-安全建议" class="headerlink" title="6.3 安全建议"></a>6.3 安全建议</h3><ul><li><strong>启用TLS</strong>：为所有API和控制台流量强制启用TLS加密传输。</li><li><strong>使用IAM</strong>：实施最小权限原则，为不同应用创建专用的用户和策略。</li><li><strong>密钥管理</strong>：定期轮换访问密钥和密钥加密密钥（KEK）。</li><li><strong>审计日志</strong>：启用并定期审计访问日志，监控异常行为。</li></ul><h3 id="6-4-监控和维护"><a href="#6-4-监控和维护" class="headerlink" title="6.4 监控和维护"></a>6.4 监控和维护</h3><ul><li><strong>Prometheus集成</strong>：利用MinIO内置的Prometheus端点，进行全面的监控和告警。</li><li><strong>定期健康检查</strong>：定期运行 <code>mc admin heal</code> 检查数据完整性。</li><li><strong>容量规划</strong>：监控磁盘使用率，并根据增长趋势制定扩容计划。</li><li><strong>灾难恢复演练</strong>：定期进行灾备演练，确保备份和恢复流程有效。</li></ul><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><h3 id="7-1-MinIO-核心优势总览"><a href="#7-1-MinIO-核心优势总览" class="headerlink" title="7.1 MinIO 核心优势总览"></a>7.1 MinIO 核心优势总览</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TB    subgraph &quot;MinIO 核心优势&quot;        A[MinIO对象存储] --&gt; B[简洁高性能]        A --&gt; C[云原生设计]        A --&gt; D[S3兼容性]        A --&gt; E[企业级特性]                B --&gt; B1[无主架构]        B --&gt; B2[纠删码优化]        B --&gt; B3[AVX512加速]                C --&gt; C1[轻量级容器化]        C --&gt; C2[易于自动化运维]        C --&gt; C3[水平扩展]                D --&gt; D1[事实标准API]        D --&gt; D2[庞大的生态系统]        D --&gt; D3[无缝迁移]                E --&gt; E1[加密与安全]        E --&gt; E2[生命周期管理]        E --&gt; E3[多租户与联邦]    end  </pre></div><h3 id="7-2-技术特色总结"><a href="#7-2-技术特色总结" class="headerlink" title="7.2 技术特色总结"></a>7.2 技术特色总结</h3><p>MinIO 通过以下关键技术实现了其独特的优势：</p><ul><li><strong>架构创新</strong>：<ul><li><strong>无主设计</strong>：采用确定性哈希算法和纠删码集合，从根本上消除了单点故障和性能瓶颈。</li><li><strong>Reed-Solomon纠删码</strong>：提供比传统副本更高的存储效率和更灵活的容错能力。</li><li><strong>自描述元数据</strong>：<code>xl.json</code>随对象存储，确保数据的完整性、可移植性和恢复的简便性。</li></ul></li><li><strong>性能优化</strong>：<ul><li><strong>SIMD加速</strong>：利用AVX512&#x2F;NEON等指令集，将纠删码计算的CPU开销降至最低。</li><li><strong>智能并行处理</strong>：读写操作仅限于纠删码集合内的节点，精准并行，避免了不必要的网络风暴。</li></ul></li><li><strong>运维友好</strong>：<ul><li><strong>极简设计</strong>：单个二进制文件，无复杂依赖，配置简单。</li><li><strong>自动修复</strong>：内置数据完整性检查和自愈机制，大大降低了运维负担。</li></ul></li></ul><h3 id="7-3-适用场景总结"><a href="#7-3-适用场景总结" class="headerlink" title="7.3 适用场景总结"></a>7.3 适用场景总结</h3><p>MinIO 在以下场景中表现尤为出色：</p><ul><li><strong>云原生应用存储</strong>：作为Kubernetes等容器化环境的持久化存储后端。</li><li><strong>数据湖与AI&#x2F;ML</strong>：为Spark、Presto、TensorFlow等框架提供高性能、可扩展的统一存储层。</li><li><strong>备份与归档</strong>：为数据库、虚拟机、应用日志提供高性价比、高可靠的数据保护方案。</li><li><strong>CDN与媒体服务</strong>：作为静态资源（图片、视频）的源站，满足高并发访问需求。</li></ul><h3 id="7-4-总体评价"><a href="#7-4-总体评价" class="headerlink" title="7.4 总体评价"></a>7.4 总体评价</h3><p>MinIO 是一个功能强大、性能卓越且设计简洁的对象存储解决方案。它通过对分布式系统核心问题的深刻理解和创新性的工程实现，成功地在性能、可靠性、可扩展性和易用性之间取得了卓越的平衡。</p><p>对于寻求在私有云、混合云或边缘环境中部署S3兼容存储的组织而言，MinIO无疑是当前市场上最具竞争力的选择之一。</p><h3 id="7-5-最佳实践建议"><a href="#7-5-最佳实践建议" class="headerlink" title="7.5 最佳实践建议"></a>7.5 最佳实践建议</h3><h4 id="分阶段部署策略"><a href="#分阶段部署策略" class="headerlink" title="分阶段部署策略"></a>分阶段部署策略</h4><ol><li><strong>规划阶段</strong>：<ul><li>根据业务需求选择合适的纠删码配置（EC:4是良好起点）。</li><li>规划集群节点和驱动器数量，确保它们均匀分布在不同故障域。</li><li>设计长远的扩容策略（对等扩容 vs 联邦扩容）。</li></ul></li><li><strong>部署阶段</strong>：<ul><li>确保硬件和网络配置满足性能要求（高速网络 + NVMe SSD）。</li><li>使用自动化工具（如Ansible, Terraform）进行声明式部署和配置管理。</li><li>配置DNS轮询或负载均衡器。</li></ul></li><li><strong>运维阶段</strong>：<ul><li>集成Prometheus和Grafana，建立完善的监控和告警体系。</li><li>定期执行 <code>mc admin heal</code> 进行数据巡检。</li><li>定期进行安全审计和密钥轮换。</li></ul></li><li><strong>优化阶段</strong>：<ul><li>根据监控数据，持续调优系统参数。</li><li>根据业务增长，执行预先规划的扩容策略。</li></ul></li></ol><h4 id="关键技术要点"><a href="#关键技术要点" class="headerlink" title="关键技术要点"></a>关键技术要点</h4><ul><li><strong>理解纠删码</strong>：深入理解纠删码的K、M值对可靠性和存储效率的影响。</li><li><strong>理解元数据</strong>：清晰区分对象元数据和配置元数据的不同管理方式。</li><li><strong>善用硬件特性</strong>：充分利用AVX512、NVMe、高速网络等硬件特性来释放MinIO的全部潜力。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MinIO </tag>
            
            <tag> 对象存储 </tag>
            
            <tag> 分布式存储 </tag>
            
            <tag> S3兼容 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CRC-32技术详解：从原理到HDFS应用实践</title>
      <link href="/2025/06/16/CRC-32%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0HDFS%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5/"/>
      <url>/2025/06/16/CRC-32%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E4%BB%8E%E5%8E%9F%E7%90%86%E5%88%B0HDFS%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="CRC-32技术详解：从原理到HDFS应用实践"><a href="#CRC-32技术详解：从原理到HDFS应用实践" class="headerlink" title="CRC-32技术详解：从原理到HDFS应用实践"></a>CRC-32技术详解：从原理到HDFS应用实践</h1><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ol><li><a href="#1-crc-32%E6%A6%82%E8%BF%B0">CRC-32概述</a></li><li><a href="#2-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%B8%8E%E5%A4%9A%E9%A1%B9%E5%BC%8F">数学基础：二进制与多项式</a></li><li><a href="#3-crc%E5%A4%9A%E9%A1%B9%E5%BC%8F%E9%99%A4%E6%B3%95%E5%8E%9F%E7%90%86">CRC多项式除法原理</a><ul><li><a href="#31-crc%E7%9A%84%E6%95%B0%E5%AD%A6%E6%A8%A1%E5%9E%8B">3.1 CRC的数学模型</a></li><li><a href="#32-%E7%94%9F%E6%88%90%E5%A4%9A%E9%A1%B9%E5%BC%8F%E8%AF%A6%E8%A7%A3">3.2 生成多项式详解</a></li><li><a href="#33-%E5%A4%9A%E9%A1%B9%E5%BC%8F%E9%99%A4%E6%B3%95%E6%AD%A5%E9%AA%A4%E8%AF%A6%E8%A7%A3">3.3 多项式除法步骤详解</a></li><li><a href="#34-%E9%99%A4%E6%B3%95%E8%A7%84%E5%88%99%E6%80%BB%E7%BB%93">3.4 除法规则总结</a></li></ul></li><li><a href="#4-crc-32%E8%AE%A1%E7%AE%97%E8%BF%87%E7%A8%8B%E8%AF%A6%E8%A7%A3">CRC-32计算过程详解</a></li><li><a href="#5-%E5%AE%9E%E7%8E%B0%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF">实现优化技术</a></li><li><a href="#6-hdfs%E4%B8%AD%E7%9A%84crc-32%E5%BA%94%E7%94%A8">HDFS中的CRC-32应用</a></li><li><a href="#7-%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B">总结与展望</a></li></ol><hr><h2 id="1-CRC-32概述"><a href="#1-CRC-32概述" class="headerlink" title="1. CRC-32概述"></a>1. CRC-32概述</h2><h3 id="1-1-什么是CRC-32"><a href="#1-1-什么是CRC-32" class="headerlink" title="1.1 什么是CRC-32"></a>1.1 什么是CRC-32</h3><p>CRC-32（Cyclic Redundancy Check，循环冗余校验）是一种广泛使用的错误检测算法。它通过对数据进行多项式除法运算，生成一个32位的校验值，用于检测数据在传输或存储过程中是否发生错误。</p><h3 id="1-2-CRC-32的主要特性"><a href="#1-2-CRC-32的主要特性" class="headerlink" title="1.2 CRC-32的主要特性"></a>1.2 CRC-32的主要特性</h3><ul><li><p><strong>错误检测能力强</strong>：</p><ul><li>可以检测所有单比特错误</li><li>可以检测所有双比特错误</li><li>可以检测所有奇数个比特错误</li><li>可以检测所有长度≤32位的突发错误</li><li>可以检测99.9999997%的长度&gt;32位的突发错误</li></ul></li><li><p><strong>计算效率高</strong>：</p><ul><li>支持硬件加速（SSE4.2指令集）</li><li>可以使用查表法优化</li><li>支持并行计算和增量计算</li></ul></li><li><p><strong>应用广泛</strong>：</p><ul><li>网络通信（以太网、WiFi）</li><li>存储系统（HDFS、ZFS）</li><li>文件压缩（ZIP、PNG）</li><li>数据校验（各种协议和格式）</li></ul></li></ul><h3 id="1-3-CRC-32的变体"><a href="#1-3-CRC-32的变体" class="headerlink" title="1.3 CRC-32的变体"></a>1.3 CRC-32的变体</h3><p>主要有两种常用的CRC-32变体：</p><ol><li><p><strong>CRC-32（IEEE 802.3）</strong></p><ul><li>多项式：0x04C11DB7</li><li>也称为CRC-32-IEEE或标准CRC-32</li></ul></li><li><p><strong>CRC-32C（Castagnoli）</strong></p><ul><li>多项式：0x1EDC6F41</li><li>具有更好的错误检测性能</li><li>支持硬件加速（SSE4.2）</li><li>HDFS等现代系统的首选</li></ul></li></ol><hr><h2 id="2-数学基础：二进制与多项式"><a href="#2-数学基础：二进制与多项式" class="headerlink" title="2. 数学基础：二进制与多项式"></a>2. 数学基础：二进制与多项式</h2><h3 id="2-1-为什么要用多项式表示"><a href="#2-1-为什么要用多项式表示" class="headerlink" title="2.1 为什么要用多项式表示"></a>2.1 为什么要用多项式表示</h3><p>CRC算法基于有限域GF(2)上的多项式算术。在这个数学体系中：</p><ul><li>系数只能是0或1</li><li>加法和减法都等同于异或（XOR）运算</li><li>没有进位和借位</li></ul><p>这种表示方法使得复杂的错误检测算法可以用简单的位运算实现。</p><h3 id="2-2-二进制到多项式的转换规则"><a href="#2-2-二进制到多项式的转换规则" class="headerlink" title="2.2 二进制到多项式的转换规则"></a>2.2 二进制到多项式的转换规则</h3><h4 id="转换规则"><a href="#转换规则" class="headerlink" title="转换规则"></a>转换规则</h4><ul><li><strong>位编号</strong>：从右到左，从0开始</li><li><strong>转换原则</strong>：如果第n位是1，则多项式包含x^n项</li></ul><h4 id="示例解析"><a href="#示例解析" class="headerlink" title="示例解析"></a>示例解析</h4><p>以二进制数 <code>10110101</code> 为例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">二进制数据: 1  0  1  1  0  1  0  1</span><br><span class="line">位位置:     7  6  5  4  3  2  1  0  （从右往左）</span><br><span class="line">            ↓  ↓  ↓  ↓  ↓  ↓  ↓  ↓</span><br><span class="line">对应幂次:  x⁷ x⁶ x⁵ x⁴ x³ x² x¹ x⁰</span><br><span class="line">是否包含:   ✓  ✗  ✓  ✓  ✗  ✓  ✗  ✓</span><br><span class="line"></span><br><span class="line">结果多项式: x⁷ + x⁵ + x⁴ + x² + x⁰</span><br></pre></td></tr></table></figure><h4 id="更多示例"><a href="#更多示例" class="headerlink" title="更多示例"></a>更多示例</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 示例1：全1字节</span></span><br><span class="line"><span class="number">11111111</span> → x⁷ + x⁶ + x⁵ + x⁴ + x³ + x² + x¹ + x⁰</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例2：2的幂</span></span><br><span class="line"><span class="number">10000000</span> → x⁷</span><br><span class="line">00000001 → x⁰ (即<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 示例3：交替位</span></span><br><span class="line"><span class="number">10101010</span> → x⁷ + x⁵ + x³ + x¹</span><br></pre></td></tr></table></figure><h3 id="2-3-多项式运算与二进制运算的对应关系"><a href="#2-3-多项式运算与二进制运算的对应关系" class="headerlink" title="2.3 多项式运算与二进制运算的对应关系"></a>2.3 多项式运算与二进制运算的对应关系</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  flowchart LR    subgraph &quot;二进制运算&quot;        A1[&quot;XOR运算&quot;]         A2[&quot;左移运算&quot;]        A3[&quot;右移运算&quot;]    end        subgraph &quot;多项式运算&quot;        B1[&quot;多项式加&#x2F;减法&quot;]        B2[&quot;乘以x&quot;]        B3[&quot;除以x&quot;]    end        A1 -.-&gt; B1    A2 -.-&gt; B2    A3 -.-&gt; B3  </pre></div><hr><h2 id="3-CRC多项式除法原理"><a href="#3-CRC多项式除法原理" class="headerlink" title="3. CRC多项式除法原理"></a>3. CRC多项式除法原理</h2><h3 id="3-1-CRC的数学模型"><a href="#3-1-CRC的数学模型" class="headerlink" title="3.1 CRC的数学模型"></a>3.1 CRC的数学模型</h3><p>CRC的核心是计算数据的多项式除法余数：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CRC = (M(x) × x^n) mod G(x)</span><br></pre></td></tr></table></figure><p>其中：</p><ul><li>M(x)：原始数据的多项式表示</li><li>G(x)：生成多项式</li><li>n：CRC的位数（对于CRC-32，n&#x3D;32）</li><li>mod：取余运算</li></ul><blockquote><p><strong>关键点</strong>：M(x) × x^n 表示将原始数据左移n位，等同于在数据后附加n个0。这是为了给CRC值预留空间，使得数据和CRC可以作为一个整体进行验证。</p></blockquote><h3 id="3-2-生成多项式详解"><a href="#3-2-生成多项式详解" class="headerlink" title="3.2 生成多项式详解"></a>3.2 生成多项式详解</h3><h4 id="3-2-1-什么是生成多项式"><a href="#3-2-1-什么是生成多项式" class="headerlink" title="3.2.1 什么是生成多项式"></a>3.2.1 什么是生成多项式</h4><p>生成多项式（Generator Polynomial）是CRC算法的核心参数，它是一个预先定义的、固定的多项式，用作除法运算中的”除数”。理解生成多项式的关键点：</p><ol><li><p><strong>角色定位</strong></p><ul><li>生成多项式 &#x3D; 除数（固定不变）</li><li>数据 &#x3D; 被除数（每次不同）</li><li>CRC值 &#x3D; 余数</li></ul></li><li><p><strong>数学特性</strong></p><ul><li>最高位和最低位必须为1</li><li>位数决定了CRC的长度（n位生成多项式产生n-1位CRC）</li><li>不同的生成多项式具有不同的错误检测能力</li></ul></li></ol><h4 id="3-2-2-为什么需要生成多项式"><a href="#3-2-2-为什么需要生成多项式" class="headerlink" title="3.2.2 为什么需要生成多项式"></a>3.2.2 为什么需要生成多项式</h4><p>生成多项式的选择直接影响CRC的错误检测能力：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">类比理解：</span><br><span class="line">- 使用质数7作除数：13 mod 7 = 6, 20 mod 7 = 6（可能碰撞）</span><br><span class="line">- 使用质数11作除数：13 mod 11 = 2, 20 mod 11 = 9（不同余数）</span><br><span class="line"></span><br><span class="line">不同的除数（生成多项式）会产生不同的错误检测特性</span><br></pre></td></tr></table></figure><h4 id="3-2-3-常见的生成多项式"><a href="#3-2-3-常见的生成多项式" class="headerlink" title="3.2.3 常见的生成多项式"></a>3.2.3 常见的生成多项式</h4><p>不同的CRC标准使用不同的生成多项式，这些都是经过数学验证的最优选择：</p><table><thead><tr><th>CRC类型</th><th>生成多项式（二进制）</th><th>十六进制</th><th>多项式表示</th></tr></thead><tbody><tr><td>CRC-4</td><td>10011</td><td>0x13</td><td>x⁴ + x + 1</td></tr><tr><td>CRC-8</td><td>100000111</td><td>0x107</td><td>x⁸ + x² + x + 1</td></tr><tr><td>CRC-16-IBM</td><td>11000000000000101</td><td>0x18005</td><td>x¹⁶ + x¹⁵ + x² + 1</td></tr><tr><td>CRC-16-CCITT</td><td>10001000000100001</td><td>0x11021</td><td>x¹⁶ + x¹² + x⁵ + 1</td></tr><tr><td>CRC-32</td><td>100000100110000010001110110110111</td><td>0x04C11DB7</td><td>x³² + x²⁶ + x²³ + x²² + x¹⁶ + x¹² + x¹¹ + x¹⁰ + x⁸ + x⁷ + x⁵ + x⁴ + x² + x + 1</td></tr><tr><td>CRC-32C</td><td>11110110111000110111101000000001</td><td>0x1EDC6F41</td><td>x³² + x²⁸ + x²⁷ + x²⁶ + x²⁵ + x²³ + x²² + x²⁰ + x¹⁹ + x¹⁸ + x¹⁴ + x¹³ + x¹¹ + x¹⁰ + x⁹ + x⁸ + x⁶ + 1</td></tr></tbody></table><blockquote><p><strong>多项式表示法说明</strong>: 生成多项式的最高次幂（例如CRC-32中的 <code>x³²</code>）在十六进制表示中是隐含的。<code>0x04C11DB7</code> 实际上是一个32位的数字，代表了从 <code>x³¹</code>到 <code>x⁰</code> 的系数。因此，一个n位的CRC算法使用的生成多项式，其最高次幂为n。</p></blockquote><h4 id="3-2-4-生成多项式的选择标准"><a href="#3-2-4-生成多项式的选择标准" class="headerlink" title="3.2.4 生成多项式的选择标准"></a>3.2.4 生成多项式的选择标准</h4><p>选择生成多项式时需要考虑以下因素：</p><ol><li><p><strong>汉明距离（Hamming Distance）</strong></p><ul><li>决定了能检测的最少错误位数</li><li>CRC-32C对于2974字节以下的数据，汉明距离为6</li></ul></li><li><p><strong>错误检测覆盖率</strong></p><ul><li>检测突发错误的能力</li><li>检测随机错误的概率</li></ul></li><li><p><strong>计算效率</strong></p><ul><li>某些多项式支持硬件加速</li><li>CRC-32C被选中部分原因是Intel SSE4.2的支持</li></ul></li></ol><h4 id="3-2-5-生成多项式与数据的关系"><a href="#3-2-5-生成多项式与数据的关系" class="headerlink" title="3.2.5 生成多项式与数据的关系"></a>3.2.5 生成多项式与数据的关系</h4><p>重要概念澄清：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 错误理解</span></span><br><span class="line">数据 = <span class="number">1101</span> → 生成多项式也应该是<span class="number">1101</span>？ ❌</span><br><span class="line"></span><br><span class="line"><span class="comment"># 正确理解</span></span><br><span class="line">数据 = <span class="number">1101</span>（变化的输入）</span><br><span class="line">生成多项式 = <span class="number">1011</span>（固定的算法参数） ✓</span><br><span class="line"></span><br><span class="line"><span class="comment"># 类比</span></span><br><span class="line">计算平方根：</span><br><span class="line">- 数据 = <span class="number">16</span>（要计算平方根的数）</span><br><span class="line">- 算法 = 牛顿迭代法（固定的方法）</span><br><span class="line">- 初始值 = <span class="number">4</span>（算法的参数）</span><br></pre></td></tr></table></figure><h3 id="3-3-多项式除法步骤详解"><a href="#3-3-多项式除法步骤详解" class="headerlink" title="3.3 多项式除法步骤详解"></a>3.3 多项式除法步骤详解</h3><p>让我们通过一个简单的例子理解CRC除法过程：</p><p><strong>示例数据</strong>：</p><ul><li>数据：<code>1101</code>（二进制）</li><li>生成多项式：<code>1011</code>（x³ + x¹ + x⁰）</li><li>附加零后：<code>1101000</code></li></ul><blockquote><p><strong>注意</strong>：这里的生成多项式<code>1011</code>是为了演示而选择的一个简单4位多项式。在实际应用中，生成多项式是预先定义的标准值（如CRC-32C使用0x1EDC6F41）。数据和生成多项式是两个独立的参数，没有必然联系。</p></blockquote><h4 id="为什么要附加零？"><a href="#为什么要附加零？" class="headerlink" title="为什么要附加零？"></a>为什么要附加零？</h4><p>在CRC计算中附加零是一个关键步骤，其原因如下：</p><ol><li><p><strong>数学原理</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CRC的定义：CRC = (M(x) × x^n) mod G(x)</span><br><span class="line"></span><br><span class="line">其中：</span><br><span class="line">- M(x) × x^n 相当于将数据左移n位</span><br><span class="line">- n是CRC的位数（生成多项式位数-1）</span><br><span class="line">- 在二进制中，左移n位等同于附加n个0</span><br></pre></td></tr></table></figure></li><li><p><strong>为CRC预留空间</strong></p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">原始数据：    1101</span><br><span class="line">附加3个零：   1101000</span><br><span class="line">                 ↑</span><br><span class="line">                 预留给3位CRC的空间</span><br><span class="line"></span><br><span class="line">最终传输：    1101[CRC]</span><br></pre></td></tr></table></figure></li><li><p><strong>确保除法的正确性</strong></p></li></ol><ul><li>不附加零：相当于计算 M(x) mod G(x)，会丢失低位信息</li><li>附加零后：计算 (M(x) × x^n) mod G(x)，保留所有信息</li></ul><ol start="4"><li><p><strong>实际例子对比</strong></p>   <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 不附加零（错误做法）</span></span><br><span class="line"><span class="number">1101</span> ÷ <span class="number">1011</span> = <span class="number">1</span> 余 <span class="number">00</span>10</span><br><span class="line"></span><br><span class="line"><span class="comment"># 附加零（正确做法）</span></span><br><span class="line"><span class="number">1101000</span> ÷ <span class="number">1011</span> = <span class="number">1110</span> 余 <span class="number">0</span>101</span><br><span class="line"></span><br><span class="line"><span class="comment"># CRC = 101，可以附加到原始数据后：1101101</span></span><br></pre></td></tr></table></figure></li><li><p><strong>验证时的作用</strong></p>   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">接收方收到：1101101</span><br><span class="line">验证：1101101 ÷ 1011 = 商 余 0</span><br><span class="line">余数为0表示数据正确</span><br></pre></td></tr></table></figure></li></ol><p>这就是为什么在所有CRC计算中都需要先附加相应位数的零。对于CRC-32，需要附加32个零；对于CRC-16，需要附加16个零。</p><h4 id="详细除法过程"><a href="#详细除法过程" class="headerlink" title="详细除法过程"></a>详细除法过程</h4><p>以下是模2除法（XOR除法）的详细步骤。关键在于：<strong>对齐、异或、移位</strong>。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">      1110  &lt;-- 商 (商在CRC计算中不重要)</span><br><span class="line">    ________</span><br><span class="line">1011|1101000  &lt;-- 被除数 (数据 + 附加的零)</span><br><span class="line">    ^1011      &lt;-- 第一次XOR: 1101 XOR 1011</span><br><span class="line">    ----</span><br><span class="line">     01100     &lt;-- 结果, 并带下一位</span><br><span class="line">      ^1011    &lt;-- 最高位是1, 但110小于1011, 所以实际是与0000异或, 然后移位</span><br><span class="line">                 直到窗口数据&#x27;1100&#x27;的最高位是1</span><br><span class="line">       ^1011   &lt;-- 移位直到数据变为1100, 1100 XOR 1011</span><br><span class="line">       ----</span><br><span class="line">        01110  &lt;-- 结果, 并带下一位</span><br><span class="line">         ^1011 &lt;-- 移位直到数据变为1110, 1110 XOR 1011</span><br><span class="line">         ----</span><br><span class="line">          0101 &lt;-- 最终余数 (CRC值)</span><br></pre></td></tr></table></figure><p><strong>步骤分解:</strong></p><ol><li><p><strong>对齐</strong>: 将除数<code>1011</code>与被除数<code>1101000</code>的最高位对齐。</p><ul><li><code>1101000</code></li><li><code>1011</code></li></ul></li><li><p><strong>第一次XOR</strong>: 执行XOR运算。</p><ul><li><code>1101 XOR 1011 = 0110</code></li></ul></li><li><p><strong>移位并带入新位</strong>: 将结果<code>0110</code>与被除数的下一位<code>0</code>组合，形成新的处理窗口<code>1100</code>。(前面的0被忽略，我们总是处理与除数等宽的窗口)。</p><ul><li>当前状态: <code>(0)110000</code></li><li>处理窗口: <code>1100</code></li></ul></li><li><p><strong>第二次XOR</strong>: 窗口<code>1100</code>的最高位是1，所以执行XOR。</p><ul><li><code>1100 XOR 1011 = 0111</code></li></ul></li><li><p><strong>移位并带入新位</strong>: 将结果<code>0111</code>与下一位<code>0</code>组合，形成<code>1110</code>。</p><ul><li>当前状态: <code>(00)11100</code></li><li>处理窗口: <code>1110</code></li></ul></li><li><p><strong>第三次XOR</strong>: 窗口<code>1110</code>的最高位是1，所以执行XOR。</p><ul><li><code>1110 XOR 1011 = 0101</code></li></ul></li><li><p><strong>结束</strong>: 所有数据位都已处理完毕。最终的余数是<code>0101</code>。这就是3位的CRC校验码。</p></li></ol><blockquote><p><strong>核心规则</strong>: 只要处理窗口的最高位是1，就执行XOR；如果是0，则等同于和<code>0000</code>做XOR，结果不变，只需左移一位，带入下一位数据即可。</p></blockquote><h3 id="3-4-除法规则总结"><a href="#3-4-除法规则总结" class="headerlink" title="3.4 除法规则总结"></a>3.4 除法规则总结</h3><ol><li><strong>对齐执行XOR</strong>：将生成多项式与当前数据窗口的最高位对齐，如果窗口最高位为1，则执行XOR运算。</li><li><strong>使用XOR代替减法</strong>：在GF(2)域中，减法等同于XOR，没有进位和借位。</li><li><strong>逐位处理</strong>：每次处理后，窗口向右（或数据向左）移动一位，纳入新的数据位。</li><li><strong>余数即CRC</strong>：当所有数据位都处理完毕后，寄存器中剩下的值就是最终的余数，即CRC值。</li></ol><hr><h2 id="4-CRC-32计算过程详解"><a href="#4-CRC-32计算过程详解" class="headerlink" title="4. CRC-32计算过程详解"></a>4. CRC-32计算过程详解</h2><h3 id="4-1-CRC-32C的参数"><a href="#4-1-CRC-32C的参数" class="headerlink" title="4.1 CRC-32C的参数"></a>4.1 CRC-32C的参数</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">生成多项式: 0x1EDC6F41</span><br><span class="line">初始值: 0xFFFFFFFF</span><br><span class="line">最终异或值: 0xFFFFFFFF</span><br><span class="line">输入反转: 是</span><br><span class="line">输出反转: 是</span><br></pre></td></tr></table></figure><h4 id="4-1-1-参数详解"><a href="#4-1-1-参数详解" class="headerlink" title="4.1.1 参数详解"></a>4.1.1 参数详解</h4><ul><li><p><strong>生成多项式 (Generator Polynomial)</strong>: 这是CRC算法的核心，决定了其错误检测能力。CRC-32C使用的<code>0x1EDC6F41</code>在数学上被证明具有优秀的性能，并得到了硬件（SSE4.2指令集）的支持。</p></li><li><p><strong>初始值 (Initial Value)</strong>: CRC计算寄存器的起始值。通常设为全1（<code>0xFFFFFFFF</code>），这可以避免全零数据块计算出的CRC值为零的情况，增强了对包含大量连续零的数据的检测能力。</p></li><li><p><strong>最终异或值 (Final XOR Value)</strong>: 在计算完成后，CRC结果会与这个值进行XOR操作。这样做可以防止某些简单的、可预测的数据模式（例如，在数据末尾附加零）不会导致CRC值发生可预测的变化。对于CRC-32C，这个值也是<code>0xFFFFFFFF</code>。</p></li><li><p><strong>输入&#x2F;输出反转 (Input&#x2F;Output Reflection)</strong>: 这是一个非常关键但容易混淆的参数。</p><ul><li><strong>输入反转</strong>: 指在处理每个输入字节时，其比特位顺序是否需要颠倒。例如，字节<code>0x41</code> (二进制 <code>01000001</code>) 如果需要输入反转，会变成 <code>10000010</code> (十六进制 <code>0x82</code>) 再参与运算。</li><li><strong>输出反转</strong>: 指在所有计算完成后，最终的CRC结果是否需要进行比特位反转。</li><li><strong>为什么需要反转？</strong>: 反转通常是为了匹配某些历史实现或硬件处理数据的方式（例如，最低有效位优先 LSB-first）。CRC-32和CRC-32C标准都要求对输入和输出进行反转。</li></ul></li></ul><h3 id="4-2-基本计算流程"><a href="#4-2-基本计算流程" class="headerlink" title="4.2 基本计算流程"></a>4.2 基本计算流程</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  flowchart TD    A[&quot;输入数据&quot;] --&gt; B[&quot;初始化CRC&#x3D;0xFFFFFFFF&quot;]    B --&gt; C[&quot;读取一个字节&quot;]    C --&gt; D{&quot;还有数据?&quot;}    D --&gt;|是| E[&quot;字节与CRC高8位XOR&quot;]    E --&gt; F[&quot;8次位处理循环&quot;]    F --&gt; G{&quot;最高位&#x3D;1?&quot;}    G --&gt;|是| H[&quot;左移1位后与多项式XOR&quot;]    G --&gt;|否| I[&quot;仅左移1位&quot;]    H --&gt; J[&quot;继续下一位&quot;]    I --&gt; J    J --&gt; K{&quot;8位处理完?&quot;}    K --&gt;|否| G    K --&gt;|是| C    D --&gt;|否| L[&quot;CRC取反&quot;]    L --&gt; M[&quot;输出最终CRC-32值&quot;]  </pre></div><h3 id="4-3-详细计算示例"><a href="#4-3-详细计算示例" class="headerlink" title="4.3 详细计算示例"></a>4.3 详细计算示例</h3><p>以计算字符串 “A”（ASCII值0x41）的CRC-32C为例：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 步骤1：初始化</span></span><br><span class="line">CRC = <span class="number">0xFFFFFFFF</span></span><br><span class="line">输入字节 = <span class="number">0x41</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤2：字节与CRC高8位异或</span></span><br><span class="line">CRC = <span class="number">0xFFFFFFFF</span></span><br><span class="line">高<span class="number">8</span>位 = <span class="number">0xFF</span></span><br><span class="line">CRC = (CRC &amp; <span class="number">0x00FFFFFF</span>) | ((<span class="number">0xFF</span> ^ <span class="number">0x41</span>) &lt;&lt; <span class="number">24</span>)</span><br><span class="line">    = <span class="number">0xBEFFFFFF</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤3：8次位处理</span></span><br><span class="line">位<span class="number">1</span>: <span class="number">0xBEFFFFFF</span>，最高位=<span class="number">1</span></span><br><span class="line">     CRC = (<span class="number">0xBEFFFFFF</span> &lt;&lt; <span class="number">1</span>) ^ <span class="number">0x1EDC6F41</span></span><br><span class="line">     = <span class="number">0x7DFFFFFE</span> ^ <span class="number">0x1EDC6F41</span></span><br><span class="line">     = <span class="number">0x632390BF</span></span><br><span class="line"></span><br><span class="line">位<span class="number">2</span>: <span class="number">0x632390BF</span>，最高位=<span class="number">0</span></span><br><span class="line">     CRC = <span class="number">0x632390BF</span> &lt;&lt; <span class="number">1</span></span><br><span class="line">     = <span class="number">0xC647217E</span></span><br><span class="line"></span><br><span class="line"><span class="meta">... </span>(继续<span class="number">6</span>次)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 步骤4：最终取反</span></span><br><span class="line">最终CRC = 计算结果 ^ <span class="number">0xFFFFFFFF</span></span><br></pre></td></tr></table></figure><h3 id="4-4-完整的Python实现"><a href="#4-4-完整的Python实现" class="headerlink" title="4.4 完整的Python实现"></a>4.4 完整的Python实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">CRC32C</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;CRC-32C完整实现&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    POLY = <span class="number">0x1EDC6F41</span>      <span class="comment"># Castagnoli多项式</span></span><br><span class="line">    INIT = <span class="number">0xFFFFFFFF</span>      <span class="comment"># 初始值</span></span><br><span class="line">    XOROUT = <span class="number">0xFFFFFFFF</span>    <span class="comment"># 最终异或值</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="comment"># 生成查找表用于优化</span></span><br><span class="line">        <span class="variable language_">self</span>.table = <span class="variable language_">self</span>._generate_table()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_table</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;生成256项的查找表&quot;&quot;&quot;</span></span><br><span class="line">        table = []</span><br><span class="line">        <span class="keyword">for</span> byte <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">256</span>):</span><br><span class="line">            crc = byte &lt;&lt; <span class="number">24</span></span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">                <span class="keyword">if</span> crc &amp; <span class="number">0x80000000</span>:</span><br><span class="line">                    crc = ((crc &lt;&lt; <span class="number">1</span>) ^ <span class="variable language_">self</span>.POLY) &amp; <span class="number">0xFFFFFFFF</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    crc = (crc &lt;&lt; <span class="number">1</span>) &amp; <span class="number">0xFFFFFFFF</span></span><br><span class="line">            table.append(crc)</span><br><span class="line">        <span class="keyword">return</span> table</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_bit_by_bit</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;逐位计算（教学用，展示原理）&quot;&quot;&quot;</span></span><br><span class="line">        crc = <span class="variable language_">self</span>.INIT</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> byte <span class="keyword">in</span> data:</span><br><span class="line">            <span class="comment"># 将当前字节与CRC寄存器的高8位对齐并进行XOR</span></span><br><span class="line">            <span class="comment"># byte &lt;&lt; 24 将8位的字节数据移动到32位字的高位</span></span><br><span class="line">            crc ^= (byte &lt;&lt; <span class="number">24</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 接下来对这8个新位中的每一位进行处理</span></span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">8</span>):</span><br><span class="line">                <span class="keyword">if</span> crc &amp; <span class="number">0x80000000</span>:</span><br><span class="line">                    crc = ((crc &lt;&lt; <span class="number">1</span>) ^ <span class="variable language_">self</span>.POLY) &amp; <span class="number">0xFFFFFFFF</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    crc = (crc &lt;&lt; <span class="number">1</span>) &amp; <span class="number">0xFFFFFFFF</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> crc ^ <span class="variable language_">self</span>.XOROUT</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">compute_table_driven</span>(<span class="params">self, data</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;查表法计算（实际使用）&quot;&quot;&quot;</span></span><br><span class="line">        crc = <span class="variable language_">self</span>.INIT</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> byte <span class="keyword">in</span> data:</span><br><span class="line">            table_idx = ((crc &gt;&gt; <span class="number">24</span>) ^ byte) &amp; <span class="number">0xFF</span></span><br><span class="line">            crc = ((crc &lt;&lt; <span class="number">8</span>) ^ <span class="variable language_">self</span>.table[table_idx]) &amp; <span class="number">0xFFFFFFFF</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> crc ^ <span class="variable language_">self</span>.XOROUT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line">crc32c = CRC32C()</span><br><span class="line">data = <span class="string">b&quot;Hello, HDFS!&quot;</span></span><br><span class="line">result = crc32c.compute_table_driven(data)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;CRC-32C: 0x<span class="subst">&#123;result:08X&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure><hr><h2 id="5-实现优化技术"><a href="#5-实现优化技术" class="headerlink" title="5. 实现优化技术"></a>5. 实现优化技术</h2><h3 id="5-1-查表法优化"><a href="#5-1-查表法优化" class="headerlink" title="5.1 查表法优化"></a>5.1 查表法优化</h3><p>查表法通过预计算所有可能的单字节CRC值，将8次位操作简化为一次查表：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查表法的核心逻辑</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">crc32c_table_driven</span>(<span class="params">data, table</span>):</span><br><span class="line">    crc = <span class="number">0xFFFFFFFF</span></span><br><span class="line">    <span class="keyword">for</span> byte <span class="keyword">in</span> data:</span><br><span class="line">        index = ((crc &gt;&gt; <span class="number">24</span>) ^ byte) &amp; <span class="number">0xFF</span></span><br><span class="line">        crc = ((crc &lt;&lt; <span class="number">8</span>) ^ table[index]) &amp; <span class="number">0xFFFFFFFF</span></span><br><span class="line">    <span class="keyword">return</span> crc ^ <span class="number">0xFFFFFFFF</span></span><br></pre></td></tr></table></figure><p><strong>性能对比</strong>：</p><ul><li>逐位计算：O(8n) 位操作</li><li>查表法：O(n) 查表操作</li><li>提升约8倍性能</li></ul><h3 id="5-2-硬件加速"><a href="#5-2-硬件加速" class="headerlink" title="5.2 硬件加速"></a>5.2 硬件加速</h3><p>现代CPU（支持SSE4.2）提供专门的CRC32指令：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;nmmintrin.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">uint32_t</span> <span class="title function_">crc32c_hardware</span><span class="params">(<span class="type">const</span> <span class="type">uint8_t</span>* data, <span class="type">size_t</span> len)</span> &#123;</span><br><span class="line">    <span class="type">uint32_t</span> crc = <span class="number">0xFFFFFFFF</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 8字节对齐处理</span></span><br><span class="line">    <span class="type">size_t</span> i = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span> (; i + <span class="number">8</span> &lt;= len; i += <span class="number">8</span>) &#123;</span><br><span class="line">        crc = _mm_crc32_u64(crc, *(<span class="type">uint64_t</span>*)(data + i));</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 处理剩余字节</span></span><br><span class="line">    <span class="keyword">for</span> (; i &lt; len; i++) &#123;</span><br><span class="line">        crc = _mm_crc32_u8(crc, data[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> crc ^ <span class="number">0xFFFFFFFF</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>性能提升</strong>：比查表法快10-20倍</p><h3 id="5-3-CRC组合技术"><a href="#5-3-CRC组合技术" class="headerlink" title="5.3 CRC组合技术"></a>5.3 CRC组合技术</h3><p>CRC的一个重要特性是可组合性，这在HDFS中特别有用。这意味着可以独立计算两个数据块A和B的CRC值，然后通过一个数学运算将它们组合成数据块A+B的最终CRC值，而无需重新扫描整个A+B。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">polynomial_multiply_mod</span>(<span class="params">a, b, poly=<span class="number">0x1EDC6F41</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    在GF(2)域上执行多项式乘法，结果模除以poly。</span></span><br><span class="line"><span class="string">    这在普通整数运算中等价于 (a * b) % poly，但这里全是位运算。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> b &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">if</span> b &amp; <span class="number">1</span>:  <span class="comment"># 如果b的当前最低有效位是1</span></span><br><span class="line">            result ^= a</span><br><span class="line">        </span><br><span class="line">        a &lt;&lt;= <span class="number">1</span>  <span class="comment"># a 左移一位，相当于乘以 x</span></span><br><span class="line">        <span class="keyword">if</span> a &amp; (<span class="number">1</span> &lt;&lt; <span class="number">32</span>):  <span class="comment"># 如果 a 的第32位是1 (即溢出)</span></span><br><span class="line">            a ^= poly  <span class="comment"># 执行模除 (XOR)</span></span><br><span class="line">        </span><br><span class="line">        b &gt;&gt;= <span class="number">1</span>  <span class="comment"># 处理 b 的下一位</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_power_mod</span>(<span class="params">base, exponent, poly=<span class="number">0x1EDC6F41</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    计算 base^exponent mod poly (使用快速幂算法，也叫平方乘算法)。</span></span><br><span class="line"><span class="string">    在GF(2)域中，base为2(即多项式x)，用于计算 x 的高次幂。</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    result = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> exponent &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">if</span> exponent &amp; <span class="number">1</span>:</span><br><span class="line">            result = polynomial_multiply_mod(result, base, poly)</span><br><span class="line">        base = polynomial_multiply_mod(base, base, poly)</span><br><span class="line">        exponent &gt;&gt;= <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">combine_crc32c</span>(<span class="params">crc1, crc2, len2, poly=<span class="number">0x1EDC6F41</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    组合两个CRC-32C校验和。</span></span><br><span class="line"><span class="string">    crc1: 第一个数据块的CRC值。</span></span><br><span class="line"><span class="string">    crc2: 第二个数据块的CRC值。</span></span><br><span class="line"><span class="string">    len2: 第二个数据块的长度（字节）。</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    原理: CRC(A || B) = CRC(CRC(A) || B) = CRC(B) ⊕ (CRC(A) × x^(|B|*8) mod G(x))</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 注意: 传入的crc1和crc2应该是未经最终异或的原始CRC寄存器值。</span></span><br><span class="line">    <span class="comment"># 如果是最终值, 需要先 `crc_val ^ XOROUT` 转换回来。</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 1. 计算 x 的 (len2 * 8) 次幂，模除以生成多项式。</span></span><br><span class="line">    <span class="comment">#    基数是 x, 在GF(2)中就是2。</span></span><br><span class="line">    power_of_x = compute_power_mod(<span class="number">2</span>, len2 * <span class="number">8</span>, poly)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 将 crc1 左移 len2 * 8 位, 同样模除以生成多项式。</span></span><br><span class="line">    <span class="comment">#    这等价于 crc1 乘以 x^(len2*8)。</span></span><br><span class="line">    crc1_shifted = polynomial_multiply_mod(crc1, power_of_x, poly)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 将移位后的crc1与crc2进行异或，得到最终的组合CRC。</span></span><br><span class="line">    <span class="keyword">return</span> crc2 ^ crc1_shifted</span><br></pre></td></tr></table></figure><hr><h2 id="6-HDFS中的CRC-32应用"><a href="#6-HDFS中的CRC-32应用" class="headerlink" title="6. HDFS中的CRC-32应用"></a>6. HDFS中的CRC-32应用</h2><h3 id="6-1-HDFS的数据完整性架构"><a href="#6-1-HDFS的数据完整性架构" class="headerlink" title="6.1 HDFS的数据完整性架构"></a>6.1 HDFS的数据完整性架构</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  flowchart TB    subgraph &quot;HDFS数据完整性层次&quot;        A[&quot;文件级CRC&quot;] --&gt; B[&quot;块级CRC&quot;]        B --&gt; C[&quot;Chunk级CRC&lt;br&#x2F;&gt;(默认512字节)&quot;]    end        subgraph &quot;存储结构&quot;        D[&quot;数据块文件&lt;br&#x2F;&gt;(blk_xxxxx)&quot;]         E[&quot;元数据文件&lt;br&#x2F;&gt;(blk_xxxxx.meta)&quot;]        E -.-&gt;|包含CRC| D    end        subgraph &quot;校验时机&quot;        F[&quot;写入时计算&quot;]        G[&quot;传输时验证&quot;]        H[&quot;后台扫描&quot;]        I[&quot;读取时校验&quot;]    end  </pre></div><h3 id="6-2-CRC在HDFS中的使用场景"><a href="#6-2-CRC在HDFS中的使用场景" class="headerlink" title="6.2 CRC在HDFS中的使用场景"></a>6.2 CRC在HDFS中的使用场景</h3><h4 id="6-2-1-数据写入流程"><a href="#6-2-1-数据写入流程" class="headerlink" title="6.2.1 数据写入流程"></a>6.2.1 数据写入流程</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">1. 客户端计算chunk CRC</span><br><span class="line">   ↓</span><br><span class="line">2. 发送数据+CRC到DataNode</span><br><span class="line">   ↓</span><br><span class="line">3. DataNode验证CRC</span><br><span class="line">   ↓</span><br><span class="line">4. 存储数据块和.meta文件</span><br><span class="line">   ↓</span><br><span class="line">5. 定期后台验证</span><br></pre></td></tr></table></figure><h4 id="6-2-2-数据读取流程"><a href="#6-2-2-数据读取流程" class="headerlink" title="6.2.2 数据读取流程"></a>6.2.2 数据读取流程</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  sequenceDiagram    participant Client as 客户端    participant DN as DataNode    participant Disk as 磁盘        Client-&gt;&gt;DN: 请求读取数据块    DN-&gt;&gt;Disk: 读取数据和CRC    Disk--&gt;&gt;DN: 返回数据+CRC    DN-&gt;&gt;DN: 验证CRC    alt CRC正确        DN--&gt;&gt;Client: 返回数据+CRC        Client-&gt;&gt;Client: 再次验证CRC    else CRC错误        DN--&gt;&gt;Client: 报告错误        Client-&gt;&gt;Client: 尝试其他副本    end  </pre></div><h3 id="6-3-HDFS的后台扫描机制"><a href="#6-3-HDFS的后台扫描机制" class="headerlink" title="6.3 HDFS的后台扫描机制"></a>6.3 HDFS的后台扫描机制</h3><h4 id="6-3-1-Block-Scanner（块扫描器）"><a href="#6-3-1-Block-Scanner（块扫描器）" class="headerlink" title="6.3.1 Block Scanner（块扫描器）"></a>6.3.1 Block Scanner（块扫描器）</h4><p><strong>功能</strong>：定期扫描所有数据块，主动发现损坏</p><p><strong>工作机制</strong>：</p><ul><li>维护正常扫描队列和可疑块队列</li><li>可疑块（读取时出错的块）优先扫描</li><li>通过限流避免影响正常IO</li></ul><p><strong>关键配置</strong>：</p><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- hdfs-site.xml --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.block.scanner.volume.bytes.per.second<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>1048576<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!-- 1MB/s --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>扫描带宽限制<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.scan.period.hours<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">value</span>&gt;</span>504<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!-- 3周 --&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">description</span>&gt;</span>完整扫描周期<span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><h4 id="6-3-2-Directory-Scanner（目录扫描器）"><a href="#6-3-2-Directory-Scanner（目录扫描器）" class="headerlink" title="6.3.2 Directory Scanner（目录扫描器）"></a>6.3.2 Directory Scanner（目录扫描器）</h4><p><strong>功能</strong>：检查内存中的块信息与磁盘文件的一致性</p><p><strong>检查内容</strong>：</p><ul><li>块文件和元数据文件是否都存在</li><li>文件大小是否正确</li><li>检测孤立文件</li></ul><p><strong>运行频率</strong>：默认每6小时</p><h4 id="6-3-3-Disk-Checker（磁盘检查器）"><a href="#6-3-3-Disk-Checker（磁盘检查器）" class="headerlink" title="6.3.3 Disk Checker（磁盘检查器）"></a>6.3.3 Disk Checker（磁盘检查器）</h4><p><strong>功能</strong>：检测磁盘级别的故障</p><p><strong>触发条件</strong>：</p><ul><li>仅在发生IOException时触发</li><li>最多每5-6秒运行一次</li></ul><p><strong>检查内容</strong>：</p><ul><li>目录存在性和权限</li><li>基本的读写能力</li></ul><h3 id="6-4-文件级CRC的演进"><a href="#6-4-文件级CRC的演进" class="headerlink" title="6.4 文件级CRC的演进"></a>6.4 文件级CRC的演进</h3><h4 id="6-4-1-传统方式：MD5MD5CRC32"><a href="#6-4-1-传统方式：MD5MD5CRC32" class="headerlink" title="6.4.1 传统方式：MD5MD5CRC32"></a>6.4.1 传统方式：MD5MD5CRC32</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">原理：MD5(MD5(chunk_crc1) + MD5(chunk_crc2) + ...)</span><br><span class="line">问题：</span><br><span class="line">- 依赖块大小和chunk大小</span><br><span class="line">- 不同配置的HDFS之间无法比较</span><br><span class="line">- 不支持与非HDFS系统比较</span><br></pre></td></tr></table></figure><h4 id="6-4-2-新方式：COMPOSITE-CRC32"><a href="#6-4-2-新方式：COMPOSITE-CRC32" class="headerlink" title="6.4.2 新方式：COMPOSITE-CRC32"></a>6.4.2 新方式：COMPOSITE-CRC32</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">原理：直接组合各chunk的CRC值</span><br><span class="line">优势：</span><br><span class="line">- 独立于块配置</span><br><span class="line">- 支持跨系统比较</span><br><span class="line">- 支持增量计算（如文件追加）</span><br></pre></td></tr></table></figure><h3 id="6-5-实际应用示例"><a href="#6-5-实际应用示例" class="headerlink" title="6.5 实际应用示例"></a>6.5 实际应用示例</h3><h4 id="示例1：数据迁移校验"><a href="#示例1：数据迁移校验" class="headerlink" title="示例1：数据迁移校验"></a>示例1：数据迁移校验</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">verify_hdfs_migration</span>(<span class="params">source_hdfs, target_hdfs, file_path</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;验证HDFS间的数据迁移&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 获取源文件的COMPOSITE-CRC</span></span><br><span class="line">    source_crc = source_hdfs.get_file_checksum(</span><br><span class="line">        file_path, </span><br><span class="line">        checksum_type=<span class="string">&#x27;COMPOSITE-CRC32C&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 获取目标文件的COMPOSITE-CRC</span></span><br><span class="line">    target_crc = target_hdfs.get_file_checksum(</span><br><span class="line">        file_path,</span><br><span class="line">        checksum_type=<span class="string">&#x27;COMPOSITE-CRC32C&#x27;</span></span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 比较CRC</span></span><br><span class="line">    <span class="keyword">if</span> source_crc == target_crc:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;文件 <span class="subst">&#123;file_path&#125;</span> 迁移成功&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;文件 <span class="subst">&#123;file_path&#125;</span> 校验失败!&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br></pre></td></tr></table></figure><h4 id="示例2：增量追加验证"><a href="#示例2：增量追加验证" class="headerlink" title="示例2：增量追加验证"></a>示例2：增量追加验证</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">verify_append_operation</span>(<span class="params">hdfs, file_path, append_data</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;验证文件追加操作的完整性&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 获取追加前的CRC和长度</span></span><br><span class="line">    original_checksum = hdfs.get_file_checksum(file_path)</span><br><span class="line">    original_length = hdfs.get_file_status(file_path).length</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算追加数据的CRC</span></span><br><span class="line">    append_crc = calculate_crc32c(append_data)</span><br><span class="line">    append_length = <span class="built_in">len</span>(append_data)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 预计算组合后的CRC</span></span><br><span class="line">    expected_crc = combine_crc32c(</span><br><span class="line">        original_checksum.crc,</span><br><span class="line">        append_crc,</span><br><span class="line">        append_length</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 执行追加</span></span><br><span class="line">    hdfs.append(file_path, append_data)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 验证</span></span><br><span class="line">    new_checksum = hdfs.get_file_checksum(file_path)</span><br><span class="line">    <span class="keyword">return</span> new_checksum.crc == expected_crc</span><br></pre></td></tr></table></figure><hr><h2 id="7-总结与展望"><a href="#7-总结与展望" class="headerlink" title="7. 总结与展望"></a>7. 总结与展望</h2><h3 id="7-1-关键要点总结"><a href="#7-1-关键要点总结" class="headerlink" title="7.1 关键要点总结"></a>7.1 关键要点总结</h3><ol><li><p><strong>CRC-32的数学基础</strong></p><ul><li>基于GF(2)域的多项式除法</li><li>二进制运算对应多项式运算</li><li>XOR运算是核心操作</li></ul></li><li><p><strong>实现优化</strong></p><ul><li>查表法：8倍性能提升</li><li>硬件加速：10-20倍提升</li><li>CRC组合：支持并行和增量计算</li></ul></li><li><p><strong>HDFS应用</strong></p><ul><li>多层次的完整性保护</li><li>主动的后台扫描机制</li><li>支持跨系统的校验比较</li></ul></li></ol><h3 id="7-2-最佳实践建议"><a href="#7-2-最佳实践建议" class="headerlink" title="7.2 最佳实践建议"></a>7.2 最佳实践建议</h3><ol><li><p><strong>选择合适的CRC变体</strong></p><ul><li>新系统优先使用CRC-32C（硬件支持）</li><li>考虑未来可能的CRC-64升级</li></ul></li><li><p><strong>性能优化</strong></p><ul><li>优先使用硬件加速</li><li>合理设置扫描参数避免影响业务</li><li>利用CRC组合特性进行并行计算</li></ul></li><li><p><strong>数据完整性策略</strong></p><ul><li>实施多层次的校验机制</li><li>定期进行全量扫描</li><li>监控和告警异常情况</li></ul></li></ol><h3 id="7-3-未来发展方向"><a href="#7-3-未来发展方向" class="headerlink" title="7.3 未来发展方向"></a>7.3 未来发展方向</h3><ol><li><p><strong>更长的CRC</strong></p><ul><li>CRC-64将提供更低的碰撞概率</li><li>等待硬件原生支持</li></ul></li><li><p><strong>更智能的扫描策略</strong></p><ul><li>基于机器学习的故障预测</li><li>自适应的扫描频率调整</li></ul></li><li><p><strong>跨云存储的统一校验</strong></p><ul><li>标准化的校验接口</li><li>支持更多存储系统</li></ul></li></ol><p>通过深入理解CRC-32的原理和实现，我们可以更好地利用这一技术保护数据完整性，构建更可靠的分布式存储系统。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop HDFS存储机制与块大小选择权衡</title>
      <link href="/2025/06/15/Hadoop%20HDFS%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%9D%97%E5%A4%A7%E5%B0%8F%E9%80%89%E6%8B%A9%E6%9D%83%E8%A1%A1/"/>
      <url>/2025/06/15/Hadoop%20HDFS%E5%AD%98%E5%82%A8%E6%9C%BA%E5%88%B6%E4%B8%8E%E5%9D%97%E5%A4%A7%E5%B0%8F%E9%80%89%E6%8B%A9%E6%9D%83%E8%A1%A1/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop-HDFS存储机制与块大小选择权衡"><a href="#Hadoop-HDFS存储机制与块大小选择权衡" class="headerlink" title="Hadoop HDFS存储机制与块大小选择权衡"></a>Hadoop HDFS存储机制与块大小选择权衡</h1><h2 id="一、HDFS块存储机制核心原理"><a href="#一、HDFS块存储机制核心原理" class="headerlink" title="一、HDFS块存储机制核心原理"></a>一、HDFS块存储机制核心原理</h2><h3 id="1-1-逻辑块-vs-物理存储"><a href="#1-1-逻辑块-vs-物理存储" class="headerlink" title="1.1 逻辑块 vs 物理存储"></a>1.1 逻辑块 vs 物理存储</h3><p>HDFS中的<strong>块大小（block size）</strong>是一个逻辑概念，而非物理预分配：</p><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[&quot;HDFS存储机制&quot;] --&gt; B[&quot;逻辑层面&quot;]    A --&gt; C[&quot;物理层面&quot;]        B --&gt; D[&quot;块大小: 最大容量限制&lt;br&#x2F;&gt;(如128MB)&quot;]    C --&gt; E[&quot;实际占用: 文件真实大小&lt;br&#x2F;&gt;(如1MB文件只占1MB)&quot;]        F[&quot;1MB文件&quot;] --&gt; G[&quot;创建1个块&lt;br&#x2F;&gt;(上限128MB)&quot;]    G --&gt; H[&quot;磁盘占用: 1MB&quot;]        I[&quot;150MB文件&quot;] --&gt; J[&quot;块1: 128MB&lt;br&#x2F;&gt;块2: 22MB&quot;]    J --&gt; K[&quot;磁盘占用: 150MB&quot;]        style D fill:#bbf,stroke:#333,stroke-width:2px    style E fill:#bfb,stroke:#333,stroke-width:2px    style H fill:#9f9,stroke:#333,stroke-width:2px    style K fill:#9f9,stroke:#333,stroke-width:2px  </pre></div><h3 id="1-2-核心设计特点"><a href="#1-2-核心设计特点" class="headerlink" title="1.2 核心设计特点"></a>1.2 核心设计特点</h3><table><thead><tr><th>特性</th><th>说明</th><th>优势</th></tr></thead><tbody><tr><td><strong>按需分配</strong></td><td>只占用文件实际大小的空间</td><td>避免空间浪费</td></tr><tr><td><strong>逻辑分块</strong></td><td>块是管理单位，不是物理单位</td><td>灵活高效</td></tr><tr><td><strong>大块设计</strong></td><td>默认128MB，远大于传统文件系统</td><td>减少元数据开销</td></tr></tbody></table><h2 id="二、HDFS存储设计的优缺点分析"><a href="#二、HDFS存储设计的优缺点分析" class="headerlink" title="二、HDFS存储设计的优缺点分析"></a>二、HDFS存储设计的优缺点分析</h2><h3 id="2-1-设计优势"><a href="#2-1-设计优势" class="headerlink" title="2.1 设计优势"></a>2.1 设计优势</h3><ol><li><strong>空间效率</strong>：小文件不会浪费预分配的块空间</li><li><strong>元数据优化</strong>：大文件使用较少的块，减少NameNode压力</li><li><strong>顺序读写</strong>：大块有利于顺序IO，提高吞吐量</li><li><strong>网络效率</strong>：减少客户端与DataNode的交互次数</li></ol><h3 id="2-2-主要问题：小文件困境"><a href="#2-2-主要问题：小文件困境" class="headerlink" title="2.2 主要问题：小文件困境"></a>2.2 主要问题：小文件困境</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[&quot;小文件问题&quot;] --&gt; B[&quot;元数据爆炸&quot;]    A --&gt; C[&quot;MapReduce性能&quot;]    A --&gt; D[&quot;资源利用率&quot;]        B --&gt; E[&quot;每个文件至少1个块&lt;br&#x2F;&gt;每个块约150字节元数据&lt;br&#x2F;&gt;100万小文件&#x3D;150MB内存&quot;]        C --&gt; F[&quot;每个块对应1个Map任务&lt;br&#x2F;&gt;任务启动开销&gt;处理时间&lt;br&#x2F;&gt;调度器压力大&quot;]        D --&gt; G[&quot;DataNode管理开销&lt;br&#x2F;&gt;心跳通信增加&lt;br&#x2F;&gt;块报告负担重&quot;]        H[&quot;解决方案&quot;] --&gt; I[&quot;HAR归档&quot;]    H --&gt; J[&quot;SequenceFile&quot;]    H --&gt; K[&quot;合并小文件&quot;]    H --&gt; L[&quot;HBase存储&quot;]        style A fill:#f99,stroke:#333,stroke-width:3px    style E fill:#faa,stroke:#333,stroke-width:2px    style F fill:#faa,stroke:#333,stroke-width:2px    style G fill:#faa,stroke:#333,stroke-width:2px    style H fill:#9f9,stroke:#333,stroke-width:3px  </pre></div><h2 id="三、块大小选择的权衡分析"><a href="#三、块大小选择的权衡分析" class="headerlink" title="三、块大小选择的权衡分析"></a>三、块大小选择的权衡分析</h2><h3 id="3-1-不同块大小的影响"><a href="#3-1-不同块大小的影响" class="headerlink" title="3.1 不同块大小的影响"></a>3.1 不同块大小的影响</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph LR    A[&quot;块大小选择&quot;] --&gt; B[&quot;关键指标&quot;]        B --&gt; C[&quot;元数据量&quot;]    B --&gt; D[&quot;并行度&quot;]    B --&gt; E[&quot;任务粒度&quot;]    B --&gt; F[&quot;网络开销&quot;]    B --&gt; G[&quot;容错代价&quot;]        C --&gt; C1[&quot;块越大，元数据越少&quot;]    D --&gt; D1[&quot;块越小，并行度越高&quot;]    E --&gt; E1[&quot;块大小决定Map任务处理时间&quot;]    F --&gt; F1[&quot;块越大，网络传输次数越少&quot;]    G --&gt; G1[&quot;块越大，失败重算代价越高&quot;]        style A fill:#bbf,stroke:#333,stroke-width:3px    style B fill:#fbf,stroke:#333,stroke-width:2px  </pre></div><h3 id="3-2-块大小对比分析"><a href="#3-2-块大小对比分析" class="headerlink" title="3.2 块大小对比分析"></a>3.2 块大小对比分析</h3><table><thead><tr><th>块大小</th><th>元数据压力</th><th>并行度</th><th>任务粒度</th><th>适用场景</th><th>风险点</th></tr></thead><tbody><tr><td><strong>64MB</strong></td><td>高</td><td>很高</td><td>细</td><td>• 小文件多<br>• 计算密集型<br>• 小集群</td><td>• NameNode内存压力<br>• 调度开销大</td></tr><tr><td><strong>128MB</strong><br>(默认)</td><td>中等</td><td>高</td><td>适中</td><td>• 通用场景<br>• 混合负载<br>• 中等规模集群</td><td>• 平衡各方面<br>• 经过验证</td></tr><tr><td><strong>256MB</strong></td><td>低</td><td>中等</td><td>粗</td><td>• 大文件为主<br>• 流式处理<br>• 大规模集群</td><td>• 并行度下降<br>• 负载不均</td></tr><tr><td><strong>512MB+</strong></td><td>很低</td><td>低</td><td>很粗</td><td>• 超大文件<br>• 批处理<br>• 特殊优化</td><td>• 灵活性差<br>• 故障影响大</td></tr></tbody></table><h3 id="3-3-128MB成为默认值的原因"><a href="#3-3-128MB成为默认值的原因" class="headerlink" title="3.3 128MB成为默认值的原因"></a>3.3 128MB成为默认值的原因</h3><p>选择128MB作为HDFS默认块大小，主要基于三个方面的综合考虑：技术因素、实践因素和平衡考虑。</p><h4 id="3-3-1-技术因素"><a href="#3-3-1-技术因素" class="headerlink" title="3.3.1 技术因素"></a>3.3.1 技术因素</h4><h5 id="1-磁盘传输时间"><a href="#1-磁盘传输时间" class="headerlink" title="1. 磁盘传输时间"></a>1. 磁盘传输时间</h5><ul><li><p>目标：块传输时间控制在1-2秒内完成</p></li><li><p>计算基础：当时主流磁盘的传输速度约为100MB&#x2F;s</p></li><li><p>结果：128MB的块可以在1-2秒内完成传输，这是一个合理的时间范围</p></li></ul><h5 id="2-网络带宽利用"><a href="#2-网络带宽利用" class="headerlink" title="2. 网络带宽利用"></a>2. 网络带宽利用</h5><ul><li><p>需求：充分利用数据中心的网络带宽</p></li><li><p>考虑：块不能太小（会产生过多的网络请求），也不能太大（单次传输时间过长）</p></li><li><p>效果：128MB能够较好地利用千兆网络带宽</p></li></ul><h5 id="3-NameNode内存占用"><a href="#3-NameNode内存占用" class="headerlink" title="3. NameNode内存占用"></a>3. NameNode内存占用</h5><ul><li><p>约束：每个块在NameNode中占用约150字节的元数据</p></li><li><p>计算：128MB的块大小使得NameNode能够管理PB级数据而不会内存溢出</p></li><li><p>平衡：在可管理的文件数量和内存消耗之间取得平衡</p></li></ul><h4 id="3-3-2-实践因素"><a href="#3-3-2-实践因素" class="headerlink" title="3.3.2 实践因素"></a>3.3.2 实践因素</h4><h5 id="1-Google-GFS的经验借鉴"><a href="#1-Google-GFS的经验借鉴" class="headerlink" title="1. Google GFS的经验借鉴"></a>1. Google GFS的经验借鉴</h5><ul><li><p>参考：Google文件系统（GFS）使用64MB的块大小</p></li><li><p>改进：Hadoop基于GFS的经验，考虑到硬件发展，将块大小翻倍到128MB</p></li><li><p>验证：这个选择被证明是成功的</p></li></ul><h5 id="2-硬件技术发展"><a href="#2-硬件技术发展" class="headerlink" title="2. 硬件技术发展"></a>2. 硬件技术发展</h5><ul><li><p>趋势：从HDFS设计之初到正式发布，磁盘容量和网络速度都有显著提升</p></li><li><p>适应：128MB比64MB更适合新一代硬件</p></li><li><p>前瞻：为未来几年的硬件发展预留了空间</p></li></ul><h5 id="3-大规模生产环境验证"><a href="#3-大规模生产环境验证" class="headerlink" title="3. 大规模生产环境验证"></a>3. 大规模生产环境验证</h5><ul><li><p>测试：Yahoo、Facebook等公司的大规模部署验证</p></li><li><p>反馈：在各种工作负载下表现稳定</p></li><li><p>优化：经过多次调优后确定的最佳值</p></li></ul><h4 id="3-3-3-平衡考虑"><a href="#3-3-3-平衡考虑" class="headerlink" title="3.3.3 平衡考虑"></a>3.3.3 平衡考虑</h4><h5 id="1-元数据量-vs-并行度"><a href="#1-元数据量-vs-并行度" class="headerlink" title="1. 元数据量 vs 并行度"></a>1. 元数据量 vs 并行度</h5><ul><li><p>矛盾：块越大，元数据越少，但并行处理能力下降</p></li><li><p>权衡：128MB在减少元数据压力的同时，仍保持良好的并行度</p></li><li><p>效果：适合大多数MapReduce作业的需求</p></li></ul><h5 id="2-吞吐量-vs-延迟"><a href="#2-吞吐量-vs-延迟" class="headerlink" title="2. 吞吐量 vs 延迟"></a>2. 吞吐量 vs 延迟</h5><ul><li><p>吞吐量需求：大块有利于顺序读写，提高整体吞吐量</p></li><li><p>延迟要求：块不能太大，否则单个任务处理时间过长</p></li><li><p>平衡点：128MB使得单个Map任务运行时间在合理范围内（通常几十秒到几分钟）</p></li></ul><h5 id="3-效率-vs-灵活性"><a href="#3-效率-vs-灵活性" class="headerlink" title="3. 效率 vs 灵活性"></a>3. 效率 vs 灵活性</h5><ul><li><p>效率追求：大块减少了客户端与NameNode、DataNode的交互次数</p></li><li><p>灵活性需求：不能太大，要能适应不同大小的文件</p></li><li><p>折中方案：128MB既高效又保持了一定的灵活性</p></li></ul><h2 id="四、最佳实践与建议"><a href="#四、最佳实践与建议" class="headerlink" title="四、最佳实践与建议"></a>四、最佳实践与建议</h2><h3 id="4-1-块大小选择决策树"><a href="#4-1-块大小选择决策树" class="headerlink" title="4.1 块大小选择决策树"></a>4.1 块大小选择决策树</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">文件特征分析</span><br><span class="line">├── 平均文件大小 &lt; 100MB</span><br><span class="line">│   ├── 文件数量极多 → 考虑文件合并策略</span><br><span class="line">│   └── 文件数量适中 → 保持128MB</span><br><span class="line">├── 平均文件大小 100MB-1GB</span><br><span class="line">│   └── 默认128MB最优</span><br><span class="line">└── 平均文件大小 &gt; 1GB</span><br><span class="line">    ├── 批处理为主 → 考虑256MB</span><br><span class="line">    └── 实时性要求高 → 保持128MB</span><br></pre></td></tr></table></figure><h3 id="4-2-动态调整策略"><a href="#4-2-动态调整策略" class="headerlink" title="4.2 动态调整策略"></a>4.2 动态调整策略</h3><ol><li><p><strong>监控指标</strong></p><ul><li>NameNode内存使用率</li><li>Map任务平均执行时间</li><li>数据本地性比例</li><li>集群整体吞吐量</li></ul></li><li><p><strong>调整时机</strong></p><ul><li>NameNode内存 &gt; 80% → 增大块大小</li><li>Map任务 &lt; 30秒 → 考虑增大块大小</li><li>Map任务 &gt; 10分钟 → 考虑减小块大小</li><li>新硬件部署 → 重新评估块大小</li></ul></li></ol><h3 id="4-3-配置建议"><a href="#4-3-配置建议" class="headerlink" title="4.3 配置建议"></a>4.3 配置建议</h3><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- hdfs-site.xml 配置示例 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 默认块大小 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>134217728<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!-- 128MB --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">&lt;!-- 针对特定目录设置 --&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 大文件目录使用256MB --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.blocksize./large-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>268435456<span class="tag">&lt;/<span class="name">value</span>&gt;</span> <span class="comment">&lt;!-- 256MB --&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="五、总结"><a href="#五、总结" class="headerlink" title="五、总结"></a>五、总结</h2><h3 id="关键要点"><a href="#关键要点" class="headerlink" title="关键要点"></a>关键要点</h3><ol><li><strong>HDFS块存储本质</strong>：逻辑分块，物理按需，避免空间浪费</li><li><strong>块大小权衡核心</strong>：在元数据开销和并行处理能力之间找平衡</li><li><strong>128MB的合理性</strong>：经过大规模生产环境验证的经验值</li><li><strong>灵活调整原则</strong>：根据实际工作负载和硬件条件动态优化</li><li><strong>小文件是硬伤</strong>：需要额外的策略和工具来解决</li></ol><h3 id="发展趋势"><a href="#发展趋势" class="headerlink" title="发展趋势"></a>发展趋势</h3><ul><li><strong>硬件进步</strong>：SSD普及、网络提速，支持更大的块</li><li><strong>新型存储</strong>：对象存储、列式存储补充HDFS不足</li><li><strong>智能优化</strong>：自适应块大小、动态调整策略</li><li><strong>云原生化</strong>：存算分离架构下的新挑战</li></ul>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 iptables NAT：DNAT 与 SNAT 详解</title>
      <link href="/2025/06/13/iptables-nat-dnat-snat/"/>
      <url>/2025/06/13/iptables-nat-dnat-snat/</url>
      
        <content type="html"><![CDATA[<h1 id="深入理解-iptables-NAT：DNAT-与-SNAT-详解"><a href="#深入理解-iptables-NAT：DNAT-与-SNAT-详解" class="headerlink" title="深入理解 iptables NAT：DNAT 与 SNAT 详解"></a>深入理解 iptables NAT：DNAT 与 SNAT 详解</h1><h2 id="1-NAT-技术背景"><a href="#1-NAT-技术背景" class="headerlink" title="1. NAT 技术背景"></a>1. NAT 技术背景</h2><h3 id="1-1-什么是-NAT"><a href="#1-1-什么是-NAT" class="headerlink" title="1.1 什么是 NAT"></a>1.1 什么是 NAT</h3><p>NAT（Network Address Translation，网络地址转换）是一种网络技术，用于在 IP 数据包通过路由器或防火墙时，修改数据包的源 IP 地址或目标 IP 地址。NAT 技术最初是为了解决 IPv4 地址短缺问题而设计的。</p><h3 id="1-2-NAT-的重要性"><a href="#1-2-NAT-的重要性" class="headerlink" title="1.2 NAT 的重要性"></a>1.2 NAT 的重要性</h3><ol><li><p><strong>解决 IPv4 地址短缺</strong></p><ul><li>允许多个私有 IP 地址共享一个公网 IP</li><li>延缓 IPv4 地址耗尽问题</li></ul></li><li><p><strong>网络安全</strong></p><ul><li>隐藏内部网络结构</li><li>提供基本的防火墙功能</li></ul></li><li><p><strong>网络隔离</strong></p><ul><li>实现私有网络与公网的隔离</li><li>简化网络管理</li></ul></li></ol><h2 id="2-DNAT-详解"><a href="#2-DNAT-详解" class="headerlink" title="2. DNAT 详解"></a>2. DNAT 详解</h2><h3 id="2-1-什么是-DNAT"><a href="#2-1-什么是-DNAT" class="headerlink" title="2.1 什么是 DNAT"></a>2.1 什么是 DNAT</h3><p>DNAT（Destination Network Address Translation，目标地址转换）是一种 NAT 技术，用于修改数据包的目标 IP 地址和端口。当外部网络访问内部服务器时，DNAT 将目标地址转换为内部服务器的实际地址。</p><h3 id="2-2-DNAT-工作原理"><a href="#2-2-DNAT-工作原理" class="headerlink" title="2.2 DNAT 工作原理"></a>2.2 DNAT 工作原理</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph LR    A[外部请求] --&gt;|目标: 公网IP:80| B[路由器]    B --&gt;|DNAT转换| C[内部服务器]    C --&gt;|目标: 内网IP:8080| D[实际服务]  </pre></div><h3 id="2-3-DNAT-使用场景"><a href="#2-3-DNAT-使用场景" class="headerlink" title="2.3 DNAT 使用场景"></a>2.3 DNAT 使用场景</h3><ol><li><p><strong>端口转发</strong></p><ul><li>将外部端口映射到内部服务器</li><li>实现服务对外暴露</li></ul></li><li><p><strong>负载均衡</strong></p><ul><li>将请求分发到多个内部服务器</li><li>实现简单的负载均衡</li></ul></li><li><p><strong>服务隐藏</strong></p><ul><li>隐藏内部服务器的真实 IP</li><li>提高安全性</li></ul></li></ol><h3 id="2-4-DNAT-配置示例"><a href="#2-4-DNAT-配置示例" class="headerlink" title="2.4 DNAT 配置示例"></a>2.4 DNAT 配置示例</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将外部 80 端口转发到内部服务器的 8080 端口</span></span><br><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination 192.168.1.100:8080</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将特定 IP 的请求转发到内部服务器</span></span><br><span class="line">iptables -t nat -A PREROUTING -d 203.0.113.1 -j DNAT --to-destination 192.168.1.100</span><br></pre></td></tr></table></figure><h2 id="3-SNAT-详解"><a href="#3-SNAT-详解" class="headerlink" title="3. SNAT 详解"></a>3. SNAT 详解</h2><h3 id="3-1-什么是-SNAT"><a href="#3-1-什么是-SNAT" class="headerlink" title="3.1 什么是 SNAT"></a>3.1 什么是 SNAT</h3><p>SNAT（Source Network Address Translation，源地址转换）是一种 NAT 技术，用于修改数据包的源 IP 地址。当内部网络访问外部网络时，SNAT 将源地址转换为公网 IP 地址。</p><h3 id="3-2-SNAT-工作原理"><a href="#3-2-SNAT-工作原理" class="headerlink" title="3.2 SNAT 工作原理"></a>3.2 SNAT 工作原理</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph LR    A[内部主机] --&gt;|源: 内网IP| B[路由器]    B --&gt;|SNAT转换| C[外部网络]    C --&gt;|源: 公网IP| D[目标服务器]  </pre></div><h3 id="3-3-SNAT-使用场景"><a href="#3-3-SNAT-使用场景" class="headerlink" title="3.3 SNAT 使用场景"></a>3.3 SNAT 使用场景</h3><ol><li><p><strong>共享上网</strong></p><ul><li>多个内网主机共享一个公网 IP</li><li>实现内网访问外网</li></ul></li><li><p><strong>隐藏内网结构</strong></p><ul><li>保护内部网络拓扑</li><li>提高安全性</li></ul></li><li><p><strong>负载均衡</strong></p><ul><li>实现出站流量的负载均衡</li><li>优化网络性能</li></ul></li></ol><h3 id="3-4-SNAT-配置示例"><a href="#3-4-SNAT-配置示例" class="headerlink" title="3.4 SNAT 配置示例"></a>3.4 SNAT 配置示例</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将内网流量转换为公网 IP</span></span><br><span class="line">iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -j SNAT --to-source 203.0.113.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用动态 IP 进行转换</span></span><br><span class="line">iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -j MASQUERADE</span><br></pre></td></tr></table></figure><h2 id="4-DNAT-与-SNAT-的区别"><a href="#4-DNAT-与-SNAT-的区别" class="headerlink" title="4. DNAT 与 SNAT 的区别"></a>4. DNAT 与 SNAT 的区别</h2><h3 id="4-1-主要区别"><a href="#4-1-主要区别" class="headerlink" title="4.1 主要区别"></a>4.1 主要区别</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[NAT类型] --&gt; B[DNAT]    A --&gt; C[SNAT]    B --&gt; D[修改目标地址]    B --&gt; E[在PREROUTING链处理]    C --&gt; F[修改源地址]    C --&gt; G[在POSTROUTING链处理]  </pre></div><h3 id="4-2-应用场景对比"><a href="#4-2-应用场景对比" class="headerlink" title="4.2 应用场景对比"></a>4.2 应用场景对比</h3><ol><li><p><strong>DNAT</strong></p><ul><li>主要用于入站流量</li><li>实现端口转发</li><li>隐藏内部服务器</li></ul></li><li><p><strong>SNAT</strong></p><ul><li>主要用于出站流量</li><li>实现共享上网</li><li>保护内网安全</li></ul></li></ol><h2 id="5-与-iptables-的关系"><a href="#5-与-iptables-的关系" class="headerlink" title="5. 与 iptables 的关系"></a>5. 与 iptables 的关系</h2><h3 id="5-1-在-iptables-中的位置"><a href="#5-1-在-iptables-中的位置" class="headerlink" title="5.1 在 iptables 中的位置"></a>5.1 在 iptables 中的位置</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[数据包] --&gt; B[PREROUTING链]    B --&gt; C[路由决策]    C --&gt; D[FORWARD链]    D --&gt; E[POSTROUTING链]    B --&gt; F[DNAT处理]    E --&gt; G[SNAT处理]  </pre></div><h3 id="5-2-规则链交互"><a href="#5-2-规则链交互" class="headerlink" title="5.2 规则链交互"></a>5.2 规则链交互</h3><ol><li><p><strong>DNAT 处理流程</strong></p><ul><li>在 PREROUTING 链进行 DNAT</li><li>影响后续的路由决策</li><li>可能触发 SNAT 处理</li></ul></li><li><p><strong>SNAT 处理流程</strong></p><ul><li>在 POSTROUTING 链进行 SNAT</li><li>在数据包发送前修改源地址</li><li>不影响路由决策</li></ul></li></ol><h2 id="6-最佳实践"><a href="#6-最佳实践" class="headerlink" title="6. 最佳实践"></a>6. 最佳实践</h2><h3 id="6-1-配置建议"><a href="#6-1-配置建议" class="headerlink" title="6.1 配置建议"></a>6.1 配置建议</h3><ol><li><p><strong>规则顺序</strong></p><ul><li>先配置 DNAT 规则</li><li>后配置 SNAT 规则</li><li>注意规则优先级</li></ul></li><li><p><strong>性能优化</strong></p><ul><li>使用 ipset 管理大量 IP</li><li>合理设置连接跟踪</li><li>避免过度复杂的规则</li></ul></li><li><p><strong>安全考虑</strong></p><ul><li>限制允许的端口范围</li><li>记录关键 NAT 操作</li><li>定期审查规则</li></ul></li></ol><h3 id="6-2-常见问题"><a href="#6-2-常见问题" class="headerlink" title="6.2 常见问题"></a>6.2 常见问题</h3><ol><li><p><strong>连接跟踪</strong></p><ul><li>确保启用 conntrack</li><li>适当设置超时时间</li><li>处理连接跟踪表溢出</li></ul></li><li><p><strong>性能问题</strong></p><ul><li>监控 NAT 性能</li><li>优化规则结构</li><li>考虑使用硬件加速</li></ul></li></ol><h2 id="7-总结"><a href="#7-总结" class="headerlink" title="7. 总结"></a>7. 总结</h2><p>DNAT 和 SNAT 是 iptables 中最重要的 NAT 技术，它们分别处理入站和出站流量的地址转换。理解这两种技术的原理和应用场景，对于网络管理和安全防护都至关重要。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 网络 </tag>
            
            <tag> 安全 </tag>
            
            <tag> 防火墙 </tag>
            
            <tag> NAT </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解 iptables 规则链：原理与实践</title>
      <link href="/2025/06/13/iptables-rule-chains/"/>
      <url>/2025/06/13/iptables-rule-chains/</url>
      
        <content type="html"><![CDATA[<h1 id="深入理解-iptables-规则链：原理与实践"><a href="#深入理解-iptables-规则链：原理与实践" class="headerlink" title="深入理解 iptables 规则链：原理与实践"></a>深入理解 iptables 规则链：原理与实践</h1><h2 id="1-iptables-简介"><a href="#1-iptables-简介" class="headerlink" title="1. iptables 简介"></a>1. iptables 简介</h2><p>iptables 是 Linux 系统中最常用的防火墙工具，它提供了强大的包过滤和 NAT 功能。通过 iptables，我们可以实现网络访问控制、端口转发、负载均衡等功能。</p><h2 id="2-使用场景"><a href="#2-使用场景" class="headerlink" title="2. 使用场景"></a>2. 使用场景</h2><h3 id="2-1-常见应用场景"><a href="#2-1-常见应用场景" class="headerlink" title="2.1 常见应用场景"></a>2.1 常见应用场景</h3><ul><li>服务器安全防护</li><li>网络访问控制</li><li>端口转发</li><li>NAT 转换</li><li>流量监控</li><li>DDoS 防护</li></ul><h2 id="3-规则链（Chains）详解"><a href="#3-规则链（Chains）详解" class="headerlink" title="3. 规则链（Chains）详解"></a>3. 规则链（Chains）详解</h2><h3 id="3-1-内置链"><a href="#3-1-内置链" class="headerlink" title="3.1 内置链"></a>3.1 内置链</h3><p>iptables 包含五个内置链：</p><ul><li><strong>INPUT</strong>: 处理进入本机的数据包</li><li><strong>OUTPUT</strong>: 处理从本机发出的数据包</li><li><strong>FORWARD</strong>: 处理经过本机转发的数据包</li><li><strong>PREROUTING</strong>: 数据包进入路由表之前</li><li><strong>POSTROUTING</strong>: 数据包离开路由表之后</li></ul><h3 id="3-2-处理流程图"><a href="#3-2-处理流程图" class="headerlink" title="3.2 处理流程图"></a>3.2 处理流程图</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[数据包进入] --&gt; B{目标地址?}    B --&gt;|本机| C[INPUT链]    B --&gt;|其他主机| D[FORWARD链]    C --&gt; E[本机处理]    D --&gt; F[POSTROUTING链]    E --&gt; G[OUTPUT链]    G --&gt; F    F --&gt; H[发送数据包]  </pre></div><h2 id="4-技术原理"><a href="#4-技术原理" class="headerlink" title="4. 技术原理"></a>4. 技术原理</h2><h3 id="4-1-工作原理"><a href="#4-1-工作原理" class="headerlink" title="4.1 工作原理"></a>4.1 工作原理</h3><p>iptables 基于 Netfilter 框架，通过钩子（hooks）机制在数据包处理的关键位置插入处理函数。每个链都包含一系列规则，数据包会按顺序匹配这些规则。</p><h3 id="4-2-规则匹配过程"><a href="#4-2-规则匹配过程" class="headerlink" title="4.2 规则匹配过程"></a>4.2 规则匹配过程</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph LR    A[数据包] --&gt; B[规则1]    B --&gt;|匹配| C[执行动作]    B --&gt;|不匹配| D[规则2]    D --&gt;|匹配| C    D --&gt;|不匹配| E[规则3]    E --&gt;|匹配| C    E --&gt;|不匹配| F[默认策略]  </pre></div><h2 id="5-路由表详解"><a href="#5-路由表详解" class="headerlink" title="5. 路由表详解"></a>5. 路由表详解</h2><h3 id="5-1-路由表基本概念"><a href="#5-1-路由表基本概念" class="headerlink" title="5.1 路由表基本概念"></a>5.1 路由表基本概念</h3><p>路由表是 Linux 系统中用于决定数据包转发路径的核心组件。它包含了网络路由信息，告诉系统如何将数据包发送到目标地址。</p><h3 id="5-2-路由表类型"><a href="#5-2-路由表类型" class="headerlink" title="5.2 路由表类型"></a>5.2 路由表类型</h3><p>Linux 系统中有多个路由表：</p><ol><li><p><strong>主路由表（Table 254）</strong></p><ul><li>系统默认路由表</li><li>包含所有网络接口的路由信息</li></ul></li><li><p><strong>本地路由表（Table 255）</strong></p><ul><li>包含本地网络接口的路由</li><li>用于本地通信</li></ul></li><li><p><strong>自定义路由表</strong></p><ul><li>用户可以根据需要创建</li><li>用于实现策略路由</li></ul></li></ol><h3 id="5-3-路由表与-iptables-的关系"><a href="#5-3-路由表与-iptables-的关系" class="headerlink" title="5.3 路由表与 iptables 的关系"></a>5.3 路由表与 iptables 的关系</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[数据包] --&gt; B[PREROUTING链]    B --&gt; C[路由决策]    C --&gt; D{目标地址?}    D --&gt;|本机| E[INPUT链]    D --&gt;|其他主机| F[FORWARD链]    E --&gt; G[本地进程]    F --&gt; H[POSTROUTING链]    H --&gt; I[发送数据包]  </pre></div><h3 id="5-4-路由表操作命令"><a href="#5-4-路由表操作命令" class="headerlink" title="5.4 路由表操作命令"></a>5.4 路由表操作命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看路由表</span></span><br><span class="line">ip route show</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加路由</span></span><br><span class="line">ip route add 192.168.1.0/24 via 192.168.0.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除路由</span></span><br><span class="line">ip route del 192.168.1.0/24</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看特定路由表</span></span><br><span class="line">ip route show table 254</span><br></pre></td></tr></table></figure><h3 id="5-5-路由表字段说明"><a href="#5-5-路由表字段说明" class="headerlink" title="5.5 路由表字段说明"></a>5.5 路由表字段说明</h3><ol><li><p><strong>目标网络（Destination）</strong></p><ul><li>数据包要到达的网络地址</li><li>可以是具体 IP 或网段</li></ul></li><li><p><strong>网关（Gateway）</strong></p><ul><li>下一跳路由器的 IP 地址</li><li>直接连接时显示 “dev” 接口</li></ul></li><li><p><strong>网络接口（Interface）</strong></p><ul><li>数据包发送的网络接口</li><li>如 eth0、wlan0 等</li></ul></li><li><p><strong>度量值（Metric）</strong></p><ul><li>路由的优先级</li><li>数值越小优先级越高</li></ul></li></ol><h3 id="5-6-路由表与-iptables-的交互"><a href="#5-6-路由表与-iptables-的交互" class="headerlink" title="5.6 路由表与 iptables 的交互"></a>5.6 路由表与 iptables 的交互</h3><ol><li><p><strong>PREROUTING 链</strong></p><ul><li>在路由决策之前处理数据包</li><li>可以修改目标地址（DNAT）</li></ul></li><li><p><strong>POSTROUTING 链</strong></p><ul><li>在路由决策之后处理数据包</li><li>可以修改源地址（SNAT）</li></ul></li><li><p><strong>FORWARD 链</strong></p><ul><li>处理需要转发的数据包</li><li>在路由决策之后执行</li></ul></li></ol><h3 id="5-7-实际应用示例"><a href="#5-7-实际应用示例" class="headerlink" title="5.7 实际应用示例"></a>5.7 实际应用示例</h3><ol><li><p><strong>多网卡环境</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 添加默认路由</span></span><br><span class="line">ip route add default via 192.168.1.1 dev eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加特定网段路由</span></span><br><span class="line">ip route add 10.0.0.0/8 via 192.168.2.1 dev eth1</span><br></pre></td></tr></table></figure></li><li><p><strong>策略路由</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建自定义路由表</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;100 custom&quot;</span> &gt;&gt; /etc/iproute2/rt_tables</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加策略路由规则</span></span><br><span class="line">ip rule add from 192.168.1.0/24 table custom</span><br></pre></td></tr></table></figure></li></ol><h2 id="6-使用方法"><a href="#6-使用方法" class="headerlink" title="6. 使用方法"></a>6. 使用方法</h2><h3 id="6-1-基本命令"><a href="#6-1-基本命令" class="headerlink" title="6.1 基本命令"></a>6.1 基本命令</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看规则</span></span><br><span class="line">iptables -L</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加规则</span></span><br><span class="line">iptables -A INPUT -p tcp --dport 80 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除规则</span></span><br><span class="line">iptables -D INPUT -p tcp --dport 80 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存规则</span></span><br><span class="line">iptables-save &gt; /etc/iptables/rules.v4</span><br></pre></td></tr></table></figure><h3 id="6-2-常用参数"><a href="#6-2-常用参数" class="headerlink" title="6.2 常用参数"></a>6.2 常用参数</h3><ul><li><code>-A</code>: 添加规则</li><li><code>-D</code>: 删除规则</li><li><code>-L</code>: 列出规则</li><li><code>-F</code>: 清空规则</li><li><code>-p</code>: 指定协议</li><li><code>-s</code>: 源地址</li><li><code>-d</code>: 目标地址</li><li><code>--dport</code>: 目标端口</li><li><code>-j</code>: 指定动作</li></ul><h2 id="7-Kubernetes-中的-iptables-应用"><a href="#7-Kubernetes-中的-iptables-应用" class="headerlink" title="7. Kubernetes 中的 iptables 应用"></a>7. Kubernetes 中的 iptables 应用</h2><h3 id="7-1-kube-proxy-与-iptables"><a href="#7-1-kube-proxy-与-iptables" class="headerlink" title="7.1 kube-proxy 与 iptables"></a>7.1 kube-proxy 与 iptables</h3><p>在 Kubernetes 中，kube-proxy 组件使用 iptables 实现以下核心功能：</p><ol><li><p><strong>Service 负载均衡</strong></p><ul><li>通过 iptables 规则将 Service 的流量转发到后端 Pod</li><li>实现简单的轮询负载均衡</li></ul></li><li><p><strong>Service 类型支持</strong></p><ul><li>ClusterIP：内部访问</li><li>NodePort：节点端口映射</li><li>LoadBalancer：外部负载均衡器集成</li></ul></li></ol><h3 id="7-2-实现原理"><a href="#7-2-实现原理" class="headerlink" title="7.2 实现原理"></a>7.2 实现原理</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[外部请求] --&gt; B[NodePort]    B --&gt; C[iptables PREROUTING]    C --&gt; D[Service IP]    D --&gt; E[iptables FORWARD]    E --&gt; F[Pod IP]    F --&gt; G[容器]  </pre></div><h3 id="7-3-关键-iptables-链"><a href="#7-3-关键-iptables-链" class="headerlink" title="7.3 关键 iptables 链"></a>7.3 关键 iptables 链</h3><p>Kubernetes 主要使用以下 iptables 链：</p><ul><li><strong>KUBE-SERVICES</strong>: 处理所有 Service 的入口流量</li><li><strong>KUBE-NODEPORTS</strong>: 处理 NodePort 类型的 Service</li><li><strong>KUBE-POSTROUTING</strong>: 处理 SNAT（源地址转换）</li><li><strong>KUBE-MARK-MASQ</strong>: 标记需要做 SNAT 的数据包</li></ul><h3 id="7-4-实际效果"><a href="#7-4-实际效果" class="headerlink" title="7.4 实际效果"></a>7.4 实际效果</h3><ol><li><p><strong>服务发现</strong></p><ul><li>通过 iptables 规则实现 Service 到 Pod 的映射</li><li>支持 Pod 的动态扩缩容</li></ul></li><li><p><strong>负载均衡</strong></p><ul><li>基于 iptables 的简单轮询</li><li>支持会话亲和性（Session Affinity）</li></ul></li><li><p><strong>网络策略</strong></p><ul><li>实现 Pod 间的访问控制</li><li>支持网络隔离</li></ul></li></ol><h3 id="7-5-性能考虑"><a href="#7-5-性能考虑" class="headerlink" title="7.5 性能考虑"></a>7.5 性能考虑</h3><ol><li><p><strong>规则数量</strong></p><ul><li>每个 Service 和 Pod 都会产生多条 iptables 规则</li><li>大规模集群可能导致规则数量激增</li></ul></li><li><p><strong>优化方案</strong></p><ul><li>使用 ipset 优化大量 IP 地址的匹配</li><li>考虑使用 IPVS 模式替代 iptables 模式</li></ul></li></ol><h2 id="8-类似技术扩展"><a href="#8-类似技术扩展" class="headerlink" title="8. 类似技术扩展"></a>8. 类似技术扩展</h2><h3 id="8-1-相关技术"><a href="#8-1-相关技术" class="headerlink" title="8.1 相关技术"></a>8.1 相关技术</h3><ol><li><p><strong>nftables</strong></p><ul><li>iptables 的继任者</li><li>更简洁的语法</li><li>更好的性能</li></ul></li><li><p><strong>eBPF</strong></p><ul><li>更灵活的数据包处理</li><li>可编程性更强</li><li>性能更好</li></ul></li><li><p><strong>ipset</strong></p><ul><li>高效的 IP 地址集合管理</li><li>与 iptables 配合使用</li><li>提升规则匹配效率</li></ul></li></ol><h3 id="8-2-技术对比"><a href="#8-2-技术对比" class="headerlink" title="8.2 技术对比"></a>8.2 技术对比</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[防火墙技术] --&gt; B[iptables]    A --&gt; C[nftables]    A --&gt; D[eBPF]    B --&gt; E[成熟稳定]    B --&gt; F[使用广泛]    C --&gt; G[语法简洁]    C --&gt; H[性能优化]    D --&gt; I[高度可编程]    D --&gt; J[性能最佳]  </pre></div><h2 id="9-最佳实践"><a href="#9-最佳实践" class="headerlink" title="9. 最佳实践"></a>9. 最佳实践</h2><ol><li>规则顺序优化</li><li>使用 ipset 管理大量 IP</li><li>定期备份规则</li><li>使用注释说明规则用途</li><li>遵循最小权限原则</li></ol><h2 id="10-总结"><a href="#10-总结" class="headerlink" title="10. 总结"></a>10. 总结</h2><p>iptables 作为 Linux 系统中最强大的防火墙工具，通过其灵活的规则链机制，可以实现复杂的网络控制功能。理解其工作原理和正确使用，对于系统安全和网络管理都至关重要。</p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>iptables 官方文档</li><li>Linux Netfilter 文档</li><li>nftables 官方文档</li><li>eBPF 技术文档</li></ol>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 网络 </tag>
            
            <tag> 安全 </tag>
            
            <tag> 防火墙 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 网络基础概念详解：从硬件到应用</title>
      <link href="/2025/06/13/linux-network-basics/"/>
      <url>/2025/06/13/linux-network-basics/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux-网络基础概念详解：从硬件到应用"><a href="#Linux-网络基础概念详解：从硬件到应用" class="headerlink" title="Linux 网络基础概念详解：从硬件到应用"></a>Linux 网络基础概念详解：从硬件到应用</h1><h2 id="1-网络硬件基础"><a href="#1-网络硬件基础" class="headerlink" title="1. 网络硬件基础"></a>1. 网络硬件基础</h2><h3 id="1-1-网卡（Network-Interface-Card，NIC）"><a href="#1-1-网卡（Network-Interface-Card，NIC）" class="headerlink" title="1.1 网卡（Network Interface Card，NIC）"></a>1.1 网卡（Network Interface Card，NIC）</h3><p>网卡是计算机与网络之间的物理接口，负责网络数据的收发。它是网络通信的物理基础。</p><h4 id="1-1-1-网卡类型"><a href="#1-1-1-网卡类型" class="headerlink" title="1.1.1 网卡类型"></a>1.1.1 网卡类型</h4><ol><li><p><strong>按接口类型</strong></p><ul><li>RJ45 接口：最常见的以太网接口</li><li>光纤接口：支持更高速率和更长距离</li><li>无线接口：支持 WiFi 连接</li><li>USB 接口：便携式网卡</li></ul></li><li><p><strong>按速率分类</strong></p><ul><li>10Mbps：早期以太网</li><li>100Mbps：快速以太网</li><li>1Gbps：千兆以太网</li><li>10Gbps：万兆以太网</li><li>40Gbps&#x2F;100Gbps：高速数据中心</li></ul></li><li><p><strong>按功能分类</strong></p><ul><li>普通网卡：基本网络连接</li><li>服务器网卡：支持多队列、TOE</li><li>智能网卡：支持硬件卸载</li><li>虚拟化网卡：支持 SR-IOV</li></ul></li></ol><h4 id="1-1-2-网卡工作原理"><a href="#1-1-2-网卡工作原理" class="headerlink" title="1.1.2 网卡工作原理"></a>1.1.2 网卡工作原理</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[网卡] --&gt; B[物理层]    B --&gt; C[数据链路层]    C --&gt; D[网络层]        B --&gt; E[信号处理]    B --&gt; F[时钟同步]    B --&gt; G[编码解码]        C --&gt; H[MAC地址]    C --&gt; I[帧处理]    C --&gt; J[错误检测]        D --&gt; K[数据包处理]    D --&gt; L[协议支持]    D --&gt; M[流量控制]  </pre></div><h4 id="1-1-3-网卡寄存器"><a href="#1-1-3-网卡寄存器" class="headerlink" title="1.1.3 网卡寄存器"></a>1.1.3 网卡寄存器</h4><ol><li><p><strong>控制寄存器</strong></p><ul><li>命令寄存器：控制网卡操作</li><li>状态寄存器：反映网卡状态</li><li>中断寄存器：管理中断</li></ul></li><li><p><strong>数据寄存器</strong></p><ul><li>发送缓冲区</li><li>接收缓冲区</li><li>DMA 控制</li></ul></li><li><p><strong>配置寄存器</strong></p><ul><li>MAC 地址</li><li>工作模式</li><li>速率设置</li></ul></li></ol><h3 id="1-2-网卡驱动"><a href="#1-2-网卡驱动" class="headerlink" title="1.2 网卡驱动"></a>1.2 网卡驱动</h3><p>网卡驱动是操作系统与网卡硬件之间的桥梁，负责管理网卡硬件资源，实现数据包的收发。</p><h4 id="1-2-1-驱动架构"><a href="#1-2-1-驱动架构" class="headerlink" title="1.2.1 驱动架构"></a>1.2.1 驱动架构</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[应用层] --&gt; B[Socket API]    B --&gt; C[网络协议栈]    C --&gt; D[网卡驱动]    D --&gt; E[网卡硬件]        D --&gt; F[初始化模块]    D --&gt; G[数据收发模块]    D --&gt; H[中断处理模块]    D --&gt; I[状态管理模块]  </pre></div><h4 id="1-2-2-驱动功能详解"><a href="#1-2-2-驱动功能详解" class="headerlink" title="1.2.2 驱动功能详解"></a>1.2.2 驱动功能详解</h4><ol><li><p><strong>初始化功能</strong></p><ul><li>硬件检测和识别</li><li>寄存器初始化</li><li>中断设置</li><li>DMA 配置</li><li>缓冲区分配</li></ul></li><li><p><strong>数据收发功能</strong></p><ul><li>数据包封装</li><li>校验和计算</li><li>DMA 传输</li><li>错误处理</li><li>流量控制</li></ul></li><li><p><strong>中断处理功能</strong></p><ul><li>接收中断</li><li>发送完成中断</li><li>错误中断</li><li>状态变化中断</li></ul></li><li><p><strong>状态管理功能</strong></p><ul><li>链路状态监控</li><li>错误统计</li><li>性能统计</li><li>电源管理</li></ul></li></ol><h4 id="1-2-3-驱动工作流程"><a href="#1-2-3-驱动工作流程" class="headerlink" title="1.2.3 驱动工作流程"></a>1.2.3 驱动工作流程</h4><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  sequenceDiagram    participant App as 应用程序    participant Kernel as 内核    participant Driver as 网卡驱动    participant NIC as 网卡硬件        App-&gt;&gt;Kernel: 系统调用    Kernel-&gt;&gt;Driver: 驱动接口调用    Driver-&gt;&gt;NIC: 写寄存器    NIC-&gt;&gt;Driver: 中断通知    Driver-&gt;&gt;Kernel: 中断处理    Kernel-&gt;&gt;App: 返回结果  </pre></div><h2 id="2-网络接口"><a href="#2-网络接口" class="headerlink" title="2. 网络接口"></a>2. 网络接口</h2><h3 id="2-1-物理接口"><a href="#2-1-物理接口" class="headerlink" title="2.1 物理接口"></a>2.1 物理接口</h3><h4 id="2-1-1-单端口网卡"><a href="#2-1-1-单端口网卡" class="headerlink" title="2.1.1 单端口网卡"></a>2.1.1 单端口网卡</h4><ol><li><p><strong>基本特性</strong></p><ul><li>单个物理接口</li><li>标准 MAC 地址</li><li>基本网络功能</li><li>适用于普通工作站</li></ul></li><li><p><strong>使用场景</strong></p><ul><li>个人电脑</li><li>普通服务器</li><li>网络终端设备</li></ul></li></ol><h4 id="2-1-2-多端口网卡"><a href="#2-1-2-多端口网卡" class="headerlink" title="2.1.2 多端口网卡"></a>2.1.2 多端口网卡</h4><ol><li><p><strong>类型</strong></p><ul><li>双端口网卡</li><li>四端口网卡</li><li>八端口网卡</li></ul></li><li><p><strong>高级特性</strong></p><ul><li>链路聚合</li><li>负载均衡</li><li>故障转移</li><li>多队列支持</li></ul></li><li><p><strong>应用场景</strong></p><ul><li>服务器</li><li>网络设备</li><li>存储设备</li></ul></li></ol><h3 id="2-2-虚拟接口"><a href="#2-2-虚拟接口" class="headerlink" title="2.2 虚拟接口"></a>2.2 虚拟接口</h3><h4 id="2-2-1-VLAN-接口"><a href="#2-2-1-VLAN-接口" class="headerlink" title="2.2.1 VLAN 接口"></a>2.2.1 VLAN 接口</h4><ol><li><p><strong>工作原理</strong></p><ul><li>基于 802.1Q 协议</li><li>在数据帧中添加 VLAN 标签</li><li>实现虚拟局域网隔离</li></ul></li><li><p><strong>配置示例</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 VLAN 接口</span></span><br><span class="line">ip <span class="built_in">link</span> add <span class="built_in">link</span> eth0 name eth0.100 <span class="built_in">type</span> vlan <span class="built_in">id</span> 100</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 IP 地址</span></span><br><span class="line">ip addr add 192.168.100.1/24 dev eth0.100</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用接口</span></span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> eth0.100 up</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 VLAN 信息</span></span><br><span class="line">ip -d <span class="built_in">link</span> show eth0.100</span><br></pre></td></tr></table></figure></li><li><p><strong>使用场景</strong></p><ul><li>网络隔离</li><li>安全区域划分</li><li>流量控制</li></ul></li></ol><h4 id="2-2-2-子接口"><a href="#2-2-2-子接口" class="headerlink" title="2.2.2 子接口"></a>2.2.2 子接口</h4><ol><li><p><strong>特性</strong></p><ul><li>基于物理接口创建</li><li>支持多个 IP 地址</li><li>独立的路由表</li><li>独立的防火墙规则</li></ul></li><li><p><strong>配置示例</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建子接口</span></span><br><span class="line">ip addr add 192.168.1.100/24 dev eth0:0</span><br><span class="line">ip addr add 192.168.2.100/24 dev eth0:1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置路由</span></span><br><span class="line">ip route add 192.168.1.0/24 dev eth0:0</span><br><span class="line">ip route add 192.168.2.0/24 dev eth0:1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看子接口</span></span><br><span class="line">ip addr show eth0:0</span><br></pre></td></tr></table></figure></li><li><p><strong>应用场景</strong></p><ul><li>多网段配置</li><li>网络隔离</li><li>负载均衡</li></ul></li></ol><h4 id="2-2-3-网桥接口"><a href="#2-2-3-网桥接口" class="headerlink" title="2.2.3 网桥接口"></a>2.2.3 网桥接口</h4><ol><li><p><strong>工作原理</strong></p><ul><li>二层交换功能</li><li>学习 MAC 地址</li><li>转发数据帧</li><li>支持 STP 协议</li></ul></li><li><p><strong>配置示例</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建网桥</span></span><br><span class="line">brctl addbr br0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加接口</span></span><br><span class="line">brctl addif br0 eth0</span><br><span class="line">brctl addif br0 eth1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用网桥</span></span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> br0 up</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 IP 地址</span></span><br><span class="line">ip addr add 192.168.1.1/24 dev br0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看网桥信息</span></span><br><span class="line">brctl show</span><br></pre></td></tr></table></figure></li><li><p><strong>使用场景</strong></p><ul><li>虚拟化环境</li><li>容器网络</li><li>网络隔离</li></ul></li></ol><h4 id="2-2-4-绑定接口（Bond）"><a href="#2-2-4-绑定接口（Bond）" class="headerlink" title="2.2.4 绑定接口（Bond）"></a>2.2.4 绑定接口（Bond）</h4><ol><li><p><strong>绑定模式</strong></p><ul><li>mode&#x3D;0：轮询模式</li><li>mode&#x3D;1：主备模式</li><li>mode&#x3D;2：XOR 模式</li><li>mode&#x3D;3：广播模式</li><li>mode&#x3D;4：802.3ad 模式</li><li>mode&#x3D;5：适配器传输负载均衡</li><li>mode&#x3D;6：适配器适应性负载均衡</li></ul></li><li><p><strong>配置示例</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建绑定接口</span></span><br><span class="line">ip <span class="built_in">link</span> add bond0 <span class="built_in">type</span> bond</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置绑定模式</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /sys/class/net/bond0/bonding/mode</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加从属接口</span></span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> eth0 master bond0</span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> eth1 master bond0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启用绑定接口</span></span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> bond0 up</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 IP 地址</span></span><br><span class="line">ip addr add 192.168.1.100/24 dev bond0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看绑定状态</span></span><br><span class="line"><span class="built_in">cat</span> /proc/net/bonding/bond0</span><br></pre></td></tr></table></figure></li><li><p><strong>应用场景</strong></p><ul><li>高可用性</li><li>负载均衡</li><li>带宽聚合</li></ul></li></ol><h2 id="3-网络协议栈"><a href="#3-网络协议栈" class="headerlink" title="3. 网络协议栈"></a>3. 网络协议栈</h2><h3 id="3-1-协议层次"><a href="#3-1-协议层次" class="headerlink" title="3.1 协议层次"></a>3.1 协议层次</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[应用层] --&gt; B[传输层]    B --&gt; C[网络层]    C --&gt; D[数据链路层]    D --&gt; E[物理层]        A --&gt; F[HTTP&#x2F;FTP&#x2F;DNS]    A --&gt; G[SMTP&#x2F;POP3]    A --&gt; H[SSH&#x2F;TELNET]        B --&gt; I[TCP]    B --&gt; J[UDP]        C --&gt; K[IP]    C --&gt; L[ICMP]    C --&gt; M[IGMP]        D --&gt; N[以太网]    D --&gt; O[ARP]    D --&gt; P[RARP]        E --&gt; Q[网卡驱动]    E --&gt; R[物理介质]  </pre></div><h3 id="3-2-关键协议详解"><a href="#3-2-关键协议详解" class="headerlink" title="3.2 关键协议详解"></a>3.2 关键协议详解</h3><h4 id="3-2-1-TCP-IP-协议族"><a href="#3-2-1-TCP-IP-协议族" class="headerlink" title="3.2.1 TCP&#x2F;IP 协议族"></a>3.2.1 TCP&#x2F;IP 协议族</h4><ol><li><p><strong>IP 协议</strong></p><ul><li>版本：IPv4&#x2F;IPv6</li><li>功能：路由和寻址</li><li>特点：无连接、不可靠</li><li>数据包格式：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">+------------------+</span><br><span class="line">|    版本/头长度    |</span><br><span class="line">+------------------+</span><br><span class="line">|    服务类型      |</span><br><span class="line">+------------------+</span><br><span class="line">|    总长度        |</span><br><span class="line">+------------------+</span><br><span class="line">|    标识          |</span><br><span class="line">+------------------+</span><br><span class="line">|    标志/片偏移    |</span><br><span class="line">+------------------+</span><br><span class="line">|    TTL          |</span><br><span class="line">+------------------+</span><br><span class="line">|    协议          |</span><br><span class="line">+------------------+</span><br><span class="line">|    校验和        |</span><br><span class="line">+------------------+</span><br><span class="line">|    源IP地址      |</span><br><span class="line">+------------------+</span><br><span class="line">|    目标IP地址    |</span><br><span class="line">+------------------+</span><br><span class="line">|    选项          |</span><br><span class="line">+------------------+</span><br><span class="line">|    数据          |</span><br><span class="line">+------------------+</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>TCP 协议</strong></p><ul><li>特点：面向连接、可靠传输</li><li>功能：流量控制、拥塞控制</li><li>数据包格式：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">+------------------+</span><br><span class="line">|    源端口        |</span><br><span class="line">+------------------+</span><br><span class="line">|    目标端口      |</span><br><span class="line">+------------------+</span><br><span class="line">|    序列号        |</span><br><span class="line">+------------------+</span><br><span class="line">|    确认号        |</span><br><span class="line">+------------------+</span><br><span class="line">|    标志位        |</span><br><span class="line">+------------------+</span><br><span class="line">|    窗口大小      |</span><br><span class="line">+------------------+</span><br><span class="line">|    校验和        |</span><br><span class="line">+------------------+</span><br><span class="line">|    紧急指针      |</span><br><span class="line">+------------------+</span><br><span class="line">|    选项          |</span><br><span class="line">+------------------+</span><br><span class="line">|    数据          |</span><br><span class="line">+------------------+</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>UDP 协议</strong></p><ul><li>特点：无连接、不可靠</li><li>功能：简单高效</li><li>数据包格式：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">+------------------+</span><br><span class="line">|    源端口        |</span><br><span class="line">+------------------+</span><br><span class="line">|    目标端口      |</span><br><span class="line">+------------------+</span><br><span class="line">|    长度          |</span><br><span class="line">+------------------+</span><br><span class="line">|    校验和        |</span><br><span class="line">+------------------+</span><br><span class="line">|    数据          |</span><br><span class="line">+------------------+</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>ICMP 协议</strong></p><ul><li>功能：网络诊断</li><li>类型：请求&#x2F;应答</li><li>常见消息：<ul><li>Echo Request&#x2F;Reply</li><li>Destination Unreachable</li><li>Time Exceeded</li><li>Parameter Problem</li></ul></li></ul></li></ol><h4 id="3-2-2-应用层协议"><a href="#3-2-2-应用层协议" class="headerlink" title="3.2.2 应用层协议"></a>3.2.2 应用层协议</h4><ol><li><p><strong>HTTP 协议</strong></p><ul><li>版本：HTTP&#x2F;1.0、HTTP&#x2F;1.1、HTTP&#x2F;2</li><li>特点：无状态、可扩展</li><li>请求方法：GET、POST、PUT、DELETE</li><li>状态码：200、404、500 等</li></ul></li><li><p><strong>FTP 协议</strong></p><ul><li>模式：主动模式、被动模式</li><li>功能：文件传输</li><li>命令：PUT、GET、LIST</li><li>安全：FTPS、SFTP</li></ul></li><li><p><strong>DNS 协议</strong></p><ul><li>功能：域名解析</li><li>记录类型：A、AAAA、CNAME、MX</li><li>查询类型：递归、迭代</li><li>端口：53</li></ul></li><li><p><strong>SMTP 协议</strong></p><ul><li>功能：邮件传输</li><li>命令：HELO、MAIL、RCPT、DATA</li><li>安全：STARTTLS、SMTPS</li><li>端口：25、465</li></ul></li></ol><h2 id="4-网络端口"><a href="#4-网络端口" class="headerlink" title="4. 网络端口"></a>4. 网络端口</h2><h3 id="4-1-端口概念详解"><a href="#4-1-端口概念详解" class="headerlink" title="4.1 端口概念详解"></a>4.1 端口概念详解</h3><ol><li><p><strong>端口范围</strong></p><ul><li>0-1023：知名端口</li><li>1024-49151：注册端口</li><li>49152-65535：动态端口</li></ul></li><li><p><strong>端口状态</strong></p><ul><li>LISTEN：监听状态</li><li>ESTABLISHED：已建立连接</li><li>TIME_WAIT：等待关闭</li><li>CLOSE_WAIT：等待关闭</li><li>FIN_WAIT：等待结束</li></ul></li><li><p><strong>端口复用</strong></p><ul><li>SO_REUSEADDR</li><li>SO_REUSEPORT</li><li>多进程监听</li><li>负载均衡</li></ul></li></ol><h3 id="4-2-常见端口及服务"><a href="#4-2-常见端口及服务" class="headerlink" title="4.2 常见端口及服务"></a>4.2 常见端口及服务</h3><ol><li><p><strong>Web 服务</strong></p><ul><li>80：HTTP</li><li>443：HTTPS</li><li>8080：代理服务器</li><li>8443：HTTPS 代理</li></ul></li><li><p><strong>数据库服务</strong></p><ul><li>3306：MySQL</li><li>5432：PostgreSQL</li><li>6379：Redis</li><li>27017：MongoDB</li></ul></li><li><p><strong>邮件服务</strong></p><ul><li>25：SMTP</li><li>110：POP3</li><li>143：IMAP</li><li>465：SMTPS</li></ul></li><li><p><strong>文件服务</strong></p><ul><li>21：FTP</li><li>22：SFTP</li><li>445：SMB</li><li>2049：NFS</li></ul></li><li><p><strong>远程管理</strong></p><ul><li>22：SSH</li><li>23：Telnet</li><li>3389：RDP</li><li>5900：VNC</li></ul></li></ol><h2 id="5-防火墙"><a href="#5-防火墙" class="headerlink" title="5. 防火墙"></a>5. 防火墙</h2><h3 id="5-1-iptables-详解"><a href="#5-1-iptables-详解" class="headerlink" title="5.1 iptables 详解"></a>5.1 iptables 详解</h3><h4 id="5-1-1-表（Tables）"><a href="#5-1-1-表（Tables）" class="headerlink" title="5.1.1 表（Tables）"></a>5.1.1 表（Tables）</h4><ol><li><p><strong>filter 表</strong></p><ul><li>默认表</li><li>用于包过滤</li><li>链：INPUT、OUTPUT、FORWARD</li></ul></li><li><p><strong>nat 表</strong></p><ul><li>用于地址转换</li><li>链：PREROUTING、POSTROUTING、OUTPUT</li></ul></li><li><p><strong>mangle 表</strong></p><ul><li>用于数据包修改</li><li>链：PREROUTING、INPUT、FORWARD、OUTPUT、POSTROUTING</li></ul></li><li><p><strong>raw 表</strong></p><ul><li>用于连接跟踪</li><li>链：PREROUTING、OUTPUT</li></ul></li></ol><h4 id="5-1-2-链（Chains）"><a href="#5-1-2-链（Chains）" class="headerlink" title="5.1.2 链（Chains）"></a>5.1.2 链（Chains）</h4><ol><li><p><strong>INPUT 链</strong></p><ul><li>处理入站数据包</li><li>目标地址为本机</li><li>常用规则：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 允许已建立的连接</span></span><br><span class="line">iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 允许特定端口</span></span><br><span class="line">iptables -A INPUT -p tcp --dport 80 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 允许特定 IP</span></span><br><span class="line">iptables -A INPUT -s 192.168.1.100 -j ACCEPT</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>OUTPUT 链</strong></p><ul><li>处理出站数据包</li><li>源地址为本机</li><li>常用规则：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 允许所有出站流量</span></span><br><span class="line">iptables -A OUTPUT -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 限制特定端口</span></span><br><span class="line">iptables -A OUTPUT -p tcp --dport 25 -j DROP</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>FORWARD 链</strong></p><ul><li>处理转发数据包</li><li>经过本机的数据包</li><li>常用规则：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 允许转发</span></span><br><span class="line">iptables -A FORWARD -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 限制特定网段</span></span><br><span class="line">iptables -A FORWARD -s 192.168.1.0/24 -j DROP</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>PREROUTING 链</strong></p><ul><li>数据包进入路由表之前</li><li>用于 DNAT</li><li>常用规则：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 端口转发</span></span><br><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination 192.168.1.100:8080</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>POSTROUTING 链</strong></p><ul><li>数据包离开路由表之后</li><li>用于 SNAT</li><li>常用规则：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 源地址转换</span></span><br><span class="line">iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -j SNAT --to-source 203.0.113.1</span><br></pre></td></tr></table></figure></li></ul></li></ol><h4 id="5-1-3-匹配条件"><a href="#5-1-3-匹配条件" class="headerlink" title="5.1.3 匹配条件"></a>5.1.3 匹配条件</h4><ol><li><p><strong>基本匹配</strong></p><ul><li>源地址：-s</li><li>目标地址：-d</li><li>协议：-p</li><li>接口：-i&#x2F;-o</li></ul></li><li><p><strong>扩展匹配</strong></p><ul><li>状态：-m state</li><li>多端口：-m multiport</li><li>连接限制：-m limit</li><li>字符串：-m string</li></ul></li><li><p><strong>目标动作</strong></p><ul><li>ACCEPT：接受</li><li>DROP：丢弃</li><li>REJECT：拒绝</li><li>LOG：记录</li><li>DNAT：目标地址转换</li><li>SNAT：源地址转换</li></ul></li></ol><h3 id="5-2-防火墙规则示例"><a href="#5-2-防火墙规则示例" class="headerlink" title="5.2 防火墙规则示例"></a>5.2 防火墙规则示例</h3><ol><li><p><strong>基本防护</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 清除现有规则</span></span><br><span class="line">iptables -F</span><br><span class="line">iptables -X</span><br><span class="line">iptables -Z</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置默认策略</span></span><br><span class="line">iptables -P INPUT DROP</span><br><span class="line">iptables -P FORWARD DROP</span><br><span class="line">iptables -P OUTPUT ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 允许本地回环</span></span><br><span class="line">iptables -A INPUT -i lo -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 允许已建立的连接</span></span><br><span class="line">iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 允许 SSH</span></span><br><span class="line">iptables -A INPUT -p tcp --dport 22 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 允许 HTTP/HTTPS</span></span><br><span class="line">iptables -A INPUT -p tcp --dport 80 -j ACCEPT</span><br><span class="line">iptables -A INPUT -p tcp --dport 443 -j ACCEPT</span><br></pre></td></tr></table></figure></li><li><p><strong>NAT 配置</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用 IP 转发</span></span><br><span class="line"><span class="built_in">echo</span> 1 &gt; /proc/sys/net/ipv4/ip_forward</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 SNAT</span></span><br><span class="line">iptables -t nat -A POSTROUTING -s 192.168.1.0/24 -j SNAT --to-source 203.0.113.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 DNAT</span></span><br><span class="line">iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination 192.168.1.100:8080</span><br></pre></td></tr></table></figure></li><li><p><strong>高级规则</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 限制连接数</span></span><br><span class="line">iptables -A INPUT -p tcp --dport 80 -m <span class="built_in">limit</span> --<span class="built_in">limit</span> 25/minute --limit-burst 100 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 防止 SYN 洪水攻击</span></span><br><span class="line">iptables -A INPUT -p tcp --syn -m <span class="built_in">limit</span> --<span class="built_in">limit</span> 1/s --limit-burst 3 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 记录特定流量</span></span><br><span class="line">iptables -A INPUT -p tcp --dport 80 -j LOG --log-prefix <span class="string">&quot;HTTP: &quot;</span></span><br></pre></td></tr></table></figure></li></ol><h2 id="6-完整数据流程"><a href="#6-完整数据流程" class="headerlink" title="6. 完整数据流程"></a>6. 完整数据流程</h2><h3 id="6-1-数据包发送流程"><a href="#6-1-数据包发送流程" class="headerlink" title="6.1 数据包发送流程"></a>6.1 数据包发送流程</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  sequenceDiagram    participant App as Java应用    participant Socket as Socket API    participant TCP as TCP层    participant IP as IP层    participant NIC as 网卡驱动    participant HW as 网卡硬件    participant Net as 网络    App-&gt;&gt;Socket: 调用write()    Socket-&gt;&gt;Socket: 数据复制到内核缓冲区    Socket-&gt;&gt;TCP: 数据封装    TCP-&gt;&gt;TCP: 添加TCP头    TCP-&gt;&gt;TCP: 计算校验和    TCP-&gt;&gt;IP: 添加TCP头    IP-&gt;&gt;IP: 添加IP头    IP-&gt;&gt;IP: 计算校验和    IP-&gt;&gt;IP: 路由查找    IP-&gt;&gt;NIC: 数据包发送    NIC-&gt;&gt;NIC: DMA传输    NIC-&gt;&gt;HW: 数据包发送    HW-&gt;&gt;HW: 添加帧头    HW-&gt;&gt;HW: 计算FCS    HW-&gt;&gt;Net: 物理发送  </pre></div><h3 id="6-2-数据包接收流程"><a href="#6-2-数据包接收流程" class="headerlink" title="6.2 数据包接收流程"></a>6.2 数据包接收流程</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  sequenceDiagram    participant Net as 网络    participant HW as 网卡硬件    participant NIC as 网卡驱动    participant IP as IP层    participant TCP as TCP层    participant Socket as Socket API    participant App as Java应用    Net-&gt;&gt;HW: 接收数据包    HW-&gt;&gt;HW: 校验FCS    HW-&gt;&gt;HW: 去除帧头    HW-&gt;&gt;NIC: 触发中断    NIC-&gt;&gt;NIC: 中断处理    NIC-&gt;&gt;NIC: DMA传输    NIC-&gt;&gt;IP: 数据包接收    IP-&gt;&gt;IP: 校验IP头    IP-&gt;&gt;IP: 去除IP头    IP-&gt;&gt;TCP: 数据包传递    TCP-&gt;&gt;TCP: 校验TCP头    TCP-&gt;&gt;TCP: 去除TCP头    TCP-&gt;&gt;TCP: 重组数据包    TCP-&gt;&gt;Socket: 数据就绪    Socket-&gt;&gt;App: 通知应用    App-&gt;&gt;Socket: 调用read()    Socket-&gt;&gt;App: 返回数据  </pre></div><h3 id="6-3-详细处理流程"><a href="#6-3-详细处理流程" class="headerlink" title="6.3 详细处理流程"></a>6.3 详细处理流程</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[客户端] --&gt;|发送请求| B[网络]    B --&gt;|数据包到达| C[网卡]    C --&gt;|触发中断| D[网卡驱动]    D --&gt;|DMA传输| E[内核缓冲区]    E --&gt;|软中断| F[网络协议栈]    F --&gt;|协议解析| G[Socket层]    G --&gt;|数据就绪| H[Java NIO]    H --&gt;|事件通知| I[Java应用]    I --&gt;|处理请求| J[业务逻辑]        C --&gt;|硬件校验| K[帧校验]    K --&gt;|校验通过| D    K --&gt;|校验失败| L[丢弃数据包]        F --&gt;|IP层处理| M[路由查找]    M --&gt;|找到路由| F    M --&gt;|未找到路由| N[ICMP错误]        F --&gt;|TCP层处理| O[连接跟踪]    O --&gt;|新连接| P[创建连接]    O --&gt;|已有连接| Q[更新连接]        G --&gt;|Socket处理| R[缓冲区管理]    R --&gt;|缓冲区满| S[流量控制]    R --&gt;|缓冲区空| T[等待数据]        H --&gt;|NIO处理| U[事件循环]    U --&gt;|读事件| V[数据读取]    U --&gt;|写事件| W[数据发送]        I --&gt;|应用处理| X[请求解析]    X --&gt;|业务处理| Y[响应生成]    Y --&gt;|数据发送| Z[响应返回]  </pre></div><h2 id="7-网络性能优化"><a href="#7-网络性能优化" class="headerlink" title="7. 网络性能优化"></a>7. 网络性能优化</h2><h3 id="7-1-系统层面"><a href="#7-1-系统层面" class="headerlink" title="7.1 系统层面"></a>7.1 系统层面</h3><h4 id="7-1-1-网卡优化"><a href="#7-1-1-网卡优化" class="headerlink" title="7.1.1 网卡优化"></a>7.1.1 网卡优化</h4><ol><li><p><strong>中断合并</strong></p><ul><li>减少 CPU 中断</li><li>提高吞吐量</li><li>配置示例：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看中断合并设置</span></span><br><span class="line">ethtool -c eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中断合并</span></span><br><span class="line">ethtool -C eth0 rx-usecs 100 tx-usecs 100</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>多队列支持</strong></p><ul><li>多 CPU 处理</li><li>负载均衡</li><li>配置示例：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看队列数</span></span><br><span class="line">ethtool -l eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置队列数</span></span><br><span class="line">ethtool -L eth0 combined 8</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>大页内存</strong></p><ul><li>减少 TLB 缺失</li><li>提高性能</li><li>配置示例：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 分配大页</span></span><br><span class="line"><span class="built_in">echo</span> 1024 &gt; /proc/sys/vm/nr_hugepages</span><br><span class="line"></span><br><span class="line"><span class="comment"># 挂载大页文件系统</span></span><br><span class="line">mount -t hugetlbfs none /dev/hugepages</span><br></pre></td></tr></table></figure></li></ul></li></ol><h4 id="7-1-2-协议栈优化"><a href="#7-1-2-协议栈优化" class="headerlink" title="7.1.2 协议栈优化"></a>7.1.2 协议栈优化</h4><ol><li><p><strong>TCP 参数调优</strong></p><ul><li>缓冲区大小</li><li>超时设置</li><li>拥塞控制</li><li>配置示例：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置 TCP 缓冲区</span></span><br><span class="line">sysctl -w net.core.rmem_max=16777216</span><br><span class="line">sysctl -w net.core.wmem_max=16777216</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置 TCP 超时</span></span><br><span class="line">sysctl -w net.ipv4.tcp_keepalive_time=300</span><br><span class="line">sysctl -w net.ipv4.tcp_keepalive_intvl=15</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置拥塞控制</span></span><br><span class="line">sysctl -w net.ipv4.tcp_congestion_control=cubic</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>连接跟踪</strong></p><ul><li>优化连接表</li><li>超时设置</li><li>配置示例：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置连接跟踪表大小</span></span><br><span class="line">sysctl -w net.netfilter.nf_conntrack_max=1000000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置超时时间</span></span><br><span class="line">sysctl -w net.netfilter.nf_conntrack_tcp_timeout_established=3600</span><br></pre></td></tr></table></figure></li></ul></li></ol><h3 id="7-2-应用层面"><a href="#7-2-应用层面" class="headerlink" title="7.2 应用层面"></a>7.2 应用层面</h3><h4 id="7-2-1-Java-网络优化"><a href="#7-2-1-Java-网络优化" class="headerlink" title="7.2.1 Java 网络优化"></a>7.2.1 Java 网络优化</h4><ol><li><p><strong>NIO 使用</strong></p><ul><li>非阻塞 IO</li><li>事件驱动</li><li>示例代码：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建 Selector</span></span><br><span class="line"><span class="type">Selector</span> <span class="variable">selector</span> <span class="operator">=</span> Selector.open();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建 ServerSocketChannel</span></span><br><span class="line"><span class="type">ServerSocketChannel</span> <span class="variable">serverChannel</span> <span class="operator">=</span> ServerSocketChannel.open();</span><br><span class="line">serverChannel.configureBlocking(<span class="literal">false</span>);</span><br><span class="line">serverChannel.socket().bind(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(<span class="number">8080</span>));</span><br><span class="line">serverChannel.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 事件循环</span></span><br><span class="line"><span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    selector.select();</span><br><span class="line">    Set&lt;SelectionKey&gt; keys = selector.selectedKeys();</span><br><span class="line">    Iterator&lt;SelectionKey&gt; it = keys.iterator();</span><br><span class="line">    <span class="keyword">while</span> (it.hasNext()) &#123;</span><br><span class="line">        <span class="type">SelectionKey</span> <span class="variable">key</span> <span class="operator">=</span> it.next();</span><br><span class="line">        it.remove();</span><br><span class="line">        <span class="keyword">if</span> (key.isAcceptable()) &#123;</span><br><span class="line">            <span class="comment">// 处理连接</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.isReadable()) &#123;</span><br><span class="line">            <span class="comment">// 处理读取</span></span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (key.isWritable()) &#123;</span><br><span class="line">            <span class="comment">// 处理写入</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>连接池管理</strong></p><ul><li>连接复用</li><li>超时控制</li><li>示例配置：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建连接池</span></span><br><span class="line"><span class="type">PoolingHttpClientConnectionManager</span> <span class="variable">cm</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PoolingHttpClientConnectionManager</span>();</span><br><span class="line">cm.setMaxTotal(<span class="number">100</span>);</span><br><span class="line">cm.setDefaultMaxPerRoute(<span class="number">20</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建 HttpClient</span></span><br><span class="line"><span class="type">CloseableHttpClient</span> <span class="variable">httpClient</span> <span class="operator">=</span> HttpClients.custom()</span><br><span class="line">    .setConnectionManager(cm)</span><br><span class="line">    .setDefaultRequestConfig(RequestConfig.custom()</span><br><span class="line">        .setConnectTimeout(<span class="number">5000</span>)</span><br><span class="line">        .setSocketTimeout(<span class="number">5000</span>)</span><br><span class="line">        .build())</span><br><span class="line">    .build();</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>超时设置</strong></p><ul><li>连接超时</li><li>读取超时</li><li>写入超时</li><li>示例代码：<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 设置超时</span></span><br><span class="line"><span class="type">Socket</span> <span class="variable">socket</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Socket</span>();</span><br><span class="line">socket.connect(<span class="keyword">new</span> <span class="title class_">InetSocketAddress</span>(host, port), <span class="number">5000</span>);</span><br><span class="line">socket.setSoTimeout(<span class="number">5000</span>);</span><br></pre></td></tr></table></figure></li></ul></li></ol><h4 id="7-2-2-监控指标"><a href="#7-2-2-监控指标" class="headerlink" title="7.2.2 监控指标"></a>7.2.2 监控指标</h4><ol><li><p><strong>网络吞吐量</strong></p><ul><li>带宽使用率</li><li>数据包速率</li><li>错误率</li><li>监控工具：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 iftop 监控带宽</span></span><br><span class="line">iftop -i eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 nethogs 监控进程</span></span><br><span class="line">nethogs eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 iperf 测试带宽</span></span><br><span class="line">iperf -s</span><br><span class="line">iperf -c server</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>延迟统计</strong></p><ul><li>往返时间</li><li>连接延迟</li><li>处理延迟</li><li>监控工具：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 使用 ping 测试延迟</span></span><br><span class="line">ping -c 100 server</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 tcpping 测试 TCP 延迟</span></span><br><span class="line">tcpping -c 100 server 80</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>错误计数</strong></p><ul><li>丢包率</li><li>重传率</li><li>错误率</li><li>监控工具：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看网卡统计</span></span><br><span class="line">ethtool -S eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 TCP 统计</span></span><br><span class="line">netstat -s</span><br></pre></td></tr></table></figure></li></ul></li></ol><h2 id="8-常见问题排查"><a href="#8-常见问题排查" class="headerlink" title="8. 常见问题排查"></a>8. 常见问题排查</h2><h3 id="8-1-网络连接问题"><a href="#8-1-网络连接问题" class="headerlink" title="8.1 网络连接问题"></a>8.1 网络连接问题</h3><h4 id="8-1-1-物理层"><a href="#8-1-1-物理层" class="headerlink" title="8.1.1 物理层"></a>8.1.1 物理层</h4><ol><li><p><strong>网线连接</strong></p><ul><li>检查网线</li><li>检查接口</li><li>检查指示灯</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看网卡状态</span></span><br><span class="line">ethtool eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看接口信息</span></span><br><span class="line">ip <span class="built_in">link</span> show eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试网线</span></span><br><span class="line">mii-tool eth0</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>网卡状态</strong></p><ul><li>驱动加载</li><li>中断配置</li><li>DMA 设置</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看驱动信息</span></span><br><span class="line">lsmod | grep e1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看中断</span></span><br><span class="line"><span class="built_in">cat</span> /proc/interrupts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看 DMA</span></span><br><span class="line">dmesg | grep DMA</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>驱动问题</strong></p><ul><li>驱动版本</li><li>兼容性</li><li>配置参数</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 更新驱动</span></span><br><span class="line">modprobe -r e1000</span><br><span class="line">modprobe e1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看驱动参数</span></span><br><span class="line">modinfo e1000</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置驱动参数</span></span><br><span class="line"><span class="built_in">echo</span> <span class="string">&quot;options e1000 debug=1&quot;</span> &gt; /etc/modprobe.d/e1000.conf</span><br></pre></td></tr></table></figure></li></ul></li></ol><h4 id="8-1-2-网络层"><a href="#8-1-2-网络层" class="headerlink" title="8.1.2 网络层"></a>8.1.2 网络层</h4><ol><li><p><strong>IP 配置</strong></p><ul><li>地址设置</li><li>子网掩码</li><li>网关配置</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 IP 配置</span></span><br><span class="line">ip addr show</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置 IP 地址</span></span><br><span class="line">ip addr add 192.168.1.100/24 dev eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置网关</span></span><br><span class="line">ip route add default via 192.168.1.1</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>路由表</strong></p><ul><li>路由条目</li><li>默认路由</li><li>策略路由</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看路由表</span></span><br><span class="line">ip route show</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加路由</span></span><br><span class="line">ip route add 192.168.2.0/24 via 192.168.1.1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除路由</span></span><br><span class="line">ip route del 192.168.2.0/24</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>防火墙规则</strong></p><ul><li>规则配置</li><li>链设置</li><li>策略配置</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看规则</span></span><br><span class="line">iptables -L -n -v</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加规则</span></span><br><span class="line">iptables -A INPUT -p tcp --dport 80 -j ACCEPT</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存规则</span></span><br><span class="line">iptables-save &gt; /etc/iptables/rules.v4</span><br></pre></td></tr></table></figure></li></ul></li></ol><h4 id="8-1-3-应用层"><a href="#8-1-3-应用层" class="headerlink" title="8.1.3 应用层"></a>8.1.3 应用层</h4><ol><li><p><strong>端口监听</strong></p><ul><li>服务状态</li><li>端口占用</li><li>访问权限</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看端口</span></span><br><span class="line">netstat -tuln</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看进程</span></span><br><span class="line">lsof -i :80</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试端口</span></span><br><span class="line">telnet localhost 80</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>服务状态</strong></p><ul><li>进程状态</li><li>日志信息</li><li>配置检查</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看服务状态</span></span><br><span class="line">systemctl status nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看日志</span></span><br><span class="line">journalctl -u nginx</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查配置</span></span><br><span class="line">nginx -t</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>日志分析</strong></p><ul><li>错误日志</li><li>访问日志</li><li>系统日志</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看系统日志</span></span><br><span class="line"><span class="built_in">tail</span> -f /var/log/syslog</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看应用日志</span></span><br><span class="line"><span class="built_in">tail</span> -f /var/log/nginx/error.log</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分析日志</span></span><br><span class="line">grep <span class="string">&quot;error&quot;</span> /var/log/nginx/error.log</span><br></pre></td></tr></table></figure></li></ul></li></ol><h3 id="8-2-性能问题"><a href="#8-2-性能问题" class="headerlink" title="8.2 性能问题"></a>8.2 性能问题</h3><h4 id="8-2-1-系统资源"><a href="#8-2-1-系统资源" class="headerlink" title="8.2.1 系统资源"></a>8.2.1 系统资源</h4><ol><li><p><strong>CPU 使用率</strong></p><ul><li>进程 CPU</li><li>中断处理</li><li>上下文切换</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看 CPU 使用</span></span><br><span class="line">top</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看中断</span></span><br><span class="line"><span class="built_in">cat</span> /proc/interrupts</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看上下文切换</span></span><br><span class="line">vmstat 1</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>内存使用</strong></p><ul><li>物理内存</li><li>虚拟内存</li><li>缓冲区</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看内存使用</span></span><br><span class="line">free -m</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看虚拟内存</span></span><br><span class="line">vmstat 1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看缓冲区</span></span><br><span class="line"><span class="built_in">cat</span> /proc/meminfo</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>网络带宽</strong></p><ul><li>带宽使用</li><li>数据包大小</li><li>协议分布</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看带宽使用</span></span><br><span class="line">iftop -i eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看数据包</span></span><br><span class="line">tcpdump -i eth0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看协议分布</span></span><br><span class="line">nethogs eth0</span><br></pre></td></tr></table></figure></li></ul></li></ol><h4 id="8-2-2-应用资源"><a href="#8-2-2-应用资源" class="headerlink" title="8.2.2 应用资源"></a>8.2.2 应用资源</h4><ol><li><p><strong>连接数</strong></p><ul><li>活动连接</li><li>等待连接</li><li>连接限制</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看连接数</span></span><br><span class="line">netstat -an | grep ESTABLISHED | <span class="built_in">wc</span> -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看等待连接</span></span><br><span class="line">netstat -an | grep LISTEN | <span class="built_in">wc</span> -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看连接限制</span></span><br><span class="line"><span class="built_in">ulimit</span> -n</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>线程数</strong></p><ul><li>活动线程</li><li>线程池</li><li>线程限制</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看线程数</span></span><br><span class="line">ps -eLf | <span class="built_in">wc</span> -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看线程池</span></span><br><span class="line">jstack &lt;pid&gt;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看线程限制</span></span><br><span class="line"><span class="built_in">ulimit</span> -u</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>缓冲区大小</strong></p><ul><li>发送缓冲区</li><li>接收缓冲区</li><li>缓冲区限制</li><li>排查步骤：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看缓冲区</span></span><br><span class="line">sysctl -a | grep mem</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置缓冲区</span></span><br><span class="line">sysctl -w net.core.rmem_max=16777216</span><br><span class="line">sysctl -w net.core.wmem_max=16777216</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看限制</span></span><br><span class="line"><span class="built_in">ulimit</span> -a</span><br></pre></td></tr></table></figure></li></ul></li></ol><h2 id="9-总结"><a href="#9-总结" class="headerlink" title="9. 总结"></a>9. 总结</h2><p>Linux 网络是一个复杂的系统，涉及从硬件到应用的多个层次。理解这些基础概念和完整的数据流程，对于网络问题排查和性能优化都至关重要。通过本文的详细介绍，读者可以：</p><ol><li>理解网络硬件和驱动的工作原理</li><li>掌握网络接口的配置和管理</li><li>了解网络协议栈的工作机制</li><li>熟悉防火墙的配置和使用</li><li>掌握网络性能优化的方法</li><li>学会网络问题的排查技巧</li></ol><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>Linux 内核网络子系统文档</li><li>TCP&#x2F;IP 协议详解</li><li>Java NIO 编程指南</li><li>Linux 网络性能调优指南</li><li>iptables 官方文档</li><li>网络故障排查手册</li></ol>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Linux </tag>
            
            <tag> 网络 </tag>
            
            <tag> 系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深入理解网络接口、端口与网卡：关系与工作流程</title>
      <link href="/2025/06/13/network-interfaces-ports-nics/"/>
      <url>/2025/06/13/network-interfaces-ports-nics/</url>
      
        <content type="html"><![CDATA[<h1 id="深入理解网络接口、端口与网卡：关系与工作流程"><a href="#深入理解网络接口、端口与网卡：关系与工作流程" class="headerlink" title="深入理解网络接口、端口与网卡：关系与工作流程"></a>深入理解网络接口、端口与网卡：关系与工作流程</h1><h2 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1. 基本概念"></a>1. 基本概念</h2><h3 id="1-1-网卡（Network-Interface-Card，NIC）"><a href="#1-1-网卡（Network-Interface-Card，NIC）" class="headerlink" title="1.1 网卡（Network Interface Card，NIC）"></a>1.1 网卡（Network Interface Card，NIC）</h3><p>网卡是计算机硬件设备，负责网络数据的收发。它是连接计算机与网络的物理接口。</p><p>主要特点：</p><ul><li>物理设备</li><li>具有唯一的 MAC 地址</li><li>支持特定的网络协议（如以太网）</li><li>可以是有线或无线网卡</li></ul><h3 id="1-2-网络接口（Network-Interface）"><a href="#1-2-网络接口（Network-Interface）" class="headerlink" title="1.2 网络接口（Network Interface）"></a>1.2 网络接口（Network Interface）</h3><p>网络接口是操作系统对网卡的抽象表示，是操作系统与网卡交互的软件接口。</p><p>主要特点：</p><ul><li>软件层面的抽象</li><li>具有 IP 地址</li><li>可以配置网络参数</li><li>可以创建虚拟接口</li></ul><h3 id="1-3-网络端口（Network-Port）"><a href="#1-3-网络端口（Network-Port）" class="headerlink" title="1.3 网络端口（Network Port）"></a>1.3 网络端口（Network Port）</h3><p>网络端口是传输层（TCP&#x2F;UDP）的概念，用于区分同一 IP 地址上的不同应用程序。</p><p>主要特点：</p><ul><li>逻辑概念</li><li>范围：0-65535</li><li>用于应用程序通信</li><li>可以动态分配</li></ul><h2 id="2-三者关系"><a href="#2-三者关系" class="headerlink" title="2. 三者关系"></a>2. 三者关系</h2><h3 id="2-1-层次关系"><a href="#2-1-层次关系" class="headerlink" title="2.1 层次关系"></a>2.1 层次关系</h3><pre class="mermaid">graph TD    A[应用层] --> B[传输层/端口]    B --> C[网络层/IP]    C --> D[网络接口]    D --> E[数据链路层/MAC]    E --> F[物理层/网卡]</pre><h3 id="2-2-对应关系"><a href="#2-2-对应关系" class="headerlink" title="2.2 对应关系"></a>2.2 对应关系</h3><pre class="mermaid">graph LR    A[网卡] -->|物理设备| B[网络接口]    B -->|IP地址| C[网络端口]    C -->|应用程序| D[服务]</pre><h2 id="3-工作流程"><a href="#3-工作流程" class="headerlink" title="3. 工作流程"></a>3. 工作流程</h2><h3 id="3-1-数据发送流程"><a href="#3-1-数据发送流程" class="headerlink" title="3.1 数据发送流程"></a>3.1 数据发送流程</h3><pre class="mermaid">sequenceDiagram    participant App as 应用程序    participant Port as 网络端口    participant IP as IP地址    participant Interface as 网络接口    participant NIC as 网卡    participant Network as 网络    App->>Port: 发送数据    Port->>IP: 添加端口信息    IP->>Interface: 选择网络接口    Interface->>NIC: 通过接口发送    NIC->>Network: 物理发送</pre><h3 id="3-2-数据接收流程"><a href="#3-2-数据接收流程" class="headerlink" title="3.2 数据接收流程"></a>3.2 数据接收流程</h3><pre class="mermaid">sequenceDiagram    participant Network as 网络    participant NIC as 网卡    participant Interface as 网络接口    participant IP as IP地址    participant Port as 网络端口    participant App as 应用程序    Network->>NIC: 接收数据    NIC->>Interface: 传递给接口    Interface->>IP: 解析IP地址    IP->>Port: 解析端口    Port->>App: 传递给应用</pre><h2 id="4-实际应用"><a href="#4-实际应用" class="headerlink" title="4. 实际应用"></a>4. 实际应用</h2><h3 id="4-1-网卡配置"><a href="#4-1-网卡配置" class="headerlink" title="4.1 网卡配置"></a>4.1 网卡配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看网卡信息</span></span><br><span class="line">lspci | grep -i ethernet</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看网络接口</span></span><br><span class="line">ip addr show</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置网络接口</span></span><br><span class="line">ip addr add 192.168.1.100/24 dev eth0</span><br></pre></td></tr></table></figure><h3 id="4-2-端口管理"><a href="#4-2-端口管理" class="headerlink" title="4.2 端口管理"></a>4.2 端口管理</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看端口使用情况</span></span><br><span class="line">netstat -tuln</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看特定端口</span></span><br><span class="line">netstat -tuln | grep 80</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开放端口（使用 iptables）</span></span><br><span class="line">iptables -A INPUT -p tcp --dport 80 -j ACCEPT</span><br></pre></td></tr></table></figure><h3 id="4-3-网络接口管理"><a href="#4-3-网络接口管理" class="headerlink" title="4.3 网络接口管理"></a>4.3 网络接口管理</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启用接口</span></span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> eth0 up</span><br><span class="line"></span><br><span class="line"><span class="comment"># 禁用接口</span></span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> eth0 down</span><br><span class="line"></span><br><span class="line"><span class="comment"># 配置接口参数</span></span><br><span class="line">ethtool -s eth0 speed 1000 duplex full</span><br></pre></td></tr></table></figure><h2 id="5-常见场景"><a href="#5-常见场景" class="headerlink" title="5. 常见场景"></a>5. 常见场景</h2><h3 id="5-1-多网卡配置"><a href="#5-1-多网卡配置" class="headerlink" title="5.1 多网卡配置"></a>5.1 多网卡配置</h3><pre class="mermaid">graph TD    A[服务器] --> B[eth0]    A --> C[eth1]    B --> D[内网]    C --> E[外网]    B --> F[192.168.1.0/24]    C --> G[203.0.113.0/24]</pre><h3 id="5-2-虚拟接口"><a href="#5-2-虚拟接口" class="headerlink" title="5.2 虚拟接口"></a>5.2 虚拟接口</h3><pre class="mermaid">graph TD    A[物理网卡] --> B[eth0]    B --> C[eth0:0]    B --> D[eth0:1]    C --> E[192.168.1.100]    D --> F[192.168.1.101]</pre><h3 id="5-3-端口转发"><a href="#5-3-端口转发" class="headerlink" title="5.3 端口转发"></a>5.3 端口转发</h3><pre class="mermaid">graph LR    A[外部请求] -->|80端口| B[路由器]    B -->|8080端口| C[内部服务器]</pre><h2 id="6-性能优化"><a href="#6-性能优化" class="headerlink" title="6. 性能优化"></a>6. 性能优化</h2><h3 id="6-1-网卡优化"><a href="#6-1-网卡优化" class="headerlink" title="6.1 网卡优化"></a>6.1 网卡优化</h3><ol><li><p><strong>中断合并</strong></p><ul><li>减少 CPU 中断</li><li>提高吞吐量</li></ul></li><li><p><strong>队列管理</strong></p><ul><li>多队列支持</li><li>负载均衡</li></ul></li></ol><h3 id="6-2-接口优化"><a href="#6-2-接口优化" class="headerlink" title="6.2 接口优化"></a>6.2 接口优化</h3><ol><li><p><strong>MTU 调整</strong></p><ul><li>优化数据包大小</li><li>减少分片</li></ul></li><li><p><strong>缓冲区设置</strong></p><ul><li>调整接收缓冲区</li><li>调整发送缓冲区</li></ul></li></ol><h3 id="6-3-端口优化"><a href="#6-3-端口优化" class="headerlink" title="6.3 端口优化"></a>6.3 端口优化</h3><ol><li><p><strong>端口复用</strong></p><ul><li>启用 SO_REUSEADDR</li><li>提高端口利用率</li></ul></li><li><p><strong>连接管理</strong></p><ul><li>调整 TIME_WAIT</li><li>优化连接池</li></ul></li></ol><h2 id="7-故障排查"><a href="#7-故障排查" class="headerlink" title="7. 故障排查"></a>7. 故障排查</h2><h3 id="7-1-网卡故障"><a href="#7-1-网卡故障" class="headerlink" title="7.1 网卡故障"></a>7.1 网卡故障</h3><ol><li><p><strong>物理连接</strong></p><ul><li>检查网线</li><li>检查网卡状态</li></ul></li><li><p><strong>驱动问题</strong></p><ul><li>更新驱动</li><li>检查兼容性</li></ul></li></ol><h3 id="7-2-接口故障"><a href="#7-2-接口故障" class="headerlink" title="7.2 接口故障"></a>7.2 接口故障</h3><ol><li><p><strong>配置问题</strong></p><ul><li>检查 IP 配置</li><li>检查路由表</li></ul></li><li><p><strong>状态异常</strong></p><ul><li>检查接口状态</li><li>检查错误计数</li></ul></li></ol><h3 id="7-3-端口故障"><a href="#7-3-端口故障" class="headerlink" title="7.3 端口故障"></a>7.3 端口故障</h3><ol><li><p><strong>端口占用</strong></p><ul><li>检查端口使用</li><li>检查服务状态</li></ul></li><li><p><strong>防火墙问题</strong></p><ul><li>检查防火墙规则</li><li>检查 SELinux</li></ul></li></ol><h2 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h2><p>网络接口、端口和网卡是网络通信中的三个重要概念，它们分别位于不同的网络层次，共同协作完成网络通信。理解它们之间的关系和工作流程，对于网络管理和故障排查都至关重要。</p><h2 id="9-网卡多接口详解"><a href="#9-网卡多接口详解" class="headerlink" title="9. 网卡多接口详解"></a>9. 网卡多接口详解</h2><h3 id="9-1-网卡多接口类型"><a href="#9-1-网卡多接口类型" class="headerlink" title="9.1 网卡多接口类型"></a>9.1 网卡多接口类型</h3><ol><li><p><strong>物理接口</strong></p><ul><li>一个网卡可以支持多个物理接口</li><li>例如：双端口网卡、四端口网卡</li><li>每个物理接口都有独立的 MAC 地址</li></ul></li><li><p><strong>虚拟接口</strong></p><ul><li>基于单个物理网卡创建多个虚拟接口</li><li>常见类型：<ul><li>VLAN 接口（802.1Q）</li><li>子接口（eth0:0, eth0:1）</li><li>桥接接口</li><li>绑定接口（bond）</li></ul></li></ul></li></ol><h3 id="9-2-多接口配置示例"><a href="#9-2-多接口配置示例" class="headerlink" title="9.2 多接口配置示例"></a>9.2 多接口配置示例</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 VLAN 接口</span></span><br><span class="line">ip <span class="built_in">link</span> add <span class="built_in">link</span> eth0 name eth0.100 <span class="built_in">type</span> vlan <span class="built_in">id</span> 100</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建子接口</span></span><br><span class="line">ip addr add 192.168.1.100/24 dev eth0:0</span><br><span class="line">ip addr add 192.168.2.100/24 dev eth0:1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建网桥</span></span><br><span class="line">brctl addbr br0</span><br><span class="line">brctl addif br0 eth0</span><br></pre></td></tr></table></figure><h3 id="9-3-多接口应用场景"><a href="#9-3-多接口应用场景" class="headerlink" title="9.3 多接口应用场景"></a>9.3 多接口应用场景</h3><pre class="mermaid">graph TD    A[物理网卡] --> B[eth0]    B --> C[eth0:0]    B --> D[eth0:1]    B --> E[eth0.100]    C --> F[192.168.1.0/24]    D --> G[192.168.2.0/24]    E --> H[VLAN 100]</pre><ol><li><p><strong>网络隔离</strong></p><ul><li>不同网段隔离</li><li>安全区域划分</li><li>流量控制</li></ul></li><li><p><strong>负载均衡</strong></p><ul><li>多接口绑定</li><li>流量分发</li><li>高可用性</li></ul></li><li><p><strong>虚拟化环境</strong></p><ul><li>虚拟机网络</li><li>容器网络</li><li>云平台网络</li></ul></li></ol><h3 id="9-4-多接口管理"><a href="#9-4-多接口管理" class="headerlink" title="9.4 多接口管理"></a>9.4 多接口管理</h3><ol><li><p><strong>接口命名</strong></p><ul><li>物理接口：eth0, eth1</li><li>子接口：eth0:0, eth0:1</li><li>VLAN接口：eth0.100</li><li>绑定接口：bond0</li></ul></li><li><p><strong>配置管理</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看所有接口</span></span><br><span class="line">ip <span class="built_in">link</span> show</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看接口详细信息</span></span><br><span class="line">ip addr show</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看接口统计信息</span></span><br><span class="line">ip -s <span class="built_in">link</span> show eth0</span><br></pre></td></tr></table></figure></li><li><p><strong>性能考虑</strong></p><ul><li>接口带宽共享</li><li>资源竞争</li><li>优先级设置</li></ul></li></ol><h3 id="9-5-多接口最佳实践"><a href="#9-5-多接口最佳实践" class="headerlink" title="9.5 多接口最佳实践"></a>9.5 多接口最佳实践</h3><ol><li><p><strong>规划建议</strong></p><ul><li>合理规划 IP 地址</li><li>考虑网络拓扑</li><li>预留扩展空间</li></ul></li><li><p><strong>安全建议</strong></p><ul><li>接口访问控制</li><li>流量监控</li><li>日志记录</li></ul></li><li><p><strong>维护建议</strong></p><ul><li>定期检查状态</li><li>监控性能</li><li>及时更新配置</li></ul></li></ol><h2 id="10-网卡接口类型详解"><a href="#10-网卡接口类型详解" class="headerlink" title="10. 网卡接口类型详解"></a>10. 网卡接口类型详解</h2><h3 id="10-1-物理接口类型"><a href="#10-1-物理接口类型" class="headerlink" title="10.1 物理接口类型"></a>10.1 物理接口类型</h3><ol><li><p><strong>单端口网卡</strong></p><ul><li>最基本的网卡类型</li><li>只有一个物理网络接口</li><li>适用于普通工作站和服务器</li></ul></li><li><p><strong>多端口网卡</strong></p><ul><li>双端口网卡：两个物理接口</li><li>四端口网卡：四个物理接口</li><li>适用于需要多网络连接的服务器</li><li>支持链路聚合和负载均衡</li></ul></li><li><p><strong>光纤网卡</strong></p><ul><li>支持光纤连接</li><li>提供更高的带宽</li><li>适用于数据中心和高速网络</li></ul></li><li><p><strong>无线网卡</strong></p><ul><li>支持 WiFi 连接</li><li>移动设备常用</li><li>支持多种无线标准（802.11a&#x2F;b&#x2F;g&#x2F;n&#x2F;ac&#x2F;ax）</li></ul></li></ol><h3 id="10-2-虚拟接口类型"><a href="#10-2-虚拟接口类型" class="headerlink" title="10.2 虚拟接口类型"></a>10.2 虚拟接口类型</h3><ol><li><p><strong>VLAN 接口</strong></p><ul><li>基于 802.1Q 协议</li><li>实现虚拟局域网隔离</li><li>支持跨物理网络的逻辑隔离</li><li>配置示例：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 VLAN 接口</span></span><br><span class="line">ip <span class="built_in">link</span> add <span class="built_in">link</span> eth0 name eth0.100 <span class="built_in">type</span> vlan <span class="built_in">id</span> 100</span><br><span class="line">ip addr add 192.168.100.1/24 dev eth0.100</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>子接口</strong></p><ul><li>基于物理接口创建</li><li>支持多个 IP 地址</li><li>适用于多网段配置</li><li>配置示例：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建子接口</span></span><br><span class="line">ip addr add 192.168.1.100/24 dev eth0:0</span><br><span class="line">ip addr add 192.168.2.100/24 dev eth0:1</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>网桥接口</strong></p><ul><li>连接多个网络接口</li><li>实现二层交换功能</li><li>常用于虚拟化环境</li><li>配置示例：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建网桥</span></span><br><span class="line">brctl addbr br0</span><br><span class="line">brctl addif br0 eth0</span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> br0 up</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>绑定接口（Bond）</strong></p><ul><li>多个物理接口绑定</li><li>提供高可用性和负载均衡</li><li>支持多种绑定模式</li><li>配置示例：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建绑定接口</span></span><br><span class="line">ip <span class="built_in">link</span> add bond0 <span class="built_in">type</span> bond</span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> eth0 master bond0</span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> eth1 master bond0</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>隧道接口</strong></p><ul><li>支持各种隧道协议</li><li>用于 VPN 和跨网络通信</li><li>常见类型：GRE、IPIP、VXLAN</li><li>配置示例：<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建 GRE 隧道</span></span><br><span class="line">ip tunnel add tun0 mode gre remote 203.0.113.1 <span class="built_in">local</span> 192.168.1.100</span><br><span class="line">ip <span class="built_in">link</span> <span class="built_in">set</span> tun0 up</span><br></pre></td></tr></table></figure></li></ul></li></ol><h3 id="10-3-网卡多接口的作用"><a href="#10-3-网卡多接口的作用" class="headerlink" title="10.3 网卡多接口的作用"></a>10.3 网卡多接口的作用</h3><ol><li><p><strong>网络隔离</strong></p><pre class="mermaid">   graph TD    A[物理网卡] --> B[eth0]    B --> C[VLAN 100]    B --> D[VLAN 200]    C --> E[部门A网络]    D --> F[部门B网络]</pre></li><li><p><strong>负载均衡</strong></p><pre class="mermaid">   graph LR    A[流量] --> B[eth0]    A --> C[eth1]    B --> D[服务器]    C --> D</pre></li><li><p><strong>高可用性</strong></p><pre class="mermaid">   graph TD    A[主接口] --> B[服务]    C[备用接口] --> B    D[故障检测] --> A    D --> C</pre></li></ol><h3 id="10-4-多接口应用场景"><a href="#10-4-多接口应用场景" class="headerlink" title="10.4 多接口应用场景"></a>10.4 多接口应用场景</h3><ol><li><p><strong>企业网络</strong></p><ul><li>部门网络隔离</li><li>安全区域划分</li><li>流量控制</li></ul></li><li><p><strong>数据中心</strong></p><ul><li>服务器高可用</li><li>负载均衡</li><li>网络虚拟化</li></ul></li><li><p><strong>云平台</strong></p><ul><li>虚拟机网络</li><li>容器网络</li><li>多租户隔离</li></ul></li><li><p><strong>安全防护</strong></p><ul><li>网络隔离</li><li>流量监控</li><li>访问控制</li></ul></li></ol><h3 id="10-5-多接口优势"><a href="#10-5-多接口优势" class="headerlink" title="10.5 多接口优势"></a>10.5 多接口优势</h3><ol><li><p><strong>灵活性</strong></p><ul><li>支持多种网络配置</li><li>适应不同网络需求</li><li>便于网络扩展</li></ul></li><li><p><strong>可靠性</strong></p><ul><li>提供冗余连接</li><li>支持故障转移</li><li>提高系统可用性</li></ul></li><li><p><strong>性能</strong></p><ul><li>支持负载均衡</li><li>提高带宽利用率</li><li>优化网络性能</li></ul></li><li><p><strong>安全性</strong></p><ul><li>实现网络隔离</li><li>控制访问权限</li><li>保护敏感数据</li></ul></li></ol><h3 id="10-6-多接口注意事项"><a href="#10-6-多接口注意事项" class="headerlink" title="10.6 多接口注意事项"></a>10.6 多接口注意事项</h3><ol><li><p><strong>资源消耗</strong></p><ul><li>增加系统负载</li><li>需要更多内存</li><li>可能影响性能</li></ul></li><li><p><strong>配置复杂度</strong></p><ul><li>需要专业知识</li><li>配置容易出错</li><li>维护成本高</li></ul></li><li><p><strong>兼容性</strong></p><ul><li>驱动支持</li><li>协议兼容</li><li>设备限制</li></ul></li></ol>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> 网络 </tag>
            
            <tag> 系统 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux内核的netfilter详解</title>
      <link href="/2025/06/12/Linux%E5%86%85%E6%A0%B8%E7%9A%84netfilter%E8%AF%A6%E8%A7%A3/"/>
      <url>/2025/06/12/Linux%E5%86%85%E6%A0%B8%E7%9A%84netfilter%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="Linux内核的netfilter详解"><a href="#Linux内核的netfilter详解" class="headerlink" title="Linux内核的netfilter详解"></a>Linux内核的netfilter详解</h1><p>Linux内核的netfilter是一个强大的网络数据包过滤和处理框架，它是Linux内核网络栈的核心组件之一。</p><h2 id="🔍-什么是netfilter"><a href="#🔍-什么是netfilter" class="headerlink" title="🔍 什么是netfilter"></a>🔍 什么是netfilter</h2><p><strong>netfilter</strong>是Linux内核中的一个框架，它提供了一系列的钩子（hooks）来允许内核模块在网络栈的不同位置注册回调函数，从而实现对网络数据包的拦截、修改、过滤和处理。</p><h2 id="🏗️-netfilter架构"><a href="#🏗️-netfilter架构" class="headerlink" title="🏗️ netfilter架构"></a>🏗️ netfilter架构</h2><h3 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h3><ul><li><strong>钩子点（Hook Points）</strong>: 在网络栈的关键位置设置的拦截点</li><li><strong>钩子函数（Hook Functions）</strong>: 注册在钩子点上的处理函数</li><li><strong>优先级系统</strong>: 决定多个钩子函数的执行顺序</li><li><strong>返回值机制</strong>: 控制数据包的后续处理流程</li></ul><h3 id="五个主要钩子点"><a href="#五个主要钩子点" class="headerlink" title="五个主要钩子点"></a>五个主要钩子点</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. NF_INET_PRE_ROUTING    # 路由决策前</span><br><span class="line">2. NF_INET_LOCAL_IN       # 本地输入</span><br><span class="line">3. NF_INET_FORWARD        # 转发</span><br><span class="line">4. NF_INET_LOCAL_OUT      # 本地输出</span><br><span class="line">5. NF_INET_POST_ROUTING   # 路由决策后</span><br></pre></td></tr></table></figure><h2 id="📊-数据包处理流程"><a href="#📊-数据包处理流程" class="headerlink" title="📊 数据包处理流程"></a>📊 数据包处理流程</h2><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  flowchart TD    A[网络接口接收数据包] --&gt; B[NF_INET_PRE_ROUTING]    B --&gt; C{路由决策}    C --&gt;|本地| D[NF_INET_LOCAL_IN]    C --&gt;|转发| E[NF_INET_FORWARD]    D --&gt; F[本地进程]    F --&gt; G[NF_INET_LOCAL_OUT]    E --&gt; H[NF_INET_POST_ROUTING]    G --&gt; H    H --&gt; I[网络接口发送数据包]        style B fill:#ff9999    style D fill:#ff9999    style E fill:#ff9999    style G fill:#ff9999    style H fill:#ff9999  </pre></div><h2 id="🌐-Linux网络数据包完整流程"><a href="#🌐-Linux网络数据包完整流程" class="headerlink" title="🌐 Linux网络数据包完整流程"></a>🌐 Linux网络数据包完整流程</h2><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[网卡硬件] --&gt; B[网卡驱动]    B --&gt; C[内核网络栈]    C --&gt; D[netfilter钩子点]    D --&gt; E[协议栈处理]    E --&gt; F[Socket层]    F --&gt; G[应用程序]        style D fill:#ff9999    style C fill:#99ccff  </pre></div><h2 id="📍-netfilter的精确位置"><a href="#📍-netfilter的精确位置" class="headerlink" title="📍 netfilter的精确位置"></a>📍 netfilter的精确位置</h2><p>netfilter<strong>不是</strong>一个独立的网络层，而是<strong>嵌入在内核网络协议栈中的钩子系统</strong>。</p><h3 id="详细的数据包处理流程"><a href="#详细的数据包处理流程" class="headerlink" title="详细的数据包处理流程"></a>详细的数据包处理流程</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  flowchart TD    Start([开始]) --&gt; A[网卡接收数据包]    A --&gt; B[网卡驱动处理]    B --&gt; C[进入内核网络栈]    C --&gt; D[PRE_ROUTING钩子]    D --&gt; E{路由决策}        E --&gt;|本机数据包| F[LOCAL_IN钩子]    F --&gt; G[传递给应用程序]    G --&gt; End1([结束])        E --&gt;|需要转发| H[FORWARD钩子]    H --&gt; I[POST_ROUTING钩子]    I --&gt; J[从网卡发出]    J --&gt; End2([结束])        K[应用程序] --&gt; L[LOCAL_OUT钩子]    L --&gt; M[POST_ROUTING钩子]    M --&gt; N[从网卡发出]    N --&gt; End3([结束])        style D fill:#ffcccc    style F fill:#ffcccc    style H fill:#ffcccc    style L fill:#ffcccc    style I fill:#ffcccc    style M fill:#ffcccc  </pre></div><h2 id="🏗️-在网络协议栈中的具体位置"><a href="#🏗️-在网络协议栈中的具体位置" class="headerlink" title="🏗️ 在网络协议栈中的具体位置"></a>🏗️ 在网络协议栈中的具体位置</h2><h3 id="完整的网络层次结构"><a href="#完整的网络层次结构" class="headerlink" title="完整的网络层次结构"></a>完整的网络层次结构</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[应用程序&lt;br&#x2F;&gt;HTTP, SSH等] --&gt; B[Socket API]    B --&gt; C[传输层&lt;br&#x2F;&gt;TCP&#x2F;UDP]    C --&gt; D[网络层 IP + netfilter钩子]    D --&gt; E[数据链路层&lt;br&#x2F;&gt;Ethernet]    E --&gt; F[物理层&lt;br&#x2F;&gt;网卡驱动]        style D fill:#ffcccc        G[netfilter在这里!] -.-&gt; D    style G fill:#yellow  </pre></div><h2 id="🎯-实际例子：数据包的旅程"><a href="#🎯-实际例子：数据包的旅程" class="headerlink" title="🎯 实际例子：数据包的旅程"></a>🎯 实际例子：数据包的旅程</h2><h3 id="场景：外部HTTP请求访问本机80端口"><a href="#场景：外部HTTP请求访问本机80端口" class="headerlink" title="场景：外部HTTP请求访问本机80端口"></a>场景：外部HTTP请求访问本机80端口</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  flowchart TD    A[网卡接收到TCP包&lt;br&#x2F;&gt;目标端口80] --&gt; B[网卡驱动将包传递给内核]    B --&gt; C[IP层开始处理]    C --&gt; D[PRE_ROUTING钩子]    D --&gt; E[路由决策:这是发给本机的包]    E --&gt; F[LOCAL_IN钩子]    F --&gt; G[传递给TCP层]    G --&gt; H[传递给监听80端口的应用程序&lt;br&#x2F;&gt;如Apache]        D -.-&gt; D1[iptables DNAT规则检查&lt;br&#x2F;&gt;连接跟踪记录&lt;br&#x2F;&gt;可能的端口转发]    F -.-&gt; F1[iptables INPUT链规则检查&lt;br&#x2F;&gt;防火墙过滤&lt;br&#x2F;&gt;ACCEPT继续,DROP丢弃]        style D fill:#ffcccc    style F fill:#ffcccc    style D1 fill:#ffffcc    style F1 fill:#ffffcc  </pre></div><h3 id="场景：本机作为路由器转发数据包"><a href="#场景：本机作为路由器转发数据包" class="headerlink" title="场景：本机作为路由器转发数据包"></a>场景：本机作为路由器转发数据包</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  flowchart TD    A[网卡A接收到数据包] --&gt; B[PRE_ROUTING钩子]    B --&gt; C[路由决策:需要从网卡B转发出去]    C --&gt; D[FORWARD钩子]    D --&gt; E[POST_ROUTING钩子]    E --&gt; F[从网卡B发出]        B -.-&gt; B1[NAT PREROUTING规则]    D -.-&gt; D1[iptables FORWARD链检查&lt;br&#x2F;&gt;转发策略验证]    E -.-&gt; E1[NAT POSTROUTING规则&lt;br&#x2F;&gt;MASQUERADE处理]        style B fill:#ffcccc    style D fill:#ffcccc    style E fill:#ffcccc    style B1 fill:#ffffcc    style D1 fill:#ffffcc    style E1 fill:#ffffcc  </pre></div><h2 id="🛠️-主要功能"><a href="#🛠️-主要功能" class="headerlink" title="🛠️ 主要功能"></a>🛠️ 主要功能</h2><h3 id="netfilter功能架构"><a href="#netfilter功能架构" class="headerlink" title="netfilter功能架构"></a>netfilter功能架构</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[netfilter] --&gt; B[数据包过滤]    A --&gt; C[网络地址转换]    A --&gt; D[数据包修改]    A --&gt; E[连接跟踪]        B --&gt; B1[源&#x2F;目标IP过滤]    B --&gt; B2[端口号过滤]    B --&gt; B3[协议类型过滤]    B --&gt; B4[状态跟踪过滤]        C --&gt; C1[SNAT源地址转换]    C --&gt; C2[DNAT目标地址转换]    C --&gt; C3[MASQUERADE地址伪装]    C --&gt; C4[端口映射]        D --&gt; D1[IP头部修改]    D --&gt; D2[传输层头部修改]    D --&gt; D3[数据包标记]    D --&gt; D4[QoS标记]        E --&gt; E1[TCP连接状态]    E --&gt; E2[UDP伪连接]    E --&gt; E3[相关连接处理]        style A fill:#ff9999    style B fill:#99ccff    style C fill:#99ccff    style D fill:#99ccff    style E fill:#99ccff  </pre></div><h2 id="🔧-基于netfilter的工具"><a href="#🔧-基于netfilter的工具" class="headerlink" title="🔧 基于netfilter的工具"></a>🔧 基于netfilter的工具</h2><h3 id="工具生态系统"><a href="#工具生态系统" class="headerlink" title="工具生态系统"></a>工具生态系统</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[netfilter内核框架] --&gt; B[iptables]    A --&gt; C[nftables]    A --&gt; D[conntrack]    A --&gt; E[ebtables]    A --&gt; F[arptables]        B --&gt; B1[防火墙规则]    B --&gt; B2[NAT配置]    B --&gt; B3[端口转发]        C --&gt; C1[新一代防火墙]    C --&gt; C2[统一规则语法]    C --&gt; C3[更好的性能]        D --&gt; D1[连接跟踪]    D --&gt; D2[状态监控]    D --&gt; D3[连接管理]        style A fill:#ff9999    style B fill:#99ccff    style C fill:#99ccff    style D fill:#99ccff    style E fill:#99ccff    style F fill:#99ccff  </pre></div><h2 id="💻-编程接口"><a href="#💻-编程接口" class="headerlink" title="💻 编程接口"></a>💻 编程接口</h2><h3 id="内核模块开发"><a href="#内核模块开发" class="headerlink" title="内核模块开发"></a>内核模块开发</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/netfilter.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;linux/netfilter_ipv4.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">unsigned</span> <span class="type">int</span> <span class="title function_">hook_func</span><span class="params">(<span class="type">void</span> *priv,</span></span><br><span class="line"><span class="params">                              <span class="keyword">struct</span> sk_buff *skb,</span></span><br><span class="line"><span class="params">                              <span class="type">const</span> <span class="keyword">struct</span> nf_hook_state *state)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 处理数据包</span></span><br><span class="line">    <span class="keyword">return</span> NF_ACCEPT;  <span class="comment">// 或 NF_DROP, NF_STOLEN, NF_QUEUE, NF_REPEAT</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">nf_hook_ops</span> <span class="title">netfilter_ops</span> =</span> &#123;</span><br><span class="line">    .hook = hook_func,</span><br><span class="line">    .hooknum = NF_INET_PRE_ROUTING,</span><br><span class="line">    .pf = PF_INET,</span><br><span class="line">    .priority = NF_IP_PRI_FIRST,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h3 id="用户空间接口"><a href="#用户空间接口" class="headerlink" title="用户空间接口"></a>用户空间接口</h3><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// libnetfilter_queue 示例</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;libnetfilter_queue/libnetfilter_queue.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="type">static</span> <span class="type">int</span> <span class="title function_">cb</span><span class="params">(<span class="keyword">struct</span> nfq_q_handle *qh, <span class="keyword">struct</span> nfgenmsg *nfmsg,</span></span><br><span class="line"><span class="params">              <span class="keyword">struct</span> nfq_data *nfa, <span class="type">void</span> *data)</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="comment">// 处理队列中的数据包</span></span><br><span class="line">    <span class="keyword">return</span> nfq_set_verdict(qh, id, NF_ACCEPT, <span class="number">0</span>, <span class="literal">NULL</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="🎯-应用场景"><a href="#🎯-应用场景" class="headerlink" title="🎯 应用场景"></a>🎯 应用场景</h2><h3 id="应用场景分类"><a href="#应用场景分类" class="headerlink" title="应用场景分类"></a>应用场景分类</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph LR    A[&quot;netfilter应用场景&quot;] --&gt; B[&quot;网络安全&quot;]    A --&gt; C[&quot;网络管理&quot;]    A --&gt; D[&quot;性能优化&quot;]    A --&gt; E[&quot;监控审计&quot;]        B --&gt; B1[&quot;防火墙&quot;]    B --&gt; B2[&quot;入侵防护&quot;]    B --&gt; B3[&quot;访问控制&quot;]        C --&gt; C1[&quot;负载均衡&quot;]    C --&gt; C2[&quot;NAT网关&quot;]    C --&gt; C3[&quot;路由策略&quot;]        D --&gt; D1[&quot;流量整形&quot;]    D --&gt; D2[&quot;带宽控制&quot;]    D --&gt; D3[&quot;QoS管理&quot;]        E --&gt; E1[&quot;流量分析&quot;]    E --&gt; E2[&quot;连接监控&quot;]    E --&gt; E3[&quot;安全审计&quot;]        style A fill:#ff9999    style B fill:#99ccff    style C fill:#99ccff    style D fill:#99ccff    style E fill:#99ccff  </pre></div><h2 id="⚡-性能特点"><a href="#⚡-性能特点" class="headerlink" title="⚡ 性能特点"></a>⚡ 性能特点</h2><h3 id="性能优势与注意事项"><a href="#性能优势与注意事项" class="headerlink" title="性能优势与注意事项"></a>性能优势与注意事项</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[&quot;netfilter性能特点&quot;] --&gt; B[&quot;优势&quot;]    A --&gt; C[&quot;注意事项&quot;]        B --&gt; B1[&quot;内核级处理&lt;br&#x2F;&gt;高性能，低延迟&quot;]    B --&gt; B2[&quot;零拷贝&lt;br&#x2F;&gt;避免不必要的数据复制&quot;]    B --&gt; B3[&quot;模块化设计&lt;br&#x2F;&gt;灵活的功能组合&quot;]    B --&gt; B4[&quot;状态跟踪&lt;br&#x2F;&gt;智能的连接管理&quot;]        C --&gt; C1[&quot;CPU开销&lt;br&#x2F;&gt;复杂规则会影响性能&quot;]    C --&gt; C2[&quot;内存使用&lt;br&#x2F;&gt;连接跟踪表占用内存&quot;]    C --&gt; C3[&quot;规则优化&lt;br&#x2F;&gt;需要合理设计规则顺序&quot;]        style B fill:#ccffcc    style C fill:#ffcccc  </pre></div><h2 id="🔄-与其他组件的关系"><a href="#🔄-与其他组件的关系" class="headerlink" title="🔄 与其他组件的关系"></a>🔄 与其他组件的关系</h2><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph TD    A[&quot;应用层工具&quot;] --&gt; B[&quot;用户空间库&quot;]    B --&gt; C[&quot;系统调用接口&quot;]    C --&gt; D[&quot;netfilter框架&quot;]    D --&gt; E[&quot;网络协议栈&quot;]    E --&gt; F[&quot;网络设备驱动&quot;]        A1[&quot;iptables&quot;] --&gt; A    A2[&quot;nftables&quot;] --&gt; A        B1[&quot;libnetfilter_*&quot;] --&gt; B        C1[&quot;netlink socket&quot;] --&gt; C    C2[&quot;sysfs接口&quot;] --&gt; C        D1[&quot;钩子管理&quot;] --&gt; D    D2[&quot;规则匹配&quot;] --&gt; D    D3[&quot;连接跟踪&quot;] --&gt; D        E1[&quot;TCP&#x2F;IP&quot;] --&gt; E    E2[&quot;路由子系统&quot;] --&gt; E        F1[&quot;以太网驱动&quot;] --&gt; F    F2[&quot;无线网卡驱动&quot;] --&gt; F        style D fill:#ff9999    style E fill:#99ccff  </pre></div><h2 id="🔍-netfilter钩子详细流程"><a href="#🔍-netfilter钩子详细流程" class="headerlink" title="🔍 netfilter钩子详细流程"></a>🔍 netfilter钩子详细流程</h2><h3 id="钩子执行机制"><a href="#钩子执行机制" class="headerlink" title="钩子执行机制"></a>钩子执行机制</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  sequenceDiagram    participant App as 应用程序    participant Kernel as 内核网络栈    participant Hook as netfilter钩子    participant Rule as 规则引擎    participant Target as 目标动作        Note over Kernel: 数据包到达钩子点    Kernel-&gt;&gt;Hook: 调用钩子函数    Hook-&gt;&gt;Rule: 遍历规则链        alt 规则匹配        Rule-&gt;&gt;Target: 执行目标动作        Target--&gt;&gt;Hook: 返回处理结果    else 无匹配规则        Rule--&gt;&gt;Hook: 返回默认策略    end        alt NF_ACCEPT        Hook--&gt;&gt;Kernel: 继续处理        Kernel-&gt;&gt;App: 传递给应用    else NF_DROP        Hook--&gt;&gt;Kernel: 丢弃数据包    else NF_QUEUE        Hook--&gt;&gt;App: 传递给用户空间    end  </pre></div><h2 id="💡-关键理解点"><a href="#💡-关键理解点" class="headerlink" title="💡 关键理解点"></a>💡 关键理解点</h2><h3 id="netfilter核心概念"><a href="#netfilter核心概念" class="headerlink" title="netfilter核心概念"></a>netfilter核心概念</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph LR    A[&quot;netfilter核心概念&quot;] --&gt; B[&quot;钩子系统&quot;]    A --&gt; C[&quot;返回值机制&quot;]    A --&gt; D[&quot;优先级系统&quot;]    A --&gt; E[&quot;设计哲学&quot;]        B --&gt; B1[&quot;嵌入在IP层中&quot;]    B --&gt; B2[&quot;不是独立网络层&quot;]    B --&gt; B3[&quot;每个包都经过钩子点&quot;]    B --&gt; B4[&quot;支持多模块注册&quot;]        C --&gt; C1[&quot;NF_ACCEPT继续处理&quot;]    C --&gt; C2[&quot;NF_DROP丢弃数据包&quot;]    C --&gt; C3[&quot;NF_STOLEN钩子接管&quot;]    C --&gt; C4[&quot;NF_QUEUE用户空间处理&quot;]    C --&gt; C5[&quot;NF_REPEAT重新处理&quot;]        D --&gt; D1[&quot;决定执行顺序&quot;]    D --&gt; D2[&quot;支持多个钩子函数&quot;]    D --&gt; D3[&quot;灵活的模块组合&quot;]        E --&gt; E1[&quot;机制与策略分离&quot;]    E --&gt; E2[&quot;内核提供机制&quot;]    E --&gt; E3[&quot;用户空间实现策略&quot;]        style A fill:#ff9999    style B fill:#99ccff    style C fill:#99ccff    style D fill:#99ccff    style E fill:#99ccff  </pre></div><h2 id="🎯-总结"><a href="#🎯-总结" class="headerlink" title="🎯 总结"></a>🎯 总结</h2><p>netfilter是Linux网络安全和网络管理的基础设施，为构建防火墙、NAT、负载均衡等网络功能提供了强大而灵活的底层支持。它的设计哲学是”机制与策略分离”，内核提供机制，用户空间工具实现策略。</p><h3 id="netfilter的本质"><a href="#netfilter的本质" class="headerlink" title="netfilter的本质"></a>netfilter的本质</h3><div class="mermaid-wrap"><pre class="mermaid-src" hidden>  graph LR    A[&quot;数据包&quot;] --&gt; B[&quot;检查站1&lt;br&#x2F;&gt;PRE_ROUTING&quot;]    B --&gt; C[&quot;检查站2&lt;br&#x2F;&gt;LOCAL_IN&#x2F;FORWARD&quot;]    C --&gt; D[&quot;检查站3&lt;br&#x2F;&gt;LOCAL_OUT&quot;]    D --&gt; E[&quot;检查站4&lt;br&#x2F;&gt;POST_ROUTING&quot;]    E --&gt; F[&quot;数据包继续传输&quot;]        style B fill:#ffcccc    style C fill:#ffcccc    style D fill:#ffcccc    style E fill:#ffcccc        G[&quot;netfilter &#x3D; 内核网络栈中的检查站系统&quot;] -.-&gt; B    G -.-&gt; C    G -.-&gt; D    G -.-&gt; E        style G fill:#yellow  </pre></div><p>这样，netfilter就像是在内核网络栈的关键位置设置的”检查站”，每个数据包都必须通过这些检查站，在那里可以被检查、修改或丢弃。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>JDK 线程池里真的区分 核心线程与非核心线程吗？</title>
      <link href="/2025/06/07/JDK%20%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%87%8C%E7%9C%9F%E7%9A%84%E5%8C%BA%E5%88%86%20%E6%A0%B8%E5%BF%83%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%9D%9E%E6%A0%B8%E5%BF%83%E7%BA%BF%E7%A8%8B%E5%90%97%EF%BC%9F/"/>
      <url>/2025/06/07/JDK%20%E7%BA%BF%E7%A8%8B%E6%B1%A0%E9%87%8C%E7%9C%9F%E7%9A%84%E5%8C%BA%E5%88%86%20%E6%A0%B8%E5%BF%83%E7%BA%BF%E7%A8%8B%E4%B8%8E%E9%9D%9E%E6%A0%B8%E5%BF%83%E7%BA%BF%E7%A8%8B%E5%90%97%EF%BC%9F/</url>
      
        <content type="html"><![CDATA[<h1 id="JDK-线程池里真的区分-核心线程与非核心线程吗？"><a href="#JDK-线程池里真的区分-核心线程与非核心线程吗？" class="headerlink" title="JDK 线程池里真的区分 核心线程与非核心线程吗？"></a>JDK 线程池里真的区分 核心线程与非核心线程吗？</h1><p>不少校招小伙伴对于线程池的了解，大概就是如下图：</p><ul><li>当核心线程数未满，则新建核心线程执行任务</li><li>当核心线程数满了，队列未满，则将任务放在等待队列里，等待核心线程去执行</li><li>当核心线程数满了（但未达最大线程数），队列也满了，新建非核心线程执行任务</li><li>如果已经达到最大线程数，且队列也满了，则执行饱和策略。</li></ul><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1741656129655-700e91f7-bbd8-44f0-8c1b-c8475cd0471f.png" alt="img"></p><p>但是这样的了解，可能是不够的。因为这只是一个基础的流程，稍微问细一点、深一点就不够用了。比如，我可能会问下面这些问题：</p><ul><li>都是知道核心线程默认是不销毁的，那么核心线程在队列中没有任务时<strong>，</strong>它是什么状态（线程状态），对于操作系统来说会不会分配时间片给它？</li><li>我们一般自己新创建一个线程，可能使用 new Thread，然后 执行一下 start 方法，然后这个线程 执行完run方法内代码，就销毁了。线程池 ThreadPoolExecutor 中是如何实现 线程复用的？</li><li>线程池中 区分 核心线程与非线程线程吗？他们数据结构上以及行为上有什么不同。</li><li>非核心线程是不是只执行 新提交的任务，不消费等待队列中的任务。</li></ul><p>这里我详细说说问题3：线程池中 区分 核心线程与非线程线程吗？</p><p>实际上从源代码上看，无论是 数据结构还是行为上，其根据没有字段标记这个 线程是核心线程还是非核心线程。线程被包装在一个 Work对象中。这个 Work对象中 包含一个 Thread对象和 一个Runnable对象以及一些其他变量。<strong>但是并没有变量去区分这个 work对象是 所谓核心，还是非核心<strong><strong>。</strong></strong>所以说数据结构上是一致的。</strong></p><p>源码中唯一 带有是否核心的变量 就是 下面这个 core。但是它的作用，用于检查 线程数是否超出限制。</p><p>因为线程池有两个扩容Work的时机：一个是初始时核心线程的扩容，一个是非核心线程的扩容。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">boolean</span> <span class="title function_">addWorker</span><span class="params">(Runnable firstTask, <span class="type">boolean</span> core)</span></span><br></pre></td></tr></table></figure><p>当核心线程扩容时，用的是 corePoolSize；非核心线程扩容时，用的是maximumPoolSize。</p><p>但是在Work运行后，其内部从队列中取任务或者销毁时，并不知道自己当初添加的时候是 当作核心线程来扩容的还是非核心线程扩容的。</p><p>我们可以看源码中，final void runWorker(Worker w) 中：</p><p>有一个for循环。如果task为空，并且从队列中取不到任务，则结束for循环，进入到 负责清理 Worker和管理线程状态的processWorkerExit方法里。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="keyword">void</span> <span class="title function_">runWorker</span><span class="params">(Worker w)</span> &#123;</span><br><span class="line">    <span class="type">Thread</span> <span class="variable">wt</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">    <span class="type">Runnable</span> <span class="variable">task</span> <span class="operator">=</span> w.firstTask;</span><br><span class="line">    w.firstTask = <span class="literal">null</span>;</span><br><span class="line">    w.unlock(); <span class="comment">// allow interrupts</span></span><br><span class="line">    <span class="type">boolean</span> <span class="variable">completedAbruptly</span> <span class="operator">=</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">while</span> (task != <span class="literal">null</span> || (task = getTask()) != <span class="literal">null</span>) &#123;</span><br><span class="line">            w.lock();</span><br><span class="line">            <span class="comment">// If pool is stopping, ensure thread is interrupted;</span></span><br><span class="line">            <span class="comment">// if not, ensure thread is not interrupted.  This</span></span><br><span class="line">            <span class="comment">// requires a recheck in second case to deal with</span></span><br><span class="line">            <span class="comment">// shutdownNow race while clearing interrupt</span></span><br><span class="line">            <span class="keyword">if</span> ((runStateAtLeast(ctl.get(), STOP) ||</span><br><span class="line">                 (Thread.interrupted() &amp;&amp;</span><br><span class="line">                  runStateAtLeast(ctl.get(), STOP))) &amp;&amp;</span><br><span class="line">                !wt.isInterrupted())</span><br><span class="line">                wt.interrupt();</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                beforeExecute(wt, task);</span><br><span class="line">                <span class="type">Throwable</span> <span class="variable">thrown</span> <span class="operator">=</span> <span class="literal">null</span>;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    task.run();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (RuntimeException x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> x;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Error x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> x;</span><br><span class="line">                &#125; <span class="keyword">catch</span> (Throwable x) &#123;</span><br><span class="line">                    thrown = x; <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">Error</span>(x);</span><br><span class="line">                &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                    afterExecute(task, thrown);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">                task = <span class="literal">null</span>;</span><br><span class="line">                w.completedTasks++;</span><br><span class="line">                w.unlock();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        completedAbruptly = <span class="literal">false</span>;</span><br><span class="line">    &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">        processWorkerExit(w, completedAbruptly);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>简单的说：每个Work对象 它是不知道自己的身份的，无论是他获取队列中任务，还是销毁的判断条件。都不依赖于它创建是当作核心线程创建的，还是非核心线程。<strong>所以说他们的行为是没有区别的。</strong></p><p>判断一个work是否会因为超时销毁，只看 <strong>allowCoreThreadTimeOut</strong>（是否允许核心线程超时销毁） 和 <strong>wc &gt; corePoolSize</strong> （当前线程是否超过核心线程数）。只要两个满足其一，就可能因为超时销毁。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">boolean</span> <span class="variable">timed</span> <span class="operator">=</span> allowCoreThreadTimeOut || wc &gt; corePoolSize;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut))</span><br><span class="line">    &amp;&amp; (wc &gt; <span class="number">1</span> || workQueue.isEmpty())) &#123;</span><br><span class="line">    <span class="keyword">if</span> (compareAndDecrementWorkerCount(c))</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">null</span>;</span><br><span class="line">    <span class="keyword">continue</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MySQL 索引失效场景</title>
      <link href="/2025/06/07/MySQL%20%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E5%9C%BA%E6%99%AF/"/>
      <url>/2025/06/07/MySQL%20%E7%B4%A2%E5%BC%95%E5%A4%B1%E6%95%88%E5%9C%BA%E6%99%AF/</url>
      
        <content type="html"><![CDATA[<h1 id="MySQL-索引失效场景"><a href="#MySQL-索引失效场景" class="headerlink" title="MySQL 索引失效场景"></a>MySQL 索引失效场景</h1><ol><li>索引列参与计算或进行函数操作</li><li>使用OR，并且OR的两边存在&lt; 或者 &gt; 的时候</li><li>使用like操作，但是不满足左匹配，例如：”%java”</li><li>隐式类型转换，比如一个string类型列，使用数字来查询。这种情况有一个特列，如果字段类型为int类型，而查询条件添加了单引号或者双引号，则Mysql会参数转化为int类型，这种情况也可以走索引。</li><li>不等于比较。这种情况也是有可能会走索引的，比如用id进行!&#x3D;，是可能走索引的。</li><li>使用is not null时不走索引，使用 is null 走索引</li><li>order by。如果order by的时候数据量很小，数据库可能直接在内存中进行排序。</li><li>in。一般在in中的值比较少的时候可能会走索引优化，但如果选项比较多，可能不走索引。</li><li>联合索引失效。比如联合索引（a，b，c），进行查询时没有满足最左匹配（查b，查c，查b c）</li><li>存储引擎不能使用索引范围条件右边的列</li><li>两列做比较。如果两个列数据都有索引，但是在查询条件中对两列数据进行了对比操作，则会导致索引失效。</li><li>查询条件是用no in时，如果是主键则走索引。如果是普通索引，则失效</li><li>not exists 不走索引，exists 可能走索引</li></ol><hr><h3 id="1-索引列参与计算或函数操作"><a href="#1-索引列参与计算或函数操作" class="headerlink" title="1. 索引列参与计算或函数操作"></a><strong>1. 索引列参与计算或函数操作</strong></h3><ul><li><strong>正常判断</strong>：索引列直接使用原始值。</li><li><strong>失效原因</strong>：索引存储的是列原始值，计算或函数操作后生成的值无法匹配索引结构。</li><li><strong>具体原理</strong>：B+ 树索引基于原始值构建，计算或函数会破坏值与索引的映射关系，导致无法通过索引树快速定位。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> <span class="keyword">YEAR</span>(create_time) <span class="operator">=</span> <span class="number">2023</span>;</span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="operator">+</span> <span class="number">10</span> <span class="operator">=</span> <span class="number">20</span>;</span><br><span class="line"><span class="comment">-- 正常</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> create_time <span class="keyword">BETWEEN</span> <span class="string">&#x27;2023-01-01&#x27;</span> <span class="keyword">AND</span> <span class="string">&#x27;2023-12-31&#x27;</span>;</span><br></pre></td></tr></table></figure><hr><h3 id="2-使用-OR-且两边存在范围查询"><a href="#2-使用-OR-且两边存在范围查询" class="headerlink" title="2. 使用 OR 且两边存在范围查询"></a><strong>2. 使用</strong> <code>OR</code> <strong>且两边存在范围查询</strong></h3><ul><li><strong>正常判断</strong>：<code>OR</code> 两侧均有索引且逻辑简单。</li><li><strong>失效原因</strong>：<code>OR</code> 要求同时满足多个条件，若任意一侧无索引或涉及范围查询，优化器可能放弃索引。</li><li><strong>具体原理</strong>：MySQL 对 <code>OR</code> 的优化能力有限，若无法合并索引范围，则选择全表扫描。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效（假设 d 列无索引）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="operator">&gt;</span> <span class="number">10</span> <span class="keyword">OR</span> d <span class="operator">=</span> <span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 优化方法</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="operator">&gt;</span> <span class="number">10</span> </span><br><span class="line"><span class="keyword">UNION</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> d <span class="operator">=</span> <span class="number">5</span>;</span><br></pre></td></tr></table></figure><hr><h3 id="3-LIKE-不满足左匹配"><a href="#3-LIKE-不满足左匹配" class="headerlink" title="3. LIKE 不满足左匹配"></a><strong>3.</strong> <code>LIKE</code> <strong>不满足左匹配</strong></h3><ul><li><strong>正常判断</strong>：<code>LIKE</code> 使用前缀匹配（如 <code>&#39;abc%&#39;</code>）。</li><li><strong>失效原因</strong>：以通配符开头（<code>%</code> 或 <code>_</code>）破坏索引前缀有序性。</li><li><strong>具体原理</strong>：B+ 树索引按前缀排序，无法反向或中间模糊匹配。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> name <span class="keyword">LIKE</span> <span class="string">&#x27;%java&#x27;</span>;</span><br><span class="line"><span class="comment">-- 正常</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> name <span class="keyword">LIKE</span> <span class="string">&#x27;java%&#x27;</span>;</span><br></pre></td></tr></table></figure><hr><h3 id="4-隐式类型转换"><a href="#4-隐式类型转换" class="headerlink" title="4. 隐式类型转换"></a><strong>4. 隐式类型转换</strong></h3><ul><li><strong>正常判断</strong>：查询值与列类型严格一致。</li><li><strong>失效原因</strong>：类型不匹配导致 MySQL 隐式转换，破坏索引匹配。</li><li><strong>具体原理</strong>：索引存储的是列定义的类型，隐式转换相当于对列使用函数（如 <code>CAST</code>）。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效（假设 a 是 VARCHAR）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="operator">=</span> <span class="number">123</span>;  <span class="comment">-- MySQL 执行 CAST(a AS INT)</span></span><br><span class="line"><span class="comment">-- 正常（特例：字段为 INT，查询值带引号）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> id <span class="operator">=</span> <span class="string">&#x27;123&#x27;</span>;  <span class="comment">-- id 是 INT 类型</span></span><br></pre></td></tr></table></figure><hr><h3 id="5-不等于比较（-或-）"><a href="#5-不等于比较（-或-）" class="headerlink" title="5. 不等于比较（!= 或 &lt;&gt;）"></a><strong>5. 不等于比较（</strong><code>!=</code> <strong>或</strong> <code>&lt;&gt;</code><strong>）</strong></h3><ul><li><strong>正常判断</strong>：主键或唯一索引可能走索引。</li><li><strong>失效原因</strong>：非主键的不等于操作需扫描大部分数据，优化器认为全表更快。</li><li><strong>具体原理</strong>：索引适合定位少量数据，不等于操作需遍历索引树大部分节点。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效（普通索引）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="operator">!=</span> <span class="number">5</span>;</span><br><span class="line"><span class="comment">-- 正常（主键或覆盖索引）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> id <span class="operator">!=</span> <span class="number">5</span>;  <span class="comment">-- id 是主键</span></span><br></pre></td></tr></table></figure><hr><h3 id="6-IS-NOT-NULL-与-IS-NULL"><a href="#6-IS-NOT-NULL-与-IS-NULL" class="headerlink" title="6. IS NOT NULL 与 IS NULL"></a><strong>6.</strong> <code>IS NOT NULL</code> <strong>与</strong> <code>IS NULL</code></h3><ul><li><strong>正常判断</strong>：<code>IS NULL</code> 可走索引，<code>IS NOT NULL</code> 可能失效。</li><li><strong>失效原因</strong>：<code>IS NOT NULL</code> 需遍历所有非空值，成本高。</li><li><strong>具体原理</strong>：索引中 <code>NULL</code> 值集中存储（InnoDB），<code>IS NULL</code> 可快速定位，而 <code>IS NOT NULL</code> 需扫描全索引。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="keyword">IS</span> <span class="keyword">NOT NULL</span>;</span><br><span class="line"><span class="comment">-- 正常</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="keyword">IS</span> <span class="keyword">NULL</span>;</span><br></pre></td></tr></table></figure><hr><h3 id="7-ORDER-BY-排序"><a href="#7-ORDER-BY-排序" class="headerlink" title="7. ORDER BY 排序"></a><strong>7.</strong> <code>ORDER BY</code> <strong>排序</strong></h3><ul><li><strong>正常判断</strong>：排序字段有索引且顺序一致。</li><li><strong>失效原因</strong>：小数据量直接在内存排序；排序字段无索引或顺序不匹配。</li><li><strong>具体原理</strong>：索引本身有序，若 <code>ORDER BY</code> 字段与索引顺序一致，可避免 <code>filesort</code> 操作。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效（无索引）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> a;</span><br><span class="line"><span class="comment">-- 正常（索引支持排序）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> a, b;  <span class="comment">-- 索引 (a, b)</span></span><br></pre></td></tr></table></figure><hr><h3 id="8-IN-条件"><a href="#8-IN-条件" class="headerlink" title="8. IN 条件"></a><strong>8.</strong> <code>IN</code> <strong>条件</strong></h3><ul><li><strong>正常判断</strong>：<code>IN</code> 列表较短且选择性高。</li><li><strong>失效原因</strong>：长列表导致优化器认为全表扫描更快。</li><li><strong>具体原理</strong>：<code>IN</code> 本质是多个 <code>OR</code>，列表过长时索引检索成本超过全表扫描。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效（列表过长）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="keyword">IN</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,...,<span class="number">1000</span>);</span><br><span class="line"><span class="comment">-- 正常（主键或短列表）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> id <span class="keyword">IN</span> (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>);</span><br></pre></td></tr></table></figure><hr><h3 id="9-联合索引未遵循最左前缀"><a href="#9-联合索引未遵循最左前缀" class="headerlink" title="9. 联合索引未遵循最左前缀"></a><strong>9. 联合索引未遵循最左前缀</strong></h3><ul><li><strong>正常判断</strong>：查询条件包含最左列且顺序合理。</li><li><strong>失效原因</strong>：未包含最左列，或中间列被范围查询中断。</li><li><strong>具体原理</strong>：联合索引按 <code>(a, b, c)</code> 顺序构建 B+ 树，缺少中间列导致后续列无序。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效（缺少 a）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> b<span class="operator">=</span><span class="number">2</span> <span class="keyword">AND</span> c<span class="operator">=</span><span class="number">3</span>;</span><br><span class="line"><span class="comment">-- 部分失效（c 无法直接利用索引）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a<span class="operator">=</span><span class="number">1</span> <span class="keyword">AND</span> c<span class="operator">=</span><span class="number">3</span>;</span><br></pre></td></tr></table></figure><hr><h3 id="10-范围查询阻断后续列"><a href="#10-范围查询阻断后续列" class="headerlink" title="10. 范围查询阻断后续列"></a><strong>10. 范围查询阻断后续列</strong></h3><ul><li><strong>正常判断</strong>：范围查询列在联合索引末尾。</li><li><strong>失效原因</strong>：范围查询（如 <code>&gt;</code>、<code>BETWEEN</code>）后，后续列无法使用索引。</li><li><strong>具体原理</strong>：范围查询导致索引后续列无序，无法通过 B+ 树快速定位。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 仅 a 和 b 走索引，c 失效</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a<span class="operator">=</span><span class="number">1</span> <span class="keyword">AND</span> b<span class="operator">&gt;</span><span class="number">10</span> <span class="keyword">AND</span> c<span class="operator">=</span><span class="number">2</span>;</span><br></pre></td></tr></table></figure><hr><h3 id="11-两列比较操作"><a href="#11-两列比较操作" class="headerlink" title="11. 两列比较操作"></a><strong>11. 两列比较操作</strong></h3><ul><li><strong>正常判断</strong>：单列条件使用索引。</li><li><strong>失效原因</strong>：索引不支持列间比较。</li><li><strong>具体原理</strong>：索引存储列值与行位置的映射，无法直接比较两列值。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="operator">=</span> b;</span><br></pre></td></tr></table></figure><hr><h3 id="12-NOT-IN-条件"><a href="#12-NOT-IN-条件" class="headerlink" title="12. NOT IN 条件"></a><strong>12.</strong> <code>NOT IN</code> <strong>条件</strong></h3><ul><li><strong>正常判断</strong>：主键 <code>NOT IN</code> 可能走索引。</li><li><strong>失效原因</strong>：普通索引需回表验证，优化器认为全表扫描更快。</li><li><strong>具体原理</strong>：主键索引包含完整数据，普通索引需回表检查是否满足 <code>NOT IN</code>。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效（普通索引）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> a <span class="keyword">NOT</span> <span class="keyword">IN</span> (<span class="number">1</span>,<span class="number">2</span>);</span><br><span class="line"><span class="comment">-- 正常（主键）</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> <span class="keyword">WHERE</span> id <span class="keyword">NOT</span> <span class="keyword">IN</span> (<span class="number">1</span>,<span class="number">2</span>);</span><br></pre></td></tr></table></figure><hr><h3 id="13-NOT-EXISTS-子查询"><a href="#13-NOT-EXISTS-子查询" class="headerlink" title="13. NOT EXISTS 子查询"></a><strong>13.</strong> <code>NOT EXISTS</code> <strong>子查询</strong></h3><ul><li><strong>正常判断</strong>：<code>EXISTS</code> 可能走索引，<code>NOT EXISTS</code> 通常失效。</li><li><strong>失效原因</strong>：<code>NOT EXISTS</code> 需逐行验证子查询，无法利用索引。</li><li><strong>具体原理</strong>：子查询需全表扫描或全索引扫描，成本较高。</li><li><strong>示例 SQL</strong>：</li></ul><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">-- 失效</span></span><br><span class="line"><span class="keyword">SELECT</span> <span class="operator">*</span> <span class="keyword">FROM</span> <span class="keyword">table</span> t1 </span><br><span class="line"><span class="keyword">WHERE</span> <span class="keyword">NOT</span> <span class="keyword">EXISTS</span> (<span class="keyword">SELECT</span> <span class="number">1</span> <span class="keyword">FROM</span> <span class="keyword">table</span> t2 <span class="keyword">WHERE</span> t1.id <span class="operator">=</span> t2.id);</span><br></pre></td></tr></table></figure><hr>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis 底层数据结构</title>
      <link href="/2025/06/07/Redis%20%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
      <url>/2025/06/07/Redis%20%E5%BA%95%E5%B1%82%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis-底层数据结构"><a href="#Redis-底层数据结构" class="headerlink" title="Redis 底层数据结构"></a>Redis 底层数据结构</h1><p>原文拷贝：<a href="https://pdai.tech/md/db/nosql-redis/db-redis-x-redis-ds.html">https://pdai.tech/md/db/nosql-redis/db-redis-x-redis-ds.html</a></p><h2 id="1-底层数据结构引入"><a href="#1-底层数据结构引入" class="headerlink" title="1. 底层数据结构引入"></a>1. 底层数据结构引入</h2><p>在对对象机制（redisObject）有了初步认识之后，我们便可以继续理解如下的底层数据结构部分：</p><ul><li>简单动态字符串 - sds</li><li>压缩列表 - ZipList</li><li>快表 - QuickList</li><li>字典&#x2F;哈希表 - Dict</li><li>整数集 - IntSet</li><li>跳表 - ZSkipList</li></ul><h2 id=""><a href="#" class="headerlink" title=""></a><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683186163371-8b104d7d-6d48-48be-b36f-00239b94f2c6-20250605104506666.png" alt="img"></h2><h2 id="2-简单动态字符串-sds"><a href="#2-简单动态字符串-sds" class="headerlink" title="2. 简单动态字符串 - sds"></a>2. 简单动态字符串 - sds</h2><p>Redis 是用 C 语言写的，但是对于Redis的字符串，却不是 C 语言中的字符串（即以空字符’\0’结尾的字符数组），它是自己构建了一种名为 <strong>简单动态字符串（simple dynamic string,SDS</strong>）的抽象类型，并将 SDS 作为 Redis的默认字符串表示。</p><h3 id="2-1-SDS-定义"><a href="#2-1-SDS-定义" class="headerlink" title="2.1. SDS 定义"></a>2.1. SDS 定义</h3><p>这是一种用于存储二进制数据的一种结构, 具有动态扩容的特点. 其实现位于src&#x2F;sds.h与src&#x2F;sds.c中。</p><ul><li><strong>SDS的总体概览</strong>如下图:</li></ul><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683186200481-7f03df1c-74c9-40d7-98bb-dcd47b24fef0.png" alt="img"></p><p>其中sdshdr是头部, buf是真实存储用户数据的地方. 另外注意, 从命名上能看出来, 这个数据结构除了能存储二进制数据, 显然是用于设计作为字符串使用的, 所以在buf中, 用户数据后总跟着一个\0. 即图中 “数据” + “\0” 是为所谓的buf。</p><ul><li>如下是<strong>6.0源码中sds相关的结构</strong>：</li></ul><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683186307934-1a2abbea-4cc0-4975-bbce-43e33ab4cfe6-20250605104457766.png" alt="img"></p><p>通过上图我们可以看到，SDS有五种不同的头部. 其中sdshdr5实际并未使用到. 所以实际上有四种不同的头部, 分别如下:</p><p>其中：</p><ul><li><ul><li>len 保存了SDS保存字符串的长度</li><li>buf[] 数组用来保存字符串的每个元素</li><li>alloc分别以uint8, uint16, uint32, uint64表示整个SDS, 除过头部与末尾的\0, 剩余的字节数.</li><li>flags 始终为一字节, 以低三位标示着头部的类型, 高5位未使用.</li></ul></li></ul><h3 id="2-2-为什么使用SDS"><a href="#2-2-为什么使用SDS" class="headerlink" title="2.2. 为什么使用SDS"></a>2.2. 为什么使用SDS</h3><p><strong>为什么不使用C语言字符串实现，而是使用 SDS呢</strong>？这样实现有什么好处？</p><ul><li><strong>常数复杂度获取字符串长度</strong></li></ul><p>由于 len 属性的存在，我们获取 SDS 字符串的长度只需要读取 len 属性，时间复杂度为 O(1)。而对于 C 语言，获取字符串的长度通常是经过遍历计数来实现的，时间复杂度为 O(n)。通过 strlen key 命令可以获取 key 的字符串长度。</p><ul><li><strong>杜绝缓冲区溢出</strong></li></ul><p>我们知道在 C 语言中使用 strcat 函数来进行两个字符串的拼接，一旦没有分配足够长度的内存空间，就会造成缓冲区溢出。而对于 SDS 数据类型，在进行字符修改的时候，<strong>会首先根据记录的 len 属性检查内存空间是否满足需求</strong>，如果不满足，会进行相应的空间扩展，然后在进行修改操作，所以不会出现缓冲区溢出。</p><ul><li><strong>减少修改字符串的内存重新分配次数</strong></li></ul><p>C语言由于不记录字符串的长度，所以如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。</p><p>而对于SDS，由于len属性和alloc属性的存在，对于修改字符串SDS实现了<strong>空间预分配</strong>和<strong>惰性空间释放</strong>两种策略：</p><p>1、空间预分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。</p><p>2、惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 alloc 属性将这些字节的数量记录下来，等待后续使用。（当然SDS也提供了相应的API，当我们有需要时，也可以手动释放这些未使用的空间。）</p><ul><li><strong>二进制安全</strong></li></ul><p>因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而所有 SDS 的API 都是以处理二进制的方式来处理 buf 里面的元素，并且 SDS 不是以空字符串来判断是否结束，而是以 len 属性表示的长度来判断字符串是否结束。</p><ul><li><strong>兼容部分 C 字符串函数</strong></li></ul><p>虽然 SDS 是二进制安全的，但是一样遵从每个字符串都是以空字符串结尾的惯例，这样可以重用 C 语言库&lt;string.h&gt; 中的一部分函数。</p><h3 id="2-3-空间预分配补进一步理解"><a href="#2-3-空间预分配补进一步理解" class="headerlink" title="2.3. 空间预分配补进一步理解"></a>2.3. 空间预分配补进一步理解</h3><p>当执行追加操作时，比如现在给key&#x3D;‘Hello World’的字符串后追加‘ again!’则这时的len&#x3D;18，free由0变成了18，此时的buf&#x3D;’Hello World again!\0………………..’(.表示空格)，也就是buf的内存空间是18+18+1&#x3D;37个字节，其中‘\0’占1个字节redis给字符串多分配了18个字节的预分配空间，所以下次还有append追加的时候，如果预分配空间足够，就无须在进行空间分配了。在当前版本中，当新字符串的长度小于1M时，redis会分配他们所需大小一倍的空间，当大于1M的时候，就为他们额外多分配1M的空间。</p><p>思考：<strong>这种分配策略会浪费内存资源吗</strong>？</p><p>答：执行过APPEND 命令的字符串会带有额外的预分配空间，这些预分配空间不会被释放，除非该字符串所对应的键被删除，或者等到关闭Redis 之后，再次启动时重新载入的字符串对象将不会有预分配空间。因为执行APPEND 命令的字符串键数量通常并不多，占用内存的体积通常也不大，所以这一般并不算什么问题。另一方面，如果执行APPEND 操作的键很多，而字符串的体积又很大的话，那可能就需要修改Redis 服务器，让它定时释放一些字符串键的预分配空间，从而更有效地使用内存。</p><h3 id="2-4-小结"><a href="#2-4-小结" class="headerlink" title="2.4. 小结"></a>2.4. 小结</h3><p>redis的字符串表示为sds，而不是C字符串（以\0结尾的char*）， 它是Redis 底层所使用的字符串表示，它被用在几乎所有的Redis 模块中。可以看如下对比：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683186398426-e49e97b8-1a09-4af9-b24e-69d9427e0a86-20250605104730696.png" alt="img"></p><p>一般来说，SDS 除了保存数据库中的字符串值以外，SDS 还可以作为缓冲区（buffer）：包括 AOF 模块中的AOF缓冲区以及客户端状态中的输入缓冲区。</p><h2 id="3-压缩列表-ZipList"><a href="#3-压缩列表-ZipList" class="headerlink" title="3. 压缩列表 - ZipList"></a>3. 压缩列表 - ZipList</h2><p>ziplist是为了提高存储效率而设计的一种特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。它能在O(1)的时间复杂度下完成list两端的push和pop操作。但是因为每次操作都需要重新分配ziplist的内存，所以实际复杂度和ziplist的内存使用量相关。</p><h3 id="3-1-ziplist结构"><a href="#3-1-ziplist结构" class="headerlink" title="3.1. ziplist结构"></a>3.1. ziplist结构</h3><p>先看下6.0中对应的源码和介绍</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683186463010-998f824b-0c42-4671-975c-e4ecd0303661.png" alt="img"></p><p>整个ziplist在内存中的存储格式如下：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683186477713-f4b4e9f1-70c0-41aa-af35-d8cdd8872970-20250605104738622.png" alt="img"></p><ul><li>zlbytes字段的类型是uint32_t, 这个字段中存储的是整个ziplist所占用的内存的字节数</li><li>zltail字段的类型是uint32_t, 它指的是ziplist中最后一个entry的偏移量. 用于快速定位最后一个entry, 以快速完成pop等操作</li><li>zllen字段的类型是uint16_t, 它指的是整个ziplit中entry的数量. 这个值只占2bytes（16位）: 如果ziplist中entry的数目小于65535(2的16次方), 那么该字段中存储的就是实际entry的值. 若等于或超过65535, 那么该字段的值固定为65535, 但实际数量需要一个个entry的去遍历所有entry才能得到.</li><li>zlend是一个终止字节, 其值为全F, 即0xff. ziplist保证任何情况下, 一个entry的首字节都不会是255</li></ul><h3 id="3-2-Entry结构"><a href="#3-2-Entry结构" class="headerlink" title="3.2. Entry结构"></a>3.2. Entry结构</h3><p>那么entry是什么结构呢？</p><p><strong>先看下源码中相关介绍</strong></p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683186554347-d3b74eed-8e4b-42fd-9f2d-0cc62bd39af1-20250605104447715.png" alt="img"></p><p><strong>第一种情况</strong>：一般结构 <prevlen> <encoding> <entry-data></p><p>prevlen：前一个entry的大小，编码方式见下文；</p><p>encoding：不同的情况下值不同，用于表示当前entry的类型和长度；</p><p>entry-data：真是用于存储entry表示的数据；</p><p><strong>第二种情况</strong>：在entry中存储的是int类型时，encoding和entry-data会合并在encoding中表示，此时没有entry-data字段；</p><p>redis中，在存储数据时，会先尝试将string转换成int存储，节省空间；</p><p>此时entry结构：<prevlen> <encoding></p><ul><li><strong>prevlen编码</strong></li></ul><p>当前一个元素长度小于254（255用于zlend）的时候，prevlen长度为1个字节，值即为前一个entry的长度，如果长度大于等于254的时候，prevlen用5个字节表示，第一字节设置为254，后面4个字节存储一个小端的无符号整型，表示前一个entry的长度；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;prevlen from 0 to 253&gt; &lt;encoding&gt; &lt;entry&gt;      //长度小于254结构 0xFE &lt;4 bytes unsigned little endian prevlen&gt; &lt;encoding&gt; &lt;entry&gt;   //长度大于等于254</span><br></pre></td></tr></table></figure><ul><li><strong>encoding编码</strong></li></ul><p>encoding的长度和值根据保存的是int还是string，还有数据的长度而定；</p><p>前两位用来表示类型，当为“11”时，表示entry存储的是int类型，其它表示存储的是string；</p><p><strong>存储string时</strong>：</p><p>|00pppppp| ：此时encoding长度为1个字节，该字节的后六位表示entry中存储的string长度，因为是6位，所以entry中存储的string长度不能超过63；</p><p>|01pppppp|qqqqqqqq| 此时encoding长度为两个字节；此时encoding的后14位用来存储string长度，长度不能超过16383；</p><p>|10000000|qqqqqqqq|rrrrrrrr|ssssssss|ttttttt| 此时encoding长度为5个字节，后面的4个字节用来表示encoding中存储的字符串长度，长度不能超过2^32 - 1;</p><p><strong>存储int时</strong>：</p><p>|11000000| encoding为3个字节，后2个字节表示一个int16；</p><p>|11010000| encoding为5个字节，后4个字节表示一个int32;</p><p>|11100000| encoding 为9个字节，后8字节表示一个int64;</p><p>|11110000| encoding为4个字节，后3个字节表示一个有符号整型；</p><p>|11111110| encoding为2字节，后1个字节表示一个有符号整型；</p><p>|1111xxxx| encoding长度就只有1个字节，xxxx表示一个0 - 12的整数值；</p><p>|11111111| 还记得zlend么？</p><ul><li><strong>源码中数据结构支撑</strong></li></ul><p>你可以看到为了操作上的简易实际还增加了几个属性</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/* We use this function to receive information about a ziplist entry. * Note that this is not how the data is actually encoded, is just what we * get filled by a function in order to operate more easily. */ typedef struct zlentry &#123;    unsigned int prevrawlensize; /* Bytes used to encode the previous entry len*/    unsigned int prevrawlen;     /* Previous entry len. */    unsigned int lensize;        /* Bytes used to encode this entry type/len.                                    For example strings have a 1, 2 or 5 bytes                                    header. Integers always use a single byte.*/    unsigned int len;            /* Bytes used to represent the actual entry.                                    For strings this is just the string length                                    while for integers it is 1, 2, 3, 4, 8 or                                    0 (for 4 bit immediate) depending on the                                    number range. */    unsigned int headersize;     /* prevrawlensize + lensize. */    unsigned char encoding;      /* Set to ZIP_STR_* or ZIP_INT_* depending on                                    the entry encoding. However for 4 bits                                    immediate integers this can assume a range                                    of values and must be range-checked. */    unsigned char *p;            /* Pointer to the very start of the entry, that                                    is, this points to prev-entry-len field. */ &#125; zlentry;</span><br></pre></td></tr></table></figure><ul><li><ul><li>prevrawlensize表示 previous_entry_length字段的长度</li><li>prevrawlen表示 previous_entry_length字段存储的内容</li><li>lensize表示 encoding字段的长度</li><li>len表示数据内容长度</li><li>headersize 表示当前元素的首部长度，即previous_entry_length字段长度与encoding字段长度之和</li><li>encoding表示数据类型</li><li>p表示当前元素首地址</li></ul></li></ul><h3 id="3-3-为什么ZipList特别省内存"><a href="#3-3-为什么ZipList特别省内存" class="headerlink" title="3.3. 为什么ZipList特别省内存"></a>3.3. 为什么ZipList特别省内存</h3><p>所以只有理解上面的Entry结构，我们才会真正理解ZipList为什么是特别节省内存的数据结构。</p><ul><li>ziplist节省内存是相对于普通的list来说的，如果是普通的数组，那么它每个元素占用的内存是一样的且取决于最大的那个元素（很明显它是需要预留空间的）；</li><li>所以ziplist在设计时就很容易想到要尽量让每个元素按照实际的内容大小存储，<strong>所以增加encoding字段</strong>，针对不同的encoding来细化存储大小；</li><li>这时候还需要解决的一个问题是遍历元素时如何定位下一个元素呢？在普通数组中每个元素定长，所以不需要考虑这个问题；但是ziplist中每个data占据的内存不一样，所以为了解决遍历，需要增加记录上一个元素的length，<strong>所以增加了prelen字段</strong>。</li></ul><p><strong>为什么我们去研究ziplist特别节省内存的数据结构</strong>？ 在实际应用中，大量存储字符串的优化是需要你对底层的数据结构有一定的理解的，而ziplist在场景优化的时候也被考虑采用的首选。</p><h3 id="3-4-ziplist的缺点"><a href="#3-4-ziplist的缺点" class="headerlink" title="3.4. ziplist的缺点"></a>3.4. ziplist的缺点</h3><p>最后我们再看看它的一些缺点：</p><ul><li>ziplist也不预留内存空间, 并且在移除结点后, 也是立即缩容, 这代表每次写操作都会进行内存分配操作.</li><li>结点如果扩容, 导致结点占用的内存增长, 并且超过254字节的话, 可能会导致链式反应: 其后一个结点的entry.prevlen需要从一字节扩容至五字节. <strong>最坏情况下, 第一个结点的扩容, 会导致整个ziplist表中的后续所有结点的entry.prevlen字段扩容</strong>. 虽然这个内存重分配的操作依然只会发生一次, 但代码中的时间复杂度是o(N)级别, 因为链式扩容只能一步一步的计算. 但这种情况的概率十分的小, 一般情况下链式扩容能连锁反映五六次就很不幸了. 之所以说这是一个蛋疼问题, 是因为, 这样的坏场景下, 其实时间复杂度并不高: 依次计算每个entry新的空间占用, 也就是o(N), 总体占用计算出来后, 只执行一次内存重分配, 与对应的memmove操作, 就可以了.</li></ul><h2 id="4-快表-QuickList"><a href="#4-快表-QuickList" class="headerlink" title="4. 快表 - QuickList"></a>4. 快表 - QuickList</h2><p>quicklist这个结构是Redis在3.2版本后新加的, 之前的版本是list(即linkedlist)， 用于String数据类型中。</p><p>它是一种以ziplist为结点的双端链表结构. 宏观上, quicklist是一个链表, 微观上, 链表中的每个结点都是一个ziplist。</p><h3 id="4-1-quicklist结构"><a href="#4-1-quicklist结构" class="headerlink" title="4.1. quicklist结构"></a>4.1. quicklist结构</h3><ul><li>如下是<strong>6.0源码中quicklist相关的结构</strong>：</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Node, quicklist, and Iterator are the only data structures used currently. */</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/* quicklistNode is a 32 byte struct describing a ziplist for a quicklist.</span></span><br><span class="line"><span class="comment"> * We use bit fields keep the quicklistNode at 32 bytes.</span></span><br><span class="line"><span class="comment"> * count: 16 bits, max 65536 (max zl bytes is 65k, so max count actually &lt; 32k).</span></span><br><span class="line"><span class="comment"> * encoding: 2 bits, RAW=1, LZF=2.</span></span><br><span class="line"><span class="comment"> * container: 2 bits, NONE=1, ZIPLIST=2.</span></span><br><span class="line"><span class="comment"> * recompress: 1 bit, bool, true if node is temporarry decompressed for usage.</span></span><br><span class="line"><span class="comment"> * attempted_compress: 1 bit, boolean, used for verifying during testing.</span></span><br><span class="line"><span class="comment"> * extra: 10 bits, free for future use; pads out the remainder of 32 bits */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">prev</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">next</span>;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *zl;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> sz;             <span class="comment">/* ziplist size in bytes */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> count : <span class="number">16</span>;     <span class="comment">/* count of items in ziplist */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> encoding : <span class="number">2</span>;   <span class="comment">/* RAW==1 or LZF==2 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> container : <span class="number">2</span>;  <span class="comment">/* NONE==1 or ZIPLIST==2 */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> recompress : <span class="number">1</span>; <span class="comment">/* was this node previous compressed? */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> attempted_compress : <span class="number">1</span>; <span class="comment">/* node can&#x27;t compress; too small */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> extra : <span class="number">10</span>; <span class="comment">/* more bits to steal for future usage */</span></span><br><span class="line">&#125; quicklistNode;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* quicklistLZF is a 4+N byte struct holding &#x27;sz&#x27; followed by &#x27;compressed&#x27;.</span></span><br><span class="line"><span class="comment"> * &#x27;sz&#x27; is byte length of &#x27;compressed&#x27; field.</span></span><br><span class="line"><span class="comment"> * &#x27;compressed&#x27; is LZF data with total (compressed) length &#x27;sz&#x27;</span></span><br><span class="line"><span class="comment"> * <span class="doctag">NOTE:</span> uncompressed length is stored in quicklistNode-&gt;sz.</span></span><br><span class="line"><span class="comment"> * When quicklistNode-&gt;zl is compressed, node-&gt;zl points to a quicklistLZF */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistLZF</span> &#123;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> sz; <span class="comment">/* LZF size in bytes*/</span></span><br><span class="line">    <span class="type">char</span> compressed[];</span><br><span class="line">&#125; quicklistLZF;</span><br><span class="line"></span><br><span class="line"><span class="comment">/* Bookmarks are padded with realloc at the end of of the quicklist struct.</span></span><br><span class="line"><span class="comment"> * They should only be used for very big lists if thousands of nodes were the</span></span><br><span class="line"><span class="comment"> * excess memory usage is negligible, and there&#x27;s a real need to iterate on them</span></span><br><span class="line"><span class="comment"> * in portions.</span></span><br><span class="line"><span class="comment"> * When not used, they don&#x27;t add any memory overhead, but when used and then</span></span><br><span class="line"><span class="comment"> * deleted, some overhead remains (to avoid resonance).</span></span><br><span class="line"><span class="comment"> * The number of bookmarks used should be kept to minimum since it also adds</span></span><br><span class="line"><span class="comment"> * overhead on node deletion (searching for a bookmark to update). */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistBookmark</span> &#123;</span></span><br><span class="line">    quicklistNode *node;</span><br><span class="line">    <span class="type">char</span> *name;</span><br><span class="line">&#125; quicklistBookmark;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/* quicklist is a 40 byte struct (on 64-bit systems) describing a quicklist.</span></span><br><span class="line"><span class="comment"> * &#x27;count&#x27; is the number of total entries.</span></span><br><span class="line"><span class="comment"> * &#x27;len&#x27; is the number of quicklist nodes.</span></span><br><span class="line"><span class="comment"> * &#x27;compress&#x27; is: -1 if compression disabled, otherwise it&#x27;s the number</span></span><br><span class="line"><span class="comment"> *                of quicklistNodes to leave uncompressed at ends of quicklist.</span></span><br><span class="line"><span class="comment"> * &#x27;fill&#x27; is the user-requested (or default) fill factor.</span></span><br><span class="line"><span class="comment"> * &#x27;bookmakrs are an optional feature that is used by realloc this struct,</span></span><br><span class="line"><span class="comment"> *      so that they don&#x27;t consume memory when not used. */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklist</span> &#123;</span></span><br><span class="line">    quicklistNode *head;</span><br><span class="line">    quicklistNode *tail;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> count;        <span class="comment">/* total count of all entries in all ziplists */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> len;          <span class="comment">/* number of quicklistNodes */</span></span><br><span class="line">    <span class="type">int</span> fill : QL_FILL_BITS;              <span class="comment">/* fill factor for individual nodes */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> compress : QL_COMP_BITS; <span class="comment">/* depth of end nodes not to compress;0=off */</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> bookmark_count: QL_BM_BITS;</span><br><span class="line">    quicklistBookmark bookmarks[];</span><br><span class="line">&#125; quicklist;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistIter</span> &#123;</span></span><br><span class="line">    <span class="type">const</span> quicklist *quicklist;</span><br><span class="line">    quicklistNode *current;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *zi;</span><br><span class="line">    <span class="type">long</span> offset; <span class="comment">/* offset in current ziplist */</span></span><br><span class="line">    <span class="type">int</span> direction;</span><br><span class="line">&#125; quicklistIter;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistEntry</span> &#123;</span></span><br><span class="line">    <span class="type">const</span> quicklist *quicklist;</span><br><span class="line">    quicklistNode *node;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *zi;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">char</span> *value;</span><br><span class="line">    <span class="type">long</span> <span class="type">long</span> longval;</span><br><span class="line">    <span class="type">unsigned</span> <span class="type">int</span> sz;</span><br><span class="line">    <span class="type">int</span> offset;</span><br><span class="line">&#125; quicklistEntry;</span><br></pre></td></tr></table></figure><p>这里定义了6个结构体:</p><ul><li>quicklistNode, 宏观上, quicklist是一个链表, 这个结构描述的就是链表中的结点. 它通过zl字段持有底层的ziplist. 简单来讲, 它描述了一个ziplist实例</li><li>quicklistLZF, ziplist是一段连续的内存, 用LZ4算法压缩后, 就可以包装成一个quicklistLZF结构. 是否压缩quicklist中的每个ziplist实例是一个可配置项. 若这个配置项是开启的, 那么quicklistNode.zl字段指向的就不是一个ziplist实例, 而是一个压缩后的quicklistLZF实例</li><li>quicklistBookmark, 在quicklist尾部增加的一个书签，它只有在大量节点的多余内存使用量可以忽略不计的情况且确实需要分批迭代它们，才会被使用。当不使用它们时，它们不会增加任何内存开销。</li><li>quicklist. 这就是一个双链表的定义. head, tail分别指向头尾指针. len代表链表中的结点. count指的是整个quicklist中的所有ziplist中的entry的数目. fill字段影响着每个链表结点中ziplist的最大占用空间, compress影响着是否要对每个ziplist以LZ4算法进行进一步压缩以更节省内存空间.</li><li>quicklistIter是一个迭代器</li><li>quicklistEntry是对ziplist中的entry概念的封装. quicklist作为一个封装良好的数据结构, 不希望使用者感知到其内部的实现, 所以需要把ziplist.entry的概念重新包装一下.</li></ul><h3 id="4-2-quicklist内存布局图"><a href="#4-2-quicklist内存布局图" class="headerlink" title="4.2. quicklist内存布局图"></a>4.2. quicklist内存布局图</h3><p>quicklist的内存布局图如下所示:</p><h3 id="4-3-quicklist更多额外信息"><a href="#4-3-quicklist更多额外信息" class="headerlink" title="4.3. quicklist更多额外信息"></a>4.3. quicklist更多额外信息</h3><p>下面是有关quicklist的更多额外信息:</p><ul><li>quicklist.fill的值影响着每个链表结点中, ziplist的长度.</li></ul><ol><li><ol><li>当数值为负数时, 代表以字节数限制单个ziplist的最大长度. 具体为:</li><li>-1 不超过4kb</li><li>-2 不超过 8kb</li><li>-3 不超过 16kb</li><li>-4 不超过 32kb</li><li>-5 不超过 64kb</li><li>当数值为正数时, 代表以entry数目限制单个ziplist的长度. 值即为数目. 由于该字段仅占16位, 所以以entry数目限制ziplist的容量时, 最大值为2^15个</li></ol></li></ol><ul><li>quicklist.compress的值影响着quicklistNode.zl字段指向的是原生的ziplist, 还是经过压缩包装后的quicklistLZF</li></ul><ol><li><ol><li>0 表示不压缩, zl字段直接指向ziplist</li><li>1 表示quicklist的链表头尾结点不压缩, 其余结点的zl字段指向的是经过压缩后的quicklistLZF</li><li>2 表示quicklist的链表头两个, 与末两个结点不压缩, 其余结点的zl字段指向的是经过压缩后的quicklistLZF</li><li>以此类推, 最大值为2^16</li></ol></li></ol><ul><li>quicklistNode.encoding字段, 以指示本链表结点所持有的ziplist是否经过了压缩. 1代表未压缩, 持有的是原生的ziplist, 2代表压缩过</li><li>quicklistNode.container字段指示的是每个链表结点所持有的数据类型是什么. 默认的实现是ziplist, 对应的该字段的值是2, 目前Redis没有提供其它实现. 所以实际上, 该字段的值恒为2</li><li>quicklistNode.recompress字段指示的是当前结点所持有的ziplist是否经过了解压. 如果该字段为1即代表之前被解压过, 且需要在下一次操作时重新压缩.</li></ul><p>quicklist的具体实现代码篇幅很长, 这里就不贴代码片断了, 从内存布局上也能看出来, 由于每个结点持有的ziplist是有上限长度的, 所以在与操作时要考虑的分支情况比较多。</p><p>quicklist有自己的优点, 也有缺点, 对于使用者来说, 其使用体验类似于线性数据结构, list作为最传统的双链表, 结点通过指针持有数据, 指针字段会耗费大量内存. ziplist解决了耗费内存这个问题. 但引入了新的问题: 每次写操作整个ziplist的内存都需要重分配. quicklist在两者之间做了一个平衡. 并且使用者可以通过自定义quicklist.fill, 根据实际业务情况, 经验主义调参.</p><h2 id="5-字典-哈希表-Dict"><a href="#5-字典-哈希表-Dict" class="headerlink" title="5. 字典&#x2F;哈希表 - Dict"></a>5. 字典&#x2F;哈希表 - Dict</h2><p>本质上就是哈希表, 这个在很多语言中都有，对于开发人员人员来说比较熟悉，这里就简单介绍下。</p><h3 id="5-1-数据结构"><a href="#5-1-数据结构" class="headerlink" title="5.1. 数据结构"></a>5.1. 数据结构</h3><p><strong>哈希表结构定义</strong>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictht</span>&#123;</span></span><br><span class="line">    <span class="comment">//哈希表数组</span></span><br><span class="line">    dictEntry **table;</span><br><span class="line">    <span class="comment">//哈希表大小</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> size;</span><br><span class="line">    <span class="comment">//哈希表大小掩码，用于计算索引值</span></span><br><span class="line">    <span class="comment">//总是等于 size-1</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> sizemask;</span><br><span class="line">    <span class="comment">//该哈希表已有节点的数量</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> used;</span><br><span class="line"> </span><br><span class="line">&#125;dictht</span><br></pre></td></tr></table></figure><p>哈希表是由数组 table 组成，table 中每个元素都是指向 dict.h&#x2F;dictEntry 结构，dictEntry 结构定义如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span>&#123;</span></span><br><span class="line">     <span class="comment">//键</span></span><br><span class="line">     <span class="type">void</span> *key;</span><br><span class="line">     <span class="comment">//值</span></span><br><span class="line">     <span class="class"><span class="keyword">union</span>&#123;</span></span><br><span class="line">          <span class="type">void</span> *val;</span><br><span class="line">          uint64_tu64;</span><br><span class="line">          int64_ts64;</span><br><span class="line">     &#125;v;</span><br><span class="line"> </span><br><span class="line">     <span class="comment">//指向下一个哈希表节点，形成链表</span></span><br><span class="line">     <span class="class"><span class="keyword">struct</span> <span class="title">dictEntry</span> *<span class="title">next</span>;</span></span><br><span class="line">&#125;dictEntry</span><br></pre></td></tr></table></figure><p>key 用来保存键，val 属性用来保存值，值可以是一个指针，也可以是uint64_t整数，也可以是int64_t整数。</p><p>注意这里还有一个指向下一个哈希表节点的指针，我们知道哈希表最大的问题是存在哈希冲突，如何解决哈希冲突，有开放地址法和链地址法。这里采用的便是链地址法，通过next这个指针可以将多个哈希值相同的键值对连接在一起，用来<strong>解决哈希冲突</strong>。</p><h3 id="5-2-一些要点"><a href="#5-2-一些要点" class="headerlink" title="5.2. 一些要点"></a>5.2. 一些要点</h3><ul><li><strong>哈希算法</strong>：Redis计算哈希值和索引值方法如下：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#1、使用字典设置的哈希函数，计算键 key 的哈希值</span></span><br><span class="line"><span class="built_in">hash</span> = dict-&gt;<span class="built_in">type</span>-&gt;hashFunction(key);</span><br><span class="line"></span><br><span class="line"><span class="comment">#2、使用哈希表的sizemask属性和第一步得到的哈希值，计算索引值</span></span><br><span class="line">index = <span class="built_in">hash</span> &amp; dict-&gt;ht[x].sizemask;</span><br></pre></td></tr></table></figure><ul><li><strong>解决哈希冲突</strong>：这个问题上面我们介绍了，方法是链地址法。通过字典里面的 *next 指针指向下一个具有相同索引值的哈希表节点。</li><li><strong>扩容和收缩</strong>：当哈希表保存的键值对太多或者太少时，就要通过 rerehash(重新散列）来对哈希表进行相应的扩展或者收缩。具体步骤：</li></ul><p>1、如果执行扩展操作，会基于原哈希表创建一个大小等于 ht[0].used*2n 的哈希表（也就是每次扩展都是根据原哈希表已使用的空间扩大一倍创建另一个哈希表）。相反如果执行的是收缩操作，每次收缩是根据已使用空间缩小一倍创建一个新的哈希表。</p><p>2、重新利用上面的哈希算法，计算索引值，然后将键值对放到新的哈希表位置上。</p><p>3、所有键值对都迁徙完毕后，释放原哈希表的内存空间。</p><ul><li><strong>触发扩容的条件</strong>：</li></ul><p>1、服务器目前没有执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于1。</p><p>2、服务器目前正在执行 BGSAVE 命令或者 BGREWRITEAOF 命令，并且负载因子大于等于5。</p><p>ps：负载因子 &#x3D; 哈希表已保存节点数量 &#x2F; 哈希表大小。</p><ul><li><strong>渐近式 rehash</strong></li></ul><p>什么叫渐进式 rehash？也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。如果保存在Redis中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成Redis一段时间内不能进行别的操作。所以Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。</p><h2 id="6-整数集-IntSet"><a href="#6-整数集-IntSet" class="headerlink" title="6. 整数集 - IntSet"></a>6. 整数集 - IntSet</h2><p>整数集合（intset）是集合类型的底层实现之一，当一个集合只包含整数值元素，并且这个集合的元素数量不多时，Redis 就会使用整数集合作为集合键的底层实现。</p><h3 id="6-1-intset结构"><a href="#6-1-intset结构" class="headerlink" title="6.1. intset结构"></a>6.1. intset结构</h3><p>首先看源码结构</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">intset</span> &#123;</span></span><br><span class="line">    <span class="type">uint32_t</span> encoding;</span><br><span class="line">    <span class="type">uint32_t</span> length;</span><br><span class="line">    <span class="type">int8_t</span> contents[];</span><br><span class="line">&#125; intset;</span><br></pre></td></tr></table></figure><p>encoding 表示编码方式，的取值有三个：INTSET_ENC_INT16, INTSET_ENC_INT32, INTSET_ENC_INT64</p><p>length 代表其中存储的整数的个数</p><p>contents 指向实际存储数值的连续内存区域, 就是一个数组；整数集合的每个元素都是 contents 数组的一个数组项（item），各个项在数组中按值得大小<strong>从小到大有序排序</strong>，且数组中不包含任何重复项。（虽然 intset 结构将 contents 属性声明为 int8_t 类型的数组，但实际上 contents 数组并不保存任何 int8_t 类型的值，contents 数组的真正类型取决于 encoding 属性的值）</p><h3 id="6-2-内存布局图"><a href="#6-2-内存布局图" class="headerlink" title="6.2. 内存布局图"></a>6.2. 内存布局图</h3><p>其内存布局如下图所示</p><p>我们可以看到，content数组里面每个元素的数据类型是由encoding来决定的，那么如果原来的数据类型是int16, 当我们再插入一个int32类型的数据时怎么办呢？这就是下面要说的intset的升级。</p><h3 id="6-3-整数集合的升级"><a href="#6-3-整数集合的升级" class="headerlink" title="6.3. 整数集合的升级"></a>6.3. 整数集合的升级</h3><p>当在一个int16类型的整数集合中插入一个int32类型的值，整个集合的所有元素都会转换成32类型。 整个过程有三步：</p><ul><li>根据新元素的类型（比如int32），扩展整数集合底层数组的空间大小，并为新元素分配空间。</li><li>将底层数组现有的所有元素都转换成与新元素相同的类型， 并将类型转换后的元素放置到正确的位上， 而且在放置元素的过程中， 需要继续维持底层数组的有序性质不变。</li><li>最后改变encoding的值，length+1。</li></ul><p><strong>那么如果我们删除掉刚加入的int32类型时，会不会做一个降级操作呢</strong>？</p><p>不会。主要还是减少开销的权衡。</p><h2 id="7-跳表-ZSkipList"><a href="#7-跳表-ZSkipList" class="headerlink" title="7. 跳表 - ZSkipList"></a>7. 跳表 - ZSkipList</h2><p><a href="https://zhuanlan.zhihu.com/p/576984787">redis zskiplist跳表，性能堪比红黑树？（深度分析）</a></p><p>跳跃表结构在 Redis 中的运用场景只有一个，那就是作为有序列表 (Zset) 的使用。跳跃表的性能可以保证在查找，删除，添加等操作的时候在对数期望时间内完成，这个性能是可以和平衡树来相比较的，而且在实现方面比平衡树要优雅，这就是跳跃表的长处。跳跃表的缺点就是需要的存储空间比较大，属于利用空间来换取时间的数据结构。</p><h3 id="7-1-什么是跳跃表"><a href="#7-1-什么是跳跃表" class="headerlink" title="7.1. 什么是跳跃表"></a>7.1. 什么是跳跃表</h3><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683188767947-029a8488-19ac-4266-b882-ac1f83760bf7-20250605104436000.png" alt="img"></p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683188755238-44e4cadc-ee00-4cb5-80c8-0b8dc991022f.webp" alt="img"></p><p>跳跃表要解决什么问题呢？如果你一上来就去看它的实现，你很难理解设计的本质，所以先要看它的设计要解决什么问题。</p><p>对于于一个单链表来讲，即便链表中存储的数据是有序的，如果我们要想在其中查找某个数据，也只能从头到尾遍历链表。这样查找效率就会很低，时间复杂度会很高，是 O(n)。比如查找12，需要7次查找</p><p>如果我们增加如下两级索引，那么它搜索次数就变成了3次</p><h3 id="7-2-Redis跳跃表的设计"><a href="#7-2-Redis跳跃表的设计" class="headerlink" title="7.2. Redis跳跃表的设计"></a>7.2. Redis跳跃表的设计</h3><p>redis跳跃表并没有在单独的类（比如skplist.c)中定义，而是其定义在server.h中, 如下:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* ZSETs use a specialized version of Skiplists */</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> &#123;</span></span><br><span class="line">    sds ele;</span><br><span class="line">    <span class="type">double</span> score;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">backward</span>;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistLevel</span> &#123;</span></span><br><span class="line">        <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">forward</span>;</span></span><br><span class="line">        <span class="type">unsigned</span> <span class="type">int</span> span;</span><br><span class="line">    &#125; level[];</span><br><span class="line">&#125; zskiplistNode;</span><br><span class="line"></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">zskiplist</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">zskiplistNode</span> *<span class="title">header</span>, *<span class="title">tail</span>;</span></span><br><span class="line">    <span class="type">unsigned</span> <span class="type">long</span> length;</span><br><span class="line">    <span class="type">int</span> level;</span><br><span class="line">&#125; zskiplist;</span><br></pre></td></tr></table></figure><p>其内存布局如下图:</p><p><strong>zskiplist的核心设计要点</strong></p><ul><li><p><strong>头节点</strong>不持有任何数据, 且其level[]的长度为32</p></li><li><p><strong>每个结点</strong></p></li><li><ul><li>ele字段，持有数据，是sds类型</li><li>score字段, 其标示着结点的得分, 结点之间凭借得分来判断先后顺序, 跳跃表中的结点按结点的得分升序排列.</li><li>backward指针, 这是原版跳跃表中所没有的. 该指针指向结点的前一个紧邻结点.</li><li>level字段, 用以记录所有结点(除过头节点外)；每个结点中最多持有32个zskiplistLevel结构. 实际数量在结点创建时, 按幂次定律随机生成(不超过32). 每个zskiplistLevel中有两个字段</li></ul></li><li><ul><li><ul><li>forward字段指向比自己得分高的某个结点(不一定是紧邻的), 并且, 若当前zskiplistLevel实例在level[]中的索引为X, 则其forward字段指向的结点, 其level[]字段的容量至少是X+1. 这也是上图中, 为什么forward指针总是画的水平的原因.</li><li>span字段代表forward字段指向的结点, 距离当前结点的距离. 紧邻的两个结点之间的距离定义为1.</li></ul></li></ul></li></ul><h3 id="7-3-为什么不用平衡树或者哈希表"><a href="#7-3-为什么不用平衡树或者哈希表" class="headerlink" title="7.3. 为什么不用平衡树或者哈希表"></a>7.3. 为什么不用平衡树或者哈希表</h3><ul><li><strong>为什么不是平衡树，先看下作者的回答</strong></li></ul><p>There are a few reasons:</p><p>They are not very memory intensive. It’s up to you basically. Changing parameters about the probability of a node to have a given number of levels will make then less memory intensive than btrees.</p><p>A sorted set is often target of many ZRANGE or ZREVRANGE operations, that is, traversing the skip list as a linked list. With this operation the cache locality of skip lists is at least as good as with other kind of balanced trees.</p><p>They are simpler to implement, debug, and so forth. For instance thanks to the skip list simplicity I received a patch (already in Redis master) with augmented skip lists implementing ZRANK in O(log(N)). It required little changes to the code.</p><p>About the Append Only durability &amp; speed, I don’t think it is a good idea to optimize Redis at cost of more code and more complexity for a use case that IMHO should be rare for the Redis target (fsync() at every command). Almost no one is using this feature even with ACID SQL databases, as the performance hint is big anyway.</p><p>About threads: our experience shows that Redis is mostly I&#x2F;O bound. I’m using threads to serve things from Virtual Memory. The long term solution to exploit all the cores, assuming your link is so fast that you can saturate a single core, is running multiple instances of Redis (no locks, almost fully scalable linearly with number of cores), and using the “Redis Cluster” solution that I plan to develop in the future.</p><p>简而言之就是实现简单且达到了类似效果。</p><ul><li><strong>skiplist与平衡树、哈希表的比较</strong></li></ul><p>skiplist和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。</p><p>在做范围查找的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。</p><p>平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。</p><p>从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1&#x2F;(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p&#x3D;1&#x2F;4，那么平均每个节点包含1.33个指针，比平衡树更有优势。</p><p>查找单个key，skiplist和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。</p><p>从算法实现难度上来比较，skiplist比平衡树要简单得多。</p><h2 id="8-参考文章"><a href="#8-参考文章" class="headerlink" title="8. 参考文章"></a>8. 参考文章</h2><ul><li>Redis 6.0源码</li><li><a href="https://www.cnblogs.com/neooelric/p/9621736.html">https://www.cnblogs.com/neooelric/p/9621736.html</a></li></ul><p>还参考了</p><p><a href="https://www.cnblogs.com/hunternet/p/11248192.html">https://www.cnblogs.com/hunternet/p/11248192.html</a></p><p><a href="https://www.jianshu.com/p/8ac45fd01548">https://www.jianshu.com/p/8ac45fd01548</a></p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>JVM新生代只有一个Eden+S0 可以吗</title>
      <link href="/2025/06/07/%E6%96%B0%E7%94%9F%E4%BB%A3%E5%8F%AA%E6%9C%89%E4%B8%80%E4%B8%AAEden+S0%20%E5%8F%AF%E4%BB%A5%E5%90%97/"/>
      <url>/2025/06/07/%E6%96%B0%E7%94%9F%E4%BB%A3%E5%8F%AA%E6%9C%89%E4%B8%80%E4%B8%AAEden+S0%20%E5%8F%AF%E4%BB%A5%E5%90%97/</url>
      
        <content type="html"><![CDATA[<h1 id="JVM新生代只有一个Eden-S0-可以吗"><a href="#JVM新生代只有一个Eden-S0-可以吗" class="headerlink" title="JVM新生代只有一个Eden+S0 可以吗"></a>JVM新生代只有一个Eden+S0 可以吗</h1><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1742279689877-fe42aa96-5291-48a1-9804-ae55a6877eab.png" alt="img"></p><p>先直接说答案：<strong>理论上可以，也能实现标记-复制算法。但工程上不可以，因为会大大浪费空间。</strong></p><p>标记-复制算法下，新生代三个区域是怎么使用的：</p><ol><li>初始时，Eden、S0、S1 都是空</li><li>对象都分配在 Eden区，如果Eden区快满了就触发垃圾回收，把 Eden区中的存活对象转移到一个块空的survivor区（S0），然后 Eden区清空。（一次youngGC结束）</li><li>再次分配新对象到 Eden，再次触发垃圾回收（此时不光标记 Eden，还需要标记S0了），然后将这两个区域存活的转移到 另一块空的survivor区（S1），清理S0、Eden区（一次youngGC结束）</li><li>再次分配新对象到 Eden，再次触发垃圾回收（此时不光标记 Eden，还需要标记S1了），然后将这两个区域存活的转移到 另一块空的survivor区（S0）</li></ol><p>因此采用 Eden+S0+S1（8：1：1），可以保证JVM正常运行时，新生代的空间有9成可以存放对象，1成是空着的。</p><p>如果说只有两个区域，比如 Eden区和S0。那么由于标记复制算法的限制（必须由一块区域是空的）。每次只有一个区域是存放youngGC活下来的对象，一个区域是空的。</p><p>因为要轮流存放对象，那么比例应该就是1：1。那么在正常运行时，<strong>JVM新生代中只有一半的内存可以分配对象，另一半得空着</strong>。</p><p>如果说不想要有区域是空着的，那么就需要使用 标记-清除算法或者标记-整理算法，就会存在碎片和效率问题。而这与 新生代的设计初衷相违背（新生代会比较高频进行垃圾回收）</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>指令重排 真的有点阴</title>
      <link href="/2025/06/07/%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92%20%E7%9C%9F%E7%9A%84%E6%9C%89%E7%82%B9%E9%98%B4/"/>
      <url>/2025/06/07/%E6%8C%87%E4%BB%A4%E9%87%8D%E6%8E%92%20%E7%9C%9F%E7%9A%84%E6%9C%89%E7%82%B9%E9%98%B4/</url>
      
        <content type="html"><![CDATA[<h1 id="指令重排-真的有点阴"><a href="#指令重排-真的有点阴" class="headerlink" title="指令重排 真的有点阴"></a>指令重排 真的有点阴</h1><p>在 Java 中，<strong>指令重排（Instruction Reordering）</strong> 是编译器、处理器或内存系统为了提高执行效率而对指令顺序进行的优化。这种优化在单线程环境下是透明的（遵循 <code>as-if-serial</code> 语义），但在多线程环境中可能导致 <strong>可见性</strong> 和 <strong>有序性</strong> 问题。以下是 Java 中可能被指令重排的典型操作和场景，以及对应的解决方案：</p><p>——s</p><h3 id="一、可能被指令重排的操作及场景"><a href="#一、可能被指令重排的操作及场景" class="headerlink" title="一、可能被指令重排的操作及场景"></a><strong>一、可能被指令重排的操作及场景</strong></h3><h4 id="1-普通变量赋值（非-volatile）"><a href="#1-普通变量赋值（非-volatile）" class="headerlink" title="1. 普通变量赋值（非 volatile）"></a><strong>1. 普通变量赋值（非</strong> <code>volatile</code><strong>）</strong></h4><ul><li><strong>场景</strong>：<br>多个线程对同一非 <code>volatile</code> 变量进行读写。</li><li><strong>示例</strong>：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="variable">a</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"><span class="type">boolean</span> <span class="variable">flag</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 线程1</span></span><br><span class="line">a = <span class="number">1</span>;          <span class="comment">// 可能被重排到 flag 赋值之后</span></span><br><span class="line">flag = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 线程2</span></span><br><span class="line"><span class="keyword">if</span> (flag) &#123;</span><br><span class="line">    System.out.println(a); <span class="comment">// 可能输出 0（未观察到 a=1）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>问题</strong>：<br>线程1的 <code>a = 1</code> 和 <code>flag = true</code> 可能被重排，导致线程2看到 <code>flag</code> 为 <code>true</code> 时，<code>a</code> 仍为 0。</li></ul><h4 id="2-对象初始化（非安全发布）"><a href="#2-对象初始化（非安全发布）" class="headerlink" title="2. 对象初始化（非安全发布）"></a><strong>2. 对象初始化（非安全发布）</strong></h4><ul><li><strong>场景</strong>：<br>对象的构造过程中，未正确同步导致部分初始化对象被其他线程访问（如双重检查锁定问题）。</li><li><strong>示例</strong>：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Singleton</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Singleton instance;</span><br><span class="line">    <span class="keyword">private</span> <span class="type">int</span> value;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="title function_">Singleton</span><span class="params">()</span> &#123;</span><br><span class="line">        value = <span class="number">42</span>; <span class="comment">// 初始化操作可能被重排到对象引用赋值之后</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line">        <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;                     <span class="comment">// 第一次检查</span></span><br><span class="line">            <span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">                <span class="keyword">if</span> (instance == <span class="literal">null</span>) &#123;             <span class="comment">// 第二次检查</span></span><br><span class="line">                    instance = <span class="keyword">new</span> <span class="title class_">Singleton</span>();     <span class="comment">// 可能重排：先分配内存，后初始化对象</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> instance;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>问题</strong>：<br>其他线程可能获取到 <code>instance</code> 对象，但其 <code>value</code> 字段尚未初始化（值为默认值 0）。</li></ul><h4 id="3-构造函数中的-this-逸出"><a href="#3-构造函数中的-this-逸出" class="headerlink" title="3. 构造函数中的 this 逸出"></a><strong>3. 构造函数中的</strong> <code>this</code> <strong>逸出</strong></h4><ul><li><strong>场景</strong>：<br>在构造函数中将 <code>this</code> 暴露给其他线程（如注册监听器、启动线程）。</li><li><strong>示例</strong>：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">EventListener</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> id;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">EventListener</span><span class="params">(EventSource source)</span> &#123;</span><br><span class="line">        source.registerListener(() -&gt; System.out.println(id)); <span class="comment">// this 逸出</span></span><br><span class="line">        id = <span class="number">42</span>; <span class="comment">// 可能被重排到注册监听器之后</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>问题</strong>：<br><code>id</code> 的赋值可能被重排到监听器注册之后，导致监听器回调时 <code>id</code> 未被正确初始化。</li></ul><h4 id="4-复合操作（非原子性操作）"><a href="#4-复合操作（非原子性操作）" class="headerlink" title="4. 复合操作（非原子性操作）"></a><strong>4. 复合操作（非原子性操作）</strong></h4><ul><li><strong>场景</strong>：<br>多个变量的读写操作组合在一起，因重排导致逻辑错误。</li><li><strong>示例</strong>：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="variable">x</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> <span class="variable">y</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 线程1</span></span><br><span class="line">x = <span class="number">1</span>;</span><br><span class="line">y = <span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 线程2</span></span><br><span class="line"><span class="keyword">if</span> (y == <span class="number">2</span>) &#123;</span><br><span class="line">    System.out.println(x); <span class="comment">// 可能输出 0（x=1 未被执行或不可见）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li><strong>问题</strong>：<br>线程1的 <code>x = 1</code> 和 <code>y = 2</code> 可能被重排，导致线程2看到 <code>y=2</code> 但 <code>x=0</code>。</li></ul><h4 id="5-数组元素的写入"><a href="#5-数组元素的写入" class="headerlink" title="5. 数组元素的写入"></a><strong>5. 数组元素的写入</strong></h4><ul><li><strong>场景</strong>：<br>多线程访问数组元素时，元素的值和数组长度可能因重排导致不一致。</li><li><strong>示例</strong>：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>[] array = <span class="keyword">new</span> <span class="title class_">int</span>[<span class="number">10</span>];</span><br><span class="line"><span class="type">boolean</span> <span class="variable">initialized</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 线程1</span></span><br><span class="line">array[<span class="number">0</span>] = <span class="number">42</span>;         <span class="comment">// 可能被重排到 initialized=true 之后</span></span><br><span class="line">initialized = <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 线程2</span></span><br><span class="line"><span class="keyword">if</span> (initialized) &#123;</span><br><span class="line">    System.out.println(array[<span class="number">0</span>]); <span class="comment">// 可能输出 0（默认值）</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><hr><h3 id="二、不会被指令重排的操作"><a href="#二、不会被指令重排的操作" class="headerlink" title="二、不会被指令重排的操作"></a><strong>二、不会被指令重排的操作</strong></h3><h4 id="1-volatile-变量的读写"><a href="#1-volatile-变量的读写" class="headerlink" title="1. volatile 变量的读写"></a><strong>1.</strong> <code>volatile</code> <strong>变量的读写</strong></h4><ul><li><p><strong>JMM 保证</strong>：<br><code>volatile</code> 变量的读写会插入内存屏障，禁止重排：  </p></li><li><ul><li><strong>写屏障</strong>：确保 <code>volatile</code> 写之前的操作不会被重排到写之后。  </li><li><strong>读屏障</strong>：确保 <code>volatile</code> 读之后的操作不会被重排到读之前。</li></ul></li></ul><h4 id="2-synchronized-块内的操作"><a href="#2-synchronized-块内的操作" class="headerlink" title="2. synchronized 块内的操作"></a><strong>2.</strong> <code>synchronized</code> <strong>块内的操作</strong></h4><ul><li><strong>锁机制</strong>：<br>锁的获取和释放会插入内存屏障，确保临界区内的操作不会被重排到锁外。</li></ul><h4 id="3-final-字段的初始化"><a href="#3-final-字段的初始化" class="headerlink" title="3. final 字段的初始化"></a><strong>3.</strong> <code>final</code> <strong>字段的初始化</strong></h4><ul><li><strong>JMM 保证</strong>：<br>在构造函数中正确初始化的 <code>final</code> 字段，其赋值对其他线程可见（禁止重排初始化操作）。</li></ul><hr><h3 id="三、解决方案"><a href="#三、解决方案" class="headerlink" title="三、解决方案"></a><strong>三、解决方案</strong></h3><h4 id="1-使用-volatile-关键字"><a href="#1-使用-volatile-关键字" class="headerlink" title="1. 使用 volatile 关键字"></a><strong>1. 使用</strong> <code>volatile</code> <strong>关键字</strong></h4><ul><li><strong>适用场景</strong>：单变量状态标志、一次性发布对象。</li><li><strong>示例</strong>：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">volatile</span> <span class="type">boolean</span> <span class="variable">flag</span> <span class="operator">=</span> <span class="literal">false</span>;</span><br></pre></td></tr></table></figure><h4 id="2-正确同步（锁机制）"><a href="#2-正确同步（锁机制）" class="headerlink" title="2. 正确同步（锁机制）"></a><strong>2. 正确同步（锁机制）</strong></h4><ul><li><strong>适用场景</strong>：复合操作或需要强一致性的共享资源。</li><li><strong>示例</strong>：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">synchronized</span> (lock) &#123;</span><br><span class="line">    a = <span class="number">1</span>;</span><br><span class="line">    flag = <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="3-安全发布不可变对象"><a href="#3-安全发布不可变对象" class="headerlink" title="3. 安全发布不可变对象"></a><strong>3. 安全发布不可变对象</strong></h4><ul><li><strong>适用场景</strong>：对象构造完成后不可变。</li><li><strong>示例</strong>：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ImmutableObject</span> &#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="type">int</span> value;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">ImmutableObject</span><span class="params">(<span class="type">int</span> value)</span> &#123;</span><br><span class="line">        <span class="built_in">this</span>.value = value; <span class="comment">// final 字段的赋值对其他线程可见</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="4-使用线程安全容器"><a href="#4-使用线程安全容器" class="headerlink" title="4. 使用线程安全容器"></a><strong>4. 使用线程安全容器</strong></h4><ul><li><strong>适用场景</strong>：数组或集合的多线程访问。</li><li><strong>示例</strong>：</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CopyOnWriteArrayList&lt;Integer&gt; list = <span class="keyword">new</span> <span class="title class_">CopyOnWriteArrayList</span>&lt;&gt;();</span><br></pre></td></tr></table></figure><hr><h3 id="四、总结"><a href="#四、总结" class="headerlink" title="四、总结"></a><strong>四、总结</strong></h3><table><thead><tr><th><strong>操作&#x2F;场景</strong></th><th><strong>可能被重排</strong></th><th><strong>解决方案</strong></th></tr></thead><tbody><tr><td>普通变量赋值</td><td>✔️</td><td><code>volatile</code> 或同步机制</td></tr><tr><td>非安全发布的对象初始化</td><td>✔️</td><td><code>volatile</code> + 安全构造</td></tr><tr><td>构造函数中的 <code>this</code> 逸出</td><td>✔️</td><td>避免 <code>this</code> 逸出，用 <code>final</code></td></tr><tr><td>复合操作（非原子性）</td><td>✔️</td><td>锁或原子类（如 <code>AtomicInteger</code>）</td></tr><tr><td><code>volatile</code> 变量读写</td><td>✖️</td><td>无需额外处理</td></tr><tr><td><code>synchronized</code> 块内操作</td><td>✖️</td><td>无需额外处理</td></tr><tr><td><code>final</code> 字段初始化</td><td>✖️</td><td>正确初始化 <code>final</code> 字段</td></tr></tbody></table><p><strong>核心原则</strong>：<br>在多线程环境下，<strong>共享变量的访问必须通过同步机制（</strong><code>volatile</code><strong>、锁、原子类等）保证可见性和有序性</strong>，避免指令重排导致逻辑错误。而在单线程或线程封闭场景下，无需关注指令重排。</p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Redis学习笔记</title>
      <link href="/2025/06/07/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
      <url>/2025/06/07/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis学习笔记"><a href="#Redis学习笔记" class="headerlink" title="Redis学习笔记"></a>Redis学习笔记</h1><p> Redis诞生于2009年，作为一个基于内存的键值型NoSQL数据库。其有如下特点</p><ul><li>键值（key-value）型，value支持多种不同数据结构，</li><li>单线程，每个命令具有原子性。不存在很多并发带来的问题。但是此单线程只是指代命令是但线程执行的，其他模块还有各自的线程。6.0版本中引入了多线程，但指代的是 IO多线程，如：网络数据的读写和协议解析时多线程。</li><li>低延迟、速度快（基于内存、IO多路复用、良好的编码）</li><li>支持数据持久化</li><li>支持主从集群、分片集群</li><li>支持多语言客户端</li></ul><h2 id="一、Redis-的安装"><a href="#一、Redis-的安装" class="headerlink" title="一、Redis 的安装"></a>一、Redis 的安装</h2><h3 id="1-1-Redis-安装（window）"><a href="#1-1-Redis-安装（window）" class="headerlink" title="1.1 Redis 安装（window）"></a>1.1 Redis 安装（window）</h3><p>下方提供 Redis 各个版本的下载页面，我这里下载的是 3.2.100 版本。</p><p><a href="https://github.com/microsoftarchive/redis/releases">https://github.com/microsoftarchive/redis/releases</a></p><p>将下载包 解压到本地目录，然后在 redis目录下进行 cmd ，输入不同的命令进行不同的安装方式：</p><ul><li><p>临时服务安装如果你仅仅是用作学习使用，可以选择此安装方式。在 redis目录下 使用cmd 执行以下命令：redis-server.exe  redis.windows.conf该命令会创建 Redis 临时服务，生成的信息表明了 redis 在本机的 6379 端口提供服务。该种方式，不能关闭此 cmd 窗口，如果关闭则会停止 Redis 服务。<img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779113128-ac60fad7-e10e-436c-af9d-67273d4e024e.png" alt="img">保持 Redis 服务窗口开启状态，双击 redis目录下的 redis-cli.exe 即可使用 命令行操控 redis 。比如这里 使用 set 命令，存储了一个键值对 uid：1，然后通过 get 将键 uid 对应的值取出。<img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779113107-4136bd49-5e0e-45b0-b024-f5ac7d019f96.png" alt="img"></p></li><li><p>默认服务安装这种方式不用像临时安装方式一样，每次去打开 redis 临时服务，而且像正常服务一样开机自启。进入 Redis 目录下，通过cmd输入redis-server.exe –service-install redis.windows.conf –loglevel verbose<img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779113047-a2d84234-558c-4ca4-ae91-0564d9534dca.png" alt="img">通过命令行可以发现，我们已经将redis作为服务安装好了。但是你可能不能在window的服务列表中找到，redis服务必须通过命令行启动、暂停和卸载</p></li><li><ul><li>启动服务：redis-server.exe –service-start</li><li>暂停服务redis-server.exe –service-stop</li><li>卸载服务redis-server.exe –service-uninstall</li></ul></li><li><p>自定义服务安装自定义服务安装，就是将服务重命名。进入 Redis 安装包下，输入redis-server.exe –service-install redis.windows.conf –Service-name RedisServer1 –loglevel verbose这里起的名字是 RedisServer1 。与默认安装一样，不同的是在启动、暂停、卸载服务时 需要加上自定义的 Redis 服务名redis-server.exe –service-start –Service-name RedisServer1redis-server.exe –service-stop –Service-name RedisServer1redis-server.exe –service-uninstall –Service-name RedisServer1</p></li><li><p>主从服务安装即像一般的数据库的主从库一样，redis也可以配置主从库。配置的方法很简单，就是通过<strong>自定义服务器安装</strong>方式安装两个服务。<img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779111633-3351c423-c9db-4128-a4d6-3561b5e963a8.png" alt="img">修改两个服务里 redis.windows.conf 文件：主服务器（RedisServer1）：保持其 port 6379从服务器（RedisServer2）：修改</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">port 6380</span><br><span class="line"> slaveof 127.0.0.1 6379</span><br></pre></td></tr></table></figure><p>修改配置文件后，依次启动服务。然后可以在 双击主服务文件夹下的 redis-cli，去执行一个添加键值操作。双击执行 从服务器文件夹下的 redis-cli，去取出键name 对应的值，你就发现可以取到。在 Window 上 直接删除服务的方法：使用管理员权限 打开 cmd ，然后输入sc delete 服务名</p><h3 id="1-2-Redis-安装（docker）"><a href="#1-2-Redis-安装（docker）" class="headerlink" title="1.2 Redis 安装（docker）"></a>1.2 Redis 安装（docker）</h3><ul><li>下拉最新的 redis 镜像，并检查是否下拉成功</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker pull redis:latest</span><br><span class="line">docker images</span><br></pre></td></tr></table></figure><ul><li>运行容器，并映射到宿主机端口docker run -it -d –name redis-test -p 6379:6379 redis</li><li>查看是否运行成功（查看容器运行信息）docker ps</li><li>通过 redis-cli 连接使用 redis 服务</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker exec -it redis-test /bin/bash</span><br><span class="line">redis-cli</span><br></pre></td></tr></table></figure><h3 id="1-3-Redis-配置"><a href="#1-3-Redis-配置" class="headerlink" title="1.3 Redis 配置"></a>1.3 Redis 配置</h3><p>redis.config 常见配置：</p><ul><li>bind 0.0.0.0 监听的地址默认是127.0.0.1，这使得只能本地访问。如果修改成 0.0.0.0 则可以在任意 IP 地址访问。</li><li>daemonize yes守护进程，修改为 yes 之后，即可后台运行</li><li>requirepass 111111密码，设置后访问 Redis 必须输入密码</li><li>port 6379监听的端口，默认就是 6379</li><li>dir .工作目录，默认是当前目录，也就是运行 redis-server 时的命令，日志、持久化等文件都会保存在这个目录</li><li>databases 1数据库数量，设置为1，代表只使用1个库，默认有16个库，编号 0-15</li><li>maxmemory 512mb设置 redis 能够使用的最大内存</li><li>logfile “redis.log”日志文件，默认为空，不记录日志，可以指定日志文件名。</li></ul><p>启动时，指定配置文件 </p><p>redis-server redis.conf</p><h2 id="二、Redis-的基础篇"><a href="#二、Redis-的基础篇" class="headerlink" title="二、Redis 的基础篇"></a>二、Redis 的基础篇</h2><h4 id="2-1-五种基本数据结构"><a href="#2-1-五种基本数据结构" class="headerlink" title="2.1 五种基本数据结构"></a>2.1 五种基本数据结构</h4><p>Redis 共有 5 种基本数据结构：String（字符串）、List（列表）、Set（集合）、Hash（散列）、Zset（有序集合）。</p><p>这 5 种数据结构是直接提供给用户使用的，是数据的保存形式，其底层实现主要依赖这 8 种数据结构：简单动态字符串（SDS）、LinkedList（双向链表）、Hash Table（哈希表）、SkipList（跳跃表）、Intset（整数集合）、ZipList（压缩列表）、QuickList（快速列表）。</p><p>Redis 基本数据结构的底层数据结构实现如下：</p><table><thead><tr><th>String</th><th>List</th><th>Hash</th><th>Set</th><th>Zset</th></tr></thead><tbody><tr><td>SDS</td><td>LinkedList&#x2F;ZipList&#x2F;QuickList</td><td>Hash Table、ZipList</td><td>ZipList、Intset</td><td>ZipList、SkipList</td></tr></tbody></table><p>Redis 3.2 之前，List 底层实现是 LinkedList 或者 ZipList。 Redis 3.2 之后，引入了 LinkedList 和 ZipList 的结合 QuickList，List 的底层实现变为 QuickList。</p><p>你可以在 Redis 官网上找到 Redis 数据结构非常详细的介绍：</p><ul><li><a href="https://redis.com/redis-enterprise/data-structures/">Redis Data Structuresopen in new window</a></li><li><a href="https://redis.io/docs/manual/data-types/data-types-tutorial/">Redis Data types tutorialopen in new window</a></li></ul><p>未来随着 Redis 新版本的发布，可能会有新的数据结构出现，通过查阅 Redis 官网对应的介绍，你总能获取到最靠谱的信息。</p><h5 id="2-1-1-String"><a href="#2-1-1-String" class="headerlink" title="2.1.1 String"></a>2.1.1 String</h5><p>String 是 Redis 中最简单同时也是最常用的一个数据结构。</p><p>String 是一种二进制安全的数据结构，可以用来存储任何类型的数据比如字符串、整数、浮点数、图片（图片的 base64 编码或者解码或者图片的路径）、序列化后的对象。</p><p> 虽然 Redis 是用 C 语言写的，但是 Redis 并没有使用 C 的字符串表示，而是自己构建了一种 <strong>简单动态字符串</strong>（Simple Dynamic String，<strong>SDS</strong>）。相比于 C 的原生字符串，Redis 的 SDS 不光可以保存文本数据还可以保存二进制数据，并且获取字符串长度复杂度为 O(1)（C 字符串为 O(N)）,除此之外，Redis 的 SDS API 是安全的，不会造成缓冲区溢出。</p><h5 id="2-1-2-List"><a href="#2-1-2-List" class="headerlink" title="2.1.2 List"></a>2.1.2 List</h5><p> 许多高级编程语言都内置了链表的实现比如 Java 中的 LinkedList，但是 C 语言并没有实现链表，所以 Redis 实现了自己的链表数据结构。Redis 的 List 的实现为一个 <strong>双向链表</strong>，即可以支持反向查找和遍历，更方便操作，不过带来了部分额外的内存开销。</p><h5 id="2-1-3-Hash"><a href="#2-1-3-Hash" class="headerlink" title="2.1.3 Hash"></a>2.1.3 Hash</h5><p>Redis 中的 Hash 是一个 String 类型的 field-value（键值对） 的映射表，特别适合用于存储对象，后续操作的时候，你可以直接修改这个对象中的某些字段的值。</p><p>Hash 类似于 JDK1.8 前的 HashMap，内部实现也差不多(数组 + 链表)。不过，Redis 的 Hash 做了更多优化。</p><h5 id="2-1-4-Set"><a href="#2-1-4-Set" class="headerlink" title="2.1.4 Set"></a>2.1.4 Set</h5><p>Redis 中的 Set 类型是一种无序集合，集合中的元素没有先后顺序但都唯一，有点类似于 Java 中的 HashSet 。当你需要存储一个列表数据，又不希望出现重复数据时，Set 是一个很好的选择，并且 Set 提供了判断某个元素是否在一个 Set 集合内的重要接口，这个也是 List 所不能提供的。</p><p>你可以基于 Set 轻易实现交集、并集、差集的操作，比如你可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个集合。这样的话，Set 可以非常方便的实现如共同关注、共同粉丝、共同喜好等功能。这个过程也就是求交集的过程。</p><h4 id="2-1-5-SortSet"><a href="#2-1-5-SortSet" class="headerlink" title="2.1.5 SortSet"></a>2.1.5 SortSet</h4><p>Sorted Set 类似于 Set，但和 Set 相比，Sorted Set 增加了一个权重参数 score，使得集合中的元素能够按 score 进行有序排列，还可以通过 score 的范围来获取元素的列表。有点像是 Java 中 HashMap 和 TreeSet 的结合体。</p><h4 id="2-2-三种特殊数据结构"><a href="#2-2-三种特殊数据结构" class="headerlink" title="2.2 三种特殊数据结构"></a>2.2 三种特殊数据结构</h4><h4 id="2-3-Redis命令"><a href="#2-3-Redis命令" class="headerlink" title="2.3 Redis命令"></a>2.3 Redis命令</h4><h5 id="2-1-1-通用命令"><a href="#2-1-1-通用命令" class="headerlink" title="2.1.1 通用命令"></a>2.1.1 通用命令</h5><p>Redis通用指令是不分数据类型的，都可以使用的指令，常见的有：</p><ul><li>KEYS：查看符合模板的所有 key，不建议在生产环境设备上使用</li><li>DEL：删除一个指定的 key</li><li>EXISTS：判断 key 是否存在</li><li>EXPIRE：给一个 key 设置有效期，有效期到期时该 key 自动删除。可 通过 TTL KeyName，查看 key 的剩余有效期</li></ul><p>通过 help [command] 可以查看一个命令的具体用法、</p><p>使用 redis.cli.exe 打开 redis的命令行，实操：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779112046-b5cf96d3-7890-4471-a0ce-0c02c4c4d789.png" alt="img"></p><h5 id="2-1-2-String类型"><a href="#2-1-2-String类型" class="headerlink" title="2.1.2 String类型"></a>2.1.2 String类型</h5><p>String 类型，也就是字符串类型，是 Redis 中最简单的存储类型。其 value 是字符串，不过根据字符串的格式不同，又可以分为3类:</p><ul><li>String：普通字符串</li><li>int：整数类型，可以做自增、自减操作</li><li>float：浮点类型，可以做自增、自减操作，但是必须指定 增减的 值。</li></ul><p>不管何种格式，底层都是字节数组形式存储，只不过是编码方式不同。</p><p>Redis的字符串是动态字符串，是可以修改的字符串，内部结构实现类似于Java的ArrayList，预分配冗余空间的方式来减少内存的频繁分配。字符串长度小于1M，扩容都是加倍现有空间，如果长度大于1M，每次扩容增加1M。字符串类型的最大空间不能超过 512M</p><p>String的常见命令有：</p><ul><li>SET：添加或者修改 已经存在的一个 String 类型的键值对</li><li>GET：根据 key 获取 String 类型的 value</li><li>MSET：批量添加多个 String 类型的键值对</li><li>MGET：根据多个 key 获取多个 String 类型的 value</li><li>INCR：让一个整型的 key 自增 1 </li><li>INCRBY：让一个整型的 key 自增并指定步长，例如：INCRBY num 2，即可让 key &#x3D; num 的值，自增2</li><li>SETNX：添加一个 String 类型的键值对，前提是 这个 key 不存在，否则不执行</li><li>SETEX：添加一个String 类型的键值对，并指定有效期</li></ul><h5 id="2-1-3-Key的层级格式"><a href="#2-1-3-Key的层级格式" class="headerlink" title="2.1.3 Key的层级格式"></a>2.1.3 Key的层级格式</h5><p>Redis没有类似 MySQL 中的 Table 的概念，我们该如何区分不同类型的 key 呢？一般采用将 key 名称进行 分层设计。例如：学生的key，key 以 studen_ 开头。</p><p>Redis 的 key 允许有多个单词组成层级结构，多个单词之间用 “:” 隔开，格式如下：</p><p>项目名:业务名:类型:id</p><p>当然这种格式是可以自己定义的，有些公司是使用 ”__“线间隔。</p><p>如果存储对象是 Java对象，则可将对象转化为 JSON 字符串当作value存储下来。</p><h5 id="2-1-4-Hash类型"><a href="#2-1-4-Hash类型" class="headerlink" title="2.1.4 Hash类型"></a>2.1.4 Hash类型</h5><p>Hash类型，也叫散列，其中value是一个无序字典，类型于 Java 中的 HashMap 结构</p><p>String 结构是将对象序列化为 JSON 字符串后 存储，当需要修改对象某个字段时 很不方便。Hash 结构可以将对象中的每个字段独立存储，可以针对 单个字段 CRUD</p><p>Hash类型常见命令有：</p><ul><li>HSET key field value：添加或者修改 hash类型 key的field 的值</li><li>HGET key field：获取一个 hash 类型 key的field的值</li><li>HMSET：批量添加 多个 hash类型 key的field 的值HMSET student_1 name liming sex 男   &#x2F;&#x2F;为key&#x3D;student_1 的字段 添加属性 name、sex 值分别为 liming、男</li><li>HGETALL：获取一个 hash 类型的key中所有的 field和value</li><li>HKEYS：获取一个 hash 类型的key中所有的 field</li><li>HVALS：获取一个hash 类型的key中所有的 value</li><li>HINCRBY：让一个hash类型 key 的字段值自增，并指定步长</li><li>HSETNX：添加一个 hash 类型的 key 的 field值，前提时 这个 field 不存在，否则不执行</li></ul><p>底层原理：</p><p>Java的HashMap在字典很大时，rehash是个耗时操作，需要一次性全部rehash。Redis为了高性能，不能堵塞服务，就采用了渐进式rehash策略</p><p>渐进式rehash：在rehash的同时，保留新旧两个hash结构，查询时会同时查询两个hash结构，然后再后续的定时任务中以及hash的子指令中，循序渐进地将旧hash的内容一点点迁移到新的hash结构中。</p><h5 id="2-1-4-List类型"><a href="#2-1-4-List类型" class="headerlink" title="2.1.4 List类型"></a>2.1.4 List类型</h5><p>Redis中的 List 类型与 Java 中的LinkedList 类似，可以看做是一个双向链表结构。既可以支持正向检索，也支持反向检索。特点也和LinkedList类似：</p><ul><li>有序</li><li>元素可以重复</li><li>插入和删除快</li><li>查询速度一般</li></ul><p>List的常见命令：</p><ul><li>LPUSH key element ：像列表左侧插入一个或多个元素</li><li>LPOP key ：移除并返回列表左侧的第一个元素，没有则返回nil</li><li>RPUSH key element：向列表右侧插入一个或多个元素</li><li>RPOP key：移除并返回列表右侧第一个元素</li><li>LRANGE key start end：返回一段角标范围内的所有元素</li><li>BLPOP和BRPOP：与LPOP、RPOP类似，只不过在没有元素时等待指定时间，而不是直接返回nil</li><li>lindex key index：lindex 相当于 Java 链表的 get(index) 方法，它需要对链表进行遍历。其性能随着参数index增大而变差。</li><li>ltrim key startIndex endIndex：使用startIndex 、endIndex定义了一个区间，保留着区间内的值，区间外统统去除。这样可以实现一个定长的链表。index可以为负数，-1表示倒数第一个元素，-2表示倒数第二个元素。</li></ul><p>应用场景：常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进Redis的列表，另一个线程从这个列表中轮询数据进行处理。通过控制，右边进左边出，可以实现队列。通过控制，右边进右边出，可以实现栈。</p><p>原理：Redis列表底层存储不是一个简单的 linkedlist，而是成为快速列表quicklist的一个结构。首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是压缩列表ziplist。它将所有的元素紧紧挨在一起存储，分配的是一块连续的内存。当数据量比较多时，才会改成 quicklist。因为普通的链表需要的附件指针空间太大，会比较浪费空间，而且加重内存的碎片化。所以Redis将 多个 ziplist使用双向指针串起来使用。这样既满足了快速的插入删除性能，有不会出现太大的空间冗余。</p><h5 id="2-1-5-Set类型"><a href="#2-1-5-Set类型" class="headerlink" title="2.1.5 Set类型"></a>2.1.5 Set类型</h5><p>Redis的Set结构与 Java 中的HashSet类似，可以看做是一个 value 为 null 的 HashMap。因为也是一个 hash 表，因此具备与 HashSet类似的特征</p><ul><li>无序</li><li>元素不可重复</li><li>查找快</li><li>支持交集、并集、差集等功能</li></ul><p>Set常见命令：</p><ul><li>SADD key member：向set中添加一个或多个元素</li><li>SREM key member：移除set中指定的元素</li><li>SCARD key：返回set中元素的个数</li><li>SISMEMBER key member：判断一个元素是否存在于 set 中</li><li>SMEMBERS：获取 set 中的所有元素</li><li>SINTER key1 key2 ：求 key1 与 key2 的交集</li><li>SDIFF key1 key2：求 key1 与 key2 的差集 </li><li>SUNION key1 key2 ：求 key1 与 key2 的并集</li></ul><h5 id="2-1-6-SortedSet类型"><a href="#2-1-6-SortedSet类型" class="headerlink" title="2.1.6 SortedSet类型"></a>2.1.6 SortedSet类型</h5><p>Redis 的 SortedSet 是一个可排序的 set 集合，与 Java 中的 TreeSet 有些类似，但底层数据结构却差别很大。SortedSet 中的每个元素都带有一个 score 属性，可以基于 score 属性对 元素排序，底层的实现是一个跳表（SkipList）加hash表。</p><p>SortedSet具备下列特性：</p><ul><li>可排序</li><li>元素不重复</li><li>查询速度快</li></ul><p>因为 SortedSet 的可排序特性，经常被用来实现排行榜这样的功能。</p><p>SortedSet的常见命令有：</p><ul><li>ZADD key score member：添加一个或多个元素到 SortedSet，如果已经存在则更新其 score 值</li><li>ZREM key member：删除 SortedSet中的一个指定元素</li><li>ZSCORE key member：获取 SortedSet 中的指定元素的 score 值</li><li>ZRANK key member：获取 SortedSet 中的指定元素的排名</li><li>ZCAED key：获取 SortedSet 中的元素个数</li><li>ZCOUNT key min max：统计 score 值在给定范围内的所有元素的个数</li><li>ZINCRBY key increment member：让 SortedSet中的指定元素自增，步长为指定的increment值</li><li>ZRANGE key min max：按照 score 排序后，获取指定 score 范围内的元素</li><li>ZRANGEBYSCORE key min max：按照 score 排序后，获取指定 score 范围内的元素</li><li>ZDIFF、ZINTER、ZUNION：求差集、交集、并集</li></ul><p>注意：所有的排名默认都是 升序，如果要降序则在命令的Z后面添加REV即可</p><h4 id="2-2-Redis客户端"><a href="#2-2-Redis客户端" class="headerlink" title="2.2 Redis客户端"></a>2.2 Redis客户端</h4><p>Redis的客户端主要有</p><ul><li>Jedis：以Redis命令作为方法名称，学习成本低，简单实用。但是Jedis实例是线程不安全的，多线程情况下需要基于连接池实用</li><li>Lettuce：基于Netty实现的，支持同步、异步和响应式编程方式，并且是线程安全的。支持Redis的哨兵模式、集群模式和管道模式。</li><li>Redisson：是一个基于Redis实现的分布式、可伸缩的 Java 数据结构集合。包含了诸如 Map、Queue、Lock、Semaphore、AtomicLong等强大功能。</li></ul><p>而 SpringData Redis 集成了 Jedis、Lettuce</p><h5 id="2-2-1-Jedis-客户端"><a href="#2-2-1-Jedis-客户端" class="headerlink" title="2.2.1 Jedis 客户端"></a>2.2.1 Jedis 客户端</h5><p><a href="https://github.com/kongxiaoran/redisDemo">https://github.com/kongxiaoran/redisDemo</a></p><p>可以下拉该项目的 Jedis 分支，该分支已经 实现了 springboot 整合 jedis 。可以下拉看看</p><p>Jedis本身是线程不安全的，并且频繁的创建和销毁连接会有性能损耗，因此我们推荐大家使用 Jedis 连接池代替 Jedis 的直连方式。</p><h5 id="2-2-2-SpringDataRedis"><a href="#2-2-2-SpringDataRedis" class="headerlink" title="2.2.2 SpringDataRedis"></a>2.2.2 SpringDataRedis</h5><p>SpringData 是 Spring 中数据操作的模块，包含对各种数据库的集成，其中对 Redis 的集成模块就叫做 SpringDataRedis，官网地址：</p><ul><li>提供了对不同 Redis 客户端的整合（Lettuce、Jedis）</li><li>提供了 RedisTemplate 统一 API 来操作</li><li>支持 Redis 的发布订阅模型</li><li>支持 Redis 哨兵和 Redis 集群</li><li>支持基于 Lettuce 的响应式编程</li><li>支持基于 JDK、JSON、字符串、Spring对象的数据序列化及反序列化</li><li>支持基于 Redistribution的 JDK Collection实现</li></ul><h4 id="2-3-SpringDataRedis-客户端使用"><a href="#2-3-SpringDataRedis-客户端使用" class="headerlink" title="2.3 SpringDataRedis 客户端使用"></a>2.3 SpringDataRedis 客户端使用</h4><p>SpringDataRedis 提供了 RedisTemplate 工具类，其中封装了各种对 Redis 的操作。并且将不同数据类型的操作API 封装到了不同类型中：</p><table><thead><tr><th><strong>API</strong></th><th><strong>返回值类型</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>redisTemplate.opsForValue()</td><td>ValueOperations</td><td>操作 String 类型数据</td></tr><tr><td>redisTemplate.opsForHash()</td><td>HashOperations</td><td>操作 Hash 类型数据</td></tr><tr><td>redisTemplate.opsForList()</td><td>ListIOperations</td><td>操作 List 类型数据</td></tr><tr><td>redisTemplate.opsForSet()</td><td>SetOperations</td><td>操作 Set 类型数据</td></tr><tr><td>redisTemplate.opsForZSet()</td><td>ZSetOperations</td><td>操作 SortedSet 类型数据</td></tr><tr><td>redisTemplate</td><td></td><td>通用命令</td></tr></tbody></table><p><a href="https://github.com/kongxiaoran/redisDemo">https://github.com/kongxiaoran/redisDemo</a></p><p>该项目的 master 分支，使用 SpringBoot 整合了 SpringDataRedis，可以自行下拉运行。</p><h5 id="2-3-1-SpringDataRedis-的默认序列化"><a href="#2-3-1-SpringDataRedis-的默认序列化" class="headerlink" title="2.3.1 SpringDataRedis 的默认序列化"></a>2.3.1 SpringDataRedis 的默认序列化</h5><p>RedisTemplate 可以接收任意 Object 作为值 写入 Redis，只不过写入 前会把 Object 序列化为字节形式，默认是采用 JDK 序列化。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">redisTemplate.opsForValue().set(&quot;springboot&quot;,&quot;你好呀，springboot&quot;);   </span><br><span class="line">String springboot = (String) redisTemplate.opsForValue().get(&quot;springboot&quot;);</span><br><span class="line">System.out.println(springboot);</span><br></pre></td></tr></table></figure><p>得到的结果是这样的：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779112780-bf2ddbf3-24a4-47aa-b14d-5ba839abecdd.png" alt="img"></p><p>缺点很明显：</p><ul><li>可读性差</li><li>内存占用较大</li></ul><p>这是因为什么呢？查看 RedisTemplate 类，可以知道 当没有特别配置 key、value、hashKey 的 序列化策略时，</p><p>RedisTemplate 会选择使用 JDK序列化器（JdkSerializationRedisSerializer)，而此序列化器是不是适合字符串的序列化的。所以如果你的 key 通常是用 字符串格式，那么可以考虑 在序列化key时，采用其他序列化器。比如：String</p><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779116223-bc409176-9ef0-4441-87c3-073ae4c8bc51.png" alt="img"></p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779116227-ff9eae7b-6954-4282-91dc-cd89ac3f5cd8.png" alt="img"></p><h5 id="2-3-2-SpringDataRedis-提供的序列化器"><a href="#2-3-2-SpringDataRedis-提供的序列化器" class="headerlink" title="2.3.2 SpringDataRedis 提供的序列化器"></a>2.3.2 SpringDataRedis 提供的序列化器</h5><p>查看 RedisSerializer 的实现，可以看到有 7 种序列化器：</p><ul><li><p>ByteArrayRedisSerializer：字节数组序列化</p></li><li><p>GenericJackson2JsonRedisSerializer：同 FastJsonRedisSerializer 类似，而 FastJsonRedisSerializer 是由阿里巴巴FastJson包提供。具有：1. 速度快 2. 兼容性强 3. 占用内存小</p></li><li><ul><li>底层使用Jackson进行序列化并存入Redis。对于普通类型(如数值类型，字符</li><li>存入对象时由于没有存入类信息，则无法反序列化。</li></ul></li><li><p>GenericToStringSerializer：同StringRedisSerializer一样，但它可以将任何对象泛化为字符串并序列化。注意事项：GenericToStringSerializer需要调用者给传一个对象到字符串互转的Converter，使用起来其比较麻烦，所以不太推荐使用。</p></li><li><p>Jackson2JsonRedisSerializer：将对象序列化为json字符串</p></li><li><ul><li>·优点：速度快、序列化后的字符串短小精悍、不需要实现 Serializable</li><li>缺点：必须要提供要序列化对象的类型信息（.class对象）</li></ul></li><li><p>JdkSerializationRedisSerializer：使用Java自带的序列化机制将对象序列化为一个字符串。</p></li><li><ul><li>优点在于：通用性强、反序列化时不需要提供类型信息。、</li><li>缺点在于：序列化速度慢、序列化内存占用大、序列化对象必须实现 Serializable 接口、可读性差</li></ul></li><li><p>OxmSerializer：将对象序列化为xml字符串。以 xml 格式存储（但还是String类型），解析起来比较复杂，且占用空间大</p></li><li><p>StringRedisSerializer：StringRedisTemplate默认的序列化器。</p></li><li><ul><li>优点：可读性强、不需要转换</li><li>缺点：只能对字符串序列化，不能对 对象 序列化</li></ul></li></ul><h5 id="2-3-3-自定义序列化器"><a href="#2-3-3-自定义序列化器" class="headerlink" title="2.3.3 自定义序列化器"></a>2.3.3 自定义序列化器</h5><p>所以我们可以针对自己的需要，自定义 RedisTemplate，来实现对不同 key、value 使用不同的序列化器</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">@Bean</span><br><span class="line">public RedisTemplate&lt;String,Object&gt; redisTemplate(RedisConnectionFactory redisConnectionFactory)</span><br><span class="line">    throws UnknownHostException&#123;</span><br><span class="line"></span><br><span class="line">    // 创建 Template</span><br><span class="line">    RedisTemplate&lt;String,Object&gt; redisTemplate = new RedisTemplate&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    // 设置连接工厂</span><br><span class="line">    redisTemplate.setConnectionFactory(redisConnectionFactory);</span><br><span class="line"></span><br><span class="line">    // 设置序列化工具</span><br><span class="line">    GenericJackson2JsonRedisSerializer jackson2JsonRedisSerializer =</span><br><span class="line">    new GenericJackson2JsonRedisSerializer();</span><br><span class="line"></span><br><span class="line">    // key 和 hashKey 采用 String序列化</span><br><span class="line">    redisTemplate.setKeySerializer(RedisSerializer.string());</span><br><span class="line">    redisTemplate.setHashKeySerializer(RedisSerializer.string());</span><br><span class="line"></span><br><span class="line">    // value 和 hashValue 采用 JOSN序列化</span><br><span class="line">    redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);</span><br><span class="line">    redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer);</span><br><span class="line"></span><br><span class="line">    return redisTemplate;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-3-4-使用自定义序列化器存储对象"><a href="#2-3-4-使用自定义序列化器存储对象" class="headerlink" title="2.3.4 使用自定义序列化器存储对象"></a>2.3.4 使用自定义序列化器存储对象</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void testEmployee()&#123;</span><br><span class="line">    Employee employee = new Employee(3,&quot;羽&quot;,&quot;28235x02x7&quot;,1,1);</span><br><span class="line">    // 写入数据</span><br><span class="line">    redisTemplate.opsForValue().set(&quot;user_3&quot;,employee);</span><br><span class="line"></span><br><span class="line">    // 获取数据</span><br><span class="line">    Employee getEmployee = (Employee) redisTemplate.opsForValue().get(&quot;user_3&quot;);</span><br><span class="line">    System.out.println(getEmployee.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779116323-2e3c4c31-c032-4f95-985f-2c0da0eb6c51.png" alt="img"></p><p>由图可以知道，该序列化器在序列化对象，也会将 对象的字节码名称写入。这样在我们反序列化时知道对象的类型，从而反序列化成对应对象。</p><h5 id="2-3-5-使用StringRedisTemplate存储JSON对象"><a href="#2-3-5-使用StringRedisTemplate存储JSON对象" class="headerlink" title="2.3.5 使用StringRedisTemplate存储JSON对象"></a>2.3.5 使用StringRedisTemplate存储JSON对象</h5><p>但是这一个存在一个问题，JSON序列化器将类的class类型写入了 JSON结果中，存入了 Redis ，会带来额外的内存开销。为了节省内存空间，我们并不会使用 JSON 序列化器来处理 value，而是统一使用 String 序列化器，要求只能存储 String 类型的 key 和 value。当需要存储 Java 对象时，<strong>手动完成对象的序列化和反序列化</strong>。</p><p>所以还是建议手动完成对象的序列化：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void testEmployeeStringRedisTemplate()&#123;</span><br><span class="line">    Employee employee = new Employee(3,&quot;羽&quot;,&quot;2823x302x7&quot;,1,1);</span><br><span class="line">    // 写入数据 （这里使用的时 fastJson2进行序列化）</span><br><span class="line">    stringRedisTemplate.opsForValue().set(&quot;user_4&quot;, JSON.toJSONString(employee));</span><br><span class="line">    // 获取数据</span><br><span class="line">    Employee getEmployee = JSON.parseObject(stringRedisTemplate.opsForValue().get(&quot;user_4&quot;), Employee.class);</span><br><span class="line">    System.out.println(getEmployee.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h5 id="2-3-6-RedisTemplate-操作-Hash-类型"><a href="#2-3-6-RedisTemplate-操作-Hash-类型" class="headerlink" title="2.3.6 RedisTemplate 操作 Hash 类型"></a>2.3.6 RedisTemplate 操作 Hash 类型</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">@Test</span><br><span class="line">public void testHash()&#123;</span><br><span class="line">    stringRedisTemplate.opsForHash().put(&quot;xiucheng&quot;,&quot;user1&quot;,&quot;凌霄&quot;);</span><br><span class="line">    stringRedisTemplate.opsForHash().put(&quot;xiucheng&quot;,&quot;user2&quot;,&quot;羽&quot;);</span><br><span class="line"></span><br><span class="line">    Map&lt;Object, Object&gt; xiucheng = stringRedisTemplate.opsForHash().entries(&quot;xiucheng&quot;);</span><br><span class="line">    System.out.println(xiucheng.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="三、Redis-实战"><a href="#三、Redis-实战" class="headerlink" title="三、Redis 实战"></a>三、Redis 实战</h2><h3 id="3-1-Redis与MySQL双写一致性如何保证？"><a href="#3-1-Redis与MySQL双写一致性如何保证？" class="headerlink" title="3.1 Redis与MySQL双写一致性如何保证？"></a>3.1 Redis与MySQL双写一致性如何保证？</h3><h4 id="3-1-1-一致性"><a href="#3-1-1-一致性" class="headerlink" title="3.1.1 一致性"></a>3.1.1 一致性</h4><p>一致性就是数据保持一致，在分布式系统中，可以理解为多个节点中数据的值是一致的。</p><ul><li><strong>强一致性</strong>：这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大</li><li><strong>弱一致性</strong>：这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态</li><li><strong>最终一致性</strong>：最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型</li></ul><h4 id="3-1-2-三种经典的缓存模式"><a href="#3-1-2-三种经典的缓存模式" class="headerlink" title="3.1.2 三种经典的缓存模式"></a>3.1.2 三种经典的缓存模式</h4><p>缓存可以提升性能、缓解数据库压力，但是使用缓存也会导致数据<strong>不一致性</strong>的问题。一般我们是如何使用缓存呢？有三种经典的缓存模式：</p><ul><li><strong>Cache-Aside Pattern</strong>Cache-Aside Pattern，即<strong>旁路缓存模式</strong>，它的提出是为了尽可能地解决缓存与数据库的数据不一致问题。读：写：更新的时候，先<strong>更新数据库，然后再删除缓存</strong>。</li></ul><ol><li><ol><li>读的时候，先读缓存，缓存命中的话，直接返回数据</li><li>缓存没有命中的话，就去读数据库，从数据库取出数据，放入缓存后，同时返回响应。</li></ol></li></ol><ul><li><strong>Read-Through&#x2F;Write through</strong>Read&#x2F;Write Through模式中，服务端把缓存作为主要数据存储。应用程序跟数据库缓存交互，都是通过<strong>抽象缓存层</strong>完成的。读：<img src="https://cdn.nlark.com/yuque/0/2023/webp/35838370/1682779116373-baeadbf7-a12c-4bb1-9fae-bff4afb23d3b.webp" alt="img">这个简要流程是不是跟<strong>Cache-Aside</strong>很像呢？其实<strong>Read-Through</strong>就是多了一层<strong>Cache-Provider</strong>。写：当发生写请求时，也是由<strong>缓存抽象层</strong>完成数据源和缓存数据的更新：先更新数据源，再更新缓存。</li></ul><ol><li><ol><li>从缓存读取数据，读到直接返回</li><li>如果读取不到的话，从数据库加载，写入缓存后，再返回响应。</li></ol></li></ol><ul><li><strong>Write behind****Write behind</strong>跟<strong>Read-Through&#x2F;Write-Through</strong>有相似的地方，都是由Cache Provider来负责缓存和数据库的读写。它两又有个很大的不同：<strong>Read&#x2F;Write Through</strong>是同步更新缓存和数据的，<strong>Write Behind</strong>则是只更新缓存，不直接更新数据库，通过<strong>批量异步</strong>的方式来更新数据库。这种方式下，缓存和数据库的一致性不强，<strong>对一致性要求高的系统要谨慎使用</strong>。但是它适合频繁写的场景，MySQL的<strong>InnoDB Buffer Pool机制</strong>就使用到这种模式。</li></ul><h4 id="3-1-3-操作缓存的时候，删除缓存呢，还是更新缓存？"><a href="#3-1-3-操作缓存的时候，删除缓存呢，还是更新缓存？" class="headerlink" title="3.1.3 操作缓存的时候，删除缓存呢，还是更新缓存？"></a>3.1.3 操作缓存的时候，删除缓存呢，还是更新缓存？</h4><p>一般业务场景，我们使用的就是<strong>Cache-Aside</strong>模式。 有些小伙伴可能会问， <strong>Cache-Aside</strong>在写入请求的时候，为什么是<strong>删除缓存而不是更新缓存</strong>呢？我们在操作缓存的时候，到底应该删除缓存还是更新缓存呢？我们先来看个例子：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/webp/35838370/1682779116395-a6501b26-db7f-4d05-87f6-60706161333e.webp" alt="img"></p><ol><li>线程A先发起一个写操作，第一步先更新数据库</li><li>线程B再发起一个写操作，第二步更新了数据库</li><li>由于网络等原因，线程B先更新了缓存</li><li>线程A后更新缓存。</li></ol><p>这时候，缓存保存的是A的数据（老数据），数据库保存的是B的数据（新数据），数据<strong>不一致</strong>了，脏数据出现啦。如果是<strong>删除缓存取代更新缓存</strong>则不会出现这个脏数据问题。</p><p><strong>更新缓存相对于删除缓存</strong>，还有两点劣势：</p><ul><li>如果你写入的缓存值，是经过复杂计算才得到的话。更新缓存频率高的话，就浪费性能啦。</li><li>在写数据库场景多，读数据场景少的情况下，数据很多时候还没被读取到，又被更新了，这也浪费了性能呢(实际上，写多的场景，用缓存也不是很划算了)</li></ul><h4 id="3-1-3-双写的情况下，先操作数据库还是先操作缓存？"><a href="#3-1-3-双写的情况下，先操作数据库还是先操作缓存？" class="headerlink" title="3.1.3 双写的情况下，先操作数据库还是先操作缓存？"></a>3.1.3 双写的情况下，先操作数据库还是先操作缓存？</h4><p>Cache-Aside缓存模式中，有些小伙伴还是有疑问，在写入请求的时候，为什么是<strong>先操作数据库呢</strong>？为什么<strong>不先操作缓存</strong>呢？</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779117654-0e13d67f-a1bb-47ad-93a2-85dc01b9fa12.webp" alt="img"></p><ol><li>线程A发起一个写操作，第一步del cache</li><li>此时线程B发起一个读操作，cache miss</li><li>线程B继续读DB，读出来一个老数据</li><li>然后线程B把老数据设置入cache</li><li>线程A写入DB最新的数据</li></ol><p>酱紫就有问题啦，<strong>缓存和数据库的数据不一致了。缓存保存的是老数据，数据库保存的是新数据</strong>。因此，Cache-Aside 缓存模式，选择了先操作数据库而不是先操作缓存。</p><h4 id="3-1-4-缓存延时双删"><a href="#3-1-4-缓存延时双删" class="headerlink" title="3.1.4 缓存延时双删"></a>3.1.4 缓存延时双删</h4><p>有些小伙伴可能会说，不一定要先操作数据库呀，采用<strong>缓存延时双删</strong>策略就好啦？什么是延时双删呢？</p><ol><li>先删除缓存</li><li>再更新数据库</li><li>休眠一会（比如1秒），再次删除缓存。</li></ol><p>这个休眠一会，一般多久呢？都是1秒？</p><p>这个休眠时间 &#x3D; 读业务逻辑数据的耗时 + 几百毫秒。 为了确保读请求结束，写请求可以删除读请求可能带来的缓存脏数据。</p><h4 id="3-1-5-删除缓存重试机制"><a href="#3-1-5-删除缓存重试机制" class="headerlink" title="3.1.5 删除缓存重试机制"></a>3.1.5 删除缓存重试机制</h4><p>不管是<strong>延时双删</strong>还是<strong>Cache-Aside的先操作数据库再删除缓存</strong>，如果第二步的删除缓存失败呢，删除失败会导致脏数据哦~</p><p><img src="https://cdn.nlark.com/yuque/0/2023/webp/35838370/1682779117889-0a62c399-8c30-4227-9a71-ef940b73fba0.webp" alt="img"></p><p>删除缓存重试机制，会造成很多业务代码入侵。其实也可以通过 数据库的CDC 来异步淘汰 Key。</p><p>所以我们需要一些重试机制，确保 redis key 被删除了</p><h5 id="队列-重试机制"><a href="#队列-重试机制" class="headerlink" title="队列+重试机制"></a>队列+重试机制</h5><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779118664-a9c22f28-ced6-4e2d-a840-99031155209e.png" alt="img"></p><p>流程如下所示</p><ul><li>更新数据库数据</li><li>缓存因为种种问题删除失败</li><li>将需要删除的key发送至消息队列</li><li>自己消费消息，获得需要删除的key</li><li>继续重试删除操作，直到成功</li></ul><p>然而，该方案有一个缺点，对业务线代码造成大量的侵入。于是有了方案二，在方案二中，启动一个订阅程序去订阅数据库的binlog，获得需要操作的数据。在应用程序中，另起一段程序，获得这个订阅程序传来的信息，进行删除缓存操作。</p><h5 id="基于订阅binlog的同步机制"><a href="#基于订阅binlog的同步机制" class="headerlink" title="基于订阅binlog的同步机制"></a>基于订阅binlog的同步机制</h5><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779118663-d1ce53ca-9fdb-4552-89cc-0f3b181677a5.png" alt="img"><strong>技术整体思路</strong>：</p><p>MySQL binlog增量订阅消费+消息队列+增量数据更新到redis</p><p>1）读Redis：热数据基本都在Redis</p><p>2）写MySQL: 增删改都是操作MySQL</p><p>3）更新Redis数据：MySQ的数据操作binlog，来更新到Redis</p><p><strong>Redis更新</strong></p><p>1）<strong>数据操作</strong>主要分为两大块：</p><ul><li>一个是全量(将全部数据一次写入到redis)</li><li>一个是增量（实时更新）</li></ul><p>这里说的是增量,指的是mysql的update、insert、delate变更数据。</p><p>2）<strong>读取binlog后分析 ，利用消息队列,推送更新各台的redis缓存数据</strong>。</p><p>这样一旦MySQL中产生了新的写入、更新、删除等操作，就可以把binlog相关的消息推送至Redis，Redis再根据binlog中的记录，对Redis进行更新。</p><p>其实这种机制，很类似MySQL的主从备份机制，因为MySQL的主备也是通过binlog来实现的数据一致性。</p><p>这里可以结合使用canal(阿里的一款开源框架)，通过该框架可以对MySQL的binlog进行订阅，而canal正是模仿了mysql的slave数据库的备份请求，使得Redis的数据更新达到了相同的效果。</p><p>当然，这里的消息推送工具你也可以采用别的第三方：kafka、rabbitMQ等来实现推送更新Redis。</p><h3 id="3-2-缓存雪崩、穿透、击穿、污染"><a href="#3-2-缓存雪崩、穿透、击穿、污染" class="headerlink" title="3.2 缓存雪崩、穿透、击穿、污染"></a>3.2 缓存雪崩、穿透、击穿、污染</h3><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1683633583708-42a49740-34d1-42e6-a6e8-8489be91fc87.png" alt="img"></p><h4 id="3-2-1-缓存雪崩"><a href="#3-2-1-缓存雪崩" class="headerlink" title="3.2.1 缓存雪崩"></a>3.2.1 缓存雪崩</h4><p>对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，但是缓存机器意外发生了全盘宕机。缓存挂了，此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后就挂了。此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被新的流量给打死了。或者缓存中 数据大批量到过期时间，大批量数据同时查询数据库，引起数据库压力过大甚至宕机。</p><p>这就是缓存雪崩。</p><p><a href="https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/redis-caching-avalanche.png"><img src="https://github.com/doocs/advanced-java/raw/main/docs/high-concurrency/images/redis-caching-avalanche.png" alt="img"></a></p><p>大约在 3 年前，国内比较知名的一个互联网公司，曾因为缓存事故，导致雪崩，后台系统全部崩溃，事故从当天下午持续到晚上凌晨 3~4 点，公司损失了几千万。</p><p>缓存雪崩的事前事中事后的解决方案如下：</p><ul><li>事前：Redis 高可用，主从+哨兵，Redis cluster，避免全盘崩溃。</li><li>事中：本地 ehcache 缓存 + hystrix 限流&amp;降级，避免 MySQL 被打死。</li><li>事后：Redis 持久化，一旦重启，自动从磁盘上加载数据，快速恢复缓存数据。</li></ul><p>除此之外实际使用时：</p><ul><li>缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。</li><li>如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。</li><li>热点数据的过期时间尽量设置长</li></ul><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/redis-caching-avalanche-solution.png" alt="img"></p><p>用户发送一个请求，系统 A 收到请求后，先查本地 ehcache 缓存，如果没查到再查 Redis。如果 ehcache 和 Redis 都没有，再查数据库，将数据库中的结果，写入 ehcache 和 Redis 中。</p><p>限流组件，可以设置每秒的请求，有多少能通过组件，剩余的未通过的请求，怎么办？<strong>走降级</strong>！可以返回一些默认的值，或者友情提示，或者空值。</p><p>好处：</p><ul><li>数据库绝对不会死，限流组件确保了每秒只有多少个请求能通过。</li><li>只要数据库不死，就是说，对用户来说，2&#x2F;5 的请求都是可以被处理的。</li><li>只要有 2&#x2F;5 的请求可以被处理，就意味着你的系统没死，对用户来说，可能就是点击几次刷不出来页面，但是多点几次，就可以刷出来了。</li></ul><h4 id="3-2-2-缓存穿透"><a href="#3-2-2-缓存穿透" class="headerlink" title="3.2.2 缓存穿透"></a>3.2.2 缓存穿透</h4><p>对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。</p><p>黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。</p><p>举个栗子。数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。这样的话，缓存中不会有，请求每次都“<strong>视缓存于无物</strong>”，直接查询数据库。这种恶意攻击场景的缓存穿透就会直接把数据库给打死。</p><p><a href="https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/redis-caching-penetration.png"><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/redis-caching-penetration.png" alt="img"></a></p><p>解决方案：</p><ul><li>设置空值解决方式很简单，每次系统 A 从数据库中只要没查到，就写一个空值到缓存里去，比如 set -999 UNKNOWN 。然后设置一个过期时间，这样的话，下次有相同的 key 来访问的时候，在缓存失效之前，都可以直接从缓存中取数据。</li></ul><p><a href="https://github.com/doocs/advanced-java/blob/main/docs/high-concurrency/images/redis-caching-avoid-penetration.png"><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/redis-caching-avoid-penetration.png" alt="img"></a></p><ul><li><p>布隆过滤器。当然，如果黑客如果每次使用不同的负数 id 来攻击，写空值的方法可能就不奏效了。更为经常的做法是在缓存之前增加布隆过滤器，将数据库中所有可能的数据哈希映射到布隆过滤器中。然后对每个请求进行如下判断：使用布隆过滤器能够对访问的请求起到了一定的初筛作用，避免了因数据不存在引起的查询压力。</p></li><li><ul><li>请求数据的 key 不存在于布隆过滤器中，可以确定数据就一定不会存在于数据库中，系统可以立即返回不存在。</li><li>请求数据的 key 存在于布隆过滤器中，则继续再向缓存中查询。</li></ul></li><li><p>Key校验对所有可能查询的参数以hash形式存储，在控制层先进行校验，不符合则丢弃。</p></li></ul><h4 id="3-2-3-缓存击穿"><a href="#3-2-3-缓存击穿" class="headerlink" title="3.2.3 缓存击穿"></a>3.2.3 缓存击穿</h4><p>缓存击穿，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一个洞。</p><p>不同场景下的解决方式可如下：</p><ul><li>若缓存的数据是基本不会发生更新的，则可尝试将该热点数据设置为永不过期。</li><li>若缓存的数据更新不频繁，且缓存刷新的整个流程耗时较少的情况下，则可以采用基于 Redis、zookeeper 等分布式中间件的分布式互斥锁，或者本地互斥锁以保证仅少量的请求能请求数据库并重新构建缓存，其余线程则在锁释放后能访问到新缓存。在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。</li><li>若缓存的数据更新频繁或者在缓存刷新的流程耗时较长的情况下，可以利用定时线程在缓存过期前主动地重新构建缓存或者延后缓存的过期时间，以保证所有的请求能一直访问到对应的缓存。</li></ul><h4 id="3-2-4-缓存污染"><a href="#3-2-4-缓存污染" class="headerlink" title="3.2.4 缓存污染"></a>3.2.4 缓存污染</h4><p>缓存污染问题说的是缓存中一些只会被访问一次或者几次的的数据，被访问完后，再也不会被访问到，但这部分数据依然留存在缓存中，消耗缓存空间。</p><p>缓存污染会随着数据的持续增加而逐渐显露，随着服务的不断运行，缓存中会存在大量的永远不会再次被访问的数据。缓存空间是有限的，如果缓存空间满了，再往缓存里写数据时就会有额外开销，影响Redis性能。这部分额外开销主要是指写的时候判断淘汰策略，根据淘汰策略去选择要淘汰的数据，然后进行删除操作。</p><h5 id="缓存淘汰策略"><a href="#缓存淘汰策略" class="headerlink" title="缓存淘汰策略"></a>缓存淘汰策略</h5><p>Redis共支持八种淘汰策略，分别是noeviction、volatile-random、volatile-ttl、volatile-lru、volatile-lfu、allkeys-lru、allkeys-random 和 allkeys-lfu 策略。</p><p><strong>怎么理解呢</strong>？主要看分三类看：</p><ul><li><p>不淘汰 </p></li><li><ul><li>noeviction （v4.0后默认的）</li></ul></li><li><p>对设置了过期时间的数据中进行淘汰 </p></li><li><ul><li>随机：volatile-random</li><li>ttl：volatile-ttl</li><li>lru：volatile-lru</li><li>lfu：volatile-lfu</li></ul></li><li><p>全部数据进行淘汰 </p></li><li><ul><li>随机：allkeys-random</li><li>lru：allkeys-lru</li><li>lfu：allkeys-lfu</li></ul></li></ul><ol><li>noeviction该策略是Redis的默认策略。在这种策略下，一旦缓存被写满了，再有写请求来时，Redis 不再提供服务，而是直接返回错误。这种策略不会淘汰数据，所以无法解决缓存污染问题。一般生产环境不建议使用。其他七种规则都会根据自己相应的规则来选择数据进行删除操作。</li><li>volatile-random。这个算法比较简单，在设置了过期时间的键值对中，进行随机删除。因为是随机删除，无法把不再访问的数据筛选出来，所以可能依然会存在缓存污染现象，无法解决缓存污染问题。</li><li>volatile-ttl。这种算法判断淘汰数据时参考的指标比随机删除时多进行一步过期时间的排序。Redis在筛选需删除的数据时，越早过期的数据越优先被选择。</li><li>volatile-lru。LRU算法：LRU 算法的全称是 Least Recently Used，按照最近最少使用的原则来筛选数据。这种模式下会使用 LRU 算法筛选设置了过期时间的键值对。Redis优化的 <strong>LRU算法实现</strong>：Redis会记录每个数据的最近一次被访问的时间戳。在Redis在决定淘汰的数据时，第一次会随机选出 N 个数据，把它们作为一个候选集合。接下来，Redis 会比较这 N 个数据的 lru 字段，把 lru 字段值最小的数据从缓存中淘汰出去。通过随机读取待删除集合，可以让Redis不用维护一个巨大的链表，也不用操作链表，进而提升性能。Redis 选出的数据个数 N，通过 配置参数 maxmemory-samples 进行配置。个数N越大，则候选集合越大，选择到的最久未被使用的就更准确，N越小，选择到最久未被使用的数据的概率也会随之减小。</li><li>volatile-lfu。会使用 LFU 算法选择设置了过期时间的键值对。<strong>LFU 算法</strong>：LFU 缓存策略是在 LRU 策略基础上，为每个数据增加了一个计数器，来统计这个数据的访问次数。当使用 LFU 策略筛选淘汰数据时，首先会根据数据的访问次数进行筛选，把访问次数最低的数据淘汰出缓存。如果两个数据的访问次数相同，LFU 策略再比较这两个数据的访问时效性，把距离上一次访问时间更久的数据淘汰出缓存。 Redis的LFU算法实现:当 LFU 策略筛选数据时，Redis 会在候选集合中，根据数据 lru 字段的后 8bit 选择访问次数最少的数据进行淘汰。当访问次数相同时，再根据 lru 字段的前 16bit 值大小，选择访问时间最久远的数据进行淘汰。Redis 只使用了 8bit 记录数据的访问次数，而 8bit 记录的最大值是 255，这样在访问快速的情况下，如果每次被访问就将访问次数加一，很快某条数据就达到最大值255，可能很多数据都是255，那么退化成LRU算法了。所以Redis为了解决这个问题，实现了一个更优的计数规则，并可以通过配置项，来控制计数器增加的速度。<strong>参数</strong> ：lfu-log-factor ，用计数器当前的值乘以配置项 lfu_log_factor 再加 1，再取其倒数，得到一个 p 值；然后，把这个 p 值和一个取值范围在（0，1）间的随机数 r 值比大小，只有 p 值大于 r 值时，计数器才加 1。lfu-decay-time， 控制访问次数衰减。LFU 策略会计算当前时间和数据最近一次访问时间的差值，并把这个差值换算成以分钟为单位。然后，LFU 策略再把这个差值除以 lfu_decay_time 值，所得的结果就是数据 counter 要衰减的值。lfu-log-factor设置越大，递增概率越低，lfu-decay-time设置越大，衰减速度会越慢。我们在应用 LFU 策略时，一般可以将 lfu_log_factor 取值为 10。 如果业务应用中有短时高频访问的数据的话，建议把 lfu_decay_time 值设置为 1。可以快速衰减访问次数。volatile-lfu 策略是 Redis 4.0 后新增。</li><li><strong>allkeys-lru</strong>使用 LRU 算法在所有数据中进行筛选。具体LFU算法跟上述 volatile-lru 中介绍的一致，只是筛选的数据范围是全部缓存，这里就不在重复。</li><li>allkeys-random从所有键值对中随机选择并删除数据。volatile-random 跟 allkeys-random算法一样，随机删除就无法解决缓存污染问题。</li><li>allkeys-lfu使用 LFU 算法在所有数据中进行筛选。具体LFU算法跟上述 volatile-lfu 中介绍的一致，只是筛选的数据范围是全部缓存，这里就不在重复。</li></ol><p>allkeys-lfu 策略是 Redis 4.0 后新增。</p><h3 id="3-3-I-O多路复用"><a href="#3-3-I-O多路复用" class="headerlink" title="3.3 I&#x2F;O多路复用"></a>3.3 I&#x2F;O多路复用</h3><h4 id="3-3-1-有哪几种I-O模型"><a href="#3-3-1-有哪几种I-O模型" class="headerlink" title="3.3.1 有哪几种I&#x2F;O模型"></a>3.3.1 有哪几种I&#x2F;O模型</h4><p>为什么 Redis 中要使用 I&#x2F;O 多路复用这种技术呢？</p><p>首先，Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I&#x2F;O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I&#x2F;O 阻塞导致整个进程无法对其它客户提供服务，而 <strong>I&#x2F;O 多路复用</strong>就是为了解决这个问题而出现的。</p><ul><li><strong>Blocking I&#x2F;O。</strong>先来看一下传统的阻塞 I&#x2F;O 模型到底是如何工作的：当使用 read 或者 write 对某一个**文件描述符（File Descriptor 以下简称 FD)**进行读写时，如果当前 FD 不可读或不可写，整个 Redis 服务就不会对其它的操作作出响应，导致整个服务不可用。这也就是传统意义上的，也就是我们在编程中使用最多的阻塞模型。但是由于它会影响其他 FD 对应的服务，所以需要处理多个客户端任务的时候，往往都不会使用阻塞模型。</li><li><strong>I&#x2F;O多路复用。</strong>阻塞式的 I&#x2F;O 模型并不能满足这里的需求，我们需要一种效率更高的 I&#x2F;O 模型来支撑 Redis 的多个客户（redis-cli），这里涉及的就是 I&#x2F;O 多路复用模型了。在 I&#x2F;O 多路复用模型中，最重要的函数调用就是 select，该方法的能够同时监控多个文件描述符的可读可写情况，当其中的某些文件描述符可读或者可写时，select 方法就会返回可读以及可写的文件描述符个数。与此同时也有其它的 I&#x2F;O 多路复用函数 epoll&#x2F;kqueue&#x2F;evport，它们相比 select 性能更优秀，同时也能支撑更多的服务。</li></ul><h4 id="3-3-2-Reactor设计模式"><a href="#3-3-2-Reactor设计模式" class="headerlink" title="3.3.2 Reactor设计模式"></a>3.3.2 Reactor设计模式</h4><p>Redis 服务采用 Reactor 的方式来实现文件事件处理器（每一个网络连接其实都对应一个文件描述符）</p><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779118964-d5b2cf6f-b475-4166-bbc7-fcdb1c5a8759.png" alt="img"></p><p>文件事件处理器使用 I&#x2F;O 多路复用模块同时监听多个 FD，当 accept、read、write 和 close 文件事件产生时，文件事件处理器就会回调 FD 绑定的事件处理器。</p><p>虽然整个文件事件处理器是在单线程上运行的，但是通过 I&#x2F;O 多路复用模块的引入，实现了同时对多个 FD 读写的监控，提高了网络通信模型的性能，同时也可以保证整个 Redis 服务实现的简单。</p><h4 id="3-3-3-I-O多路复用模块"><a href="#3-3-3-I-O多路复用模块" class="headerlink" title="3.3.3 I&#x2F;O多路复用模块"></a>3.3.3 I&#x2F;O多路复用模块</h4><p>I&#x2F;O 多路复用模块封装了底层的 select、epoll、avport 以及 kqueue 这些 I&#x2F;O 多路复用函数，为上层提供了相同的接口。</p><p>因为 Redis 需要在多个平台上运行，同时为了最大化执行的效率与性能，所以会根据编译平台的不同选择不同的 I&#x2F;O 多路复用函数作为子模块，提供给上层统一的接口；在 Redis 中，我们通过宏定义的使用，合理的选择不同的子模块。</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779120227-db19f80f-4483-408b-8c31-bf41394af344.jpeg" alt="img"></p><p>Redis 会优先选择时间复杂度为 O(1) 的 I&#x2F;O 多路复用函数作为底层实现，包括 Solaries 10 中的 evport、Linux 中的 epoll 和 macOS&#x2F;FreeBSD 中的 kqueue，上述的这些函数都使用了内核内部的结构，并且能够服务几十万的文件描述符。</p><p>但是如果当前编译环境没有上述函数，就会选择 select 作为备选方案，由于其在使用时会扫描全部监听的描述符，所以其时间复杂度较差 O(n)O(n)，并且只能同时服务 1024 个文件描述符，所以一般并不会以 select 作为第一方案使用。</p><h3 id="3-4-脑裂问题"><a href="#3-4-脑裂问题" class="headerlink" title="3.4 脑裂问题"></a>3.4 脑裂问题</h3><p>如果在 Redis 中，形式上就是有了两个 master，记住了两个 master 才是脑裂的前提</p><h4 id="3-4-1-哨兵模式下的脑裂"><a href="#3-4-1-哨兵模式下的脑裂" class="headerlink" title="3.4.1 哨兵模式下的脑裂"></a>3.4.1 哨兵模式下的脑裂</h4><p>1个 master 与 3个 slave组成的哨兵模式（哨兵独立部署于其他节点）。两个客户端 server1、server2 都连接上了 master。但是如果 master 与 slave 及哨兵之间 网络发生了故障，但是哨兵与slave之间通讯正常，这时3个slave其中1个经过哨兵投票后，提升为新master。如果恰好此时 server1 仍然连接的是旧的master，而server2连接到了新的master。</p><p>数据就不一致了，基于 setNX 指令的分布式锁，可能会拿到相同的锁；基于 incr 生成的全局唯一 id，也可能出现重复。</p><h4 id="3-4-2-cluster-模式下的脑裂"><a href="#3-4-2-cluster-模式下的脑裂" class="headerlink" title="3.4.2 cluster 模式下的脑裂"></a>3.4.2 cluster 模式下的脑裂</h4><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779121684-93b3e741-7f57-49e9-b067-ea538dd0980b.png" alt="img"></p><p>cluster 模式下，这种情况要更复杂，例如集群中有 6 组分片，每给分片节点都有 1 主 1 从，如果出现网络分区时，各种节点之间的分区组合都有可能。</p><h5 id="手动解决问题"><a href="#手动解决问题" class="headerlink" title="手动解决问题"></a>手动解决问题</h5><p>在正常情况下，如果 master 挂了，那么写入就会失败，如果是手动解决，那么人为会检测 master 以及 slave 的网络状况，然后视情况，如果是 master 挂了，重启 master，如果是 master 与 slave 之间的连接断了，可以调试网络，这样虽然麻烦，但是是可以保证只有一个 master 的，所以只要认真负责，不会出现脑裂。</p><h5 id="自动解决问题"><a href="#自动解决问题" class="headerlink" title="自动解决问题"></a>自动解决问题</h5><p>Redis 中有一个哨兵机制，哨兵机制的作用就是通过 redis 哨兵来检测 redis 服务的状态，如果一旦发现 master 挂了，就在 slave 中选举新的 master 节点以实现故障自动转移。</p><h5 id="如何避免脑裂"><a href="#如何避免脑裂" class="headerlink" title="如何避免脑裂"></a>如何避免脑裂</h5><p>合理设置 min-slaves-to-write、min-slaves-max-lag两个参数</p><ul><li>第一个参数标识连接到 master 的最少 slave 数量</li><li>第二个参数标识 slave连接到 master 的最大延迟时间</li></ul><p>问题，就出现在这个自动故障转移上，如果是哨兵和 slave 同时与 master 断了联系，即哨兵可以监测到 slave，但是监测不到 master，而 master 虽然连接不上 slave 和哨兵，但是还是在正常运行，这样如果哨兵因为监测不到 master，认为它挂了，会在 slave 中选举新的 master，而有一部分应用仍然与旧的 master 交互。当旧的 master 与新的 master 重新建立连接，旧的 master 会同步新的 master 中的数据，而旧的 master 中的数据就会丢失。所以我认为 redis 脑裂就是自动故障转移造成的。</p><h3 id="3-4-搭建哨兵集群"><a href="#3-4-搭建哨兵集群" class="headerlink" title="3.4 搭建哨兵集群"></a>3.4 搭建哨兵集群</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line">[root@VM-4-9-centos ~]# docker run -it -d --name redis3 -p 6378:6378 redis</span><br><span class="line">1d3ab7315ac93a217136fe0fb0837104ca4e5500b0671d2acb989f92ecd8e38b</span><br><span class="line">[root@VM-4-9-centos ~]#  docker inspect -f &#x27;&#123;&#123;.Name&#125;&#125; - &#123;&#123;.NetworkSettings.IPAddress &#125;&#125;&#x27; $(docker ps -aq)</span><br><span class="line">/redis3 - 172.17.0.6</span><br><span class="line">/redis2 - 172.17.0.5</span><br><span class="line">/redis1 - 172.17.0.4</span><br><span class="line">[root@VM-4-9-centos ~]# docker exec -it redis3 /bin/bash</span><br><span class="line">root@1d3ab7315ac9:/data# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; replicaof 172.17.0.4 6379</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">&quot;kongxr&quot;</span><br><span class="line"># https://segmentfault.com/a/1190000040755506</span><br><span class="line">#1.新建一个文件： docker-compose.yml 内容如下：</span><br><span class="line">version: &#x27;3.7&#x27;</span><br><span class="line">services:</span><br><span class="line">  sentinel1:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: redis-sentinel-1</span><br><span class="line">    restart: always</span><br><span class="line">    ports:</span><br><span class="line">      - 26379:26379</span><br><span class="line">    command: redis-sentinel /usr/local/etc/redis/sentinel.conf</span><br><span class="line">    volumes:</span><br><span class="line">      - ./sentinel1.conf:/usr/local/etc/redis/sentinel.conf</span><br><span class="line">  sentinel2:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: redis-sentinel-2</span><br><span class="line">    restart: always</span><br><span class="line">    ports:</span><br><span class="line">    - 26380:26379</span><br><span class="line">    command: redis-sentinel /usr/local/etc/redis/sentinel.conf</span><br><span class="line">    volumes:</span><br><span class="line">      - ./sentinel2.conf:/usr/local/etc/redis/sentinel.conf</span><br><span class="line">  sentinel3:</span><br><span class="line">    image: redis</span><br><span class="line">    container_name: redis-sentinel-3</span><br><span class="line">    ports:</span><br><span class="line">      - 26381:26379</span><br><span class="line">    command: redis-sentinel /usr/local/etc/redis/sentinel.conf</span><br><span class="line">    volumes:</span><br><span class="line">      - ./sentinel3.conf:/usr/local/etc/redis/sentinel.conf</span><br><span class="line">      </span><br><span class="line">#2.分别新建三个文件： sentinel1.conf、sentinel2.conf、sentinel1.conf 内容都如下：</span><br><span class="line"># 自定义集群名，其中172.17.0.4 为 redis-master 的 ip，6380 为 redis-master 的端口，2 为最小投票数（因为有 3 台 Sentinel 所以可以设置成 2）</span><br><span class="line"></span><br><span class="line">port 26379</span><br><span class="line">dir /tmp</span><br><span class="line">sentinel monitor mymaster 172.17.0.4 6380 2</span><br><span class="line">sentinel down-after-milliseconds mymaster 30000</span><br><span class="line">sentinel parallel-syncs mymaster 1</span><br><span class="line">sentinel auth-pass mymaster redispwd</span><br><span class="line">sentinel failover-timeout mymaster 180000</span><br><span class="line">sentinel deny-scripts-reconfig yes</span><br><span class="line"></span><br><span class="line">#3.四个文件都放在同义目录下，并使用命令</span><br><span class="line">[root@VM-4-9-centos redis-sentinel]# docker-compose up -d</span><br><span class="line">Creating network &quot;redis-sentinel_default&quot; with the default driver</span><br><span class="line">Creating redis-sentinel-1 ... done</span><br><span class="line">Creating redis-sentinel-3 ... done</span><br><span class="line">Creating redis-sentinel-2 ... done</span><br><span class="line"></span><br><span class="line">#4.测试：进入redis1 发现，当前redis为主节点。然后将该redis关闭。</span><br><span class="line">[root@VM-4-9-centos redis-sentinel]#  docker exec -it redis1 /bin/bash</span><br><span class="line">root@f21ca2cacfea:/data# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; info replication</span><br><span class="line"># Replication</span><br><span class="line">role:master</span><br><span class="line">[root@VM-4-9-centos redis-sentinel]# docker stop redis1</span><br><span class="line">redis1</span><br></pre></td></tr></table></figure><h2 id="四、Redis应用"><a href="#四、Redis应用" class="headerlink" title="四、Redis应用"></a>四、Redis应用</h2><h3 id="4-1-分布式锁"><a href="#4-1-分布式锁" class="headerlink" title="4.1 分布式锁"></a>4.1 分布式锁</h3><p>分布式锁本质上要实现的目标就是在 Redis 里面占一个茅坑，当别的进程也要进来占时，发现已经有人蹲在那里了，就只好放弃或者稍后再试。</p><p>占坑一般是使用 setnx 指令，只允许被一个客户端占坑。先来先占，用完了，再调用 del 指令释放茅坑。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt; setnx lock01 true</span><br><span class="line">OK</span><br><span class="line">... do something critical ...</span><br><span class="line">&gt;del lock01</span><br><span class="line">(integer)1</span><br></pre></td></tr></table></figure><p>但是如果 逻辑执行到中间 出现异常了，可能会导致 del 指令没有被调用，这样就会陷入死锁，锁永远得不得释放。于是我们在拿到锁之后，再给锁加上一个过期时间，比如5s，这样即使中间出现异常也可以保证5s之后锁会自动释放。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt; setnx lock01 true</span><br><span class="line">OK</span><br><span class="line">&gt;expire lock01 5</span><br><span class="line">... do something critical</span><br><span class="line">&gt;del lock01</span><br><span class="line">(integer)1</span><br></pre></td></tr></table></figure><p>但是以上逻辑还是有问题，因为如果在 setnx 和 expire 之间服务器进程突然挂掉了，就会导致 expire 得不到执行，也会造成死锁。</p><p>这种问题的根源在于 setnex 和 expire 是两条指令而不是原子指令。如果这两条指令可以一起执行就不会出现问题。这里也不可以使用Redis事务来解决。因为 expire 是依赖于 setnx 的执行结果的，如果 setnx 没抢到锁，expire 是不应该执行的。事务里没有 if-else 分支逻辑，事务的特点是一口气执行，要么全部执行要么一个都不执行。</p><p>为了解决这个问题，Redis开源社区涌现出很大分布式锁的library，专门用来解决这个问题，其实现方式极为复杂。如果需要使用分布式锁，不能仅仅使用 Jedis 或者 redis-py 就行了，还得引入分布式锁的 library。为了治理这个乱象，Redis2.8版本中 加入了 set 指令的扩展参数，是的 setnx 和 expire 可以一起执行，彻底解决了分布式锁的乱象。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; set lock01 true ex 5 nx</span><br><span class="line">OK</span><br><span class="line">&gt; del lock01</span><br></pre></td></tr></table></figure><p>Redis 的分布式锁不能解决超时问题，如果在加锁和释放之间的逻辑执行的太长，以至于超出了锁的超时限制，就会出现问题。因为这时候锁过期了，第二个线程重新持有了这把锁，但是紧接着第一个线程执行完了业务逻辑，就把锁给释放了，第三个线程就会在第二个线程执行完之前就拿到了锁。</p><p>为了避免这个问题，Redis 分布式锁不要用于较长时间的任务。如果真的偶尔出现了，数据出现小波错乱可能需要人工介入解决</p><p>有一个更安全的方案是为 set 指令的 value 参数设置为 一个随机数，释放锁时先匹配随机数是否一致，然后再删除 key。但是匹配 value 和删除 key 不是一个原子操作，Redis也没有提供类似于 delifequals 这样的指令，这就需要使用 Lua 脚本来处理了，因为 Lua 脚本可以保证连续多个指令的原子性执行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># delifequals</span><br><span class="line">if redis.call(&quot;get&quot;,KEYS[1])==ARGV[1] then return redis.call(&quot;del&quot;,KEYS[1]) else return 0 end</span><br></pre></td></tr></table></figure><p>可重入性</p><p>可重入性就是指 线程在持有锁的情况下再次请求加锁，如果一个锁支持同一个线程的多次加锁，那么这个锁就是可重入的。Redis分布式锁如果需要支持可重入，需要对客户端的 set 方法进行包装，使用线程的 Threadlocal 变量存储当前持有锁的计数。</p><h3 id="4-2-延时队列"><a href="#4-2-延时队列" class="headerlink" title="4.2 延时队列"></a>4.2 延时队列</h3><p>平时习惯使用 RabbitMQ和Kafka作为消息队列中间件，来给应用程序之间增加异步消息传递功能。这个两个中间件都是专业的消息队列中间件，其能力很强，但是使用起来也较为繁琐。Redis的消息队列实现很简单，但是并不是专业的消息队列，它没有非常多的高级特性，没有ack保证，如果对消息的可靠性有着极致的追求，那么它就不适合使用。</p><h4 id="4-2-1-异步消息队列"><a href="#4-2-1-异步消息队列" class="headerlink" title="4.2.1 异步消息队列"></a>4.2.1 异步消息队列</h4><p>Redis 的 list（列表）数据结构 常用来作为异步消息队列使用，使用 rpush&#x2F;lpush 操作入队列，使用 lpop 和 rpop 来出队列。</p><p>客户端是通过队列的 pop 操作来获取消息，然后进行处理。处理完了再接着获取消息，再进行处理，如此往复。</p><p>如果队列空了，客户端就会陷入 pop 的死循环，不停地 pop。这就是浪费生命的空循环。空轮询不但拉高了客户端的CPU，redis的QPS也会被拉高，如果这样空轮询的客户端有几十来个，Redis 的慢查询可能会显著增多。</p><p>通常使用 sleep 来解决这个问题，让线程休眠一会。但是这样会造成消费者的延迟。可以有更好的解决方案：使用 blpop、brpop，前缀字符b代表的就是 blocking，即堵塞读。堵塞读在队列没有数据的时候，会立即进行休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为0。这个方案有个弊端，就是注意空连接问题。因为线程一直堵塞在那，Redis的客户端连接就成了闲置连接，闲置过久，服务器一般就会主动断开连接，减少闲置资源的占用。这时 blpop、brpop 会抛出异常。所以在 编写客户端消费者时，注意捕获异常和重试。</p><h4 id="4-2-2-延迟队列的实现"><a href="#4-2-2-延迟队列的实现" class="headerlink" title="4.2.2 延迟队列的实现"></a>4.2.2 延迟队列的实现</h4><p>上一节提及的 分布式锁。当客户端在处理请求时 加锁没加成功 怎么办。一般是有 3种 策略来处理加锁失败：</p><ul><li>直接抛出异常，通知用户稍后重试。</li><li>sleep，一会再重试。这种方式，会堵塞当前的消息处理线程，导致队列的后续消息处理出现延迟。如果碰撞出现较多或者队列里的消息较多，sleep 可能并不合适。因为个别 死锁的key 导致加锁不成功，线程会彻底堵死，导致后续消息永远得不到及时处理。</li><li>将请求转移到延迟队列，过会再试。这种方式较好。</li></ul><p>延时队列可以通过 Redis的 zset(有序列表)来实现。我们将消息序列化成一个字符串作为 zset 的 value，这个消息的到期处理时间作为 score，然后用多个线程轮询 zset 获取到期的任务进行处理，多个线程是为了保障可用性，万一挂了一个线程还有其他线程可以继续处理。因为有多个线程，所以需要考虑并发争抢任务，确保任务不能被多次执行。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">def delay(msg):</span><br><span class="line">msg.id = str(uuid.uuid4())</span><br><span class="line">value = json.dumps(msg)</span><br><span class="line">retry_ts = time.time() + 5</span><br><span class="line">redis.zadd(&quot;delay-queue&quot;,retry_ts,value)</span><br><span class="line">def loop():</span><br><span class="line">while True:</span><br><span class="line">values = redis.zrangebyscore(&quot;delay-queue&quot;,0,time.time(),start=0,num=1)</span><br><span class="line">if not values:</span><br><span class="line">time.sleep(1)#延迟队列是空当，休息1s</span><br><span class="line">continue</span><br><span class="line">value = value[0]</span><br><span class="line">success = redis.zrem(&quot;delay-queue&quot;,value)</span><br><span class="line">if success:</span><br><span class="line">msg = json.loads(value)</span><br><span class="line">handle_msg(msg)</span><br></pre></td></tr></table></figure><p>Redis 的 zrem 方法是多线程多进程抢任务的关键，它的返回值决定了当前实例有没有抢到任务，因为loop方法可能被多个线程、多个进程调用，同一任务可能会被多个进程线程抢到，通过 zrem 来决定唯一的属主。同时注意对 handle_msg 进行异常捕获。</p><p>上述方案还是存在明显缺点：1.原子性问题：先查询再删除 这两个操作不是原子的，明显会出现并发问题，虽然我这里判断了 zrem 的数量，但是可能会出现部分 key 被其他机器给消费的情况；2.性能问题：zrangebyscore还好，但是如果在时间间隔内产生了大量消息，如果同时处理，zrem 的性能会急剧下降。</p><p>性能问题解决：</p><ul><li>多线程并发消费</li><li>将定时任务的启动延迟时间或者每次循环的时间随机，让每台机器处理消息点有一定间隔，这样单次时间间隔内要处理的消息的数据会大大减少。</li><li>zrangebyscore 命令设置 limit，限制单次处理消息的数据</li></ul><p>原子性问题解决：</p><p>使用Lua脚本 解决zrangebyscore 和 zrem 不是原子化操作的问题。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">local key = KEYS[1]</span><br><span class="line">local min = ARGV[1]</span><br><span class="line">local max = ARGV[2]</span><br><span class="line">local result = redis.call(&#x27;zrangebyscore&#x27;,key,min,max,&#x27;LIMIT&#x27;,0,10)</span><br><span class="line">if next(result) ~= nil and #result &gt; 0 then</span><br><span class="line">local re = redis.call(&#x27;zrem&#x27;,key,unpack(reslut));</span><br><span class="line">if(re &gt; 0) then</span><br><span class="line">return result;</span><br><span class="line">end</span><br><span class="line">else</span><br><span class="line">return &#123;&#125;</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h3 id="4-3-位图"><a href="#4-3-位图" class="headerlink" title="4.3 位图"></a>4.3 位图</h3><p>在平时开发过程中，会有一些bool型数据需要存取，比如用户一年的签到记录，签了是1，没签是0，要记录365天。如果使用普通的 key&#x2F;value，每个用户要记录 365个，当用户上亿时，需要的存储空间是惊人的。</p><p>位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是 byte 数组。我们可以使用普通的 get&#x2F;set 直接获取和设置整个位图的内容，也可以使用 位图操作 getbit&#x2F;setbit 等 将byte数组看成 位数组 来处理。</p><p>Redis 的位数组是自动扩展，如果设置了某个偏移位置超过了现有的内容范围，就会自动将位数组进行零扩充。</p><h4 id="4-3-1-基本使用"><a href="#4-3-1-基本使用" class="headerlink" title="4.3.1 基本使用"></a>4.3.1 基本使用</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">&gt; setbit bitArray01 1 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 2 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 4 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 9 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 10 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 13 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; setbit bitArray01 15 1</span><br><span class="line">(integer)0</span><br><span class="line">&gt; get bitArray01</span><br><span class="line">&quot;he&quot;</span><br></pre></td></tr></table></figure><p>上面的例子，可以理解为 零存整取，同样也可以 零存零取，整存整取。零存：就是使用 setbit 对位值 进行逐个设置。整存：就是使用字符串一次性填充所有位数组，覆盖掉旧值。</p><h4 id="4-3-2-统计和查找"><a href="#4-3-2-统计和查找" class="headerlink" title="4.3.2 统计和查找"></a>4.3.2 统计和查找</h4><p>Redis 提供了位图统计指令 bitcount 和位图查找指令 bitpos，bitcount 用来统计指定位置范围内 1 的个数，bitops 用来查找指定范围内出现的第一个 0或1。</p><p>遗憾的是，start 和 end 参数是 字节索引，也就是说指定的位范围必须是 8的倍数，而不能任意指定。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">set w hello# 整存</span><br><span class="line">bitcount w 0 0 # 第一个字符中1的位数</span><br><span class="line">bitcount w 0 1 # 前两个字符中1的位数</span><br><span class="line">bitops w 0 # 第一个零位</span><br><span class="line">bitops w 1 0 1 2 # 第二到第三字符中 第一个出现1的位置</span><br></pre></td></tr></table></figure><h4 id="4-3-3-魔术指令-bitfield"><a href="#4-3-3-魔术指令-bitfield" class="headerlink" title="4.3.3 魔术指令 bitfield"></a>4.3.3 魔术指令 bitfield</h4><p>之前我们设置或者获取 指定位的值 都是单个位的，如果要一次操作多个位，就必须要使用管道来处理。Redis3.2之后，新增命令 bitfield 可以使用。其下有三个子指令分别是 get&#x2F;set&#x2F;incrby，它们都可以对指定位片段进行读写，但是最多只能处理64个连续的位，如果超过64位，就得使用多个子指令，bitfield 可以一次执行多个子指令。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">set w hello</span><br><span class="line">bitfield w get u4 0 # 从第一位开始取4个位，取出结果为无符号数（u）</span><br><span class="line">bitfield w get i3 2 # 从第三位开始取3个位，取出结果为有符号数（i）</span><br><span class="line">bitfield w get u4 0 get i3 2 # 可以一次执行多个子指令</span><br><span class="line">bitfield w et u8 8 97 #从第8个位开始，将接下来的8个位 用无符号数97 替换</span><br></pre></td></tr></table></figure><p>所谓有符号数是指 取出来的位数组中第一个位是当作符号位，剩下的才是值。如果第一位是1，那就是负数。无符号数表示非负数，没有符号位，获取到位数组全部都是值。有符号数 最多可以获取64位，无符号数 只能获取63位。</p><p>第三个指令 incrby，它用来对指定范围的位进行自增操作。既然提到了自增，就有可能出现溢出。如果增加了正数，会出现上溢。如果增加负数，会出现下溢出。如果出现溢出，就将溢出的符号位丢掉。如果是8位无符号数255，加1就变成 0。</p><h3 id="4-4-HyperLogLog"><a href="#4-4-HyperLogLog" class="headerlink" title="4.4 HyperLogLog"></a>4.4 HyperLogLog</h3><p>HyperLogLog提供的是一个不精确但是节省空间的去重计数方案：如果页面访问量非常大，比如一个爆款页面几千万的 UV，就需要一个很大的 Set集合 来统计，这就非常浪费空间。如果这样的页面很多，那所需要的存储空间是惊人的。如果对统计精确度不需要太精确，就可以使用HyperLogLog，它的标准误差是0.81%。</p><h4 id="4-4-1-使用方法"><a href="#4-4-1-使用方法" class="headerlink" title="4.4.1 使用方法"></a>4.4.1 使用方法</h4><p>HyperLogLog 提供了两个指令 pfadd 和 pfcount，一个是增加计数，一个是获取计数。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&gt; pfadd w user1</span><br><span class="line">(integer)1</span><br><span class="line">&gt; pcount w</span><br><span class="line">(integer)1</span><br></pre></td></tr></table></figure><p>除了上面两个指令，还有一个 pfmerge，用于将多个 pf 计数值累计在一起形成一个新的 pf 值。</p><h4 id="4-4-2-数学原理"><a href="#4-4-2-数学原理" class="headerlink" title="4.4.2 数学原理"></a>4.4.2 数学原理</h4><p><strong>极大似然估计的直观理解</strong></p><p>其使用的数学原理是统计学中的极大似然估计。接下去我将用多个场景逐步深入解析。<br><strong>场景1：</strong>现在有2个不透明的口袋，其中都装有100个球，A口袋中是99个白球1个黑球，B口袋中是99个黑球1个白球。当我们随机挑选一个口袋，然后从中拿出一个球。如果拿出的球是白色的，那么我们可以说“大概率”我们取出的是A口袋。这种直觉的推测其实就包含了“极大似然估计”的思想。</p><p><strong>场景2：</strong>我们只保留A口袋，其中99个白球，1个黑球。很容易我们就可以得出结论，从中取出任意一个球，是白球的概率为99%，是黑球的概率为1%。这是一种<strong>正向的推测</strong>：<br><em>我们知道了</em>**<em>条件（99个白球，1个黑球）*<em><strong>，从而推测出</strong></em></em>结果（取出任意一个球，是白球的概率为99%）***。<br>但这只是理论上的推测，如果实际取球100次，每次都放回，那么取出黑球的次数并不一定是1次，可能是0次，也可能超过1次。我们取球的次数越多，实际情况将越符合理论情况。</p><p><strong>场景3：</strong>还是A口袋，只不过此时其中白球和黑球的数量我们并不知晓。于是我们开始从中拿球，每拿出一个球都记录下结果，并将其放回。如果我们取球100次，其中99次是白球，1次是黑球，我们可以说A口袋中可能是99个白球，但并不能非常肯定。当我们取球10000次的时候，其中9900次是白球，100次是黑球，此时我们就可以大概率确定A口袋中是99个白球，而这种确定程度随着我们实际取球次数的增加也将不断增加。这就是一种<strong>反向的推测</strong>：<br><em>我们观察了</em>**<em>结果（取10000次球，9900次是白球，100次是黑球）*<em><strong>，可以推测出</strong></em></em>条件（A口袋中放了99个白球，1个黑球）***。<br>当然这种推测的结果并非是准确的，而是一种大概率的估计。<br>无论是正向推测或是反向推测，只有当实际执行操作的次数足够多的时候，才能使得实际情况更接近理论推测。这就非常符合hyperloglog的特点，只有当数据量足够大的时候，误差才会足够小。</p><p>因此极大似然估计的本质就是：当能观察的结果数量足够多时，我们就可以大概率确定产生相应结果所需要的条件的状态。这种通过大量结果反向估计条件的数学方法就是极大似然估计。</p><p><strong>伯努利实验与极大似然估计</strong></p><p>了解极大似然估计之后，我们就需要引入第二个数学概念，伯努利实验。<br>不要被这个名字唬住，伯努利实验其实就是扔硬币，接下去我们就来了解下这枚硬币要怎么扔。下文所说的硬币都是最普通的硬币，只有正反两面，且每一面朝上的概率都是50%。<br><strong>场景1：</strong>我们随机扔一次硬币，那么得到正面或反面的可能性是相同的。如果我们扔10000次硬币，那么可以估计到大概率是接近5000次正面，5000次反面。这是最简单的正向推测。</p><p><strong>场景2：</strong>如果我们扔2次硬币，是否可能2次都是正面？当然有可能，并且概率为1&#x2F;4。如果我们扔10次硬币呢，是否可能10次都是正面？虽然概率很小，但依然是有可能的，概率为1&#x2F;1024。同样的，无论是100次、1000次，即使概率很小，也依然存在全部都是正面朝上的情况，假如扔了n次，那么n次都是正面的概率为12𝑛12�。这也是正向的推测，只不过增加了全都是正面朝上的限定。</p><p><strong>场景3：</strong>现在我们按下面这种规则扔硬币：不断扔硬币，如果是正面朝上，那么就继续扔，直到出现反面朝上，此时记录下扔硬币的总次数。例如我们抛了5次硬币，前4次都是正面朝上，第5次是反面朝上，我们就记录下次数5。通过场景2，我们可以知道这种情况发生的概率为1&#x2F;32。按我们的直觉可以推测，如果一个结果发生的概率是1&#x2F;32，那么我们大体上就需要做32次同样的事情才能得到这个结果（当然从更严谨的数学角度，并不能这么说，但本文不想涉及专业的数学描述，所以姑且这么理解，其实也挺符合一般常识判断的）。<br>那么假如张三做了若干次这种实验，我观察结果，发现记录下的总次数的<strong>最大值</strong>是5，那就说明在这若干次实验中，至少发生了一次4次正面朝上，第5次反面朝上的情况，而这种情况发生的概率是1&#x2F;32，于是我推测，张三大概率总共做了32次实验。这就是一种反向推测：<br><em>即根据</em><strong><em>结果（发生了一次1&#x2F;32概率才会出现的结果）*<em><strong>，推测</strong></em></em>条件（大概率做了32次实验）*<strong>。<br>更通俗来说，如果一个结果出现的概率很小，但却实际发生了了，就可以推测这件事情被重复执行了很多次。结果出现的概率越小，事情被重复执行的次数就应当越多。就像生活中中彩票的概率很低，普通人如果想中那可不就得买很多次嘛，中奖概率越低，一般需要购买彩票的次数就越多。相应的如果一个人中奖了，我们可以说这个人</strong>大概率</strong>上购买了非常多次彩票。这就是伯努利实验与极大似然估计结合的通俗理解。</p><p><strong>另外特别注意的，我们推测条件时，需要观察的总次数的最大值，因为最大值代表了最小概率，而最小概率才是推测条件的依据。下文redis同理。</strong></p><h4 id="4-4-3-redis实现"><a href="#4-4-3-redis实现" class="headerlink" title="4.4.3 redis实现"></a>4.4.3 redis实现</h4><p>redis实现本质也是利用了“扔硬币”产生的“极大似然估计”原理，因此接下去我们就详细看看redis是怎么扔硬币的。<br>在伯努利试验的场景3中，我们做的实验有3个特点：<br>1.硬币只有正反两面。<br>2.硬币正反面出现的概率相同。<br>2.单次实验需要投掷多次硬币。</p><p>而计算机中的hash算法正好可以满足这3个条件：<br>1.hash结果的每一个bit只有0和1，代表硬币的正反两面。<br>2.如果hash算法足够好，得到的结果就足够随机，可以近似认为每一个bit的0和1产生的概率是相同的。<br>3.hash的结果如果是64个bit，正好代表投掷了64次硬币。</p><p>因此执行一次hash，就相当于完整地进行了一次场景3中的投币实验。按照约定，实验完成后，我们需要记录硬币投掷的结果。<br>假定现在有2个用户id；user1、user2<br>先对user1进行hash，假定得到如下8个bit的结果：<br>10100100<br>此时从右到左，我们约定0表示反面，1表示正面，于是在这次实验中，第一个为1的bit出现在第三位，相当于先投出了2次反面，然后投出1次正面，于是我们记录下这次实验的投掷次数为3。因为约定只要投出正面，当次实验就结束，所以第一个1左边的所有bit就不再考虑了。<br>再对user2进行hash，假定得到：<br>01101000<br>第一个为1的bit出现在第4位，于是记录下4。<br>对于<strong>每个用户的访问请求，我们都可以对用户的id进行hash</strong>（相当于场景3中进行一次实验），并记录下第一个为1的bit出现的位数（相当于场景3中记录下硬币的投掷次数），那么<strong>通过记录到的位数的最大值，我们就可以大概估计出一共进行了多少次实验</strong>（相当于场景3中的反向推测），也就是有多少个不同的用户发生了访问。<br>例如某个页面有若干个用户进行了访问，我们观察记录下的数据，发现记录下的最大值是10，就意味着hash的结果至少出现了一次右边9个bit都为0的情况。而这种情况发生的概率为1&#x2F;1024，于是我们可以推测大概有1024个用户访问过该页面，才有可能出现一次这种结果。</p><p>所以其实可以这样理解：</p><p>每个用户ID的 hash结果相当于此用户的投币结果，我们看下 hash值从右向左第一次出现1的位置。如果比之前用户hash记录出现1的位置更靠左，则记录。这样如果最后记录的最大值是10，则可以推测1024个用户访问过。</p><p>又因为同一用户ID hash结果是唯一的，所以同一个用户ID即使多次实验，也不会影响精准性。当用户越多，则我们通过概率推测的用户数量 越接近实际情况。</p><h3 id="4-5-布隆过滤器"><a href="#4-5-布隆过滤器" class="headerlink" title="4.5 布隆过滤器"></a>4.5 布隆过滤器</h3><p>HyperLogLog 可以用来进行估值，它非常有价值，可以解决很多精确度要求不高的统计需求。但是如果我们想要知道某一个值是不是已经不在 HyperLogLog 结构里面了，它就无能为力的。</p><p>现实中，比如推荐系统：用户的视频推荐系统，每次推荐 需要查看用户是否观看过此视频。问题是，当用户量很大，每个用户观看过的视频总数又很大的情况下，去重工作在在性能上考验很大。如果数据存储在 关系数据库中，去重就需要频繁地对数据库进行 exists 查询。</p><p>如果使用缓存，但是这么多历史记录全部缓存起来，就得浪费很多存储空间。布隆过滤器可以解决此问题，它可以起到去重的同时，在空间上还能节省90%以上，只是稍微那么不精确。</p><p>当布隆过滤器说 某个值存在时，这个值可能不存在；当它说这个值不存在时，那就肯定不存在。</p><p>那么可以使用布隆过滤器 判断 需要推荐的时候，是否在用户观看历史记录集合中。如果不在，则推荐。如果判断在历史记录中，实际可能在 也可能不在，因为会有概率误判。所以 可以保证推荐的内容肯定是用户没看过的，但可能 也会把极少量用户没有看过的内容 误判成用户看过，而过滤掉。</p><h4 id="4-5-1-基本使用"><a href="#4-5-1-基本使用" class="headerlink" title="4.5.1 基本使用"></a>4.5.1 基本使用</h4><p>Redis官方提供的布隆过滤器到了Redis4.0提供了插件功能之后正式登场。可以通过docker直接体验</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt; docker pull redislabs/rebloom</span><br><span class="line">&gt; docker run -p 6379:6379 redislabs/rebloom</span><br><span class="line">&gt; redis-cli</span><br></pre></td></tr></table></figure><p>布隆过滤器基本指令：</p><ul><li>bf.add [collection] [element]：添加 元素element 进入 过滤器collection</li><li>bf.exists [collection] [element]：查询 元素element 是否存在，返回1表示存在，0表示不存在</li><li>bf.madd [collection] [element01] [element02]：一次 添加多个 元素进入 过滤器</li><li>bf.mexists：一次 查询多个元素 是否在过滤器</li></ul><p>上面指令使用的布隆过滤器只是默认参数的布隆过滤器，它在外面第一次add的时候被自动创建。Redis还提供了自定义参数的布隆过滤器，需要我们在 add 之前，使用 bf.reserve 指令显式创建。如果对应的key已经存在了，bf.reserve 会报错。bf.reserve 有三个参数，分别是 key，error_rate 和 initial_size。错误率越低，需要的空间越大。initial_size 参数表示预计放入的元素数量，当实际数量超过这个值，误判率会上升。所以一般 initial_size 需要设置一个较大的数值，避免超过，导致误判率升高。如果不使用 bf.reserve，默认的 error_rate 是 0.01,默认的 initial_size 是 100。</p><p>注意：如果 initial_size 估计的过大，也会浪费存储空间，估计的过小，就会影响准确率。</p><h4 id="4-5-2-原理"><a href="#4-5-2-原理" class="headerlink" title="4.5.2 原理"></a>4.5.2 原理</h4><p>每个布隆过滤器在Redis的数据结构里面就是 一个大型的位数组和几个不一样的无偏hash函数。所以无偏就是能够把元素的 hash值 算的比较均匀。</p><p>向过滤器中添加key时，会使用多个 hash 函数对 key 进行 hash算得一个整数索引值，然后对位数组长度进行取模运算，得到一个位置。每个 hash 函数都会算得一个不同的位置。再把位数组的这几个位置都置为1，就完成了 add 操作。</p><p>向布隆过滤器询问 key 是否存在时，跟 add 一样，也会把 hash 函数的几个位置都计算出来，看看 位数组中 这几个位置是否都 为1，只要有一个为 0，那么说明布隆过滤器中 这个key不存在。如果都是1，这并不能说明这个key就一定存在，只是极有可能存在。因为这些位被置成1，可能是因为添加其他 key 时导致的。</p><p>如果这个 位数组比较稀疏，这个误判的概率就很小，如果这个数组比较拥挤，误判的概率就会变大。使用时如果实际元素开始超过初始化大小，应该对布隆过滤器进行重建，重新分配一个size更大的过滤器，再将所有历史元素批量 add 进去。</p><h4 id="4-5-3-空间占用估计"><a href="#4-5-3-空间占用估计" class="headerlink" title="4.5.3 空间占用估计"></a>4.5.3 空间占用估计</h4><p>布隆过滤器有两个参数：第一个是预计元素的数量n，第二个是错误率 f。公式根据这两个输入 得到两个输出，第一个输出是 位数组的长度i，也就是需要的存储空间大小（bit），第二个输出是 hash 函数的最佳数量 k。hash函数的数量也会直接影响到错误率，最佳的数据会有最低的错误率。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">k = 0.7 * (i/n)  # 约等于</span><br><span class="line">f = 0.6185^(i/n)# ^表示次方计算</span><br></pre></td></tr></table></figure><p>从公式可以看出：</p><ul><li>位数组 相对越长(i&#x2F;n)，错误率 f 越低</li><li>位数组 相对越长(i&#x2F;n)，hash函数需要的最佳数量也越多，影响计算效率</li><li>当一个元素平均需要 1个字节(8 bit)的指纹空间(i&#x2F;n&#x3D;8)，错误率大约2%</li><li>错误率为10%，一个元素需要的平均指纹空间为 4.792个bit</li><li>错误率为0.1%，一个元素需要的平均指纹空间为 14.377个bit</li></ul><p>从上面可以看到，一个元素需要占据15bit，那相对set集合的空间优势是不是就没有那么明显了？set中会存储每个元素的内容，而布隆过滤器仅仅存储元素的指纹。元素的内容大小就是字符串的长度，它一般有多个字节甚至几十个字节，每个元素本身还需要一个指针被set集合来引用。</p><h3 id="4-6-简单限流"><a href="#4-6-简单限流" class="headerlink" title="4.6 简单限流"></a>4.6 简单限流</h3><p>在Redis中，可以使用 ZSet 数据结构 实现该功能。可以把 zset 中的 score 值设置为 时间戳 ，这样就可以圈出一个时间段内的所有数据。即 只要 时间窗口内的数据，时间窗口外的数据都可以砍掉。那么 zset 的value 填什么值呢，也可以填时间戳，只需保证其唯一性就行。</p><p>这样就可以 用 ZSet 记录用户的行为历史，每个行为都会作为一个 zset 中的一个 key 保存下来。同一个用户同一种行为 会使用一个 zset 记录。为了节省内存，我们只需要保留时间窗口内的行为记录，同时如果用户是冷用户，滑动时间窗口内的行为是空记录，那么这个 zset 就可以从内存中移除，不再占用空间。</p><p>通过统计滑动窗口内的行为数量与阈值 max_count 进行比较就可以得出当前的行为是否允许。</p><p>整体思路：每一个行为到来时，都维护一次时间窗口。将时间窗口外的记录全部清理掉，只保留窗口内的记录。zset集合中 只有 score 值非常重要，value没有特别的意义。</p><p>缺点：要记录时间窗口内所有的行为记录。如果这个量很大，比如限定 60s 内操作不得超过 100w 次，那么这就不适合这样做限流了，因为会消耗大量的存储空间。</p><h3 id="4-7-漏斗限流"><a href="#4-7-漏斗限流" class="headerlink" title="4.7 漏斗限流"></a>4.7 漏斗限流</h3><p>Redis4.0 提供了一个限流 Redis 模块，它叫 redis-cell。该模块也使用了漏斗算法，并提供了原子的限流指令。</p><p>该模块只有1条指令 cl.throttle ，它的参数和返回值都略显复杂。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&gt; cl.throttle key 15 30 60 1</span><br><span class="line"># key是键名 </span><br><span class="line"># 第二个参数是 漏斗容量</span><br><span class="line"># 第三个参数、第四个参数 表示 60s内 最多 30次（可以当作漏斗的流速）</span><br><span class="line"># 第五个参数为 可选参数,默认为1.</span><br><span class="line"> </span><br><span class="line">指令会返回五个参数，分别表示：</span><br><span class="line"># 0表示允许，1表示拒接</span><br><span class="line"># 漏斗容量</span><br><span class="line"># 漏斗剩余空间</span><br><span class="line"># 如果拒接了，需要多长时间之后再试（多久后漏斗有空间，单位秒）</span><br><span class="line"># 多长时间后，漏斗完全空出来（单位秒）</span><br></pre></td></tr></table></figure><p>在执行限流指令时，如果被拒绝了，就需要丢弃或重试，cl.throttle 指令考虑的非常周到，连重试时间给我们了，直接取返回结果数组的第四个值进行 sleep 即可，如果不想堵塞线程，也可以异步定时任务来重试。</p><h3 id="4-8-近水楼台-GeoHash"><a href="#4-8-近水楼台-GeoHash" class="headerlink" title="4.8 近水楼台-GeoHash"></a>4.8 近水楼台-GeoHash</h3><p>Redis在 3.2 版本以后增加了 GEO 模块，意味着我们可以使用 Redis 来实现 微信[附近的人]、美团[附件的餐馆]这样的功能了。</p><h4 id="4-8-1-用数据库来算附近的人"><a href="#4-8-1-用数据库来算附近的人" class="headerlink" title="4.8.1 用数据库来算附近的人"></a>4.8.1 用数据库来算附近的人</h4><p>地图元素的位置数据使用二维的经纬度表示，经度范围 (-180,180]，纬度范围 (-90,90],纬度正负以赤道为界，北正南负，经度正负以本初子午线为界，东正西负。</p><p>当两个距离不是很远时，可以直接使用勾股定理就能算得元素之间的距离。平时使用的 [附近的人] 的功能，元素距离都不是很大，勾股定理算距离足以。不过需要注意的是，经纬度坐标的密度不一样（经度总共360度，纬度总共180度），勾股定理计算平方差时之后再求和时，需要按一定的系数比加权求和。</p><p>如果使用关系型数据库，基本采用（元素ID,经度,纬度）存储。那此时就很难通过遍历来计算所有的元素和目标元素的距离然后再进行排序，这个计算量太大了，性能指标肯定无法满足。一般的方法都是通过矩形区域来限定元素的数量，然后对区域内的元素进行 全量距离 计算再排序。</p><p>为了满足高性能的矩形区域算法，数据表需要在经纬度坐标上加上双向复合索引（x,y），这样可以最大优化查询性能。但是数据库查询性能毕竟有限，如果 附近的人 查询请求非常多，在高并发场合，这可能并不是一个很好的方案。</p><h4 id="4-8-2-GeoHash算法"><a href="#4-8-2-GeoHash算法" class="headerlink" title="4.8.2 GeoHash算法"></a>4.8.2 GeoHash算法</h4><p>业界比较通用的地理距离排序算法是 GeoHash 算法，Redis 也使用 GeoHash 算法。GeoHash 算法将二维的经纬度数据映射到一维的整数，这样所有的元素都将挂载到一条线上，距离靠近的二维坐标映射到一维后的点之间距离也会很近。当我们想要计算 [附近的人时]，首先将目标的位置 映射到这条线上，然后在这个一维的线上获取附近的点就行了。</p><p>那这个映射算法具体是怎么计算的？它将整个地球看成一个二维平面，然后划分成了一系列正方形的方格，就好比围棋棋盘。所有的地图元素坐标都将放置于唯一的方格中。方格越小，坐标越精确。然后对这些方格进行整数编码，越是靠近的方格编码越是接近。那如何编码呢？一个最简单的方案就是切蛋糕法。设想一个正方形的蛋糕摆在你面前，二刀下去均分分成四个小正方形，这四个小正方形可以分别标记为00，01，10，11四个二进制整数。然后对每个小正方形继续用二分刀法切割一下，这时每个小小正方形使用4bit的二进制整数予以表示。然后继续切下去，正方形就会越来越小，二进制整数也会越来越长，精确度就会越来越高。</p><p>上面使用的是二刀法，进行编码。实际上还有其他很多方法进行编码。</p><p>编码之后，每个地图元素的坐标都将变成一个整数，通过这个整数可以还原出元素的坐标，整数越长，还原出来的坐标值的损失程度就越小。GeoHash算法会继续对这个整数做一次 base32 编码（0-9,a-z去掉a,i,l,o四个字母）变成一个字符串。在Redis里面，经纬度使用52位的整数进行编码，放进了zset里面，zset的 value 元素的key，score 是 GeoHash 的52位的整数值。zset 的 score 虽然是浮点数，但是对于 52位的整数值，它可以无损存储。</p><p>在使用 Redis 进行 Geo 查询时，我们要时刻想到它的内部结构实际上只是一个 zset(skiplist)。通过 zset 的 score 排序就要可以得到坐标附近的其他元素（实际情况要复杂一点），通过将 score 还原成坐标值就可以得到元素的原始坐标。</p><h4 id="4-8-3-基本使用"><a href="#4-8-3-基本使用" class="headerlink" title="4.8.3 基本使用"></a>4.8.3 基本使用</h4><p>Redis 提供的 Geo 指令只有 6 个。</p><ul><li>增加geoadd 指令携带 集合名称以及多个经纬度名称三元组。这里也可以一次性 添加多个元组。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 实际使用</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.48105 39.996794 x</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.48105 39.996794 xr</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.48110 39.996894 xrt</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; geoadd company 116.48410 39.996294 xrty 112.14517 38.12541 xrtu</span><br><span class="line">(integer) 2</span><br></pre></td></tr></table></figure><p>Redis 没有提供 geo 删除指令，但是因为 geo 的底层实现是 zset，所以可以使用 zrem key member 命令实现对 地理位置信息的删除。</p><ul><li>查看距离geodist 可以用来计算两个元素之间的距离，携带 集合名称、2个名称和距离单位</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geodist company xr xrt km</span><br><span class="line">&quot;0.0120&quot;</span><br></pre></td></tr></table></figure><ul><li>获取元素位置geopos 指令可以获取集合中任意元素的经纬度坐标，可以一次获取多个。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geopos company xr</span><br><span class="line">1) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">   2) &quot;39.99679348858259686&quot;</span><br><span class="line">127.0.0.1:6379&gt; geopos company xr xrt</span><br><span class="line">1) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">   2) &quot;39.99679348858259686&quot;</span><br><span class="line">2) 1) &quot;116.4810982346534729&quot;</span><br><span class="line">   2) &quot;39.99689487742897143&quot;</span><br></pre></td></tr></table></figure><p>我们观察到获取的经纬度坐标和 geoadd 进去的坐标有轻微的误差，原因是 geohash 对二维坐标进行的一维映射是有损的，通过映射再还原回来的值会出现较小的差别。</p><ul><li>获取元素的 Hash 值geohash 可以获取元素的经纬度编码字符串，上面说过它是 base32 编码。你可以使用这个编码值去 <a href="http://geohash.org/$%7Bhash%7D">http://geohash.org/${hash}</a> 中直接定位，它是 geohash 的标准编码值。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; geohash company xr</span><br><span class="line">1) &quot;wx4gd94yjn0&quot;</span><br></pre></td></tr></table></figure><ul><li>附近的georadiusbymember 指令是最为关键的指令，它可以用来查询指定元素附近的其他元素，它的参数非常复杂。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"># 范围20公里以内最多3个元素按距离正排，它不会排除自身</span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember company xr 20 km count 3 asc</span><br><span class="line">1) &quot;finchina&quot;</span><br><span class="line">2) &quot;xr&quot;</span><br><span class="line">3) &quot;xrt&quot;</span><br><span class="line"># 三个可选参数 withcoord withdist withhash 用来携带附加参数</span><br><span class="line">127.0.0.1:6379&gt; georadiusbymember company xr 20 km withcoord withdist withhash count 3 asc</span><br><span class="line">1) 1) &quot;finchina&quot;</span><br><span class="line">   2) &quot;0.0000&quot;</span><br><span class="line">   3) (integer) 4069887154388167</span><br><span class="line">   4) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">      2) &quot;39.99679348858259686&quot;</span><br><span class="line">2) 1) &quot;xr&quot;</span><br><span class="line">   2) &quot;0.0000&quot;</span><br><span class="line">   3) (integer) 4069887154388167</span><br><span class="line">   4) 1) &quot;116.48104995489120483&quot;</span><br><span class="line">      2) &quot;39.99679348858259686&quot;</span><br><span class="line">3) 1) &quot;xrt&quot;</span><br><span class="line">   2) &quot;0.0120&quot;</span><br><span class="line">   3) (integer) 4069887154432781</span><br><span class="line">   4) 1) &quot;116.4810982346534729&quot;</span><br><span class="line">      2) &quot;39.99689487742897143&quot;</span><br></pre></td></tr></table></figure><ul><li>查询指定坐标附近的元素除了 georadiusbymember 指令根据元素查询附近的元素，Redis还提供了根据坐标值来查询附近的元素 georadius，这个指令更加有用，它可以根据用户的定位来计算。它的参数和 georadiusbymember 基本一致，除了将目标元素改成经纬度坐标值</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; georadius company 116.18119895 39.9977934 100 km withdist count 2 desc</span><br><span class="line">1) 1) &quot;xrty&quot;</span><br><span class="line">   2) &quot;25.8103&quot;</span><br><span class="line">2) 1) &quot;xrt&quot;</span><br><span class="line">   2) &quot;25.5539&quot;</span><br></pre></td></tr></table></figure><p>在一个地图应用中，车的数据、餐馆的数据、人的数据 可能会有百万千万条，如果使用 Redis 的 geo 数据结构，它们将全部放在一个 zset 集合中。在 Redis 的集群环境中，集合可能从一个节点迁移到另一个节点，如果单个key的数据过大，会对集群的迁移工作造成较大影响，在集群环境中的单个key对应的数据量不宜超过 1M，否则会导致集群迁移出现卡顿现象，影响线上服务的正常运行。</p><p>所以，这里建议 geo 的数据使用单独的 Redis 实例部署，不使用集群环境。</p><p>如果数据量过亿甚至更大，就需要对 geo 数据进行拆分。在人口特大的城市，甚至可以按区划分，这样就可以显著降低单个 zset 集合的大小。</p><h3 id="4-9-大海捞针-scan"><a href="#4-9-大海捞针-scan" class="headerlink" title="4.9 大海捞针 scan"></a>4.9 大海捞针 scan</h3><p>有时候需要从 Redis 实例成千上万的 key 中找出特定前缀的 key 列表来手动处理数据，可能是修改它的值，也可能是删除key。这里就有一个问题，如何从海量 key 中找到满足特定前缀的 key 列表？</p><p>Redis 提供了一个简单暴力的指令 keys 用来列出所有满足 特定正则字符串规则的 key。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set code1 a</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; mset code2 2 code3 3 code4 4 code5 5</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; keys code*</span><br><span class="line">1) &quot;code5&quot;</span><br><span class="line">2) &quot;code4&quot;</span><br><span class="line">3) &quot;code1&quot;</span><br><span class="line">4) &quot;code3&quot;</span><br><span class="line">5) &quot;code2&quot;</span><br></pre></td></tr></table></figure><p>这个指令非常简单，提供一个简单的正则字符串即可，但是有很明显的两个缺点。 </p><p>1.没有 offset、limit参数，一次性吐出所有满足条件的 key，万一实例中有几百万个 key 满足条件，则打印字符串太多。</p><p>2.keys 算法是 遍历算法，复杂度是 O(n)，如果实例中有上千万级以上的 key，这个指令就会导致 redis 服务卡顿，所有读写 redis 的其他指令都会被延后甚至超时，因为redis是单线程程序，顺序执行所有指令，其他指令必须等到当前 keys 指令执行完成后才可以继续。</p><p>Redis为解决这个问题，在2.8版本加入了 scan 。scan 相比 keys具备以下优点：</p><ul><li>复杂度虽然也是0(n)，但是它是通过游标分布进行的，不会堵塞线程。</li><li>提供 limit 参数，可以控制每次返回结果的最大条数，limit 只是要给 hint，返回的参数可多可少。</li><li>同 keys 一样提供 模式匹配功能。</li><li>服务器不需要为游标保存状态，游标的唯一状态就是 scan 返回给客户端的游标整数。</li><li>遍历的过程中，如果有数据修改，改动后的数据能不能被遍历到是不确定的。</li><li>单次返回的结果是空的并不意味着遍历结束，而要看返回的游标值是否为零。</li></ul><h4 id="4-9-1-scan-基础使用"><a href="#4-9-1-scan-基础使用" class="headerlink" title="4.9.1 scan 基础使用"></a>4.9.1 scan 基础使用</h4><p>往redis插入了10条数据，code1到code10。</p><p>scan 提供了三个参数，第一个是 cursor 整数值，第二个是 key 的正则模式，第三个是 遍历的 limit hint。第一次遍历时，cursor值为0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0时结束。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; scan 0 match code* count 4</span><br><span class="line">1) &quot;6&quot;</span><br><span class="line">2) 1) &quot;code8&quot;</span><br><span class="line">   2) &quot;code1&quot;</span><br><span class="line">   3) &quot;code4&quot;</span><br><span class="line">   </span><br><span class="line">127.0.0.1:6379&gt; scan 6 match code* count 4</span><br><span class="line">1) &quot;9&quot;</span><br><span class="line">2) 1) &quot;code2&quot;</span><br><span class="line">   2) &quot;code6&quot;</span><br><span class="line">   3) &quot;code9&quot;</span><br><span class="line">   4) &quot;codex&quot;</span><br><span class="line">   </span><br><span class="line">127.0.0.1:6379&gt; scan 9 match code* count 4</span><br><span class="line">1) &quot;7&quot;</span><br><span class="line">2) 1) &quot;code5&quot;</span><br><span class="line">   2) &quot;code3&quot;</span><br><span class="line">   3) &quot;code10&quot;</span><br><span class="line">   4) &quot;code7&quot;</span><br><span class="line"></span><br><span class="line">127.0.0.1:6379&gt; scan 7 match code* count 4</span><br><span class="line">1) &quot;0&quot;</span><br><span class="line">2) 1) &quot;code11&quot;</span><br></pre></td></tr></table></figure><p>从上面实际测试中可以知道，游标不是每次递增，并且所填的 limit hint 不是指代返回的结果数量，而是单次遍历的字典槽位数量(约等于)。可能 单次的 返回结果为空，但是这并不意味着 遍历已经结束。只有当返回的游标值为 0 ，才算整个遍历结束。</p><h4 id="4-9-2-字典的结构"><a href="#4-9-2-字典的结构" class="headerlink" title="4.9.2 字典的结构"></a>4.9.2 字典的结构</h4><p>在 Redis 中所有的 key 都存储在一个很大的字典中，整个字典的结构和 Java中的 HashMap 一样，是一维数组+二维链表结构。第一维数组的大小总是 2^n （n&gt;&#x3D;0)，扩容一次数组大小空间加倍，也就是 n++</p><p>scan 指令返回的游标就是第一个维数组的位置索引，我们将整个位置索引称作槽。如果不考虑字典的扩容缩容，直接按数组下标挨个遍历就行了。limit 参数就表示需要遍历的槽位数，之所以返回的结果可能多可能少，是因为不是所有的槽位都会挂接 链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个。每次遍历都会将 limit 数量的槽位上挂接的所有链表元素进行模式匹配过滤后，一次性返回给客户端。</p><h4 id="4-9-3-scan-遍历顺序"><a href="#4-9-3-scan-遍历顺序" class="headerlink" title="4.9.3 scan 遍历顺序"></a>4.9.3 scan 遍历顺序</h4><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1684724453802-b8a3e03e-5bad-4829-9d57-ec6e6b10696d.png" alt="img"></p><p>scan的遍历顺序非常特别。它不是从第一维数组的第0位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历。是考虑到字典的扩容和缩容时避免槽位和遍历重复和遗漏（后面有具体分析）。高位进位法从左边加，进位往右边移动，同普通加法正好相反。但是它们都会遍历所有的槽位并且没有重复。</p><h4 id="4-9-4-字典扩容"><a href="#4-9-4-字典扩容" class="headerlink" title="4.9.4 字典扩容"></a>4.9.4 字典扩容</h4><p>Java 中的 HashMap 有扩容的概念，当 loadFactor 达到阈值时，需要重新分配一个新的 2 倍大小的数组，然后将所有的元素全部 rehash 挂到新的数组下面。rehash 就是将元素的 hash值对数组长度进行取模运算，因为长度变了，所以每个元素挂接的槽位可能也发生了变化。有因为数组的长度是 2^n 次方，所以取模运算等价于 位与 操作。</p><p>a%8 &#x3D; a&amp;(8-1) &#x3D; a&amp;7</p><p>a%16 &#x3D; a&amp;(16-1) &#x3D; a&amp;15</p><p>a%32 &#x3D; a&amp;(32-1) &#x3D; a&amp;31</p><p>这里的 7、15、31 又称之为字典的 mask值，mask的作用就是保留 hash 值的低位，高位都被设置为 0。</p><p>看看 rehash 前后元素槽位的变化</p><p>假设当前的字段的数组长度由 8 位扩容到 16位，那么 3号槽位 011 将会被 rehash 到3号槽位和11号槽位，也就是说该槽位链表中大约有一半的元素还是3号槽位，其它的元素会放到11号槽位，11这个数字的二进制是 1011，就是对 3 的二进制 011 增加了一个高位1。</p><p>抽象一点说，假设开始槽位的二进制是 xxx，那么该槽位中的元素将被 rehash 到 0xxx 和 1xxx 即 xxx+8中。如果字典长度由16位扩容到32位，那么对于二进制槽位 xxxx 中的元素将被 rehash 到 0xxxx 和 1xxxx中。</p><p><strong>对比扩容前后的遍历顺序：</strong></p><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1684724547827-d86608c6-5109-46c3-8cc2-843deba5e1f6.png" alt="img"></p><p>观察这张图片，我们发现采用高位进位加法的遍历顺序，rehash 后的槽位 在遍历顺序上是相邻的。</p><p>假设当前即将遍历 110这个位置，那么扩容后，当前槽位上所有的元素对应的新槽位是 0110 和 1110，也就是在槽位的二进制数增加一个高位0或1.这时我们可以i直接从 0110 这个槽位开始往后继续遍历，0110 槽位之前的所有槽位都是已经遍历过的，这样就可以避免扩容后对已经遍历过的槽位进行重复遍历。</p><p>再考虑缩容，假设当前即将遍历 110 这个位置，那么缩容后，当前槽位所有的元素对应的新槽位是 10，也就是去掉槽位二进制最高位。这时我们可以直接从10这个槽位继续往后遍历，10槽位之前的所有槽位都是遍历过的，这样可以避免缩容的重复遍历。不顾缩容还是不太一样，它会对图中 010 这个槽位上的元素进行重复遍历，因为缩容后 10 槽位的元素是 010 和 110上挂接的元素的融合。</p><h4 id="4-9-5-scan-考虑-渐进式-rehash"><a href="#4-9-5-scan-考虑-渐进式-rehash" class="headerlink" title="4.9.5 scan 考虑 渐进式 rehash"></a>4.9.5 scan 考虑 渐进式 rehash</h4><p>Java的 HashMap 在扩容时会一次性将旧数组下挂接的元素全部转移到新的数组下面。如果 Map 中元素特别多，线程就会出现卡顿现象。Redis为了解决这个问题，它采用渐进式 rehash。</p><p>它同时保留旧数组和新数组，然后在定时任务中以及后续对 hash 的指令操作中渐渐将旧的数组中挂接的元素迁移到新数组上。这意味着要操作处于 rehash 中的字典，需要同时访问新旧两个数组结构。如果在旧数组下面找不到元素，还需要去新数组下面寻找。</p><p>scan 也需要考虑这个问题，对于 rehash中的字典，它需要同时扫描新旧槽位，然后将结果融合后返回给客户端。</p><h4 id="4-9-6-更多-scan-指令"><a href="#4-9-6-更多-scan-指令" class="headerlink" title="4.9.6 更多 scan 指令"></a>4.9.6 更多 scan 指令</h4><p>scan指令是一系列指令，处理可以遍历所有的 key以外，还可以对指定的容器集合进行遍历。比如 zscan 遍历 zset 集合元素，hscan 遍历 hash 字典的元素。</p><h4 id="4-9-7-大Key的扫描"><a href="#4-9-7-大Key的扫描" class="headerlink" title="4.9.7 大Key的扫描"></a>4.9.7 大Key的扫描</h4><p>因为业务人员的使用不当，在 Redis 实例中会形成很大的对象，比如一个很大的 hash，一个很大的 zset。这样的对象对Redis的集群数据迁移带来了很大问题，因为在集群环境下，如果某一个key太大，会导致数据迁移卡顿。另外在内存分配上，如果一个key太大，那么当它需要扩容时，会一次性申请更大的一块内存，这也会导致卡顿。如果这个大key被删除，内存会一次性回收，卡顿现象再一次产生。</p><p>所以在开发中请避免大key的产生。如何定位到 大key呢？可以使用 scan 命令，对于扫描出来的每一个key，使用 type 指令获取类型，然后使用相应的数据结构的 size 或者 len 方法来得到 它的大小，对于每一种类型，保留大小的前 N名作为扫描结果展示出来。</p><p>Redis 官方已经提供了 实现上面功能的 指令：redis-cli -h 127.0.0.1 -p 6379 –bigkeys 。如果担心这个指令会大幅抬升 Redis 的 ops，还可以增加一个休眠参数。redis-cli -h 127.0.0.1 -p 6379 –bigkeys -i 0.1，这个指令每隔100条 scan 指令就会休眠 0.1s，ops 就不会剧烈抬升，但是扫描的时间会变长。</p><h2 id="五、Redis-原理"><a href="#五、Redis-原理" class="headerlink" title="五、Redis 原理"></a>五、Redis 原理</h2><h3 id="5-1-线程-IO-模型"><a href="#5-1-线程-IO-模型" class="headerlink" title="5.1 线程 IO 模型"></a>5.1 线程 IO 模型</h3><p>记住高并发的 Redis 中间件是 单线程的，除此之外，Node.js、Nginx 也是单线程，但是它们都是服务器高性能的典范。</p><p>详细可以看 3.3</p><h3 id="5-2-通信协议"><a href="#5-2-通信协议" class="headerlink" title="5.2 通信协议"></a>5.2 通信协议</h3><p>Redis 的作者认为 数据库系统的瓶颈一般不在于网络流量，而是数据库自身内部逻辑处理上。所以即使 redis 使用了浪费流量的文本协议，依然可以取得极高的访问性能。</p><h4 id="5-2-1-RESP-（Redis-Serialization-Protocol）"><a href="#5-2-1-RESP-（Redis-Serialization-Protocol）" class="headerlink" title="5.2.1 RESP （Redis Serialization Protocol）"></a>5.2.1 RESP （Redis Serialization Protocol）</h4><p>RESP 是 Redis 序列化协议的简写。它是一种直观的文本协议，优势在于实现异常简单，解析性能极好。Redis 协议将传输的结构数据 分为5种单元类型，单元结束时统一加上回车换行符号\r\n。</p><ul><li>单行字符串 以 + 符号开头。</li><li>多行字符串 以 $ 符号开头，后跟字符串长度</li><li>整数值 以 : 符号开头，后跟整数的字符串形式</li><li>错误信息 以 - 符号开头</li><li>数组 以 * 号开头，后跟数组长度</li></ul><h4 id="5-2-2-小结"><a href="#5-2-2-小结" class="headerlink" title="5.2.2 小结"></a>5.2.2 小结</h4><p>Redis 协议里有大量冗余的回车换行符，但是这个并不影响它成为互联网技术领域非常受欢迎的一个文本协议。有很多开源项目使用 RESP 作为它的通讯协议。在技术领域性能并不总是一切，还有简单性、易理解性和易实现性，这些都需要进行适当权衡。</p><h3 id="5-3-持久化"><a href="#5-3-持久化" class="headerlink" title="5.3 持久化"></a>5.3 持久化</h3><p>Redis 的数据全部在内存中，如果突然宕机，数据就会全部丢失，因此必须有一种机制来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的持久化机制。</p><p>Redis 持久化机制有两种，第一种是快照，第二种是AOF日志。</p><ul><li>RDB 将数据库的快照（snapshot）以二进制的方式保存到磁盘中。</li><li>AOF 则以协议文本的方式，将所有对数据库进行过写入的命令（及其参数）记录到 AOF 文件，以此达到记录数据库状态的目的。</li></ul><p>AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行AOF重写，给AOF日志进行瘦身。</p><h4 id="5-3-1-快照"><a href="#5-3-1-快照" class="headerlink" title="5.3.1 快照"></a>5.3.1 快照</h4><p>我们都知道 Redis 是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。在服务线上请求的同时，Redis 如果还需要进行内存快照（需要使用 文件IO操作），那就很难保持不堵塞。除此之外，持久化的同时，内存数据结构还在改变。这如何应对？</p><p>Redis 使用操作系统的多进程 COW (copy on write) 机制来实现快照持久化。</p><p>Redis 在持久化时会调用 glibc 的函数 fork 产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。（这是Linux为节约内存资源，所以让其共享起来，在子进程创建时，内存增长几乎没有明显变化）</p><p>子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写入到磁盘。但是父进程不一样，它必须持续接受客户端请求，然后对内存数据结构进行不间断修改。</p><p>这时候就会使用操作系统的 COW 机制来进行数据段页面的分离。数据段页面是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。</p><p>随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的2倍大小。另一个Redis实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有 4k，一个 Redis 实例里面一般都会有成千上万的页面。</p><p>子进程因为数据没有变化，它能看到的内存里的数据在进程产生的那一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫 快照的原因。</p><h4 id="5-3-2-AOF的写入"><a href="#5-3-2-AOF的写入" class="headerlink" title="5.3.2 AOF的写入"></a>5.3.2 AOF的写入</h4><p>Redis 将所有对数据库进行过写入的命令（及其参数）记录到 AOF 文件， 以此达到记录数据库状态的目的， 为了方便起见， 我们称呼这种记录过程为同步。</p><p>举个例子， 如果执行以下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; RPUSH list 1 2 3 4</span><br><span class="line">(integer) 4</span><br><span class="line"></span><br><span class="line">redis&gt; LRANGE list 0 -1</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;3&quot;</span><br><span class="line">4) &quot;4&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; KEYS *</span><br><span class="line">1) &quot;list&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; RPOP list</span><br><span class="line">&quot;4&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; LPOP list</span><br><span class="line">&quot;1&quot;</span><br><span class="line"></span><br><span class="line">redis&gt; LPUSH list 1</span><br><span class="line">(integer) 3</span><br><span class="line"></span><br><span class="line">redis&gt; LRANGE list 0 -1</span><br><span class="line">1) &quot;1&quot;</span><br><span class="line">2) &quot;2&quot;</span><br><span class="line">3) &quot;3&quot;</span><br></pre></td></tr></table></figure><p>那么其中四条对数据库有修改的写入命令就会被同步到 AOF 文件中</p><p>除了 SELECT 命令是 AOF 程序自己加上去的之外， 其他命令都是之前我们在终端里执行的命令。</p><p>同步命令到 AOF 文件的整个过程可以分为三个阶段：</p><ol><li>命令传播：Redis 将执行完的命令、命令的参数、命令的参数个数等信息发送到 AOF 程序中。</li><li>缓存追加：AOF 程序根据接收到的命令数据，将命令转换为网络通讯协议的格式，然后将协议内容追加到服务器的 AOF 缓存中。</li><li>文件写入和保存：AOF 缓存中的内容被写入到 AOF 文件末尾，如果设定的 AOF 保存条件被满足的话， fsync 函数或者 fdatasync 函数会被调用，将写入的内容真正地保存到磁盘中。</li></ol><p>以下几个小节将详细地介绍这三个步骤。</p><h5 id="命令传播"><a href="#命令传播" class="headerlink" title="命令传播"></a>命令传播</h5><p>当一个 Redis 客户端需要执行命令时， 它通过网络连接， 将协议文本发送给 Redis 服务器。比如说， 要执行命令 SET KEY VALUE ， 客户端将向服务器发送文本 “*3\r\n$3\r\nSET\r\n$3\r\nKEY\r\n$5\r\nVALUE\r\n” 。</p><p>服务器在接到客户端的请求之后， 它会根据协议文本的内容， 选择适当的命令函数， 并将各个参数从字符串文本转换为 Redis 字符串对象（StringObject）。</p><p>比如说， 针对上面的 <a href="http://redis.readthedocs.org/en/latest/string/set.html#set">SET</a> 命令例子， Redis 将客户端的命令指针指向实现 <a href="http://redis.readthedocs.org/en/latest/string/set.html#set">SET</a> 命令的 setCommand 函数， 并创建三个 Redis 字符串对象， 分别保存 SET 、 KEY 和 VALUE 三个参数（命令也算作参数）。</p><p>每当命令函数成功执行之后， 命令参数都会被传播到 AOF 程序， 以及 REPLICATION 程序（本节不讨论这个，列在这里只是为了完整性的考虑）。</p><h5 id="缓存追加"><a href="#缓存追加" class="headerlink" title="缓存追加"></a>缓存追加</h5><p>当命令被传播到 AOF 程序之后， 程序会根据命令以及命令的参数， 将命令从字符串对象转换回原来的协议文本。</p><p>比如说， 如果 AOF 程序接受到的三个参数分别保存着 SET 、 KEY 和 VALUE 三个字符串， 那么它将生成协议文本 “*3\r\n$3\r\nSET\r\n$3\r\nKEY\r\n$5\r\nVALUE\r\n” 。</p><p>协议文本生成之后， 它会被追加到 redis.h&#x2F;redisServer 结构的 aof_buf 末尾。</p><p>redisServer 结构维持着 Redis 服务器的状态， aof_buf 域则保存着所有等待写入到 AOF 文件的协议文本：</p><h5 id="文件写入和保存"><a href="#文件写入和保存" class="headerlink" title="文件写入和保存"></a>文件写入和保存</h5><p>每当服务器常规任务函数被执行、 或者事件处理器被执行时， aof.c&#x2F;flushAppendOnlyFile 函数都会被调用， 这个函数执行以下两个工作：</p><p>WRITE：根据条件，将 aof_buf 中的缓存写入到 AOF 文件。</p><p>SAVE：根据条件，调用 fsync 或 fdatasync 函数，将 AOF 文件保存到磁盘中。</p><p>两个步骤都需要根据一定的条件来执行， 而这些条件由 AOF 所使用的保存模式来决定， 以下小节就来介绍 AOF 所使用的三种保存模式， 以及在这些模式下， 步骤 WRITE 和 SAVE 的调用条件。</p><h5 id="AOF-保存模式"><a href="#AOF-保存模式" class="headerlink" title="AOF 保存模式"></a>AOF 保存模式</h5><p>Redis 目前支持三种 AOF 保存模式，它们分别是：</p><ul><li><p>AOF_FSYNC_NO ：不保存在这种模式下， 每次调用 flushAppendOnlyFile 函数， WRITE 都会被执行， 但 SAVE 会被略过。在这种模式下， SAVE 只会在以下任意一种情况中被执行：这三种情况下的 SAVE 操作都会引起 Redis 主进程阻塞。</p></li><li><ul><li>Redis 被关闭</li><li>AOF 功能被关闭</li><li>系统的写缓存被刷新（可能是缓存已经被写满，或者定期保存操作被执行）</li></ul></li><li><p>AOF_FSYNC_EVERYSEC ：每一秒钟保存一次。在这种模式中， SAVE 原则上每隔一秒钟就会执行一次， 因为 SAVE 操作是由后台子线程调用的， 所以它不会引起服务器主进程阻塞。注意， 在上一句的说明里面使用了词语“原则上”， 在实际运行中， 程序在这种模式下对 fsync 或 fdatasync 的调用并不是每秒一次， 它和调用 flushAppendOnlyFile 函数时 Redis 所处的状态有关。每当 flushAppendOnlyFile 函数被调用时， 可能会出现以下四种情况：根据以上说明可以知道， 在“每一秒钟保存一次”模式下， 如果在情况 1 中发生故障停机， 那么用户最多损失小于 2 秒内所产生的所有数据。如果在情况 2 中发生故障停机， 那么用户损失的数据是可以超过 2 秒的。Redis 官网上所说的， AOF 在“每一秒钟保存一次”时发生故障， 只丢失 1 秒钟数据的说法， 实际上并不准确。</p></li><li><ul><li>子线程正在执行 SAVE ，并且：</li></ul></li></ul><ol><li><ol><li><ol><li>这个 SAVE 的执行时间未超过 2 秒，那么程序直接返回，并不执行 WRITE 或新的 SAVE 。</li><li>这个 SAVE 已经执行超过 2 秒，那么程序执行 WRITE ，但不执行新的 SAVE 。注意，因为这时 WRITE 的写入必须等待子线程先完成（旧的） SAVE ，因此这里 WRITE 会比平时阻塞更长时间。</li></ol></li></ol></li></ol><ul><li><ul><li>子线程没有在执行 SAVE ，并且：</li></ul></li></ul><ol><li><ol><li><ol><li>上次成功执行 SAVE 距今不超过 1 秒，那么程序执行 WRITE ，但不执行 SAVE 。</li><li>上次成功执行 SAVE 距今已经超过 1 秒，那么程序执行 WRITE 和 SAVE 。</li></ol></li></ol></li></ol><ul><li>AOF_FSYNC_ALWAYS ：每执行一个命令保存一次。在这种模式下，每次执行完一个命令之后， WRITE 和 SAVE 都会被执行。另外，因为 SAVE 是由 Redis 主进程执行的，所以在 SAVE 执行期间，主进程会被阻塞，不能接受命令请求。</li></ul><p>总结：</p><table><thead><tr><th><strong>模式</strong></th><th><strong>WRITE 是否阻塞？</strong></th><th><strong>SAVE 是否阻塞？</strong></th><th><strong>停机时丢失的数据量</strong></th></tr></thead><tbody><tr><td>AOF_FSYNC_NO</td><td>阻塞</td><td>阻塞</td><td>操作系统最后一次对 AOF 文件触发 SAVE 操作之后的数据。</td></tr><tr><td>AOF_FSYNC_EVERYSEC</td><td>阻塞</td><td>不阻塞</td><td>一般情况下不超过 2 秒钟的数据。</td></tr><tr><td>AOF_FSYNC_ALWAYS</td><td>阻塞</td><td>阻塞</td><td>最多只丢失一个命令的数据。</td></tr></tbody></table><h4 id="5-3-3-AOF-文件的读取和数据还原"><a href="#5-3-3-AOF-文件的读取和数据还原" class="headerlink" title="5.3.3 AOF 文件的读取和数据还原"></a>5.3.3 AOF 文件的读取和数据还原</h4><p>AOF 文件保存了 Redis 的数据库状态， 而文件里面包含的都是符合 Redis 通讯协议格式的命令文本。</p><p>这也就是说， 只要根据 AOF 文件里的协议， 重新执行一遍里面指示的所有命令， 就可以还原 Redis 的数据库状态了。</p><p>Redis 读取 AOF 文件并还原数据库的详细步骤如下：</p><ol><li>创建一个不带网络连接的伪客户端（fake client）。</li><li>读取 AOF 所保存的文本，并根据内容还原出命令、命令的参数以及命令的个数。</li><li>根据命令、命令的参数和命令的个数，使用伪客户端执行该命令。</li><li>执行 2 和 3 ，直到 AOF 文件中的所有命令执行完毕。</li></ol><p>完成第 4 步之后， AOF 文件所保存的数据库就会被完整地还原出来。</p><p>注意， 因为 Redis 的命令只能在客户端的上下文中被执行， 而 AOF 还原时所使用的命令来自于 AOF 文件， 而不是网络， 所以程序使用了一个没有网络连接的伪客户端来执行命令。 伪客户端执行命令的效果， 和带网络连接的客户端执行命令的效果， 完全一样。</p><h4 id="5-3-4-AOF-重写"><a href="#5-3-4-AOF-重写" class="headerlink" title="5.3.4 AOF 重写"></a>5.3.4 AOF 重写</h4><p>AOF 文件通过同步 Redis 服务器所执行的命令， 从而实现了数据库状态的记录， 但是， 这种同步方式会造成一个问题： 随着运行时间的流逝， AOF 文件会变得越来越大。</p><p>举个例子， 如果服务器执行了以下命令：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">RPUSH list 1 2 3 4      // [1, 2, 3, 4]</span><br><span class="line"></span><br><span class="line">RPOP list               // [1, 2, 3]</span><br><span class="line"></span><br><span class="line">LPOP list               // [2, 3]</span><br><span class="line"></span><br><span class="line">LPUSH list 1            // [1, 2, 3]</span><br></pre></td></tr></table></figure><p>那么光是记录 list 键的状态， AOF 文件就需要保存四条命令。而实质上，我们其实只要保存 list 最新状态的内存数据，就可以。</p><p>另一方面， 有些被频繁操作的键， 对它们所调用的命令可能有成百上千、甚至上万条， 如果这样被频繁操作的键有很多的话， AOF 文件的体积就会急速膨胀， 对 Redis 、甚至整个系统的造成影响。</p><p>为了解决以上的问题， Redis 需要对 AOF 文件进行重写（rewrite）： 创建一个新的 AOF 文件来代替原有的 AOF 文件， 新 AOF 文件和原有 AOF 文件保存的数据库状态完全一样， 但新 AOF 文件的体积小于等于原有 AOF 文件的体积。</p><h5 id="AOF-重写的实现"><a href="#AOF-重写的实现" class="headerlink" title="AOF 重写的实现"></a>AOF 重写的实现</h5><p>所谓的“重写”其实是一个有歧义的词语， 实际上， AOF 重写并不需要对原有的 AOF 文件进行任何写入和读取， 它针对的是数据库中键的当前值。</p><p>如同上面对 list 进行的四个操作后，那么当前 列表键在 Redis里的值就为 [1,2,3]。如果我们要保存这个列表的当前状态， 并且尽量减少所使用的命令数， 那么最简单的方式不是去 AOF 文件上分析前面执行的四条命令， 而是直接读取 list 键在数据库的当前值， 然后用一条 RPUSH 1 2 3 命令来代替前面的四条命令。</p><p>除了列表和集合之外， 字符串、有序集、哈希表等键也可以用类似的方法来保存状态， 并且保存这些状态所使用的命令数量， 比起之前建立这些键的状态所使用命令的数量要大大减少。</p><h5 id="AOF-后台重写"><a href="#AOF-后台重写" class="headerlink" title="AOF 后台重写"></a>AOF 后台重写</h5><p>上一节展示的 AOF 重写程序可以很好地完成创建一个新 AOF 文件的任务， 但是， 在执行这个程序的时候， 调用者线程会被阻塞。</p><p>很明显， 作为一种辅佐性的维护手段， Redis 不希望 AOF 重写造成服务器无法处理请求， 所以 Redis 决定将 AOF 重写程序放到（后台）子进程里执行， 这样处理的最大好处是：</p><ol><li>子进程进行 AOF 重写期间，主进程可以继续处理命令请求。</li><li>子进程带有主进程的数据副本，使用子进程而不是线程，可以在避免锁的情况下，保证数据的安全性。</li></ol><p>不过， 使用子进程也有一个问题需要解决： 因为子进程在进行 AOF 重写期间， 主进程还需要继续处理命令， 而新的命令可能对现有的数据进行修改， 这会让当前数据库的数据和重写后的 AOF 文件中的数据不一致。</p><p>为了解决这个问题， Redis 增加了一个 AOF 重写缓存， 这个缓存在 fork 出子进程之后开始启用， Redis 主进程在接到新的写命令之后， 除了会将这个写命令的协议内容追加到现有的 AOF 文件之外， 还会追加到这个缓存中。</p><p>换言之， 当子进程在执行 AOF 重写时， 主进程需要执行以下三个工作：</p><ol><li>处理命令请求。</li><li>将写命令追加到现有的 AOF 文件中。</li><li>将写命令追加到 AOF 重写缓存中。</li></ol><p>这样一来可以保证：</p><ol><li>现有的 AOF 功能会继续执行，即使在 AOF 重写期间发生停机，也不会有任何数据丢失。</li><li>所有对数据库进行修改的命令都会被记录到 AOF 重写缓存中。</li></ol><p>当子进程完成 AOF 重写之后， 它会向父进程发送一个完成信号， 父进程在接到完成信号之后， 会调用一个信号处理函数， 并完成以下工作：</p><ol><li>将 AOF 重写缓存中的内容全部写入到新 AOF 文件中。</li><li>对新的 AOF 文件进行改名，覆盖原有的 AOF 文件。</li></ol><p>当步骤 1 执行完毕之后， 现有 AOF 文件、新 AOF 文件和数据库三者的状态就完全一致了。</p><p>当步骤 2 执行完毕之后， 程序就完成了新旧两个 AOF 文件的交替。</p><p>这个信号处理函数执行完毕之后， 主进程就可以继续像往常一样接受命令请求了。 在整个 AOF 后台重写过程中， 只有最后的写入缓存和改名操作会造成主进程阻塞， 在其他时候， AOF 后台重写都不会对主进程造成阻塞， 这将 AOF 重写对性能造成的影响降到了最低。</p><h4 id="5-3-5-混合持久化"><a href="#5-3-5-混合持久化" class="headerlink" title="5.3.5 混合持久化"></a>5.3.5 混合持久化</h4><p>为了集成了两者的优点， Redis 4.0 提出了混合使用 AOF 日志和内存快照，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。</p><p>混合持久化工作在 AOF 日志重写过程，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p><p>也就是说，使用了混合持久化，AOF 文件的前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1684770620104-4c8fc4d7-0964-4354-9ccf-ec35e2064483.jpeg" alt="img"></p><p>这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样加载的时候速度会很快。</p><p>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得数据更少的丢失。</p><p>混合持久化优点：</p><p>混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。</p><p>混合持久化缺点：</p><p>AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；</p><p>兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。</p><h3 id="5-4-管道"><a href="#5-4-管道" class="headerlink" title="5.4 管道"></a>5.4 管道</h3><p>Redis 管道并不是 Redis 服务器直接提供的技术，这个技术实际是由客户端提供的，跟服务器没有本质关系。</p><p><strong>Redis 的消息交互：</strong></p><p>当我们使用客户端对 Redis 进行一次操作时。客户端将请求传送给服务器，服务器处理完成后，再将响应回复给客户端、这就需要花费一个网络数据包来回的时间。</p><p>如果连续执行多条指令，那就会花费多个网络数据包来回的时间。从客户端层面上来看，客户端时经历了 发送请求1-接受响应1-发送请求2-接受响应2— 这样。那么我们实际上可以调整一下，多个指令请求的请求响应顺序。即 发送请求1-发送请求2-接受请求1-接受请求2。这这样两个连续的发送请求操作和两个连续的等待请求响应操作 总共只会花费一次网络来回。</p><p>这便是管道操作的本质，服务器根本没有区别对待，还是收到一条消息，执行一条消息，回复一条消息的正常流程。客户端通过对管道中指令列表改变操作顺序就可以大幅节省 IO 时间。管道中的指令越多，效果越好。</p><h5 id="管道压力测试"><a href="#管道压力测试" class="headerlink" title="管道压力测试"></a>管道压力测试</h5><p>Redis 自带了一个压力测试工具 redis-benchmark，使用这个工具就可以进行管道测试。首先我们对一个普通的 set 指令进行压测，QPS大约 2.5w&#x2F;s。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@b7ba9713c11c:/data# redis-benchmark -t set -q</span><br><span class="line">SET: 24319.07 requests per second, p50=0.959 msec</span><br></pre></td></tr></table></figure><p>加入管道选项 -P 参数，它表示单个管道内并行的请求数量，看下面 P&#x3D;2时，QPS就可以达到 5w&#x2F;s</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">root@b7ba9713c11c:/data# redis-benchmark -t set -q -P 2</span><br><span class="line">SET: 50200.80 requests per second, p50=0.943 msec   </span><br><span class="line">root@b7ba9713c11c:/data# redis-benchmark -t set -q -P 40</span><br><span class="line">SET: 175131.36 requests per second, p50=10.391 msec </span><br><span class="line">root@b7ba9713c11c:/data# redis-benchmark -t set -q -P 100</span><br><span class="line">SET: 182149.36 requests per second, p50=26.671 msec</span><br></pre></td></tr></table></figure><p>发现到后面提高 P 参数，已经无法提高 QPS了，这一般都是因为 CPU 处理能力已经达到了瓶颈。</p><h5 id="管道本质"><a href="#管道本质" class="headerlink" title="管道本质"></a>管道本质</h5><p>下面就介绍一下一个请求的交互流程：</p><ol><li>客户端进行调用 write 将消息写到 操作系统内核 为套接字分配的 发送缓冲 sendbuffer</li><li>客户端操作系统内核将 发送缓冲的内容 发送到网卡，网卡硬件将数据通过 网际路由 送到服务器网卡。</li><li>服务器操作系统内核将 网卡的数据 放到内核为套接字分配的接受缓冲 recv buffer。</li><li>服务器进程调用 read 从接受缓冲区中 取出消息进行处理。</li><li>服务器进程调用 write 将响应消息写到 内核为套接字分配的发送缓冲 send buffer。</li><li>服务器操作系统内核 将发送缓冲的内容 发送到网卡，网卡硬件将数据通过 网际路由 发送到客户端的网卡。</li><li>客户端操作系统内核 将网卡的数据 放到内核为套接字分配的 接受缓冲 recv buffer</li><li>客户端进程调用 read 从接收缓冲区中 取出消息 返回给上层业务逻辑 进行处理。</li></ol><p>我们一开始可能以为 write 操作要等到对方收到消息才返回，但实际上不是这样的。write 操作只负责 将数据写到本地操作系统内核的 发送缓冲区然后就返回了。剩下的事 交给操作系统内核异步 将数据送到目标机器。但是如果发送缓冲区满了，那么就需要等待 缓冲区 空出，这个就是 写操作 IO 操作的真正耗时。</p><p>同理，read 操作并不是从目标机器拉取数据。read 操作只负责将 数据从本地操作系统内核的 接收缓冲区 取出来就了事。但是如果 缓冲区是空的，那么就需要等待数据到来，这个就是 读操作 IO 操作的真正耗时。</p><p>所以对于 客户端的 redis.get(key) 这样的命令来说，write 操作几乎没有耗时，直接写到 发送缓冲区就返回，而 read 操作比较耗时了，因为它要等待消息经过网络路由到目标机器处理后的响应消息，再发送到当前内核读缓冲 才可以返回。这才是一个网络来回的真正开销。</p><p>而对于管道来说，连续的 write 操作根本就没有耗时，之后第一个 read 操作会等待 一个网络的来回开销，然后响应信息到达 客户端系统内核的读缓冲了。因为 write 是连续发送，且几乎没有耗时，所以当 第一个read之后，后续所有read基本也同时随之到达 读缓冲。</p><h3 id="5-5-事务"><a href="#5-5-事务" class="headerlink" title="5.5 事务"></a>5.5 事务</h3><p>Redis 通过 MULTI、DISCARD 、EXEC 和 WATCH 四个命令来实现事务功能。事务提供了一种 “将多个命令打包，然后一次性、按顺序地执行”的机制，并且事务在执行的期间不会主动中断——服务器在执行完事务中的所有命令之后，才会继续处理其他客户端的命令。</p><p>例子：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379(TX)&gt; set name &quot;kxr&quot;</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379(TX)&gt; get name</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379(TX)&gt; sadd name-list &quot;kxr&quot; &quot;jyl&quot;</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379(TX)&gt; smembers name-list</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379(TX)&gt; exec</span><br><span class="line">1) OK</span><br><span class="line">2) &quot;kxr&quot;</span><br><span class="line">3) (integer) 2</span><br><span class="line">4) 1) &quot;jyl&quot;</span><br><span class="line">   2) &quot;kxr&quot;</span><br></pre></td></tr></table></figure><h4 id="5-5-1-事务流程"><a href="#5-5-1-事务流程" class="headerlink" title="5.5.1 事务流程"></a>5.5.1 事务流程</h4><p>一个事务从开始到执行会经历三个阶段：</p><ol><li>开始事务</li><li>命令入队</li><li>执行事务</li></ol><h5 id="开始事务"><a href="#开始事务" class="headerlink" title="开始事务"></a>开始事务</h5><p>MULTI 命令的执行 标记着事务的开始。这个命令唯一做的就是，将客户端的 REDIS_MULTI 选项打开，让客户端从非事务状态切换到事务状态。</p><h5 id="命令入队"><a href="#命令入队" class="headerlink" title="命令入队"></a>命令入队</h5><p>当客户端处于非事务状态下时，所有发送给服务端的命令都会立即被服务器执行。但是，当客户端进入事务状态之后，服务器在收到来自客户端的命令时，不会立即执行命令，而是将这些命令全部放进一个事务队列里，然后返回 QUEUED，表示命令已入队。</p><p>事务队列是一个数组，每个数组项是都包含三个属性：</p><ol><li>要执行的命令（cmd）</li><li>命令的参数（argv）</li><li>参数的个数（argc）</li></ol><h5 id="执行事务"><a href="#执行事务" class="headerlink" title="执行事务"></a>执行事务</h5><p>前面说到，当客户端进入事务状态之后，客户发送的命令就会被放进事务队列里。</p><p>但其实并不是所有的命令都会被放进事务队列，其中的例外就是 EXEC、DISCARD、MULTI 和 WATCH 这四个命令 —— 当这四个命令从客户端发送到服务器时，它们会像客户端处于非事务状态一样，直接被服务器执行。</p><p>如果客户端正处于事务状态，那么当 EXEC 命令执行时，服务器根据客户端所保存的事务队列，以先进先出（FIFO）的方式执行事务队列中的命令： 最先入队的命令最先执行，而最后入队的命令最后执行。</p><p>当事务队列里的 所有命令被执行完之后，EXEC 命令会将回复队列作为自己的执行结果返回给客户端，客户端从事务状态返回到非事务状态，至此，事务执行完毕。</p><p>事务的整个执行过程的伪代码表示：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">def <span class="title function_">execute_transaction</span><span class="params">()</span>:</span><br><span class="line"></span><br><span class="line">    # 创建空白的回复队列</span><br><span class="line">    reply_queue = []</span><br><span class="line"></span><br><span class="line">    # 取出事务队列里的所有命令、参数和参数数量</span><br><span class="line">    <span class="keyword">for</span> cmd, argv, argc in client.transaction_queue:</span><br><span class="line"></span><br><span class="line">        # 执行命令，并取得命令的返回值</span><br><span class="line">        reply = execute_redis_command(cmd, argv, argc)</span><br><span class="line"></span><br><span class="line">    # 将返回值追加到回复队列末尾</span><br><span class="line">    reply_queue.append(reply)</span><br><span class="line"></span><br><span class="line">    # 清除客户端的事务状态</span><br><span class="line">    clear_transaction_state(client)</span><br><span class="line"></span><br><span class="line">    # 清空事务队列</span><br><span class="line">    clear_transaction_queue(client)</span><br><span class="line"></span><br><span class="line">    # 将事务的执行结果返回给客户端</span><br><span class="line">    send_reply_to_client(client, reply_queue)</span><br></pre></td></tr></table></figure><p>优化：上面的 Redis 事务在发送每个指令到事务缓存队列时都要经过一次网络读写，当一个事务内部的指令较多时，需要的网络 IO 时间也会线性增长。所以通常 Redis 客户端在执行事务时都会结合 pipline 一起使用，这样可以将多次 IO 操作压缩为单次 IO 操作。</p><h4 id="5-5-2-事务里的命令"><a href="#5-5-2-事务里的命令" class="headerlink" title="5.5.2 事务里的命令"></a>5.5.2 事务里的命令</h4><p>无论是在事务状态下，还是非事务状态下，Redis 命令都是由同一个函数执行，所有它们共享很多服务器的一般设置，比如 AOF 配置、RDB 的配置，以及内存限制等等。</p><p>事务中的命令执行和普通命令执行主要是两天区别：</p><ol><li>非事务状态下的命令以单个命令执行为单位，前一个命令和后一个命令不一定是同一个客户端。而事务状态则是以一个事务为单位，执行事务队列中的所有命令：除非当前事务执行完毕，否则服务器不会中断事务，也不会执行其他客户端的命令。</li><li>在非事务状态下，执行命令所得的结果会立即被返回给客户端。而事务则将所有命令所得返回结果集合到回复队列，再作为 EXEC 命令的结果返回给客户端。</li></ol><h4 id="5-5-3-DISCARD-、-MULTI-和-WATCH-命令"><a href="#5-5-3-DISCARD-、-MULTI-和-WATCH-命令" class="headerlink" title="5.5.3 DISCARD 、 MULTI 和 WATCH 命令"></a>5.5.3 DISCARD 、 MULTI 和 WATCH 命令</h4><p>除了 EXEC 之外，服务器在客户端处于事务状态下，不加入到事务队列而执行的另外三个命令是：DISCARD 、 MULTI 和 WATCH</p><ul><li>DISCARD：命令用于取消一个事务， 它清空客户端的整个事务队列， 然后将客户端从事务状态调整回非事务状态， 最后返回字符串 OK 给客户端， 说明事务已被取消。</li><li>MULTI：Redis 的事务是不可嵌套的， 当客户端已经处于事务状态， 而客户端又再向服务器发送 <a href="http://redis.readthedocs.org/en/latest/transaction/multi.html#multi">MULTI</a> 时， 服务器只是简单地向客户端发送一个错误， 然后继续等待其他命令的入队。 <a href="http://redis.readthedocs.org/en/latest/transaction/multi.html#multi">MULTI</a> 命令的发送不会造成整个事务失败， 也不会修改事务队列中已有的数据。</li><li>WATCH：只能在客户端进入事务状态之前执行， 在事务状态下发送 WATCH 命令会引发一个错误， 但它不会造成整个事务失败， 也不会修改事务队列中已有的数据（和前面处理 MULTI 的情况一样）</li></ul><h4 id="5-5-4-带-WATCH-的事务"><a href="#5-5-4-带-WATCH-的事务" class="headerlink" title="5.5.4 带 WATCH 的事务"></a>5.5.4 带 WATCH 的事务</h4><p>WATCH 命令用于在事务开始之前监视任意数量的键： 当调用 EXEC 命令执行事务时， 如果任意一个被监视的键已经被其他客户端修改了， 那么整个事务不再执行， 直接返回失败。</p><p>以下示例展示了一个执行失败的事务例子：</p><p>第一个客户端执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; watch name</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379(TX)&gt; set name t</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379(TX)&gt; exec</span><br><span class="line">(nil)</span><br></pre></td></tr></table></figure><p>第二个客户端执行：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; set name tt</span><br><span class="line">OK</span><br></pre></td></tr></table></figure><p>在第一个客户端watch name 之后，事务执行之前，在第二个客户端中 修改 name 的值。这样当第一个客户端的执行事务时，Redis 会发现 name 整个被监视的键 已经被修改，因此客户端A的事务不会被执行，而是直接返回失败。</p><h5 id="WATCH-命令的实现"><a href="#WATCH-命令的实现" class="headerlink" title="WATCH 命令的实现"></a>WATCH 命令的实现</h5><p>在每个代表数据的 redis.h&#x2F;redisDb 结构类型中，都保存了一个 watched_keys 字典，字典的键这个数据库被监视的键，而字典的值则是一个链表，链表中保存了所有监视这个键的客户端。</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779123785-9effddfb-dddd-4212-917f-061e49039521.svg" alt="img"></p><p>其中，键 key1 正在被 client2、client5 和 client1 三个客户端监视，其他一些键也分别被其他客户端监视着。</p><p>WATCH 命令的作用，就是将 当前客户端和要监视的键在 watched_keys 中进行关联。</p><p>举个例子， 如果当前客户端为 client10086 ， 那么当客户端执行 WATCH key1 key2 时， 前面展示的 watched_keys 将被修改成这个样子：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779124149-f5a1f0b8-25ae-428c-8927-910b8c86e485.svg" alt="img"></p><p>通过 watched_keys 字典， 如果程序想检查某个键是否被监视， 那么它只要检查字典中是否存在这个键即可； 如果程序要获取监视某个键的所有客户端， 那么只要取出键的值（一个链表）， 然后对链表进行遍历即可。</p><h5 id="WATCH-的触发"><a href="#WATCH-的触发" class="headerlink" title="WATCH 的触发"></a>WATCH 的触发</h5><p>在任何对数据库键空间（key space）进行修改的命令成功执行之后 （比如 FLUSHDB 、SET、DEL、LPUSH、SADD ，诸如此类）， multi.c&#x2F;touchWatchedKey 函数都会被调用 —— 它检查数据库的 watched_keys 字典， 看是否有客户端在监视已经被命令修改的键， 如果有的话， 程序将所有监视这个&#x2F;这些被修改键的客户端的 REDIS_DIRTY_CAS 选项打开：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779123291-8a135c71-3565-4c56-9dfe-533d255158e9.svg" alt="img"></p><p>当客户端发送 <a href="http://redis.readthedocs.org/en/latest/transaction/exec.html#exec">EXEC</a> 命令、触发事务执行时， 服务器会对客户端的状态进行检查：</p><ul><li>如果客户端的 REDIS_DIRTY_CAS 选项已经被打开，那么说明被客户端监视的键至少有一个已经被修改了，事务的安全性已经被破坏。服务器会放弃执行这个事务，直接向客户端返回空回复，表示事务执行失败。</li><li>如果 REDIS_DIRTY_CAS 选项没有被打开，那么说明所有监视键都安全，服务器正式执行事务。</li></ul><p>举个例子，假设数据库的 watched_keys 字典如下图所示：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779124835-ac785dae-6d6d-4247-bd7f-8209ea924ea4.svg" alt="img"></p><p>如果某个客户端对 key1 进行了修改（比如执行 DEL key1 ）， 那么所有监视 key1 的客户端， 包括 client2 、 client5 和 client1 的 REDIS_DIRTY_CAS 选项都会被打开， 当客户端 client2 、 client5 和 client1 执行 <a href="http://redis.readthedocs.org/en/latest/transaction/exec.html#exec">EXEC</a> 的时候， 它们的事务都会以失败告终。</p><p>最后，当一个客户端结束它的事务时，无论事务是成功执行，还是失败， watched_keys 字典中和这个客户端相关的资料都会被清除。</p><h4 id="5-5-6-事务的-ACID-性质"><a href="#5-5-6-事务的-ACID-性质" class="headerlink" title="5.5.6 事务的 ACID 性质"></a>5.5.6 事务的 ACID 性质</h4><p>传统数据库，常常用 ACID 性质来检验 事务是否安全。Redis 事务保证了 一致性（C）、隔离性（I），但并不能保证 原子性（A）和 持久性（D）。</p><h5 id="原子性（Atomicity）"><a href="#原子性（Atomicity）" class="headerlink" title="原子性（Atomicity）"></a>原子性（Atomicity）</h5><p>单个 Redis 命令执行肯定是 原子性的，但 Redis 没有在事务上增加任何维持原子性的机制，所有 Redis 事务的执行并不是原子性的。</p><p>如果一个事务队列中的所有命令都被成功地执行，那么称这个事务执行成功。另一方面，如果 Redis 服务器进程在执行事务的过程中被停止 —— 比如接到 KILL 信号、宿主机器停机，等等，那么事务执行失败。当事务失败时，Redis 也不会进行任何的重试或者回滚动作。</p><p>简单总结：</p><ul><li>命令入队时就报错，会放弃事务执行，保证原子性。</li><li>命令入队时没报错，实际执行时报错，不保证原子性。</li><li>EXEC 命令执行时实例故障，如果开启 AOF 日志，可以保证原子性。</li></ul><p>其保证的是部分原子性，<strong>可以保证多个命令要么就一起执行，要么就一起不执行</strong>。但是<strong>不能保证 多个命令要么一起执行成功，要么都不执行成功</strong>。入队后，如果有命令执行失败，其之前命令执行操作并不会回退，其之后命令也照常执行。</p><h5 id="一致性（Consistency）"><a href="#一致性（Consistency）" class="headerlink" title="一致性（Consistency）"></a>一致性（Consistency）</h5><p>一致性表示：事务执行结束后，数据库的完整性约束没有被破坏，事务执行的前后顺序都是合法数据状态。</p><ul><li>实体完整性(如行的主键存在且唯一);</li><li>列完整性(如字段的类型、大小、长度要符合要求)</li><li>外键约束;</li><li>用户自定义完整性(如转账前后，两个账户余额的和应该不变)。</li></ul><p>Redis 的一致性问题 可以分为三部分来讨论：入队错误、执行错误、Redis 进程被终结。</p><ol><li>入队错误：在命令入队的过程中，如果客户端向服务器发送了错误的命令，比如命令的参数数量不对，等等， 那么服务器将向客户端返回一个出错信息， 并且将客户端的事务状态设为 REDIS_DIRTY_EXEC 。当客户端执行 EXEC 命令时， Redis 会拒绝执行状态为 REDIS_DIRTY_EXEC 的事务， 并返回失败信息。因此，带有不正确入队命令的事务不会被执行，也不会影响数据库的一致性。</li><li>执行错误：如果命令在事务执行的过程中发生错误，比如说，对一个不同类型的 key 执行了错误的操作， 那么 Redis 只会将错误包含在事务的结果中， 这不会引起事务中断或整个失败，不会影响已执行事务命令的结果，也不会影响后面要执行的事务命令， 所以它对事务的一致性也没有影响。</li><li>Redis 进程被终结如果 Redis 服务器进程在执行事务的过程中被其他进程终结，或者被管理员强制杀死，那么根据 Redis 所使用的持久化模块，可能由以下情况出现：</li></ol><ul><li><ul><li>内存模块：如果 Redis 没有采取任何持久化机制，那么重启后的数据库总是空白的，所以数据总是一致的。</li><li>RDB 模块：在执行事务时，Redis 不会中断事务去执行保存 RDB 的工作，只有在事务执行之后，保存 RDB 的工作才可能开始。所以当RDB 模式下的 Redis 服务器进程在事务中途被杀死时，事务内执行的命令，不管成功了多少，都不会被保存到 RDB 文件里。恢复数据库需要使用现有的 RDB 文件，而这个 RDB 文件的数据保存的是最近一次的数据库快照（snapshot），所以它的数据可能不是最新的，但只要 RDB 文件本身没有因为其他问题而出错，那么还原后的数据库就是一致的。</li><li>AOF 模式：因为保存 AOF 文件的工作在后台线程进行，所以即使是在事务执行的中途，保存 AOF 文件的工作也可以继续进行，因此，根据事务语句是否被写入并保存到 AOF 文件，有以下两种情况发送：</li></ul></li><li><ul><li><ul><li>如果事务语句 未写入到 AOF 文件，或 AOF 未被 SYNC 调用保存到磁盘，那么当进程被杀死之后，Redis 可以根据 最近一次成功保存到 磁盘的 AOF 文件 来还原数据库，只要 AOF 文件本身没有因为其他问题而出错，那么还原后的数据库总是一致的，但其中的数据不一定是最新的。</li><li>如果事务的部分语句 被写入到 AOF 文件中，并且 AOF 文件被成功保存，那么不完整的事务执行信息就会遗留在 AOF 文件里，当重启 Redis 时，程序会检测到 AOF 文件并不完整，Redis 会退出，并报告错误。需要使用 redis-check-aof 工具将部分成功的事务命令移除之后，才能再次启动服务器。还原之后的数据总是一致的，而且数据也是最新的（直到事务执行之前为止）。</li></ul></li></ul></li></ul><h5 id="隔离性（Isolation）"><a href="#隔离性（Isolation）" class="headerlink" title="隔离性（Isolation）"></a>隔离性（Isolation）</h5><p>Redis 是单进程程序，并且它保证在执行事务时，不会对事务进行中断，事务可以运行直到执行完所有事务队列中的命令为止。因此，Redis 的事务是总是带有隔离性的。</p><h5 id="持久性（Durability）"><a href="#持久性（Durability）" class="headerlink" title="持久性（Durability）"></a>持久性（Durability）</h5><p>因为事务不过是用队列包裹了一组 Redis 命令，并没有提供任何额外的持久性功能，所以事务的持久性由 Redis 所使用的持久化模块决定</p><ul><li>单纯的内存模式下，事务肯定是不持久的。</li><li>在 RDB 模块下，服务器可能在事务执行之后、RDB 文件更新之前的这段时间失败，所以 RDB 模式下的 Redis 事务也不持久的。</li><li>在 AOF 的 “总是SYNC” 模式下，事务的每条命令在执行成功之后，都会立即调用 fsync 或 fdatasync 将事务数据写入到 AOF文件。但是，这种保存是由后台线程进行的，主线程不会堵塞直到保存成功。所以命令执行成功到数据保存到硬盘之间，还是有一段非常小的间隔，所以这种模式下的事务也是不持久的。</li></ul><p>其他 AOF 模式也和 “总是SYNC” 模式类似，所以它们都是不持久的。</p><h4 id="5-5-7-小结"><a href="#5-5-7-小结" class="headerlink" title="5.5.7 小结"></a>5.5.7 小结</h4><ul><li>事务提供了一种将多个命令打包，然后一次性、有序地执行的机制。</li><li>事务在执行过程中不会被中断，所有事务命令执行完之后，事务才能结束。</li><li>多个命令会被入队到事务队列中，然后按先进先出（FIFO）的顺序执行。</li><li>带 WATCH 命令的事务会将客户端和被监视的键在数据库的 watched_keys 字典中进行关联，当键被修改时，程序会将所有监视被修改键的客户端的 REDIS_DIRTY_CAS 选项打开。</li><li>只有在客户端的 REDIS_DIRTY_CAS 选项未被打开时，才能执行事务，否则事务直接返回失败。</li><li>Redis 的事务保证了 ACID 中的一致性（C）和隔离性（I），但并不保证原子性（A）和持久性（D）。</li></ul><h3 id="5-6-订阅与发布"><a href="#5-6-订阅与发布" class="headerlink" title="5.6 订阅与发布"></a>5.6 订阅与发布</h3><p>Redis 通过 PUBLISH、SUBSCRIBE等命令实现了订阅与发布模式， 这个功能提供两种信息机制， 分别是订阅&#x2F;发布到频道和订阅&#x2F;发布到模式， 下文先讨论订阅&#x2F;发布到频道的实现， 再讨论订阅&#x2F;发布到模式的实现。</p><h4 id="5-6-1-频道的订阅与信息发送"><a href="#5-6-1-频道的订阅与信息发送" class="headerlink" title="5.6.1 频道的订阅与信息发送"></a>5.6.1 频道的订阅与信息发送</h4><p>Redis 的 SUBSCRIBE 命令可以让客户端订阅任意数量的频道，每当有新消息发送到被订阅的频道时，信息就会被发送给所有订阅指定频道的客户端。</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779124262-ac7f1f60-b21b-44a8-810f-6f10ac13eab1.svg" alt="img"></p><p>当有新消息通过 <a href="http://redis.readthedocs.org/en/latest/pub_sub/publish.html#publish">PUBLISH</a> 命令发送给频道 channel1 时， 这个消息就会被发送给订阅它的三个客户端：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779126625-3d2dbe1a-b372-47b6-9a25-e937747ce3fa.svg" alt="img"></p><h5 id="订阅频道"><a href="#订阅频道" class="headerlink" title="订阅频道"></a>订阅频道</h5><p>每个 Redis 服务器进程都维持着一个表示服务器状态的 redis.h&#x2F;redisServer 结构，结构的 pubsub_channels 属性是一个字典，这个字典就用于保存订阅频道的信息。</p><p>其中，字典的键为正在被订阅的频道，而字典的值则是一个链表，链表中保存了所有订阅这个频道的客户端。</p><p>比如说，在下图展示的这个 pubsub_channels 示例中， client2 、 client5 和 client1 就订阅了 channel1 ， 而其他频道也分别被别的客户端所订阅：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779126861-01cd5b87-621a-4c11-8997-fd32e7124cde.svg" alt="img"></p><p>当客户端调用 <a href="http://redis.readthedocs.org/en/latest/pub_sub/subscribe.html#subscribe">SUBSCRIBE</a> 命令时， 程序就将客户端和要订阅的频道在 pubsub_channels 字典中关联起来。</p><p>举个例子，如果客户端 client10086 执行命令 SUBSCRIBE channel1 channel2 channel3 ，那么前面展示的 pubsub_channels 将变成下面这个样子：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779127981-4b8e7194-f9c9-4e88-b812-b9f8594061e9.svg" alt="img"></p><p>通过 pubsub_channels 字典， 程序只要检查某个频道是否为字典的键， 就可以知道该频道是否正在被客户端订阅； 只要取出某个键的值， 就可以得到所有订阅该频道的客户端的信息。</p><h5 id="发送信息到频道"><a href="#发送信息到频道" class="headerlink" title="发送信息到频道"></a>发送信息到频道</h5><p>了解了 pubsub_channels 字典的结构之后， 解释 <a href="http://redis.readthedocs.org/en/latest/pub_sub/publish.html#publish">PUBLISH</a> 命令的实现就非常简单了： 当调用 PUBLISH channel message 命令， 程序首先根据 channel 定位到字典的键， 然后将信息发送给字典值链表中的所有客户端。</p><p>比如说，对于以下这个 pubsub_channels 实例， 如果某个客户端执行命令 PUBLISH channel1 “hello moto” ，那么 client2 、 client5 和 client1 三个客户端都将接收到 “hello moto” 信息：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779127370-c53aa587-36b5-4a1e-8777-e74917f5ece7.svg" alt="img"></p><h5 id="退订频道"><a href="#退订频道" class="headerlink" title="退订频道"></a>退订频道</h5><p>使用 UNSUBSCRIBE 命令可以退订指定的频道， 这个命令执行的是订阅的反操作： 它从 pubsub_channels 字典的给定频道（键）中， 删除关于当前客户端的信息， 这样被退订频道的信息就不会再发送给这个客户端。</p><h4 id="5-6-2-模式的订阅与信息发送"><a href="#5-6-2-模式的订阅与信息发送" class="headerlink" title="5.6.2 模式的订阅与信息发送"></a>5.6.2 模式的订阅与信息发送</h4><p>当使用 PUBLISH 命令发送信息到某个频道时，不仅所有订阅该频道的客户端会收到信息，如果有 某个&#x2F;某些 模式和 这个频道匹配的话，那么所有订阅 这个&#x2F;这些 频道的客户端也同样会受到信息。</p><p>下图展示了一个带有频道和模式的例子， 其中 tweet.shop.* 模式匹配了 tweet.shop.kindle 频道和 tweet.shop.ipad 频道， 并且有不同的客户端分别订阅它们三个：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779128616-e784de68-42e6-4095-bcf0-60e9c43986ec.svg" alt="img"></p><p>当有信息发送到 tweet.shop.kindle 频道时， 信息除了发送给 clientX 和 clientY 之外， 还会发送给订阅 tweet.shop.* 模式的 client123 和 client256 ：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779128540-cc69dd3a-5458-471e-aaeb-84a2e7a04712.svg" alt="img"></p><p>另一方面， 如果接收到信息的是频道 tweet.shop.ipad ， 那么 client123 和 client256 同样会收到信息：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779131307-fa5396f0-9c11-438a-b6ed-492143caca5c.svg" alt="img"></p><h5 id="订阅模式"><a href="#订阅模式" class="headerlink" title="订阅模式"></a>订阅模式</h5><p>redisServer.pubsub_patterns 属性是一个链表，链表中保存着所有和模式相关的信息。</p><p>链表中的每个节点都包含一个 redis.h&#x2F;pubsubPattern 结构：</p><p>client 属性保存着订阅模式的客户端，而 pattern 属性则保存着被订阅的模式。</p><p>每当调用 PSUBSCRIBE 命令订阅一个模式时， 程序就创建一个包含客户端信息和被订阅模式的 pubsubPattern 结构， 并将该结构添加到 redisServer.pubsub_patterns 链表中。</p><p>作为例子，下图展示了一个包含两个模式的 pubsub_patterns 链表， 其中 client123 和 client256 都正在订阅 tweet.shop.* 模式：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779131253-176aab8f-481e-490a-8bdd-e31d5c0d0268.svg" alt="img"></p><p>如果这时客户端 client10086 执行 PSUBSCRIBE broadcast.list.* ， 那么 pubsub_patterns 链表将被更新成这样：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779133621-3a05dd6e-3664-4953-abb2-eca5a3de291e.svg" alt="img"></p><p>通过遍历整个 pubsub_patterns 链表，程序可以检查所有正在被订阅的模式，以及订阅这些模式的客户端。</p><h5 id="发送信息到模式"><a href="#发送信息到模式" class="headerlink" title="发送信息到模式"></a>发送信息到模式</h5><p>发送信息到模式的工作也是由 PUBLISH 命令进行的。 PUBLISH 除了将 message 发送到所有订阅 channel 的客户端之外，它还会将 channel 和 pubsub_pattern 中的模式进行对比，如果 channel 和某个模式匹配的话，那么也将 message 发送到订阅那个模式的客户端。</p><p>举个例子，如果 Redis 服务器的 pubsub_patterns 状态如下：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/svg/35838370/1682779131145-01a1aea3-c788-4cfa-aae6-91390a521463.svg" alt="img"></p><p>那么当某个客户端发送信息 “Amazon Kindle, $69.” 到 tweet.shop.kindle 频道时， 除了所有订阅了 tweet.shop.kindle 频道的客户端会收到信息之外， 客户端 client123 和 client256 也同样会收到信息， 因为这两个客户端订阅的 tweet.shop.* 模式和 tweet.shop.kindle 频道匹配。</p><h5 id="退订模式"><a href="#退订模式" class="headerlink" title="退订模式"></a>退订模式</h5><p>使用 PUNSUBSCRIBE 命令可以退订指定的模式， 这个命令执行的是订阅模式的反操作： 程序会删除 redisServer.pubsub_patterns 链表中， 所有和被退订模式相关联的 pubsubPattern 结构， 这样客户端就不会再收到和模式相匹配的频道发来的信息。</p><h4 id="5-6-3-小结"><a href="#5-6-3-小结" class="headerlink" title="5.6.3 小结"></a>5.6.3 小结</h4><p>要点：</p><ul><li>订阅信息由服务器进程维持的 redisServer.pubsub_channels 字典保存，字典的键为被订阅的频道，字典的值为订阅频道的所有客户端。</li><li>当有新消息发送到频道时，程序遍历频道（键）所对应的（值）所有客户端，然后将消息发送到所有订阅频道的客户端上。</li><li>订阅模式的信息由服务器进程维持的 redisServer.pubsub_patterns 链表保存，链表的每个节点都保存着一个 pubsubPattern 结构，结构中保存着被订阅的模式，以及订阅该模式的客户端。程序通过遍历链表来查找某个频道是否和某个模式匹配。</li><li>当有新消息发送到频道时，除了订阅频道的客户端会收到消息之外，所有订阅了匹配频道的模式的客户端，也同样会收到消息。</li><li>退订频道和退订模式分别是订阅频道和订阅模式的反操作。</li></ul><p>缺点：</p><p>PubSub 的生产者产地过来一个消息，Redis 会直接找到相应的消费者传递过去。如果一个消费者也没有，那么消息直接丢弃。如果开始有三个消费者，一个消费者突然挂掉了，生产者会继续发送消息，另外两个消费者可以持续受到消息。但是挂掉的消费者重新连上的时候，这断连期间生产者发送的消息，对于这个消费者来说就彻底消失了。</p><p>如果 Redis 停机重启，PubSub 的消息是不会持久化的，毕竟 Redis 宕机就相当于一个消费者都没有，所有的消息直接丢弃。</p><p>正是因为 PubSub 有这些缺点，它几乎找不到合适的应用场景。所以 Redis 的作者单独开启了一个项目 Disque 专门做 多播消息队列。</p><p>github地址：<a href="https://github.com/antirez/disque-module%E3%80%82%E4%BD%86%E6%98%AF%E5%9C%A8">https://github.com/antirez/disque-module。但是在</a> Redis5.0 新增了 Stream 数据结构，这个功能给 Redis 带来了持久化消息队列，从此 PubSub 可以消失了，Disqueue 估计也不会发出它的正式版了。</p><h3 id="5-7-Redis集群模式—主从复制"><a href="#5-7-Redis集群模式—主从复制" class="headerlink" title="5.7 Redis集群模式—主从复制"></a>5.7 Redis集群模式—主从复制</h3><p><a href="https://pdai.tech/md/db/nosql-redis/db-redis-x-copy.html">https://pdai.tech/md/db/nosql-redis/db-redis-x-copy.html</a></p><p>我们知道要避免单点故障，即保证高可用，便需要冗余（副本）方式提供集群服务。而 Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离 的方式。</p><h4 id="5-7-1-主从复制概述"><a href="#5-7-1-主从复制概述" class="headerlink" title="5.7.1 主从复制概述"></a>5.7.1 主从复制概述</h4><p>主从复制，是指将一台 Redis 服务器的数据，复制到其他的 Redis 服务器。前者称为 主节点（master），后者称为 从节点（slave）。数据的复制是单向的，只能从 主节点 到 从节点。</p><p><strong>主从复制的作用</strong>主要包括：</p><ul><li><strong>数据冗余</strong>：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。</li><li><strong>故障恢复</strong>：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。</li><li><strong>负载均衡</strong>：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。</li><li><strong>高可用基石</strong>：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。</li></ul><p>主从库之间采用的是<strong>读写分离</strong>的方式。</p><ul><li>读操作：主库、从库都可以接收；</li><li>写操作：首先到主库执行，然后，主库将写操作同步给从库。</li></ul><p>在 2.8 版本之前，只有全量复制，而2.8版本之后有全量和增量复制</p><ul><li>全量（同步）复制：比如第一次同步时</li><li>增量（同步）复制：只会把主从库网络断连期间主库收到的命令，同步给从库。</li></ul><h4 id="5-7-2-全量复制"><a href="#5-7-2-全量复制" class="headerlink" title="5.7.2 全量复制"></a>5.7.2 全量复制</h4><p>当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步</p><ul><li>建立主从关系</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"># 这里我们创建了 两个 redis 实例</span><br><span class="line">[root@VM-4-9-centos ~]# docker run -it -d --name redis2 -p 6379:6379 redis</span><br><span class="line">9865ef807588457b05a4353a5c4a1699486343abab71d6682f98a6bc27497961</span><br><span class="line">[root@VM-4-9-centos ~]# docker run -it -d --name redis1 -p 6380:6379 redis</span><br><span class="line">f21ca2cacfea46f1b05baffffdafc9c46f76482cdea3d018ff7196469b75c6e9</span><br><span class="line"></span><br><span class="line"># 查看所有容器的 ip地址</span><br><span class="line">[root@VM-4-9-centos ~]# docker inspect -f &#x27;&#123;&#123;.Name&#125;&#125; - &#123;&#123;.NetworkSettings.IPAddress &#125;&#125;&#x27; $(docker ps -aq)</span><br><span class="line">/redis2 - 172.17.0.5</span><br><span class="line">/redis1 - 172.17.0.4</span><br><span class="line"></span><br><span class="line"># 使用 redis1 容器的 redis命令行，存入 key=name,value=kongxr</span><br><span class="line">[root@VM-4-9-centos ~]#  docker exec -it redis1 /bin/bash</span><br><span class="line">root@f21ca2cacfea:/data# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; set name kongxr</span><br><span class="line">OK</span><br><span class="line"></span><br><span class="line"># 使用 reids2容器内的 redis命令行。查询key=name，未获取到值。</span><br><span class="line"># 然后使用同步命令将redis2 作为从库，建立主从关系，并同步数据</span><br><span class="line">[root@VM-4-9-centos ~]# docker exec -it redis2 /bin/bash</span><br><span class="line">root@9865ef807588:/data# redis-cli</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">(nil)</span><br><span class="line">127.0.0.1:6379&gt; replicaof 172.17.0.4 6379</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">(nil)</span><br><span class="line">127.0.0.1:6379&gt; get name</span><br><span class="line">&quot;kongxr&quot;</span><br></pre></td></tr></table></figure><p>从上面的测试，可以看到 在建立主从关系后，从库会慢慢从主库中同步全量数据。</p><ul><li><p>全量复制的三个阶段</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779131543-769d79b6-8fbc-49bd-9f96-2cd53b6554a7-20250605100935711.jpeg" alt="img"></p></li></ul><ol><li><ol><li><strong>第一阶段是主从库间建立连接、协商同步的过程，主要是为了全量复制做准备。</strong>在这一步，从库和主库建立连接，并告诉主库即将开始进行同步，主库确认回复后，主从库间就可以开始同步了。具体的来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包括了主库的 runID 和 复制进度 offset 两个参数。runID，是每个 Redis 实例启动时都会自动生成的一个随机ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为 “?” 。offset，此时设为 -1，表示第一次复制。主库收到 psync 命令后，会用 FULLRESYNC 响应命令带上 两个参数：主库 runID 和主库目前的复制进度 offset ，返回给从库。从库收到响应后，会记录下这两个参数。这里有个地方需要注意，FULLRESYNC 响应表示第一次复制采用的全量复制，也就是说，主库会把当前所有的数据都复制给从库。</li><li><strong>第二个阶段，主库将所有数据同步给从库。</strong>从库收到数据后，在本地完成数据加载。这个过程依赖于内存快照生成 RDB 文件。具体来说，主库执行 bgsave 命令，生成 RDB 文件，接着将文件发送给从库。从库接收到 RDB 文件后，会先清空当前数据库，然后加载 RDB 文件。这是因为从库在通过 replicaof 命令开始和主库同步前，可能保存了其他数据。为了避免之前数据的影响，从库需要先把当前数据库清空。在主库将数据同步给从库的过程中，主库不会被堵塞，仍然可以正常接受请求。但是，请求中的写操作并没有记录到刚刚生成的 RDB 文件中。为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。</li><li><strong>第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发给从库。</strong>具体的操作是，当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样以来，主从库就实现同步了。</li></ol></li></ol><h4 id="5-7-3-增量复制"><a href="#5-7-3-增量复制" class="headerlink" title="5.7.3 增量复制"></a>5.7.3 增量复制</h4><p>在 Redis 2.8 版本引入了增量复制</p><ul><li><p>为什么会设计增量复制？如果主从库在命令传播时出现了网络闪断，那么从库就会和主库重新进行一次全量复制，开销非常大。从 Redis 2.8开始，网络断了之后，主从库会采用增量复制的方式继续同步。</p></li><li><p>增量复制流程</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779133615-180cf488-8310-45f7-9e35-8cea064b2119-20250605100916148.jpeg" alt="img"></p></li><li><p>先看两个概念： replication buffer 和 repl_backlog_bufferrepl_backlog_buffer：它是为了从库断开之后，如何找到主从差异数据而设计的环形缓冲区，从而避免全量复制带来的性能开销。如果从库断开时间太久，repl_backlog_buffer环形缓冲区被主库的写命令覆盖了，那么从库连上主库后只能乖乖地进行一次全量复制，所以<strong>repl_backlog_buffer配置尽量大一些，可以降低主从断开后全量复制的概率</strong>。而在repl_backlog_buffer中找主从差异的数据后，如何发给从库呢？这就用到了replication buffer。replication buffer：Redis和客户端通信也好，和从库通信也好，Redis都需要给分配一个 内存buffer进行数据交互，客户端是一个client，从库也是一个client，我们每个client连上Redis后，Redis都会分配一个client buffer，所有数据交互都是通过这个buffer进行的：Redis先把数据写到这个buffer中，然后再把buffer中的数据发到client socket中再通过网络发送出去，这样就完成了数据交互。所以主从在增量同步时，从库作为一个client，也会分配一个buffer，只不过这个buffer专门用来传播用户的写命令到从库，保证主从数据一致，我们通常把它叫做replication buffer。对于这个问题来说，有两个关键点：</p></li><li><ul><li><strong>如果在网络断开期间，repl_backlog_size环形缓冲区写满之后，从库是会丢失掉那部分被覆盖掉的数据，还是直接进行全量复制呢</strong>？</li></ul></li></ul><ol><li><ol><li>一个从库如果和主库断连时间过长，造成它在主库repl_backlog_buffer的slave_repl_offset位置上的数据已经被覆盖掉了，此时从库和主库间将进行全量复制。</li><li>每个从库会记录自己的slave_repl_offset，每个从库的复制进度也不一定相同。在和主库重连进行恢复时，从库会通过psync命令把自己记录的slave_repl_offset发给主库，主库会根据从库各自的复制进度，来决定这个从库可以进行增量复制，还是全量复制。</li></ol></li></ol><h4 id="5-7-4-更多理解"><a href="#5-7-4-更多理解" class="headerlink" title="5.7.4 更多理解"></a>5.7.4 更多理解</h4><h5 id="1-当主服务器不进行持久化时-复制的安全性"><a href="#1-当主服务器不进行持久化时-复制的安全性" class="headerlink" title="1.当主服务器不进行持久化时 复制的安全性"></a>1.当主服务器不进行持久化时 复制的安全性</h5><p>强烈建议主服务器开启持久化。如果真的不能开启持久化，那么一定要禁止Redis实例自动重启。</p><p>为什么不持久化的主服务器自动重启非常危险呢？为了更好的理解这个问题，看下面这个失败的例子，其中主服务器和从服务器中数据库都被删除了。</p><ul><li>我们设置节点A为主服务器，关闭持久化，节点B和C从节点A复制数据。</li><li>这时出现了一个崩溃，但Redis具有自动重启系统，重启了进程，因为关闭了持久化，节点重启后只有一个空的数据集。</li><li>节点B和C从节点A进行复制，现在节点A是空的，所以节点B和C上的复制数据也会被删除。</li><li>当在高可用系统中使用Redis Sentinel，关闭了主服务器的持久化，并且允许自动重启，这种情况是很危险的。比如主服务器可能在很短的时间就完成了重启，以至于Sentinel都无法检测到这次失败，那么上面说的这种失败的情况就发生了。</li></ul><p>如果数据比较重要，并且在使用主从复制时关闭了主服务器持久化功能的场景中，都应该禁止实例自动重启。</p><h5 id="2-为什么主从全量复制使用-RDB-而不使用-AOF？"><a href="#2-为什么主从全量复制使用-RDB-而不使用-AOF？" class="headerlink" title="2.为什么主从全量复制使用 RDB 而不使用 AOF？"></a>2.为什么主从全量复制使用 RDB 而不使用 AOF？</h5><ul><li>RDB 文件内容时经过压缩的 二进制数据（不同数据类型数据做了针对性优化），文件很小。而 AOF 文件记录的是 每一次写操作的命令，写操作越多文件会变得很大，其中还包括很多对同一个 key 的多次冗余操作。在主从全量数据同步时，传输 RDB 文件可以尽量降低对主库机器网络带宽的消耗，从库在加载 RDB 文件时，一是文件小，读取整个文件的速度会很快，二是因为RDB文件存储的都是二进制数据，从库直接按照RDB协议解析还原数据即可，速度会非常快，而AOF需要依次重放每个写命令，这个过程会经历冗长的处理逻辑，恢复速度相比 RDB 会慢得多，所以使用 RDB 进行主从全量复制的成本最低。</li><li>假设要使用 AOF 做全量复制，意味着必须打开 AOF 功能，打开 AOF 功能就要选择文件的刷盘的策略，选择不当会严重影响 Redis 性能。而 RDB 只有在需要定时备份和主从全量复制数据时，才会触发生成一次快照。而在很多就是数据不敏感的业务场景，其实时不需要开启 AOF 的。</li></ul><h5 id="3-为什么有无磁盘复制模式？"><a href="#3-为什么有无磁盘复制模式？" class="headerlink" title="3.为什么有无磁盘复制模式？"></a>3.为什么有无磁盘复制模式？</h5><p>Redis 默认时磁盘复制，但是如果使用比较低速的磁盘，这种操作会给主服务器带来比较大的压力。Redis从2.8.18版本开始尝试支持无磁盘的复制。使用这种设置时，子进程直接将RDB通过网络发送给从服务器，不使用磁盘作为中间存储。</p><p><strong>无磁盘复制模式</strong>：master创建一个新进程直接dump RDB到slave的socket，不经过主进程，不经过硬盘。适用于disk较慢，并且网络较快的时候。</p><p>使用repl-diskless-sync配置参数来启动无磁盘复制。</p><p>使用repl-diskless-sync-delay 参数来配置传输开始的延迟时间；master等待一个repl-diskless-sync-delay的秒数，如果没slave来的话，就直接传，后来的得排队等了; 否则就可以一起传。</p><h5 id="4-为什么还有-从库的从库的设计？"><a href="#4-为什么还有-从库的从库的设计？" class="headerlink" title="4.为什么还有 从库的从库的设计？"></a>4.为什么还有 从库的从库的设计？</h5><p>通过分析主从库间第一次数据同步的过程，你可以看到，一次全量复制中，对于主库来说，需要完成两个耗时的操作：<strong>生成 RDB 文件和传输 RDB 文件</strong>。</p><p>如果从库数量很多，而且都要和主库进行全量复制的话，就会导致主库忙于 fork 子进程生成 RDB 文件，进行数据全量复制。fork 这个操作会阻塞主线程处理正常请求，从而导致主库响应应用程序的请求速度变慢。此外，传输 RDB 文件也会占用主库的网络带宽，同样会给主库的资源使用带来压力。那么，有没有好的解决方法可以分担主库压力呢？</p><p>其实是有的，这就是“主 - 从 - 从”模式。</p><p>在刚才介绍的主从库模式中，所有的从库都是和主库连接，所有的全量复制也都是和主库进行的。现在，我们可以通过“主 - 从 - 从”模式<strong>将主库生成 RDB 和传输 RDB 的压力，以级联的方式分散到从库上</strong>。</p><p>简单来说，我们在部署主从集群的时候，可以手动选择一个从库（比如选择内存资源配置较高的从库），用于级联其他的从库。然后，我们可以再选择一些从库（例如三分之一的从库），在这些从库上执行如下命令，让它们和刚才所选的从库，建立起主从关系。</p><p>replicaof 所选从库的IP 6379</p><p>这样一来，这些从库就会知道，在进行同步时，不用再和主库进行交互了，只要和级联的从库进行写操作同步就行了，这就可以减轻主库上的压力，如下图所示：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779133018-6c82f9a9-6735-48d3-953f-9a4410adf454-20250605100846437.jpeg" alt="img"></p><p>级联的“主-从-从”模式好了，到这里，我们了解了主从库间通过全量复制实现数据同步的过程，以及通过“主 - 从 - 从”模式分担主库压力的方式。那么，一旦主从库完成了全量复制，它们之间就会一直维护一个网络连接，主库会通过这个连接将后续陆续收到的命令操作再同步给从库，这个过程也称为基于长连接的命令传播，可以避免频繁建立连接的开销。</p><h5 id="5-读写分离及其中的问题"><a href="#5-读写分离及其中的问题" class="headerlink" title="5.读写分离及其中的问题"></a>5.读写分离及其中的问题</h5><p>在主从复制基础上实现的读写分离，可以实现 Redis 的读负载均衡：由主节点提供写服务，由一个或者多个从节点提供读服务（多个从节点既可以提供数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可以大大提高 Redis 服务器的并发量。下面介绍在使用 Redis 读写分离时，需要注意的问题：</p><ul><li><strong>延迟与不一致问题</strong></li></ul><p>前面已经讲到，由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；使用集群同时扩展写负载和读负载等。</p><p>在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。从节点的slave-serve-stale-data参数便与此有关：它控制这种情况下从节点的表现；如果为yes（默认值），则从节点仍能够响应客户端的命令，如果为no，则从节点只能响应info、slaveof等少数命令。该参数的设置与应用对数据一致性的要求有关；如果对数据一致性要求很高，则应设置为no。</p><ul><li><strong>数据过期问题</strong></li></ul><p>在单机版Redis中，存在两种删除策略：</p><ul><li>惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。</li><li>定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。</li></ul><p>在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。</p><p>Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。</p><ul><li><strong>故障切换问题</strong></li></ul><p>在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。</p><ul><li><strong>总结</strong></li></ul><p>在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。</p><h3 id="5-8-Redis集群模式—-哨兵机制（Redis-Sentinel）"><a href="#5-8-Redis集群模式—-哨兵机制（Redis-Sentinel）" class="headerlink" title="5.8 Redis集群模式— 哨兵机制（Redis Sentinel）"></a>5.8 Redis集群模式— 哨兵机制（Redis Sentinel）</h3><p>在上文主从复制的基础上，如果节点出现故障该怎么办？在 Redis 集群中，哨兵机制是实现主从库自动切换的关键机制，它有效的解决了主从复制模式下的故障转移的问题。其与Redis2.8版本开始引用。</p><p><a href="https://xie.infoq.cn/article/f6a8c0c5218394d56f4ae329b">https://xie.infoq.cn/article/f6a8c0c5218394d56f4ae329b</a></p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779133444-1385070f-a6ee-4915-83e1-ec451d704df0-20250605100839770.png" alt="img"></p><p><strong>哨兵是一个独立的进程，作为进程，它会独立运行其原理是哨兵通过发送命令，等待Redis服务器响应，从而监控运行的多个 Redis 实例</strong></p><p>哨兵实现了什么功能呢？下面是 Redis 官方文档的描述：</p><ul><li><strong>监控（Monitoring）</strong>：哨兵会不断地检查主节点和从节点是否运作正常。</li><li><strong>自动故障转移（Automatic failover）</strong>：当主节点不能正常工作时，哨兵会开始自动故障转移操作，它会将失效主节点的其中一个从节点升级为新的主节点，并让其他从节点改为复制新的主节点。</li><li><strong>配置提供者（Configuration provider）</strong>：客户端在初始化时，通过连接哨兵来获得当前Redis服务的主节点地址。</li><li><strong>通知（Notification）</strong>：哨兵可以将故障转移的结果发送给客户端。</li></ul><p>其中，监控和自动故障转移功能，使得哨兵可以及时发现主节点故障并完成转移；而配置提供者和通知功能，则需要在与客户端的交互中才能体现。</p><h4 id="5-8-1-哨兵集群的搭建"><a href="#5-8-1-哨兵集群的搭建" class="headerlink" title="5.8.1 哨兵集群的搭建"></a>5.8.1 哨兵集群的搭建</h4><p>上图中哨兵集群式如何组建起来的？哨兵实例之间相互发现，要归功于 Redis 提供的 pub&#x2F;sub 机制，即 发布&#x2F;订阅机制</p><p>在主从集群中，主库上由一个名为 <strong>sentinel</strong>:hello 的频道，不同哨兵就是通过它来相互发现，实现互相通信的。在下图，哨兵1把自己的 IP（172.16.19.3）和端口（26579）发布到__sentinel__:hello频道上，哨兵2和3订阅了该频道。那么此时，哨兵2和3就可以从这个频道直接获取哨兵1的 IP 地址和端口号。然后，哨兵2、3可以和哨兵1建立网络连接。</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779137211-0ab99635-9d14-4bb2-a004-b883c255b4df-20250605100831797.jpeg" alt="img"></p><p>通过这个方式，哨兵2、3也可以建立网络连接，这样一来，哨兵集群就形成了。它们相互间可以通过网络连接进行通信，比如说对主库有没有下线这件事儿进行判断和协商。</p><h4 id="5-8-2-哨兵监控-Redis-库"><a href="#5-8-2-哨兵监控-Redis-库" class="headerlink" title="5.8.2 哨兵监控 Redis 库"></a>5.8.2 哨兵监控 Redis 库</h4><p>哨兵监控什么？并且如何完成监控的？</p><p>这是由哨兵向主库发送 INFO命令完成的。如下图，哨兵2给主库发送 INFO命令，主库接受到这个命令后，就会把从库列表返回给哨兵。接着，哨兵就可以根据从库列表中的连接信息，和每个从库建立连接，并在这个连接上持续的对从库进行监控。哨兵1和3 可以通过相同的方法和从库建立连接。</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779137974-8096b7fe-4c89-4541-99ac-b892ab0c5489-20250605100826937.jpeg" alt="img"></p><p>哨兵的工作内容：</p><ul><li><strong>每个 Sentinel 以每秒钟一次的频率向它所知的 Master，Slave 以及其他 Sentinel 实例发送一个 PING 命令</strong>。(<strong>心跳机制</strong>)</li><li><strong>如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel 标记为主观下线</strong>。</li><li><strong>如果一个 Master 被标记为主观下线，则正在监视这个 Master 的所有 Sentinel 要以每秒一次的频率确认 Master 的确进入了主观下线状态</strong>。（<strong>确认投票下线</strong>）</li><li><strong>当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认 Master 的确进入了主观下线状态， 则 Master 会被标记为客观下线</strong> 。</li><li><strong>在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有 Master，Slave 发送 INFO 命令</strong>。（同步数据）</li><li><strong>当 Master 被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次</strong>。</li><li><strong>若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会被移除</strong>。</li><li><strong>若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除</strong>。</li></ul><h4 id="5-8-3-主库下线的判定"><a href="#5-8-3-主库下线的判定" class="headerlink" title="5.8.3 主库下线的判定"></a>5.8.3 主库下线的判定</h4><p>哨兵如何判断主库已经下线了？</p><p>首先要区别两个概念：</p><ul><li>主观下线：任何一个哨兵都是可以监控探测，并作出 Redis 下线的判断</li><li>客观下线：有哨兵集群共同决定 Redis 节点是否下线</li></ul><p>当某个哨兵 判断主库 “主观下线”后，就会给其他哨兵发送 is-master-down-by-addr命令。接着，其他哨兵会根据自己和主库的连接情况，做出 Y 或 N 的响应，Y相当于赞成票，N相当于反对票。如果赞成票数是大于等于 哨兵配置文件中的 quorum 配置项（比如这里如果 quorum &#x3D; 2），则就可以判定 主库客观下线了。</p><h4 id="5-8-4-哨兵集群的选举"><a href="#5-8-4-哨兵集群的选举" class="headerlink" title="5.8.4 哨兵集群的选举"></a>5.8.4 哨兵集群的选举</h4><p>判断完主库下线后，由哪个哨兵节点来执行主从切换呢？这里就需要哨兵集群的选举机制了</p><ul><li>为什么必然会出现 选举&#x2F;共识 机制？为了避免哨兵的单点情况发生，所以需要一个哨兵的分布式集群。作为分布式集群，必然涉及到共识问题（即选举问题）</li><li>哨兵的选举机制是什么样的?</li></ul><ol><li><ol><li><strong>发现主库客观下线的哨兵节点（这里称为 A）向每个哨兵节点发送命令要求对方选举自己为领头哨兵（leader）</strong>；</li><li><strong>如果目标哨兵没有选举过其他人，则同意将 A 选举为领头哨兵</strong>；</li><li><strong>如果 A 发现有超过半数且超过 quorum 参数值的哨兵节点同意选自己成为领头哨兵，则 A 哨兵成功选举为领头哨兵</strong>。【<strong>sentinel 集群执行故障转移时需要选举 leader，此时涉及到 majority，majority 代表 sentinel 集群中大部分 sentinel 节点的个数，只有大于等于 max(quorum, majority) 个节点给某个 sentinel 节点投票，才能确定该 sentinel 节点为 leader，majority 的计算方式为：num(sentinels) &#x2F; 2 + 1</strong>】</li><li><strong>当有多个哨兵节点同时参与领头哨兵选举时，出现没有任何节点当选可能，此时每个参选节点等待一个随机时间进行下一轮选举，直到选出领头哨兵</strong>。</li></ol></li></ol><ul><li><p>任何一个想要 执行 主从切换操作的 哨兵，要满足两个条件：</p></li><li><ul><li>第一，拿到半数以上的赞成票；</li><li>第二，拿到的票数同时还需要大于等于哨兵配置文件中的 quorum 值。</li></ul></li></ul><p>以3个哨兵为例，假设此时的 quorum 设置为2，那么，任何一个想成为 Leader 的哨兵只要拿到 2张赞成票，就可以了。</p><p>更进一步理解</p><p>这里很多人会搞混 判定客观下线 和 是否能够主从切换（用到选举机制） 两个概念，我们再看一个例子。</p><p>Redis 1主4从，5个哨兵，哨兵配置quorum为2，如果3个哨兵故障，当主库宕机时，哨兵能否判断主库“客观下线”？能否自动切换</p><p>经过实际测试：</p><p>1、哨兵集群可以判定主库“主观下线”。由于quorum&#x3D;2，所以当一个哨兵判断主库“主观下线”后，询问另外一个哨兵后也会得到同样的结果，2个哨兵都判定“主观下线”，达到了quorum的值，因此，<strong>哨兵集群可以判定主库为“客观下线”</strong>。</p><p>2、<strong>但哨兵不能完成主从切换</strong>。哨兵标记主库“客观下线后”，在选举“哨兵领导者”时，一个哨兵必须拿到超过多数的选票(5&#x2F;2+1&#x3D;3票)。但目前只有2个哨兵活着，无论怎么投票，一个哨兵最多只能拿到2票，永远无法达到N&#x2F;2+1选票的结果。</p><h4 id="5-8-5-新主库的选出、故障转移"><a href="#5-8-5-新主库的选出、故障转移" class="headerlink" title="5.8.5 新主库的选出、故障转移"></a>5.8.5 新主库的选出、故障转移</h4><p>主库既然判定客观下线了，并且选举出了领头哨兵，那么如何从剩余的 slave节点（从库）中选择一个新的主库呢？</p><ul><li>过滤掉不健康的（下线或断线），没有回复过哨兵 ping 响应的从节点</li><li>选择 salve-priority从节点优先级最高的（redis.conf）</li><li>选择复制偏移量最大（即复制主节点最完整的从节点）</li></ul><p>新的主库选择出来了，就可以开始进行故障的转移了</p><p>假设根据我们一开始的图：（我们假设：判断主库客观下线了，同时选出sentinel 3是哨兵leader）</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779138232-d32bebb3-1e76-46dc-86d6-36e088a21802-20250605100820125.png" alt="img"></p><p><strong>故障转移流程如下</strong>：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779138529-f55bef09-55ec-4955-9c4d-5154ed2a03a3.png" alt="img"></p><p>将slave-1脱离原从节点（PS: 5.0 中应该是replicaof no one)，升级主节点，</p><p>将从节点slave-2指向新的主节点</p><p>通知客户端主节点已更换</p><p>将原主节点（oldMaster）变成从节点，指向新的主节点</p><h3 id="5-9-Redis集群模式-Redis-Cluster（高可用集群）"><a href="#5-9-Redis集群模式-Redis-Cluster（高可用集群）" class="headerlink" title="5.9 Redis集群模式-Redis Cluster（高可用集群）"></a>5.9 Redis集群模式-Redis Cluster（高可用集群）</h3><p>前面两节，主从复制和哨兵机制保障了高可用，就读写分离而言虽然 slave 节点扩展了主从的读并发能力，但是写能力和存储能力是没有得到扩展。如果面对海量数据写入，就必须构建 master（主节点分片）之间的集群，同时必然需要吸收高可用（主从复制和哨兵机制）能力，即每个 master 分片节点还需要由 slave 节点。这是分布式系统中典型的纵向扩展（集群的分片技术）</p><p>Redis Cluster是一种服务器Sharding技术(分片和路由都是在服务端实现)，采用多主多从，每一个分区都是由一个Redis主机和多个从机组成，片区和片区之间是相互平行的。Redis Cluster集群采用了P2P的模式，完全去中心化。</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779161866-f0c18226-fd15-433e-9084-a07940689300-20250605100812167.jpeg" alt="img"></p><p>如上图，官方推荐，集群部署至少要 3 台以上的master节点，好使用 3 主 3 从六个节点的模式。Redis Cluster集群具有如下几个特点：</p><ul><li>集群完全去中心化，采用多主多从；所有的redis节点彼此互联(PING-PONG机制)，内部使用二进制协议优化传输速度和带宽。</li><li>客户端与 Redis 节点直连，不需要中间代理层。客户端不需要连接集群所有节点，连接集群中任何一个可用节点即可。</li><li>每一个分区都是由一个Redis主机和多个从机组成，分片和分片之间是相互平行的。</li><li>每一个master节点负责维护一部分槽，以及槽所映射的键值数据；集群中每个节点都有全量的槽信息，通过槽每个node都知道具体数据存储到哪个node上。</li></ul><h4 id="5-9-1-哈希槽"><a href="#5-9-1-哈希槽" class="headerlink" title="5.9.1 哈希槽"></a>5.9.1 哈希槽</h4><p>Redis-cluster 没有使用一致性 hash，而是引入了 哈希槽的概念。 Redis-cluster 中有 16384（2的14次方）个哈希槽，每个 key 通过 CRC16校验后对 16383取模 来决定放置在哪个槽。Cluster 中的每个节点负责一部分槽（hash slot）【一致性hash在算法章节说】</p><p>比如集群中存在三个节点，则可能存在下面类似分配：</p><ul><li>节点 A 包含0到5500号 哈希槽</li><li>节点 B 包含 5501到11000号 哈希槽</li><li>节点 C 包含 11001到16384 哈希槽</li></ul><p>哈希槽&#x3D;CRC16(key) % 16384，为什么不直接 哈希槽&#x3D;CRC16(key)？这样就可以有 2^16个值。</p><p>这是因为redis节点发送心跳包时，需要将所有的槽放到这个心跳包。如果slots&#x3D;2^16，需占用空间 &#x3D; 2^16 &#x2F; 8 &#x2F; 1024 &#x3D; 8KB。而 slots&#x3D;16384 只占用 2KB。并且一般情况下 Redis Cluster 集群主节点数量基本不可能超过1000个，超过1000个一般会导致网络堵塞。。如果slots更少，虽然能进一步降低心跳包大小，但是 会更容易出现碰撞概率（命中失效）。所以 slots &#x3D; 16384 比较合理</p><h4 id="5-9-2-Key-Hash-Tags"><a href="#5-9-2-Key-Hash-Tags" class="headerlink" title="5.9.2 Key Hash Tags"></a>5.9.2 Key Hash Tags</h4><p>因为 key 分布在不同节点，所以 Multi-Key 操作就会受限。实际场景比如：</p><ul><li>SUNION、mset、mget，这类命令会操作多个key</li><li>事务，在一个事务中会操作多个key</li><li>LUA脚本，在LUA脚本中也会操作多个key</li></ul><p>Hash Tags 提供了一种途径，用来将多个（key）分配到相同的 hash slot 中。这时 Redis Cluster中实现 multi-key 操作的基础。</p><ul><li>key包含一个{字符</li><li>并且 如果在这个{的右面有一个}字符</li><li>并且 如果在{和}之间存在至少一个字符</li></ul><p>例如：</p><ul><li>{user1000}.following和{user1000}.followers这两个key会被hash到相同的hash slot中，因为只有user1000会被用来计算hash slot值。</li><li>foo{}{bar}这个key不会启用hash tag因为第一个{和}之间没有字符。</li><li>foozap这个key中全部内容会被用来计算hash slot</li><li>foo{bar}{zap}这个key中的bar会被用来计算计算hash slot，而zap不会</li></ul><h4 id="5-9-3-请求重定向"><a href="#5-9-3-请求重定向" class="headerlink" title="5.9.3 请求重定向"></a>5.9.3 请求重定向</h4><p>Redis cluster 采用去中心化的架构，集群的主节点各自负责一部分槽，客户端如何确定 key 到底会映射到 哪个节点上呢？这就涉及到请求重定向</p><p>在 Cluster 模式下，节点对请求的处理过程如下：</p><ol><li>检查当前 key 是否存在于 当前 node</li></ol><ul><li><ul><li>通过key有效部分使用 CRC16函数计算散列值，再对16384 取余，计算出 slot 的编号。</li><li>Redis计算得到键对应的槽后，需要查找槽所对应的节点。集群内通过消息交换每个节点都会知道所有节点的槽信息。从而得到负责该槽的 节点指针。</li></ul></li></ul><ol><li>若 slot 不是由自身负责，则返回 MOVED 重定向。</li><li>若 slot 由自身负责，且 key 在 slot 中，则返回该 key 对应结果。</li><li>若 key 不存在此 slot中，检查该 slot 是否正在迁出（MIGRATING）？</li><li>slot 正在迁出，返回 ASK错误重定向客户端到 迁移的目的服务器上</li><li>若 slot 未迁出，检查 slot 是否在导入中 ？</li><li>若 slot 导入中且由 ASKING 标记，则直接操作</li><li>否则返回 MOVED 重定向</li></ol><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779145349-c2ddfcdb-cc9b-4948-a6f2-00b3b740388c-20250605100802757.png" alt="img"></p><p>请求处理过程中，可能涉及到两个重定向，分别时 MOVED重定向、ASK重定向</p><h5 id="MOVED-重定向"><a href="#MOVED-重定向" class="headerlink" title="MOVED 重定向"></a>MOVED 重定向</h5><p>通过计算 key 和 本地 slot 缓存，得到负责 slot 的节点。一般就去请求了，但是可能有两种情况：</p><ul><li>槽命中：直接返回结果</li><li>槽不命中：即当前键命令所请求的键 不在当前请求的节点中，则当前节点会向客户端发送一个 MOVED 重定向。客户端根据 MOVED重定向所包含的内容找到目标节点，再一次发送命令。redis-cli会帮你自动重定向（如果没有集群方式启动，即没加参数 -c，redis-cli不会自动重定向）</li></ul><p>由于本地会缓存映射的存在，所以绝大部分时候都不会触发 MOVED，而MOVED是用来协助客户端更新 slot-node 映射。</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779141290-b93974ae-08a7-4639-88d8-fec2f75f06ed-20250605100753660.png" alt="img"></p><h5 id="ASK-重定向"><a href="#ASK-重定向" class="headerlink" title="ASK 重定向"></a>ASK 重定向</h5><p>集群伸缩时，集群伸缩会导致槽迁移。槽迁移过程中，一个槽内的key 会分为多个批次，依次迁移。所以存在，一部分数据在源节点，一般部分数据在迁移的目标节点。ASK重定向由此诞生</p><p>出现上述情况，客户端的命令执行流程如下：</p><ol><li>客户端根据本地 slot 缓存发送命令到源节点，如果存在 键对象 则直接执行并返回结果给客户端。</li><li>如果键对象不存在，则可能存在于目标节点。这时源节点会回复 ASK 重定向异常。格式如下：（error）ASK{slot}{targetIP}：{targetPort}</li><li>客户端从 ASK 重定向异常中 提取目标节点信息，发送 asking命令到目标节点打开客户端连接标识，再执行键命令。如果存在则执，不存在则返回不存在信息。</li></ol><h5 id="两者的区别"><a href="#两者的区别" class="headerlink" title="两者的区别"></a>两者的区别</h5><p>ASK与MOVED虽然都是对客户端的重定向控制，但是有着本质区别。ASK 重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移完成，因此只能是<strong>临时性的重定向</strong>，客户端<strong>不会更新slots缓存</strong>。但是MOVED重定向说明键对应的槽已经明确指定到新的节点，因此<strong>需要更新slots缓存</strong>。</p><h4 id="5-9-4-故障转移"><a href="#5-9-4-故障转移" class="headerlink" title="5.9.4 故障转移"></a>5.9.4 故障转移</h4><p>Redis集群自身实现了高可用。高可用首先需要解决集群部分失败的场景：当集群内少量节点出现故障时通过自动故障转移保证集群可以正常对外提供服务。</p><p>Redis集群内节点通过ping&#x2F;pong消息实现节点通信，消息不但可以传播节点槽信息，还可以传播其他状态如：主从状态、节点故障等。因此故障发现也是通过消息传播机制实现的，主要环节包括：主观下线（pfail）和客观下线（fail）。</p><p>主观下线流程：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779141957-c4410066-51a8-40ed-9ae8-f17118aaa5fd-20250605100742339.png" alt="img"></p><p>当某个节点判断另一个节点主观下线后，相应的节点状态会跟随消息在集群内传播。ping&#x2F;pong消息的消息体会携带集群1&#x2F;10的其他节点状态数据，当接受节点发现消息体中含有主观下线的节点状态时，会在本地找到故障节点的ClusterNode结构，保存到<strong>下线报告链表</strong>中。</p><p>通过Gossip消息传播，集群内节点不断收集到故障节点的下线报告。当<strong>半数以上</strong>持有槽的主节点都标记某个节点是主观下线时，触发客观下线流程。</p><p><strong>故障恢复</strong></p><p>故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它的<strong>从节点</strong>中选出一个替换它，从而保证集群的高可用。下线主节点的所有从节点承担故障恢复的义务，当从节点通过内部定时任务发现自身复制的主节点进入客观下线时，将会触发故障恢复流程：</p><ul><li>从节点与主节点断线时间超过cluster-node-time*cluster-slave-validity-factor，则当前从节点不具备故障转移资格。参数cluster-slave-validity-factor用于从节点的有效因子，默认为10。</li><li>当从节点符合故障转移资格后，更新触发故障选举的时间，只有到达该时间后才能执行后续流程。这里之所以采用<strong>延迟触发机制</strong>，主要是通过对多个从节点使用不同的延迟选举时间来支持优先级问题。复制偏移量越大说明从节点延迟越低，那么它应该具有更高的优先级来替换故障主节点。</li></ul><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779142661-ccaf9622-687f-4fd7-bb0f-9b12dd307cfe-20250605100735532.png" alt="img"></p><ul><li>发起选举。Redis集群没有直接使用从节点进行领导者选举，主要因为从节点数必须大于等于3个才能保证凑够N&#x2F;2+1个节点，将导致从节点资源浪费。使用<strong>集群内所有持有槽的主节点进行领导者选举</strong>，即使只有一个从节点也可以完成选举过程。当从节点收集到N&#x2F;2+1个持有槽的主节点投票时，从节点可以执行替换主节点操作。</li></ul><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779143549-fe48adcb-3d12-4d75-9ec8-5b30473ab45e-20250605100730766.png" alt="img"></p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779143588-93b3d1eb-7667-4589-afc0-cb041b6046c3-20250605100725335.png" alt="img"></p><p><strong>预估故障转移时间</strong></p><p>failover-time(毫秒) ≤ cluster-node-timeout + cluster-node-timeout &#x2F; 2 + 1000</p><ul><li>主观下线识别时间：cluster-node-timeout</li><li>主观下线状态消息传播时间&lt;&#x3D;cluster-node-timeout&#x2F;2。消息通信机制对超过cluster-node-timeout&#x2F;2未通信节点会发起ping消息，消息体在选择包含哪些节点时会优先选取下线状态节点，所以通常这段时间内能够收集到半数以上主节点的pfail报告从而完成故障发现。</li><li>从节点转移时间&lt;&#x3D;1000毫秒。由于存在延迟发起选举机制，偏移量最大的从节点会<strong>最多延迟<strong><strong>1</strong></strong>秒发起选举</strong>。通常第一次选举就会成功。</li></ul><p>故障转移时间跟 cluster-node-timeout 参数息息相关，默认15秒。配置时可以根据业务容忍度做出适当调整，但不是越小越好。</p><h4 id="5-9-5-脑裂问题"><a href="#5-9-5-脑裂问题" class="headerlink" title="5.9.5 脑裂问题"></a>5.9.5 脑裂问题</h4><p>什么是脑裂？</p><p>在 Redis 主从架构中，部署方式一般是「一主多从」，主节点提供写操作，从节点提供读操作。 如果主节点的网络突然发生了问题，它与所有的从节点都失联了，但是此时的主节点和客户端的网络是正常的，这个客户端并不知道 Redis 内部已经出现了问题，还在照样的向这个失联的主节点写数据（过程A），此时这些数据被旧主节点缓存到了缓冲区里，因为主从节点之间的网络问题，这些数据都是无法同步给从节点的。</p><p>这时，哨兵也发现主节点失联了，它就认为主节点挂了（但实际上主节点正常运行，只是网络出问题了），于是哨兵就会在「从节点」中选举出一个 leader 作为主节点，这时集群就有两个主节点了 —— <strong>脑裂出现了</strong>。</p><p>脑裂可能会导致数据丢失？</p><p>然后，网络突然好了，哨兵因为之前已经选举出一个新主节点了，它就会把旧主节点降级为从节点（A），然后从节点（A）会向新主节点请求数据同步，<strong>因为第一次同步是全量同步的方式，此时的从节点（A）会清空掉自己本地的数据，然后再做全量同步。所以，之前客户端在过程 A 写入的数据就会丢失了，也就是集群产生脑裂数据丢失的问题</strong>。</p><p>总结一句话就是：由于网络问题，集群节点之间失去联系。主从数据不同步；重新平衡选举，产生两个主服务。等网络恢复，旧主节点会降级为从节点，再与新主节点进行同步复制的时候，由于会从节点会清空自己的缓冲区，所以导致之前客户端写入的数据丢失了。</p><p>解决方案</p><p>当主节点发现从节点下线或者通信超时的总数量小于阈值时，那么禁止主节点进行写数据，直接把错误返回给客户端。</p><p>在 Redis 的配置文件中有两个参数我们可以设置：</p><ul><li>min-slaves-to-write x，主节点必须要有至少 x 个从节点连接，如果小于这个数，主节点会禁止写数据。</li><li>min-slaves-max-lag x，主从数据复制和同步的延迟不能超过 x 秒，如果超过，主节点会禁止写数据。</li></ul><p>我们可以把 min-slaves-to-write 和 min-slaves-max-lag 这两个配置项搭配起来使用，分别给它们设置一定的阈值，假设为 N 和 T。</p><p>这两个配置项组合后的要求是，主库连接的从库中至少有 N 个从库，和主库进行数据复制时的 ACK 消息延迟不能超过 T 秒，否则，主库就不会再接收客户端的写请求了。</p><p>即使原主库是假故障，它在假故障期间也无法响应哨兵心跳，也不能和从库进行同步，自然也就无法和从库进行 ACK 确认了。这样一来，min-slaves-to-write 和 min-slaves-max-lag 的组合要求就无法得到满足，<strong>原主库就会被限制接收客户端写请求，客户端也就不能在原主库中写入新数据了</strong>。</p><p><strong>等到新主库上线时，就只有新主库能接收和处理客户端请求，此时，新写的数据会被直接写到新主库中。而原主库会被哨兵降为从库，即使它的数据被清空了，也不会有新数据丢失。</strong></p><p>再来举个例子</p><p>假设我们将 min-slaves-to-write 设置为 1，把 min-slaves-max-lag 设置为 12s，把哨兵的 down-after-milliseconds 设置为 10s，主库因为某些原因卡住了 15s，导致哨兵判断主库客观下线，开始进行主从切换。</p><p>同时，因为原主库卡住了 15s，没有一个从库能和原主库在 12s 内进行数据复制，原主库也无法接收客户端请求了。</p><p>这样一来，主从切换完成后，也只有新主库能接收请求，不会发生脑裂，也就不会发生数据丢失的问题了。</p><h4 id="5-9-6-状态检测及维护"><a href="#5-9-6-状态检测及维护" class="headerlink" title="5.9.6 状态检测及维护"></a>5.9.6 状态检测及维护</h4><p>Redis Cluster 中节点状态如何维护呢？这些就涉及 有哪些状态、底层协议Gossip及具体的通讯机制</p><p>Cluster 中 每个节点都维护一份在自己看来当前整个集群的状态，主要包括：</p><ul><li>当前集群的状态</li><li>集群中各节点所负责的 slots 信息及其 migrate 状态</li><li>集群中各节点的 master-slave 状态</li><li>集群中各节点的存活状态及不可达投票</li></ul><p>当集群状态发生变化，如：如新节点加入、slot迁移、节点宕机、slave提升为新Master，我们希望这些变化尽快的被发现，传播到整个集群的所有节点并达成一致。节点之间相互的<strong>心跳</strong>（PING，PONG，MEET）及其携带的数据是集群状态传播最主要的途径。</p><h5 id="Gossip协议"><a href="#Gossip协议" class="headerlink" title="Gossip协议"></a>Gossip协议</h5><p>Redis Cluster 通讯底层是 Gossip 协议，所以需要对 Gossip 协议有一定了解</p><p>gossip 协议（gossip protocol）又称 epidemic 协议（epidemic protocol），是基于流行病传播方式的节点或者进程之间信息交换的协议。 在分布式系统中被广泛使用，比如我们可以使用 gossip 协议来确保网络中所有节点的数据一样。</p><p>Gossip协议已经是P2P网络中比较成熟的协议了。Gossip协议的最大的好处是，<strong>即使集群节点的数量增加，每个节点的负载也不会增加很多，几乎是恒定的。这就允许Consul管理的集群规模能横向扩展到数千个节点</strong>。</p><p>Gossip算法又被称为反熵（Anti-Entropy），熵是物理学上的一个概念，代表杂乱无章，而反熵就是在杂乱无章中寻求一致，这充分说明了Gossip的特点：在一个有界网络中，每个节点都随机地与其他节点通信，经过一番杂乱无章的通信，最终所有节点的状态都会达成一致。每个节点可能知道所有其他节点，也可能仅知道几个邻居节点，只要这些节可以通过网络连通，最终他们的状态都是一致的，当然这也是疫情传播的特点。<a href="https://www.backendcloud.cn/2017/11/12/raft-gossip/">https://www.backendcloud.cn/2017/11/12/raft-gossip/</a></p><p>上面的描述都比较学术，其实Gossip协议对于我们吃瓜群众来说一点也不陌生，Gossip协议也成为流言协议，说白了就是八卦协议，这种传播规模和传播速度都是非常快的，你可以体会一下。所以计算机中的很多算法都是源自生活，而又高于生活的</p><h5 id="Gossip协议的使用"><a href="#Gossip协议的使用" class="headerlink" title="Gossip协议的使用"></a>Gossip协议的使用</h5><p>Redis 集群是去中心化的，彼此之间状态同步考 gossip 协议通讯，集群的消息有以下几种类型：</p><ul><li>Meet 通过 cluster meet ip port命令，已有集群的节点会向新的节点发送邀请，加入现有集群。</li><li>Ping 节点每秒会向集群中其他节点发送 ping 消息，消息中带有自己已知的两个节点的地址、槽、状态信息、最后一次通信时间等</li><li>Pong 节点收到 ping 消息后会回复 pong 消息，消息中同样带有自己已知的两个节点信息</li><li>Fail 节点 ping 不通某节点后，会向集群所有节点广播该节点挂掉的消息。其他节点收到消息后标记已下线。</li></ul><h5 id="基于Gossip-协议的故障检测"><a href="#基于Gossip-协议的故障检测" class="headerlink" title="基于Gossip 协议的故障检测"></a>基于Gossip 协议的故障检测</h5><p>集群中每个节点都会定期地向集群中其他节点发送 PING 消息，以此交换各个节点状态信息，检测各个节点状态：<strong>在线状态、疑似下线状态、PFAIL、已下线状态FAIL</strong></p><p><strong>自己保存信息</strong>：当主节点A通过消息得知主节点B认为主节点D进入了疑似下线(PFAIL)状态时,主节点A会在自己的clusterState.nodes字典中找到主节点D所对应的clusterNode结构，并将主节点B的下线报告添加到clusterNode结构的fail_reports链表中，并后续关于结点D疑似下线的状态通过Gossip协议通知其他节点。</p><p><strong>一起裁定</strong>：如果集群里面，半数以上的主节点都将主节点D报告为疑似下线，那么主节点D将被标记为已下线(FAIL)状态，将主节点D标记为已下线的节点会向集群广播主节点D的FAIL消息，所有收到FAIL消息的节点都会立即更新nodes里面主节点D状态标记为已下线。</p><p><strong>最终裁定</strong>：将 node 标记为 FAIL 需要满足以下两个条件：</p><ul><li>有半数以上的主节点将 node 标记为 PFAIL 状态。</li><li>当前节点也将 node 标记为 PFAIL 状态。</li></ul><h4 id="5-9-7-通讯状态和维护"><a href="#5-9-7-通讯状态和维护" class="headerlink" title="5.9.7 通讯状态和维护"></a>5.9.7 通讯状态和维护</h4><p>我们理解了Gossip协议基础后，就可以进一步理解Redis节点之间相互的通讯<strong>心跳</strong>（PING，PONG，MEET）实现和维护了</p><ol><li>什么时候进行心跳？Redis 节点会记录其向每个节点上次发出 ping 和收到 pong 的时间，心跳发送时机与这两个值有关。通过下面的方式既能保证及时更新集群状态，又不至于使心跳数过多：</li></ol><ul><li><ul><li>每次Cron向所有未建立链接的节点发送ping或meet</li><li>每1秒从所有已知节点中随机选取5个，向其中上次收到pong最久远的一个发送ping</li><li>每次Cron向收到pong超过timeout&#x2F;2的节点发送ping</li><li>收到ping或meet，立即回复pong</li></ul></li></ul><ol><li>发送那些心跳数据？</li></ol><ul><li><ul><li>Header，发送者自己的信息：所负责的 slots 的信息；主从信息；ip port 信息；状态信息</li><li>Gossip，发送者所了解的部分其他节点的信息：ping_sent、pong_received；ip port信息；状态信息（比如发送者认为该节点已经不可到达，会在状态信息中标记其为 PFAIL或FAIL）</li></ul></li></ul><ol><li>如何处理心跳</li></ol><ul><li><ul><li>新节点加入</li></ul></li></ul><ol><li><ol><li><ol><li>发送meet包加入集群</li><li>从pong包中的 gossip 得到未知的其他节点</li><li>循环上述过程，直到最终加入集群</li></ol></li></ol></li></ol><ul><li><ul><li>Slots 信息</li></ul></li></ul><ol><li><ol><li><ol><li>判断发送者声明的 slots 信息，跟本地记录的是否不同</li><li>如果不同，且发送者 epoch较大，更新本地记录</li><li>如果不同，且发送者 epoch较小，发送 Update 信息通知发送者</li></ol></li></ol></li></ol><ul><li><ul><li>Master slave信息发现发送者的master、slave信息变化，更新本地状态</li><li>节点Fail探测（故障发现）Gossip的存在使得集群状态的改变可以更快的达到整个集群。每个心跳包中会包含多个Gossip包，那么多少个才是合适的呢，redis的选择是N&#x2F;10，其中N是节点数，这样可以保证在PFAIL投票的过期时间内，节点可以收到80%机器关于失败节点的gossip，从而使其顺利进入FAIL状态。</li></ul></li></ul><ol><li><ol><li><ol><li>超过超时时间仍然没有收到 pong 包的节点会被当前节点标记为 PFAIL</li><li>PFAIL 标记会随着 gossip 传播</li><li>每次收到心跳包会检测其中对其他节点的 PFAIL 标记，当做对该节点的FAIL的投票维护在本机</li><li>对某个节点的 PFAIL标记达到大多数时，将其变为 FAIL 标记并广播 FAIL消息</li></ol></li></ol></li><li><p>只能通过 gossip + 心跳 传递信息？当需要发布一些非常重要需要立即发送的信息时，上述 心跳+Gossip的方式就显得捉襟见肘了。这时就需要向所有集群内机器广播信息，使用广播发的场景：</p></li></ol><ul><li><ul><li>节点的 Fail 信息：当发现某一个节点不可达时，探测节点会将其标记为 PFAIL状态，并通过心跳传播出去。当某一个节点发现这个节点的 PFAIL 超过半数时修改其为 FAIL 并发起广播。</li><li>Failover Request 信息：slave 尝试发起 FailOver时 广播其要求投票的信息</li><li>新 Master 信息：FailOver成功的节点向整个集群广播自己的信息</li></ul></li></ul><h4 id="5-9-8-扩容、缩容"><a href="#5-9-8-扩容、缩容" class="headerlink" title="5.9.8 扩容、缩容"></a>5.9.8 扩容、缩容</h4><p>当集群出现容量限制或者其他一些原因需要扩容时，redis cluster提供了比较优雅的集群扩容方案。</p><ol><li>首先将新节点加入到集群中，可以通过在集群中任何一个客户端执行cluster meet 新节点ip:端口，或者通过redis-trib add node添加，新添加的节点默认在集群中都是主节点。</li><li>迁移数据 迁移数据的大致流程是，首先需要确定哪些槽需要被迁移到目标节点，然后获取槽中key，将槽中的key全部迁移到目标节点，然后向集群所有主节点广播槽（数据）全部迁移到了目标节点。直接通过redis-trib工具做数据迁移很方便。 现在假设将节点A的槽10迁移到B节点，过程如下：</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">B:cluster setslot 10 importing A.nodeId</span><br><span class="line">A:cluster setslot 10 migrating B.nodeId</span><br></pre></td></tr></table></figure><p>循环获取槽中key，将key迁移到B节点</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">A:cluster getkeysinslot 10 100</span><br><span class="line">A:migrate B.ip B.port &quot;&quot; 0 5000 keys key1[ key2....]</span><br></pre></td></tr></table></figure><p>向集群广播槽已经迁移到B节点</p><p>cluster setslot 10 node B.nodeId</p><p>缩容的大致过程与扩容一致，需要判断下线的节点是否是主节点，以及主节点上是否有槽，若主节点上有槽，需要将槽迁移到集群中其他主节点，槽迁移完成之后，需要向其他节点广播该节点准备下线（cluster forget nodeId）。最后需要将该下线主节点的从节点指向其他主节点，当然最好是先将从节点下线</p><h4 id="5-9-9-Write-Safety-分析"><a href="#5-9-9-Write-Safety-分析" class="headerlink" title="5.9.9 Write Safety 分析"></a>5.9.9 Write Safety 分析</h4><p><a href="https://segmentfault.com/a/1190000039226390">https://segmentfault.com/a/1190000039226390</a></p><p>Redis Cluster 是 Redis 的分布式实现，就如同官方文档里强调的，其设计优先考虑的是 高性能和线性扩展能力，尽量保证 write safety。这里所说的 write 丢失是指，回复 客户端响应后，后续请求中出现未做变更或者丢失的情况。导致该问题，主要在 主从切换、实例重启、脑裂三种情况下。</p><ul><li><p>主从切换</p></li><li><ul><li>被动 failover情景：master c 为主节点，负责 slot 1-100，其对应的从节点是 slave c。当master c挂掉后，slave c 在 最多2倍 cluster_node_timeout 的时间 内把 master c 标记成 FALL,进而触发 failover 逻辑。在 slave c 成功切换为 master前，slot 1-100 仍然由 master c 负责，访问也会报错。当 slave c 切换为 master 后，gossip 广播路由变更，在这个过程中，client 访问 slave c，仍然可以得到正常回应，而访问其他持有老路由的 node，请求会被 moved 到挂掉的 master c，访问报错。问题：如果写到 master 上的数据还没来得及同步到 slave 就挂掉了，那么这部分数据就会丢失（重启后不存在 merge操作）。即写入的数据丢失。master 回复 client ack 于 同步 slave 几乎同时进行的，这种情况很少发生（时间窗口小），但是这存在这个风险</li><li>主动 failover主动 failover 通过 sysadmin 在 slave node 上执行 CLUSTER FAILOVER [FORCE|TAKEOVER] 命令触发。完整的 manual failover 可以概括为以下步骤：该命令的三个选项分别由不同的行为：</li></ul></li></ul><ol><li><ol><li><ol><li>slave 发起请求，gossip 消息携带 <strong>CLUSTERMSG_TYPE_MFSTART</strong> 标识。</li><li>master 阻塞 client，停服时间为 2 倍 <strong>CLUSTER_MF_TIMEOUT</strong>，目前版本为 10s。</li><li>slave 追赶主从复制 offset 数据。</li><li>slave 开始发起选举，并最终当选。</li><li>slave 切换自身 role，接管 slots，并广播新的路由信息。</li><li>其他节点更改路由，cluster 路由打平。</li></ol></li></ol></li></ol><ul><li><ul><li><ul><li>默认选项：执行完整的 mf 流程，master 由停服行为，因此不存在write丢失问题。</li><li>FORCE选项：从第四步开始执行。在 slave c 统计选票阶段，master c 仍然可以正常接收用户请求，且主从异步复制，这些都可能导致 write 丢失。mf 将在未来的某个时间点开始执行，timeout 时间为 <strong>CLUSTER_MF_TIMEOUT</strong>（现版本为 5s），每次 clusterCron 都会检查。</li><li>TAKEOVER选项：从第五步开始执行。slave 直接增加自己的 configEpoch（无需其他node同意），接管 slots。从 slave c切换为 master 到 原 master c 更新路由 这段期间，发送到 原master 从的请求，都可能存在 write 丢失的可能。一般在一个 ping 的时间内完成，时间窗口很小。master c 和 slave c 以外节点更新路由滞后只会带来多一次的 moved 错误，不会导致 write 丢失。</li></ul></li></ul></li><li><p>master 重启clusterState 结构体中有一个 <strong>state</strong> 成员变量，表示 cluster 的全局状态，控制着当前 cluster 是否可以提供服务，有以下两种取值：</p></li><li><ul><li>cluster 状态初始化</li></ul></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#define CLUSTER_OK 0 /* Everything looks ok */</span><br><span class="line"> #define CLUSTER_FAIL 1 /* The cluster can&#x27;t work */</span><br></pre></td></tr></table></figure><p>server 重启后，state 被初始化为 <strong>CLUSTER_FAIL</strong>，此状态下的 cluster 是拒绝访问的。这对保证 write safety 是非常必要的！可以想象，如果 master A 挂掉后，对应的 slave A’ 通过选举成功当选为新 master。此时，A 重启，且恰好有一些 client 看到的路由没有更新，它们仍然会往 A 上写数据，如果接受这些 write，就会丢数据！A’ 才是这个 sharding 大家公认的 master。所以，A’ 重启后需要先禁用服务，直到路由变更完成。所以如果 <strong>CLUSTER_WRITABLE_DELAY</strong> 内，未能更新路由，可能就导致 write 丢失。</p><ul><li><ul><li>cluster 状态变更什么时候 cluster 才会出现 <strong>CLUSTER_FAIL</strong> -&gt; <strong>CLUSTER_OK</strong> 的状态变更呢。从 clusterCron 定时任务中，可以知道 clusterCron状态变更要延迟 <strong>CLUSTER_WRITABLE_DELAY</strong> 毫秒，当前版本是2s。访问延迟就是为等待 路由变更，那么什么时候触发路由变更呢？一个新 server 刚启动，它与其他 node 进行 gossip 通信的 link 都是 null，在 clusterCron 里检查出来后会依次连接，并发送 ping。作为一个路由过期的老节点，收到其他节点发来的 update 消息，更改自身路由。<strong>CLUSTER_WRITABLE_DELAY</strong> 毫秒后，A 节点恢复访问，我们认为 CLUSTER_WRITABLE_DELAY 的时间窗口足够更新路由。</li></ul></li><li><p>网络分区</p></li><li><ul><li>网络分区发生由于网络的不可靠，网络分区时一个必须要考虑的问题。当网络分区发生后，cluster 被割裂成 majority 和 minority 两部分，这里以分区中的 master 节点来区分。</li></ul></li></ul><ol><li><ol><li><ol><li>对于 minority 部分，slave 会发起选举，但是不能收到大多数 master 的选票，也就无法完成正常的 failover 流程。同时在 clusterCron 里的大部分节点会被标记为 <strong>CLUSTER_NODE_PFAIL</strong> 状态，进而触发集群状态更新。在 minority 中，cluster 状态在一段时间后，会被更改为 <strong>CLUSTER_FAIL</strong>。但，对于一个划分到 minority 的 master 节点，在状态更改前是一直可以访问的，这就有一个时间窗口，会导致 write 丢失。在 clusterCron 函数中可以计算出这个时间窗口大小：从 partition 时间开始算起，<strong>cluster_node_timeout</strong> 时间后才会有 node 标记为 PFAIL，加上 gossip 消息传播会偏向于携带 PFAIL 的节点，master节点 不必等到 <strong>cluster_node_timeout&#x2F;2</strong> 把 cluster nodes ping 遍，就可以把 cluster 标记为 <strong>CLUSTER_FAIL</strong>可以推算出，时间窗口大约为 <strong>cluster_node_timeout</strong>。另外，会记录下禁用服务的时间，即 among_minority_time</li><li>对于 majority 部分，slave 会发起选举，切换为新的master并提供服务。如果partition 时间小于 cluster_node_timeout,以至于没有 PFAIL 标识出现，就不会有 write 丢失。</li></ol></li></ol></li></ol><ul><li><ul><li>网络分区恢复当网络分区恢复后，minority 中 老的master 重新加进 cluster，master 要想提供服务，就必须先将 cluster 状态从 <strong>CLUSTER_FAIL</strong> 修改为 <strong>CLUSTER_OK</strong>，那么，应该什么时候改呢？我们知道 老master中应该是旧路由，此时它应该变更为 slave，所以，还是需要等待一段时间做路由变更，否则有可能出现 write 丢失的问题。从 clusterUpdateState 函数的逻辑里，可以看出时间窗口为 <strong>cluster_node_timeout</strong></li></ul></li></ul><p>总结：</p><p>failover 可能因为选举和主从异步复制数据偏差带来 write 丢失。master 重启通过 <strong>CLUSTER_WRITABLE_DELAY</strong> 延迟，等 cluster 状态变更为 <strong>CLUSTER_OK</strong>，可以重新访问，不存在 write 丢失。partition 中的 minority 部分，在 cluster 状态变更为 <strong>CLUSTER_FAIL</strong> 之前，可能存在 write 丢失。partition 恢复后，通过 rejoin_delay 延迟，等 cluster 状态变更为 <strong>CLUSTER_OK</strong>，可以重新访问，不存在 write 丢失。</p><h4 id="5-9-10-availability-分析"><a href="#5-9-10-availability-分析" class="headerlink" title="5.9.10 availability 分析"></a>5.9.10 availability 分析</h4><p><a href="https://segmentfault.com/a/1190000039234661?utm_source=sf-similar-article">https://segmentfault.com/a/1190000039234661?utm_source=sf-similar-article</a></p><p>主要在三种情况下，出现不可用：</p><ul><li>网络故障Redis Cluster 在发生 网络分区后，minority 部分是不可用的。假设 majority 部分有 过半数 master 和 所有不在majority的master其下的一个slave。那么，经过 NODE_TIMEOUT 时间加额外几秒钟（给slave进行failover），cluster 恢复可用状态。</li><li>sharding 缺失故障默认情况下，当检测到有 slot 没有绑定，Redis Cluster 就会停止接受请求。在这种配置下（三主三从），如果 cluster 部分节点挂掉（一个主节点和其对应的从节点都挂了），也就是说一个范围内的 slot 不再有节点负责，最终整个 cluster 会变的不能提供服务。<strong>有时候，服务部分可用比整个不可用更有意义</strong>，因此，即使一部分 sharding 可用，也要让 cluster 提供服务。redis 将这种选择权交到了用户手中，conf 里提供 <strong>cluster-require-full-coverage</strong> 参数。如果该参数为false，那么有 slot 未绑定或者 sharding确实，server 也是可以接受请求的。</li><li>当集群节点宕机，出现集群Master节点个数小于3个的时候，或者集群可用节点个数为偶数的时候，基于 failover 这种选举机制的自动主从切换过程可能会不能正常工作。标记 fail、以及选举新master的过程，都可能异常。</li></ul><h5 id="replicas-migration-功能"><a href="#replicas-migration-功能" class="headerlink" title="replicas migration 功能"></a>replicas migration 功能</h5><p>举个例子，如果一个包含N个 master 的集群，每个Master 有唯一 slave。单个 node 出现故障，cluster必定仍然可用；第二个 node 再出现再出现故障。如果第二个节点正好是上面已经故障的master节点的slave，则此时集群不可用。如果第二个节点是其他节点，则集群仍然可用。所以集群不可用的概率是 1&#x2F;(N*2-1) </p><p>Redis Cluster 为了提高可用性，这个是用于在每次故障之后，重新布局集群的slave，给没有slave的master配备上slave，以此来更好应对下次故障。</p><p>具体实现：</p><p>这种负责 部分slot但是没有健康slave的 master，就称为 orphaned master。当slave检测到自己的 master 拥有不少于2个健康slave，且 cluster 中恰好有 orphan master 时，触发 clusterHandleSlaveMigration 函数逻辑，尝试进行 slave 漂移，slave步骤有如下四步</p><ol><li>CLUSTER_FAIL 集群漂移 if (server.cluster-&gt;state !&#x3D; CLUSTER_OK) return;非 CLUSTER_OK 集群本来旧无法正常接收请求，所以也不需要漂移。</li><li>检查 cluster-migration-barrier 参数<strong>redis conf 提供了cluster-migration-barrier 参数</strong>，用来决定 slave 数量达到多少个才会把冗余 slave 漂移出去。只有 master 健康 slave 的个数超过 cluster-migration-barrier 配置的数量时，才会漂移。</li><li>选出要漂移的 slave，以及漂移给谁。选择 node name 最小的slave，漂移给遍历到的第一个 orphaned master</li><li>执行漂移在 failover 期间，master 有一段时间是没有 slave，为了防止误漂，漂移必须有一定的延迟。时间为 CLUSTER_SLAVE_MIGRATION _DELAY 现版本为 5s。</li></ol><h2 id="六、Redisson"><a href="#六、Redisson" class="headerlink" title="六、Redisson"></a>六、Redisson</h2><h3 id="6-1-分布式锁"><a href="#6-1-分布式锁" class="headerlink" title="6.1 分布式锁"></a>6.1 分布式锁</h3><p>分布式锁，是控制分布式系统不同进程共同访问共享资源的一种锁的实现。秒杀下单、抢红包等等业务场景，都需要用到分布式锁。</p><h4 id="6-1-1-常见redis-分布式锁"><a href="#6-1-1-常见redis-分布式锁" class="headerlink" title="6.1.1 常见redis 分布式锁"></a>6.1.1 常见redis 分布式锁</h4><p>一般Redis分布式锁有如下几种实现方案：</p><ul><li>命令 setnx + expire 分开写</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">if(jedis.setnx(key,lock_value) == 1)&#123; // 加锁</span><br><span class="line">    expire(key,100);  // 设置过期时间</span><br><span class="line">    try&#123;</span><br><span class="line">        do something // 业务处理</span><br><span class="line">    &#125;catch()&#123;</span><br><span class="line">        </span><br><span class="line">    &#125;finally&#123; </span><br><span class="line">      jedis.del(key); // 释放锁</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果执行完 setnx 加锁，正要执行 expire 设置过期时间，进行crash或者重启维护，那么这个锁就一直被锁住了，别的线程永远获取不到锁了，所以分布式不能这种实现。</p><ul><li>setnx + value 值过期时间为了解决方案一，发生异常锁得不到释放的场景。</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">long expires = System.currentTimeMillis() + expireTime; // 系统时间 + 设置的过期时间</span><br><span class="line">if(jedis.setnx(key,expires) == 1)&#123;</span><br><span class="line">    return true;</span><br><span class="line">&#125;</span><br><span class="line">// 如果当前锁不存在，返回加锁成功</span><br><span class="line">if (jedis.setnx(key_resource_id, String.vaue(expires)) == 1) &#123;</span><br><span class="line">        return true;</span><br><span class="line">&#125; </span><br><span class="line">// 如果锁已经存在，获取锁的过期时间</span><br><span class="line">String currentValueStr = jedis.get(key_resource_id);</span><br><span class="line"></span><br><span class="line">// 如果获取到的过期时间，小于系统当前时间，表示已经过期</span><br><span class="line">if (currentValueStr != null &amp;&amp; Long.parseLong(currentValueStr) &lt; System.currentTimeMillis()) &#123;</span><br><span class="line"></span><br><span class="line">         // 锁已过期，获取上一个锁的过期时间，并设置现在锁的过期时间</span><br><span class="line">        String oldValueStr = jedis.getSet(key_resource_id, expiresStr);</span><br><span class="line"></span><br><span class="line">        if (oldValueStr != null &amp;&amp; oldValueStr.equals(currentValueStr)) &#123;</span><br><span class="line">             // 考虑多线程并发的情况，只有一个线程的设置值和当前值相同，它才可以加锁</span><br><span class="line">             return true;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">        </span><br><span class="line">    //其他情况，均返回加锁失败</span><br><span class="line">    return false;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这一方案巧妙移除了 expire 单独设置过期时间的操作，把过期时间放到了 setnx 的 value 值中。解决了 发生异常锁得不到释放的问题。但是此方案也有自己的缺点：</p><ul><li><ul><li>过期时间是客户端自己生成的（System.currentTimeMillis()是当前系统的时间），必须要求分布式环境下，每个客户端的时间必须同步。</li><li>如果锁过期的时候，并发多个客户端同时请求过来，都执行jedis.getSet()，最终只能有一个客户端加锁成功，但是该客户端锁的过期时间，可能被别的客户端覆盖</li><li>该锁没有保存持有者的唯一标识，可能被别的客户端释放&#x2F;解锁。</li></ul></li><li><p>set 的扩展命令（set ex px nx）Redis 的 set 扩展参数（SET key value[EX seconds][PX milliseconds][NX|XX]）是原子性的。EX seconds：设定key的过期时间，时间单位是秒。PX milliseconds：设定key的过期时间，单位是毫秒NX：表示key不存在的时候，才能set成功，也即保证只有第一个客户端请求才能获取锁，而其他客户端请求只能等起释放锁，才能获取。XX：仅当key存在时设置值</p></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">if（jedis.set(key_resource_id, lock_value, &quot;NX&quot;, &quot;EX&quot;, 100s) == 1）&#123; //加锁</span><br><span class="line">    try &#123;</span><br><span class="line">        do something  //业务处理</span><br><span class="line">    &#125;catch()&#123;</span><br><span class="line">　　&#125;</span><br><span class="line">　　finally &#123;</span><br><span class="line">       jedis.del(key_resource_id); //释放锁</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>但是呢，这个方案还是可能存在问题：问题一：<strong>锁过期释放了，业务还没执行完</strong>。假设线程a获取锁成功，一直在执行临界区的代码。但是100s过去后，它还没执行完。但是，这时候锁已经过期了，此时线程b又请求过来。显然线程b就可以获得锁成功，也开始执行临界区的代码。那么问题就来了，临界区的业务代码都不是严格串行执行的啦。问题二：<strong>锁被别的线程误删</strong>。假设线程a执行完后，去释放锁。但是它不知道当前的锁可能是线程b持有的（线程a去释放锁时，有可能过期时间已经到了，此时线程b进来占有了锁）。那线程a就把线程b的锁释放掉了，但是线程b临界区业务代码可能都还没执行完呢。</p><ul><li>set ex px nx + 校验唯一随机值 再删除既然锁可能被别的线程误删，那我们给value值设置一个标记当前线程唯一的随机数，在删除的时候，校验一下，不就OK了嘛。伪代码如下：</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if（jedis.set(key_resource_id, uni_request_id, &quot;NX&quot;, &quot;EX&quot;, 100s) == 1）&#123; //加锁</span><br><span class="line">    try &#123;</span><br><span class="line">        do something  //业务处理</span><br><span class="line">    &#125;catch()&#123;</span><br><span class="line">　　&#125;</span><br><span class="line">　　finally &#123;</span><br><span class="line">       //判断是不是当前线程加的锁,是才释放</span><br><span class="line">       if (uni_request_id.equals(jedis.get(key_resource_id))) &#123;</span><br><span class="line">        jedis.del(lockKey); //释放锁</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这里，<strong>判断是不是当前线程加的锁</strong>和<strong>释放锁</strong>不是一个原子操作。如果调用jedis.del()释放锁的时候，可能这把锁已经不属于当前客户端，会解除他人加的锁。因为 finally 部分执行时不能保证原子性，一般也是用 lua脚本代替。</p><h4 id="6-1-2-Redisson-的解决方案"><a href="#6-1-2-Redisson-的解决方案" class="headerlink" title="6.1.2 Redisson 的解决方案"></a>6.1.2 Redisson 的解决方案</h4><p><strong>1. 单机方案</strong></p><p>其实上面的方案还是会存在 锁过期释放，业务没有执行完的问题。所以其实我们可以开启一个定时守护线程，每隔一段时间检查锁是否还存在，存在则对锁过期时间延长，防止锁过期提前释放。</p><p>只要线程1加锁成功，就会启动一个 watch dog，它是一个后台线程，会每隔10秒检查一下锁。如果线程1还持有锁，那么就会不断的延长锁key的过期时间。因此 Redission 解决了 业务还没执行完 锁就过期释放的 问题。</p><p><strong>2. 基于故障转移的RedLock算法</strong></p><p>上面的所有的方案都是基于单机版的，然而实际上生产环境redis都是集群部署。</p><p>直接在 redis 主从集群中使用上面的方案，会有如下问题：</p><p>客户端在 Redis 的 master 节点上拿到了 锁，但是这个锁还没有同步到 slave 节点上，master节点就发生了故障。然后进行了故障转移，slave节点升级为 master节点。因此 客户端 加的锁丢失了。</p><p>因此Redis作者antirez基于分布式环境下提出了一种更高级的分布式锁的实现方式：<strong>Redlock</strong>。</p><p><strong>Redlock架构图</strong></p><p>应用前提：在Redis的分布式环境中，我们假设有N个Redis master。这些节点<strong>完全互相独立，不存在主从复制或者其他集群协调机制</strong>。我们确保将在N个实例上使用与在Redis单实例下相同方法获取和释放锁。现在我们假设有5个Redis master节点，同时我们需要在5台服务器上面运行这些Redis实例，这样保证他们不会同时都宕掉。</p><p>实现步骤：</p><ol><li>获取当前的时间戳</li><li>依次尝试向5个实例，使用相同的 key 和 具有唯一性的value（例如UUID）获取锁。客户端请求各实例获取锁时，应有设置响应超时时间。并且这个响应超时时间尽量远小于锁的失效时间。如此设计的原因，是因为我们不能在已经挂掉的master上花费太多时间。如果花费太多时间，会造成还没向全部master请求完，锁的失效时间就已经到了。因此 如果服务器端没有在规定时间内响应，客户端应该尽快尝试去另外一个Redis实例请求获取锁。</li><li>客户端使用当前时间减去开始获取锁的时间（步骤1记录的时间），就可以得到 获取锁 所用的时间。<strong>当且仅当从大多数（N&#x2F;2+1，这里是3个节点）的Redis节点都取到锁，并且整个过程使用的时间小于锁失效时间时，锁才算获取成功</strong>。</li><li>如果取到了锁，key的真正有效时间等于有效时间减去获取锁所使用的时间（步骤3计算的结果）。</li><li>如果因为某些原因，获取锁失败（没有在至少N&#x2F;2+1个Redis实例取到锁或者取锁时间已经超过了有效时间），客户端应该在<strong>所有的Redis实例上进行解锁</strong>（即便某些Redis实例根本就没有加锁成功，防止某些节点获取到锁但是客户端没有得到响应而导致接下来的一段时间不能被重新获取锁）。</li></ol><h2 id="七、Redis应用问题"><a href="#七、Redis应用问题" class="headerlink" title="七、Redis应用问题"></a>七、Redis应用问题</h2><h3 id="7-1-Redis与MySQL双写一致性如何保证？"><a href="#7-1-Redis与MySQL双写一致性如何保证？" class="headerlink" title="7.1 Redis与MySQL双写一致性如何保证？"></a>7.1 Redis与MySQL双写一致性如何保证？</h3><p>一旦出现数据更新，redis与数据库之间的数据一致性问题就会出现。</p><p>一致性就是数据保持一致，在分布式系统中，可以理解为多个节点中数据的值是一致的。</p><ul><li><strong>强一致性</strong>：这种一致性级别是最符合用户直觉的，它要求系统写入什么，读出来的也会是什么，用户体验好，但实现起来往往对系统的性能影响大</li><li><strong>弱一致性</strong>：这种一致性级别约束了系统在写入成功后，不承诺立即可以读到写入的值，也不承诺多久之后数据能够达到一致，但会尽可能地保证到某个时间级别（比如秒级别）后，数据能够达到一致状态</li><li><strong>最终一致性</strong>：最终一致性是弱一致性的一个特例，系统会保证在一定时间内，能够达到一个数据一致的状态。这里之所以将最终一致性单独提出来，是因为它是弱一致性中非常推崇的一种一致性模型，也是业界在大型分布式系统的数据一致性上比较推崇的模型</li></ul><p><strong>是选择更新缓存还是删除缓存？</strong></p><p>如果 线程A先更新数据库，之后线程B也向数据库中更新同一值，但是B请求快，先写入了缓存，A后写入了缓存。那么实际上 缓存中还是旧值，而数据库中是B更改后的新值。导致数据最终不一致。</p><p>但是你选择的是删除缓存。那么在最后一次删除缓存后，请求再来时会查询数据库最新数据。那么就避免了这个问题。所以 我们选择 删除缓存。</p><p>不管是先删除缓存再更新数据库，还是先更新数据库再删除缓存，都有可能存在数据不一致的情况。</p><ol><li><strong>先删除缓存再更新数据库</strong>：在删除缓存后，更新数据库前。就可能会有个请求获取缓存，此时缓存没有，它就去查数据库了，就得到了脏数据。并将脏数据塞入了缓存中。这就导致了 缓存与数据库 最终不一致。</li><li><strong>先更新数据库再删除缓存</strong>：在删除缓存之前，去读到的都是 脏数据。在并发写不高、redis删除失败概率不大时，可以一定程度实现 最终一致性。但是在并发写较高，就会出现下面的情况：</li></ol><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682815161357-87e6efce-ca8a-4ce3-a1d2-592d9d2c7a6c-20250605100709115.png" alt="img"></p><p>此时 再有线程进来读取缓存，就会读取到就是a&#x3D;2，但是实际 数据库中 a&#x3D;3。这就导致了数据最终不一致。</p><p>此方案可以考虑在写并发极低的情况下使用。</p><p>但是综合来看，上面两个方案即使在不考虑 删除key 可能失败的情况，也不能保证 缓存和数据库 数据最终一致。</p><p><strong>3.延迟双删：</strong> </p><p>延迟双删再上面方案1 的基础上，增加了一步 延迟一定时间后 再删除缓存。从而避免方案1，造成的脏数据存在缓存中。达到下面左图到效果</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1684856079904-9a8380f7-4d84-40fc-88aa-a1efe58412d1-20250605100653159.png" alt="img"></p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1684856140846-5f64616b-c627-4b51-90e2-7cf9943c770d-20250605100659576.png" alt="img"></p><p>这样就可以实现 数据最终一致性。但是我们也可以清楚的发现，如果延迟时间不够，很有可能会出现 Thread-2 的写入缓存操作 在Thread-1第二次删除缓存 之后发生。那么此时，数据又会出现不一致的情况。</p><p>所以我们应当设置一个合理的 延迟时间，但是即使合理，也不能说 一定能保证在任何情况下 Thread-2 写入操作都在 Thread-1 第二次删缓存 之后。</p><p><strong>4.异步更新缓存（基于CDC的同步机制）</strong></p><p>通过CDC（数据变更跟踪）将缓存与数据库的一致性同步从业务中独立出来统一处理，保证数据一致性。</p><p>整体思路：</p><ol><li>更新、写 数据库后，会产生数据变更记录。（MySQL中有binlog日志，SQLServer中有CDC变更表）</li><li>通过数据变更记录来更新 Redis中数据</li></ol><p>这里可以使用：1. FlinkCDC 来实现 对数据库变更数据的追踪、处理；2. 数据变更记录 存入 消息队列，消费者有序实现 Redis 更新。</p><p>上面的所有方案中，都没有考虑 删除缓存失败 的可能，如果考虑删除缓存失败，可能所有方案都保证不了 数据最终一致性。所以在 删除缓存 这一操作，可以考虑 失败重试 或者 将需要删除的key存入消息队列中，依次保证 删除缓存的成功。</p><p>从整个大局来看，我们会发现 如果缓存不设置过期时间，是比较容易造成 redis与数据库 最终一致性难以保证的。最简单的方法就是 设置过期时间，这样即使脏数据在缓存中，也不会存在很久。</p><p>个人看法：小团队或者小项目可以考虑 使用方案2+设置key过期时间，较大项目可以考虑 使用方案4</p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h3 id="7-2-Redis-的大key如何处理？"><a href="#7-2-Redis-的大key如何处理？" class="headerlink" title="7.2 Redis 的大key如何处理？"></a>7.2 Redis 的大key如何处理？</h3><p>什么是 Redis 大key ？</p><p>大 key 并不是指 key 的值很大，而是 key 对应的 value 很大。</p><p>一般而言，下面这两种情况被称为大 key：</p><ul><li>String 类型的值大于 10 KB；</li><li>Hash、List、Set、ZSet 类型的元素的个数超过 5000个；</li></ul><p>大key会造成什么问题？</p><p>大 key 会带来以下四种影响：</p><ul><li><strong>客户端超时阻塞。</strong>由于 Redis 执行命令是单线程处理，然后在操作大 key 时会比较耗时，那么就会阻塞 Redis，从客户端这一视角看，就是很久很久都没有响应。</li><li><strong>引发网络阻塞。</strong>每次获取大 key 产生的网络流量较大，如果一个 key 的大小是 1 MB，每秒访问量为 1000，那么每秒会产生 1000MB 的流量，这对于普通千兆网卡的服务器来说是灾难性的。</li><li><strong>阻塞工作线程。</strong>如果使用 del 删除大 key 时，会阻塞工作线程，这样就没办法处理后续的命令。</li><li><strong>内存分布不均。</strong>集群模型在 slot 分片均匀情况下，会出现数据和查询倾斜情况，部分有大 key 的 Redis 节点占用内存多，QPS 也会比较大。</li></ul><p>如何找到大key？</p><ol><li>redis-cli –bigkeys 查找大key</li></ol><p>可以通过 redis-cli –bigkeys 命令查找大 key：</p><p>使用的时候注意事项：</p><ul><li><ul><li>最好选择在从节点上执行该命令。因为主节点上执行时，会阻塞主节点；</li><li>如果没有从节点，那么可以选择在 Redis 实例业务压力的低峰阶段进行扫描查询，以免影响到实例的正常运行；或者可以使用 -i 参数控制扫描间隔，避免长时间扫描降低 Redis 实例的性能。</li></ul></li></ul><p>该方式的不足之处：</p><ul><li><ul><li>这个方法只能返回每种类型中最大的那个 bigkey，无法得到大小排在前 N 位的 bigkey；</li><li>对于集合类型来说，这个方法只统计集合元素个数的多少，而不是实际占用的内存量。但是，一个集合中的元素个数多，并不一定占用的内存就多。因为，有可能每个元素占用的内存很小，这样的话，即使元素个数有很多，总内存开销也不大；</li></ul></li></ul><ol><li>使用 SCAN 命令查找大 key</li></ol><p>使用 SCAN 命令对数据库扫描，然后用 TYPE 命令获取返回的每一个 key 的类型。</p><p>对于 String 类型，可以直接使用 STRLEN 命令获取字符串的长度，也就是占用的内存空间字节数。</p><p>对于集合类型来说，有两种方法可以获得它占用的内存大小：</p><ul><li><ul><li>如果能够预先从业务层知道集合元素的平均大小，那么，可以使用下面的命令获取集合元素的个数，然后乘以集合元素的平均大小，这样就能获得集合占用的内存大小了。List 类型：LLEN 命令；Hash 类型：HLEN 命令；Set 类型：SCARD 命令；Sorted Set 类型：ZCARD 命令；</li><li>如果不能提前知道写入集合的元素大小，可以使用 MEMORY USAGE 命令（需要 Redis 4.0 及以上版本），查询一个键值对占用的内存空间。</li></ul></li></ul><ol><li>使用 RdbTools 工具查找大 key</li></ol><p>使用 RdbTools 第三方开源工具，可以用来解析 Redis 快照（RDB）文件，找到其中的大 key。</p><p>比如，下面这条命令，将大于 10 kb 的  key  输出到一个表格文件。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rdb dump.rdb -c memory --bytes 10240 -f redis.csv</span><br></pre></td></tr></table></figure><p>如何优化大key？</p><ul><li>对大key进行拆分和压缩</li></ul><p>例如将含有数万成员的一个HASH Key拆分为多个HASH Key，<strong>使用multiGet方法获得值，</strong>并确保每个Key的成员数量在合理范围。<strong>这样的拆分主要是为了减少单台操作的压力，而是将压力平摊到集群各个实例中，降低单台机器的IO操作。</strong></p><ul><li>对大key可以进行清理</li></ul><p>将不适用Redis能力的数据存至其它存储，并在Redis中删除此类数据。</p><ul><li>在Redis集群架构中对热Key进行复制</li></ul><p>在Redis集群架构中，由于热Key的迁移粒度问题，无法将请求分散至其他数据分片，导致单个数据分片的压力无法下降。此时，可以将对应热Key进行复制并迁移至其他数据分片，例如将热Key foo复制出3个内容完全一样的Key并名为foo2、foo3、foo4，将这三个Key迁移到其他数据分片来解决单个数据分片的热Key压力。</p><ul><li>使用读写分离架构</li></ul><p>如果热Key的产生来自于读请求，您可以将实例改造成读写分离架构来降低每个数据分片的读请求压力，甚至可以不断地增加从节点。但是读写分离架构在增加业务代码复杂度的同时，也会增加Redis集群架构复杂度。</p><h3 id="7-3-如何选择持久化策略？"><a href="#7-3-如何选择持久化策略？" class="headerlink" title="7.3 如何选择持久化策略？"></a>7.3 如何选择持久化策略？</h3><p>RDB 优点是数据恢复速度快，但是快照的频率不好把握。频率太低，丢失的数据就会比较多，频率太高，就会影响性能。</p><p>AOF 优点是丢失数据少，但是数据恢复不快。</p><p>为了集成了两者的优点， Redis 4.0 提出了<strong>混合使用 AOF 日志和内存快照</strong>，也叫混合持久化，既保证了 Redis 重启速度，又降低数据丢失风险。</p><p>混合持久化工作在 <strong>AOF 日志重写过程</strong>，当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p><p>也就是说，使用了混合持久化，AOF 文件的<strong>前半部分是 RDB 格式的全量数据，后半部分是 AOF 格式的增量数据。</strong></p><p>这样的好处在于，重启 Redis 加载数据的时候，由于前半部分是 RDB 内容，这样<strong>加载的时候速度会很快</strong>。</p><p>加载完 RDB 的内容后，才会加载后半部分的 AOF 内容，这里的内容是 Redis 后台子进程重写 AOF 期间，主线程处理的操作命令，可以使得<strong>数据更少的丢失。</strong></p><p><strong>混合持久化优点：</strong></p><ul><li>混合持久化结合了 RDB 和 AOF 持久化的优点，开头为 RDB 的格式，使得 Redis 可以更快的启动，同时结合 AOF 的优点，有减低了大量数据丢失的风险。</li></ul><p><strong>混合持久化缺点：</strong></p><ul><li>AOF 文件中添加了 RDB 格式的内容，使得 AOF 文件的可读性变得很差；</li><li>兼容性差，如果开启混合持久化，那么此混合持久化 AOF 文件，就不能用在 Redis 4.0 之前版本了。</li></ul><h2 id="八、Redis-涉及的算法"><a href="#八、Redis-涉及的算法" class="headerlink" title="八、Redis 涉及的算法"></a>八、Redis 涉及的算法</h2><h3 id="1-一致性Hash"><a href="#1-一致性Hash" class="headerlink" title="1.一致性Hash"></a>1.一致性Hash</h3><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779145889-e62ed280-3191-42c2-904d-1c8c373415eb-20250605100643333.png" alt="img"></p><h4 id="1-1-问题的由来"><a href="#1-1-问题的由来" class="headerlink" title="1.1 问题的由来"></a>1.1 问题的由来</h4><p>大多数应用，背后肯定不只有一台服务器提供服务。因为高可用或并发量的需要，都会使用多台服务器组成集群对外提供服务。那么问题来了，这么多服务器，要如何分配客户端请求呢？其实这个问题，就是 负载均衡问题了。解决负载均衡问题的算法很多，不同的负载均衡算法，适用于不同的应用场景和需求。一般，最简单的方式，就是引入一个中间的负载均衡层，让它将外界的请求 “轮流” 转发给内部的集群。比如集群有三个节点，并收到了3个请求，那么每个节点都会处理一个请求。</p><p>考虑到每个节点的硬件配置有区别，一般引用权重值。按不同节点的权重值，来分配请求，让处理能力更抢的节点，分担更多请求。</p><p>但是这种加权轮询使用场景是建立前提——每个节点存储的数据都是相同的。这样，访问任意一个节点都可以获取相同的结果。但是，这就无法应对 分布式系统。因为分布式系统，每个节点存储的数据是不同的。</p><p>比如：分布式存储系统，一般为了提高系统的容量，就会把数据水平切分到不同的节点来存储。比如 Redis，某个key应该到哪个或者那些节点上获的，应该是确定的。而不是任意访问一个节点都可以获取 key 对应的 value。</p><h4 id="1-2-直接使用哈希算法？"><a href="#1-2-直接使用哈希算法？" class="headerlink" title="1.2 直接使用哈希算法？"></a>1.2 直接使用哈希算法？</h4><p>很容易就会想到 hash算法，其可以通过一个 key 进行 哈希计算，每次都可以得到相同的值。这样就可以将某个 key 确定到一个节点了，可以满足分布式系统的负载均衡需求。</p><p>哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 hash(key) % 3 公式对数据进行了映射。如果客户端要获取指定 key 的数据，通过上面的公式定位节点。</p><p>但是这有一个很致命的问题：如果节点数据发生了变化，也就是在对系统做扩容或者缩容时，可能造成大部分映射关系改变。并且必须迁移改变了映射关系的数据，否则会查询不到数据的问题。假设总数据条数为 M，哈希算法在面对节点数量变化时，最坏情况下所有数据都需要迁移，所以它的数据迁移规模时 O（M），这样数据迁移成本太高。</p><h4 id="1-3-使用一致性哈希算法有什么问题"><a href="#1-3-使用一致性哈希算法有什么问题" class="headerlink" title="1.3 使用一致性哈希算法有什么问题?"></a>1.3 使用一致性哈希算法有什么问题?</h4><p>一致性哈希算法就很好地解决了分布式系统在扩容或者缩容时，发生过多的数据迁移的问题。一致哈希算法也用了取模运算，但于哈希算法不同的是，哈希算法是对节点数量进行取模，而一致哈希算法是对 2^32 进行取模运算&#x3D;</p><p>们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环。这个圆想可以想象成由 2^32 个点组成的圆，这个圆环被称为<strong>哈希环</strong>，如下图：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779145911-113a608a-7f26-4b41-8eff-464c49c5cdb4-20250605100626223.png" alt="img"></p><p>一致性哈希要进行两步哈希：</p><ul><li>第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；</li><li>第二步：当对数据进行存储或访问时，对数据进行哈希映射；</li></ul><p>所以，<strong>一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上</strong>。</p><p>问题来了，对「数据」进行哈希映射得到一个结果要怎么找到存储该数据的节点呢？</p><p>答案是，映射的结果值往<strong>顺时针的方向的找到第一个节点</strong>，就是存储该数据的节点。</p><p>举个例子，有 3 个节点经过哈希计算，映射到了如下图的位置：</p><p><img src="https://cdn.nlark.com/yuque/0/2023/png/35838370/1682779146288-40a6a0f2-c9c1-402e-b0b0-d5e849e93c80.png" alt="img"></p><p>接着，对要查询的 key-01 进行哈希计算，确定此 key-01 映射在哈希环的位置，然后从这个位置往顺时针的方向找到第一个节点，就是存储该 key-01 数据的节点。</p><p>比如，下图中的 key-01 映射的位置，往顺时针的方向找到第一个节点就是节点 A。</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779148088-70cf5d37-5c2c-4798-9017-0b922282dfde-20250605100619239.png" alt="img"></p><p>所以，当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：</p><ul><li>首先，对 key 进行哈希计算，确定此 key 在环上的位置；</li><li>然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。</li></ul><p>知道了一致哈希寻址的方式，我们来看看，如果增加一个节点或者减少一个节点会发生大量的数据迁移吗？</p><p>假设节点数量从 3 增加到了 4，新的节点 D 经过哈希计算后映射到了下图中的位置：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779148190-0c1b592b-c7fe-48c2-b1a3-809ba82d18c4-20250605100611637.png" alt="img"></p><p>你可以看到，key-01、key-03 都不受影响，只有 key-02 需要被迁移节点 D。</p><p>假设节点数量从 3 减少到了 2，比如将节点 A 移除：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779149035-52942a34-67f3-4b3c-b460-711a9a5e35f8-20250605100604477.png" alt="img"></p><p>你可以看到，key-02 和 key-03 不会受到影响，只有 key-01 需要被迁移节点 B。</p><p>因此，<strong>在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响</strong>。</p><p>上面这些图中 3 个节点映射在哈希环还是比较分散的，所以看起来请求都会「均衡」到每个节点。</p><p>但是<strong>一致性哈希算法并不保证节点能够在哈希环上分布均匀</strong>，这样就会带来一个问题，会有大量的请求集中在一个节点上。</p><p>比如，下图中 3 个节点的映射位置都在哈希环的右半边：</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779150974-f47dbce4-1f4a-4de3-a89c-46fe115a7c6e-20250605100557936.png" alt="img"></p><p>这时候有一半以上的数据的寻址都会找节点 A，也就是访问请求主要集中的节点 A 上，这肯定不行的呀，说好的负载均衡呢，这种情况一点都不均衡。</p><p>另外，在这种节点分布不均匀的情况下，进行容灾与扩容时，哈希环上的相邻节点容易受到过大影响，容易发生雪崩式的连锁反应。</p><p>比如，上图中如果节点 A 被移除了，当节点 A 宕机后，根据一致性哈希算法的规则，其上数据应该全部迁移到相邻的节点 B 上，这样，节点 B 的数据量、访问量都会迅速增加很多倍，一旦新增的压力超过了节点 B 的处理能力上限，就会导致节点 B 崩溃，进而形成雪崩式的连锁反应。</p><p>所以，<strong>一致性哈希算法虽然减少了数据迁移量，但是存在节点分布不均匀的问题</strong>。</p><h4 id="1-3-通过虚拟节点提高均衡度"><a href="#1-3-通过虚拟节点提高均衡度" class="headerlink" title="1.3 通过虚拟节点提高均衡度"></a>1.3 通过虚拟节点提高均衡度</h4><p>要想解决节点能在 哈希环上 分配不均匀的问题，就是要有大量的节点，节点越多，哈希环上的节点分布就越均匀。但问题是，实际上我们没有那么多节点，所以这个时候我们就加入虚拟节点，也就是对一个真实节点做多个副本。</p><p>具体做法是，不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点。所以这里有 两层 映射关系。</p><p>比如对每个节点分别设置 3 个虚拟节点：</p><ul><li>对节点 A 加上编号来作为虚拟节点：A-01、A-02、A-03</li><li>对节点 B 加上编号来作为虚拟节点：B-01、B-02、B-03</li><li>对节点 C 加上编号来作为虚拟节点：C-01、C-02、C-03</li></ul><p>引入虚拟节点后，原本哈希环上只有 3 个节点的情况，就会变成有 9 个虚拟节点映射到哈希环上，哈希环上的节点数量多了 3 倍。</p><p><img src="https://raw.githubusercontent.com/kongxiaoran/image-repo/main/blog/1682779151776-aaf4acdf-2263-4845-8949-6bcf82659d50-20250605100548993.png" alt="img"></p><p>你可以看到，<strong>节点数量多了后，节点在哈希环上的分布就相对均匀了</strong>。这时候，如果有访问请求寻址到「A-01」这个虚拟节点，接着再通过「A-01」虚拟节点找到真实节点 A，这样请求就能访问到真实节点 A 了。</p><p>上面为了方便你理解，每个真实节点仅包含 3 个虚拟节点，这样能起到的均衡效果其实很有限。而在实际的工程中，虚拟节点的数量会大很多，比如 Nginx 的一致性哈希算法，每个权重为 1 的真实节点就含有160 个虚拟节点。</p><p>另外，虚拟节点除了会提高节点的均衡度，还会提高系统的稳定性。<strong>当节点变化时，会有不同的节点共同分担系统的变化，因此稳定性更高</strong>。比如，当某个节点被移除时，对应 该节点的多个虚拟节点均会移除，而这些虚拟节点按顺时针方向的下一个虚拟节点，可能会对应不同的真实节点，即这些不同的真实节点共同分担了 节点被移除 导致的压力。</p><p>而且有虚拟节点的概念也方便了，对不同节点进行权重区分。硬件配置更好的节点，增加更多虚拟节点。</p><h4 id="1-4-总结"><a href="#1-4-总结" class="headerlink" title="1.4 总结"></a>1.4 总结</h4><p>轮训这类的策略只能适用与每个节点的数据都是相同的场景，访问任意节点都能请求到数据。但是不适用分布式系统，因为分布式系统意味着数据水平切分到了不同的节点上，访问数据的时候，一定要寻址存储该数据的节点。</p><p>哈希算法虽然能建立数据和节点的映射关系，但是每次在节点数量发生变化的时候，最坏情况下所有数据都需要迁移，这样太麻烦了，所以不适用节点数量变化的场景。</p><p>为了减少迁移的数据量，就出现了一致性哈希算法。</p><p>一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。</p><p>但是一致性哈希算法不能够均匀的分布节点，会出现大量请求都集中在一个节点的情况，在这种情况下进行容灾与扩容时，容易出现雪崩的连锁反应。</p><p>为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系。</p><p>引入虚拟节点后，可以会提高节点的均衡度，还会提高系统的稳定性。所以，带虚拟节点的一致性哈希方法不仅适合硬件配置不同的节点的场景，而且适合节点规模会发生变化的场景。</p><hr><p>摘录文章：</p><p>Redis 设计与实现（第一版）：<a href="https://redisbook.readthedocs.io/en/latest/index.html">https://redisbook.readthedocs.io/en/latest/index.html</a></p><p><a href="https://juejin.cn/post/6964531365643550751">美团二面：Redis与MySQL双写一致性如何保证？</a></p>]]></content>
      
      
      <categories>
          
          <category> 后端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>超绝插图网站推荐</title>
      <link href="/2024/12/23/%E8%B6%85%E7%BB%9D%E6%8F%92%E5%9B%BE%E7%BD%91%E7%AB%99%E6%8E%A8%E8%8D%90/"/>
      <url>/2024/12/23/%E8%B6%85%E7%BB%9D%E6%8F%92%E5%9B%BE%E7%BD%91%E7%AB%99%E6%8E%A8%E8%8D%90/</url>
      
        <content type="html"><![CDATA[<p>相信很多小伙伴，都认识到一个好的插图，对网站&#x2F;app 或者博客文章的重要性了。我常常也需要一些高质量有创意的插图，来装饰网站或app，让整体看起来非常得劲。这里推荐几个我自己用的</p><ul><li><p>pinterest</p><p>网站地址：<a href="https://www.pinterest.com/%EF%BC%8C%E5%85%8D%E8%B4%B9%E6%B3%A8%E5%86%8C%E5%92%8C%E4%B8%8B%E8%BD%BD%E5%8E%9F%E5%9B%BE">https://www.pinterest.com/，免费注册和下载原图</a></p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 前端 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>mac安装 picgo 报错 文件损坏</title>
      <link href="/2024/12/22/mac%E5%AE%89%E8%A3%85%20picgo%20%E6%8A%A5%E9%94%99%20%E6%96%87%E4%BB%B6%E6%8D%9F%E5%9D%8F/"/>
      <url>/2024/12/22/mac%E5%AE%89%E8%A3%85%20picgo%20%E6%8A%A5%E9%94%99%20%E6%96%87%E4%BB%B6%E6%8D%9F%E5%9D%8F/</url>
      
        <content type="html"><![CDATA[<h1 id="mac安装-picgo-报错-文件损坏"><a href="#mac安装-picgo-报错-文件损坏" class="headerlink" title="mac安装 picgo 报错 文件损坏"></a>mac安装 picgo 报错 文件损坏</h1><p>picgo下载地址：<a href="https://github.com/molunerfinn/picgo/releases">https://github.com/molunerfinn/picgo/releases</a></p><p>mac安装报错不是因为 picgo版本问题。而是mac的原因：<br>苹果自macOS Sierra 10.12版本起，去除了允许“任何来源”的选项（参考苹果官方文档关于系统安全性与隐私设置部分，具体链接：苹果官方文档相关页面 ）。这一系统安全策略变化，使得像PicGo这样的第三方未认证软件受到限制，即便软件本身未损坏，也可能因来源未被系统认可而无法正常打开</p><p>解决办法：</p><ol><li>给文件赋予安全性设置：<br>首先，在“访达”（Finder）中进入“应用程序”目录，将PicGo软件图标拖至终端窗口，获取其完整路径。然后，在终端执行如下命令（这里软件路径为&#x2F;Applications&#x2F;PicGo.app）：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo xattr -r -d com.apple.quarantine /Applications/PicGo.app</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> 开发/环境/软件问题 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Spark技术详解：核心原理、架构与高级实践</title>
      <link href="/2023/11/16/Spark%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E9%AB%98%E7%BA%A7%E5%AE%9E%E8%B7%B5/"/>
      <url>/2023/11/16/Spark%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86%E3%80%81%E6%9E%B6%E6%9E%84%E4%B8%8E%E9%AB%98%E7%BA%A7%E5%AE%9E%E8%B7%B5/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark技术详解：核心原理、架构与高级实践"><a href="#Spark技术详解：核心原理、架构与高级实践" class="headerlink" title="Spark技术详解：核心原理、架构与高级实践"></a>Spark技术详解：核心原理、架构与高级实践</h1><h2 id="一、引言：Spark的定位与价值"><a href="#一、引言：Spark的定位与价值" class="headerlink" title="一、引言：Spark的定位与价值"></a>一、引言：Spark的定位与价值</h2><p>Apache Spark是一个统一的分布式计算引擎，旨在提供高效、易用的大数据处理能力。与Hadoop MapReduce相比，Spark通过内存计算和DAG执行引擎实现了10-100倍的性能提升，同时支持批处理、流处理、交互式查询和机器学习等多种计算范式。</p><h3 id="1-1-Spark与Hadoop的关系"><a href="#1-1-Spark与Hadoop的关系" class="headerlink" title="1.1 Spark与Hadoop的关系"></a>1.1 Spark与Hadoop的关系</h3><p>Spark并非Hadoop的替代品，而是对Hadoop生态的补充和增强：</p><ul><li>存储层：Spark可直接访问HDFS、HBase等Hadoop存储系统</li><li>资源管理：Spark可运行在YARN、Mesos或自身的Standalone集群管理器上</li><li>计算模型：Spark提供更丰富的API和更高效的执行引擎</li></ul><h3 id="1-2-Spark核心优势"><a href="#1-2-Spark核心优势" class="headerlink" title="1.2 Spark核心优势"></a>1.2 Spark核心优势</h3><ul><li><strong>内存计算</strong>：中间结果存储在内存中，避免磁盘IO开销</li><li><strong>惰性计算</strong>：仅在需要结果时才执行计算，优化执行计划</li><li><strong>DAG引擎</strong>：基于有向无环图的执行计划，减少Shuffle操作</li><li><strong>统一平台</strong>：单一引擎支持批处理、流处理、SQL、机器学习和图计算</li><li><strong>多语言支持</strong>：提供Scala、Java、Python、R和SQL API</li></ul><h2 id="二、Spark核心架构"><a href="#二、Spark核心架构" class="headerlink" title="二、Spark核心架构"></a>二、Spark核心架构</h2><h3 id="2-1-集群架构"><a href="#2-1-集群架构" class="headerlink" title="2.1 集群架构"></a>2.1 集群架构</h3><p>Spark采用主从架构，主要由以下组件构成：</p><pre class="mermaid">%%{init: {"securityLevel": "loose"}}%%graph TD    Client[客户端] -->|提交应用| Driver[Driver<br/>(应用主控节点)]    Driver -->|申请资源| ClusterManager[集群管理器<br/>(YARN/Mesos/Standalone)]    ClusterManager -->|分配资源| Executor1[Executor<br/>(工作节点1)]    ClusterManager -->|分配资源| Executor2[Executor<br/>(工作节点2)]    ClusterManager -->|分配资源| Executor3[Executor<br/>(工作节点3)]    Driver -->|发送任务| Executor1    Driver -->|发送任务| Executor2    Driver -->|发送任务| Executor3    Executor1 -->|存储数据| Cache1[内存/磁盘缓存]    Executor2 -->|存储数据| Cache2[内存/磁盘缓存]    Executor3 -->|存储数据| Cache3[内存/磁盘缓存]    Executor1 <-->|数据 shuffle| Executor2    Executor2 <-->|数据 shuffle| Executor3</pre><h4 id="核心组件说明"><a href="#核心组件说明" class="headerlink" title="核心组件说明"></a>核心组件说明</h4><ul><li><p><strong>Driver</strong>：</p><ul><li>负责应用程序的整体控制流</li><li>维护Spark应用的元数据和执行状态</li><li>生成并优化执行计划</li><li>调度任务到Executor执行</li></ul></li><li><p><strong>Executor</strong>：</p><ul><li>在工作节点上运行的进程</li><li>执行Driver分配的任务（Task）</li><li>存储计算过程中的数据（内存或磁盘）</li><li>通过BlockManager管理数据缓存</li></ul></li><li><p><strong>Cluster Manager</strong>：</p><ul><li>负责集群资源管理和分配</li><li>支持多种模式：YARN、Mesos、Standalone、Kubernetes</li><li>不参与具体计算，仅提供资源隔离和调度</li></ul></li></ul><h3 id="2-2-应用执行流程"><a href="#2-2-应用执行流程" class="headerlink" title="2.2 应用执行流程"></a>2.2 应用执行流程</h3><ol><li><strong>提交应用</strong>：客户端通过<code>spark-submit</code>提交应用</li><li><strong>初始化Driver</strong>：集群管理器启动Driver进程</li><li><strong>资源申请</strong>：Driver向集群管理器申请资源</li><li><strong>启动Executor</strong>：集群管理器在工作节点上启动Executor</li><li><strong>任务调度</strong>：Driver将应用分解为任务并分配给Executor</li><li><strong>执行任务</strong>：Executor执行任务并缓存中间结果</li><li><strong>结果返回</strong>：任务完成后，结果返回给Driver或写入外部存储</li><li><strong>应用结束</strong>：所有任务完成，释放资源</li></ol><h3 id="2-3-核心配置参数"><a href="#2-3-核心配置参数" class="headerlink" title="2.3 核心配置参数"></a>2.3 核心配置参数</h3><table><thead><tr><th>参数类别</th><th>关键参数</th><th>说明</th><th>默认值</th></tr></thead><tbody><tr><td>资源配置</td><td><code>spark.driver.memory</code></td><td>Driver内存大小</td><td>1g</td></tr><tr><td></td><td><code>spark.executor.memory</code></td><td>每个Executor内存大小</td><td>1g</td></tr><tr><td></td><td><code>spark.executor.cores</code></td><td>每个Executor的CPU核心数</td><td>1</td></tr><tr><td></td><td><code>spark.executor.instances</code></td><td>Executor实例数</td><td>2</td></tr><tr><td>执行优化</td><td><code>spark.default.parallelism</code></td><td>默认并行度</td><td>所有Executor核心总数</td></tr><tr><td></td><td><code>spark.sql.shuffle.partitions</code></td><td>SQL shuffle分区数</td><td>200</td></tr><tr><td></td><td><code>spark.memory.fraction</code></td><td>用于执行和存储的内存比例</td><td>0.6</td></tr><tr><td>容错配置</td><td><code>spark.task.maxFailures</code></td><td>任务最大失败次数</td><td>4</td></tr><tr><td></td><td><code>spark.stage.maxConsecutiveAttempts</code></td><td>Stage最大连续尝试次数</td><td>4</td></tr></tbody></table><h2 id="三、Spark编程模型"><a href="#三、Spark编程模型" class="headerlink" title="三、Spark编程模型"></a>三、Spark编程模型</h2><h3 id="3-1-RDD：弹性分布式数据集"><a href="#3-1-RDD：弹性分布式数据集" class="headerlink" title="3.1 RDD：弹性分布式数据集"></a>3.1 RDD：弹性分布式数据集</h3><p>RDD（Resilient Distributed Dataset）是Spark的核心抽象，表示一个不可变、可分区、支持并行操作的分布式数据集。</p><h4 id="RDD核心特性"><a href="#RDD核心特性" class="headerlink" title="RDD核心特性"></a>RDD核心特性</h4><ul><li><strong>不可变性</strong>：一旦创建无法修改，只能通过转换操作生成新RDD</li><li><strong>分区机制</strong>：数据分布在多个分区中，每个分区可在不同节点上处理</li><li><strong>依赖关系</strong>：记录RDD之间的依赖关系，支持容错恢复</li><li><strong>惰性计算</strong>：转换操作（Transformation）惰性执行，行动操作（Action）触发计算</li><li><strong>持久化</strong>：支持将RDD缓存到内存或磁盘，加速重复访问</li><li><strong>分区器</strong>：控制键值对RDD的分区方式，优化数据本地性</li></ul><h4 id="RDD操作类型"><a href="#RDD操作类型" class="headerlink" title="RDD操作类型"></a>RDD操作类型</h4><table><thead><tr><th>操作类型</th><th>特点</th><th>示例</th></tr></thead><tbody><tr><td>转换操作<br>（Transformation）</td><td>惰性执行，返回新RDD</td><td><code>map()</code>, <code>filter()</code>, <code>groupByKey()</code>, <code>join()</code></td></tr><tr><td>行动操作<br>（Action）</td><td>立即执行，返回结果或写入外部系统</td><td><code>collect()</code>, <code>count()</code>, <code>take()</code>, <code>saveAsTextFile()</code></td></tr><tr><td>持久化操作<br>（Persistence）</td><td>缓存RDD到内存&#x2F;磁盘</td><td><code>cache()</code>, <code>persist()</code>, <code>unpersist()</code></td></tr></tbody></table><h4 id="RDD依赖关系"><a href="#RDD依赖关系" class="headerlink" title="RDD依赖关系"></a>RDD依赖关系</h4><p>RDD之间存在两种依赖关系，直接影响故障恢复和执行优化：</p><ul><li><p><strong>窄依赖（Narrow Dependency）</strong>：</p><ul><li>子RDD的每个分区依赖父RDD的少数分区</li><li>无需Shuffle，可在单个节点完成计算</li><li>示例：<code>map()</code>, <code>filter()</code>, <code>union()</code></li></ul></li><li><p><strong>宽依赖（Wide Dependency）</strong>：</p><ul><li>子RDD的每个分区依赖父RDD的多个分区</li><li>需要Shuffle，涉及跨节点数据传输</li><li>示例：<code>groupByKey()</code>, <code>reduceByKey()</code>, <code>join()</code></li></ul></li></ul><pre class="mermaid">%%{init: {"securityLevel": "loose"}}%%graph TD    subgraph 窄依赖        A[Parent RDD<br/>Partition 1] --> B[Child RDD<br/>Partition 1]        C[Parent RDD<br/>Partition 2] --> D[Child RDD<br/>Partition 2]    end    subgraph 宽依赖        E[Parent RDD<br/>Partition 1] --> G[Child RDD<br/>Partition 1]        E --> H[Child RDD<br/>Partition 2]        F[Parent RDD<br/>Partition 2] --> G        F --> H    end</pre><h3 id="3-2-DataFrame与Dataset"><a href="#3-2-DataFrame与Dataset" class="headerlink" title="3.2 DataFrame与Dataset"></a>3.2 DataFrame与Dataset</h3><p>Spark 1.3引入DataFrame，1.6引入Dataset，提供了比RDD更高层次的抽象和优化：</p><h4 id="DataFrame"><a href="#DataFrame" class="headerlink" title="DataFrame"></a>DataFrame</h4><ul><li>分布式的命名列数据集合，类似关系型数据库表</li><li>提供结构化API，支持SQL查询</li><li>内部使用Catalyst优化器生成高效执行计划</li><li>比RDD节省内存，因为采用列式存储和编码</li></ul><h4 id="Dataset"><a href="#Dataset" class="headerlink" title="Dataset"></a>Dataset</h4><ul><li>结合DataFrame的结构化优势和RDD的类型安全特性</li><li>在编译时进行类型检查，减少运行时错误</li><li>支持lambda表达式和关系型操作</li><li>针对JVM语言（Scala&#x2F;Java）提供类型安全，Python&#x2F;R通过动态包装实现</li></ul><h4 id="三者对比"><a href="#三者对比" class="headerlink" title="三者对比"></a>三者对比</h4><table><thead><tr><th>特性</th><th>RDD</th><th>DataFrame</th><th>Dataset</th></tr></thead><tbody><tr><td>数据表示</td><td>无类型对象集合</td><td>命名列的分布式数据集</td><td>强类型的对象集合</td></tr><tr><td>类型安全</td><td>是（编译时）</td><td>否</td><td>是（编译时）</td></tr><tr><td>优化支持</td><td>有限</td><td>完全支持Catalyst优化</td><td>完全支持Catalyst优化</td></tr><tr><td>API风格</td><td>函数式</td><td>SQL&#x2F;函数式</td><td>SQL&#x2F;函数式&#x2F;面向对象</td></tr><tr><td>序列化</td><td>Java序列化&#x2F;Kryo</td><td>Tungsten二进制格式</td><td>Tungsten二进制格式</td></tr><tr><td>内存效率</td><td>低</td><td>高</td><td>高</td></tr><tr><td>适用场景</td><td>复杂数据处理，非结构化数据</td><td>结构化数据，SQL查询</td><td>结构化数据，需要类型安全</td></tr></tbody></table><h2 id="四、Spark执行原理"><a href="#四、Spark执行原理" class="headerlink" title="四、Spark执行原理"></a>四、Spark执行原理</h2><h3 id="4-1-DAG调度器（DAG-Scheduler）"><a href="#4-1-DAG调度器（DAG-Scheduler）" class="headerlink" title="4.1 DAG调度器（DAG Scheduler）"></a>4.1 DAG调度器（DAG Scheduler）</h3><p>Spark使用DAG调度器将作业分解为Stage，并基于RDD依赖关系构建执行计划：</p><ol><li><strong>作业提交</strong>：Action操作触发作业提交</li><li><strong>DAG构建</strong>：根据RDD依赖关系构建DAG图</li><li><strong>Stage划分</strong>：以宽依赖为边界划分Stage，每个Stage包含多个Task</li><li><strong>任务集生成</strong>：为每个Stage创建TaskSet</li><li><strong>任务调度</strong>：将TaskSet提交给Task调度器</li></ol><pre class="mermaid">%%{init: {"securityLevel": "loose"}}%%graph TD    A[RDD 1] -->|map| B[RDD 2<br/>窄依赖]    B -->|filter| C[RDD 3<br/>窄依赖]    C -->|groupByKey| D[RDD 4<br/>宽依赖]    D -->|mapValues| E[RDD 5<br/>窄依赖]    E -->|reduceByKey| F[RDD 6<br/>宽依赖]    subgraph Stage 1        A        B        C    end    subgraph Stage 2        D        E    end    subgraph Stage 3        F    end</pre><h3 id="4-2-Task调度器（Task-Scheduler）"><a href="#4-2-Task调度器（Task-Scheduler）" class="headerlink" title="4.2 Task调度器（Task Scheduler）"></a>4.2 Task调度器（Task Scheduler）</h3><p>Task调度器负责将Task分配到Executor执行，并考虑数据本地性：</p><h4 id="数据本地性级别"><a href="#数据本地性级别" class="headerlink" title="数据本地性级别"></a>数据本地性级别</h4><ol><li><strong>PROCESS_LOCAL</strong>：数据在同一JVM进程中，最佳性能</li><li><strong>NODE_LOCAL</strong>：数据在同一节点上（不同进程）</li><li><strong>RACK_LOCAL</strong>：数据在同一机架的不同节点上</li><li><strong>ANY</strong>：数据在任意位置</li></ol><p>调度器优先选择高级别本地性，若无法满足则降级，并可配置等待超时时间（<code>spark.locality.wait</code>）。</p><h3 id="4-3-任务执行流程"><a href="#4-3-任务执行流程" class="headerlink" title="4.3 任务执行流程"></a>4.3 任务执行流程</h3><ol><li><strong>任务序列化</strong>：Driver序列化Task并发送到Executor</li><li><strong>任务反序列化</strong>：Executor反序列化Task</li><li><strong>数据本地化</strong>：尝试获取本地数据，否则远程拉取</li><li><strong>任务执行</strong>：执行计算逻辑</li><li><strong>结果返回</strong>：将结果返回给Driver或写入外部存储</li><li><strong>状态更新</strong>：向Driver汇报任务状态</li></ol><h3 id="4-4-Shuffle机制"><a href="#4-4-Shuffle机制" class="headerlink" title="4.4 Shuffle机制"></a>4.4 Shuffle机制</h3><p>Shuffle是宽依赖中数据重新分区的过程，是Spark性能的关键瓶颈：</p><h4 id="Shuffle过程"><a href="#Shuffle过程" class="headerlink" title="Shuffle过程"></a>Shuffle过程</h4><ol><li><p><strong>Map阶段</strong>：</p><ul><li>任务处理数据并生成中间结果</li><li>按分区器对中间结果进行分区和排序</li><li>将中间结果写入本地磁盘（Shuffle Write）</li></ul></li><li><p><strong>Reduce阶段</strong>：</p><ul><li>任务从Map节点拉取属于自己的分区数据（Shuffle Read）</li><li>合并排序拉取的数据</li><li>执行聚合操作</li></ul></li></ol><h4 id="Shuffle优化"><a href="#Shuffle优化" class="headerlink" title="Shuffle优化"></a>Shuffle优化</h4><ul><li><strong>合并输出文件</strong>：<code>spark.shuffle.consolidateFiles</code>，减少磁盘IO</li><li><strong>使用堆外内存</strong>：<code>spark.shuffle.memoryFraction</code>，避免GC问题</li><li><strong>优化排序</strong>：Tungsten引擎的堆外排序</li><li><strong>Shuffle管理器</strong>：Spark 2.x默认SortShuffleManager，替代HashShuffleManager</li></ul><h2 id="五、Spark-SQL与优化器"><a href="#五、Spark-SQL与优化器" class="headerlink" title="五、Spark SQL与优化器"></a>五、Spark SQL与优化器</h2><h3 id="5-1-Catalyst优化器"><a href="#5-1-Catalyst优化器" class="headerlink" title="5.1 Catalyst优化器"></a>5.1 Catalyst优化器</h3><p>Catalyst是Spark SQL的核心优化器，基于规则和成本的优化框架：</p><pre class="mermaid">%%{init: {"securityLevel": "loose"}}%%graph LR    A[SQL/DataSet API] --> B[未解析的逻辑计划<br/>(Unresolved Logical Plan)]    B --> C[解析后的逻辑计划<br/>(Analyzed Logical Plan)]    C --> D[优化后的逻辑计划<br/>(Optimized Logical Plan)]    D --> E[物理计划<br/>(Physical Plans)]    E --> F[选择最佳计划<br/>(Best Physical Plan)]    F --> G[执行<br/>(Execution)]</pre><h4 id="优化阶段"><a href="#优化阶段" class="headerlink" title="优化阶段"></a>优化阶段</h4><ol><li><p><strong>逻辑优化</strong>：</p><ul><li>谓词下推（Predicate Pushdown）</li><li>列裁剪（Column Pruning）</li><li>常量折叠（Constant Folding）</li><li>连接重排序（Join Reordering）</li></ul></li><li><p><strong>物理优化</strong>：</p><ul><li>选择最佳连接策略（Broadcast Hash Join、Sort Merge Join等）</li><li>确定分区方式和并行度</li><li>代码生成（Code Generation）</li></ul></li></ol><h3 id="5-2-Tungsten执行引擎"><a href="#5-2-Tungsten执行引擎" class="headerlink" title="5.2 Tungsten执行引擎"></a>5.2 Tungsten执行引擎</h3><p>Tungsten是Spark的内存管理和执行优化引擎，主要优化：</p><ul><li><strong>内存管理</strong>：使用自定义内存管理器，减少JVM对象开销</li><li><strong>二进制处理</strong>：使用二进制格式存储数据，避免Java对象头和引用开销</li><li><strong>代码生成</strong>：使用Whole-Stage Code Generation将多个算子合并为单个函数，消除虚函数调用和中间对象</li><li><strong>向量化执行</strong>：批量处理数据，利用CPU缓存和SIMD指令</li></ul><h3 id="5-3-自适应查询执行（AQE）"><a href="#5-3-自适应查询执行（AQE）" class="headerlink" title="5.3 自适应查询执行（AQE）"></a>5.3 自适应查询执行（AQE）</h3><p>Spark 3.0引入的自适应查询执行，在运行时动态优化执行计划：</p><ul><li><strong>动态合并分区</strong>：合并小数据分区，减少任务数量</li><li><strong>动态调整连接策略</strong>：根据运行时数据大小选择最佳连接方式</li><li><strong>动态优化倾斜连接</strong>：检测并处理数据倾斜</li></ul><h2 id="六、Spark-Streaming与实时处理"><a href="#六、Spark-Streaming与实时处理" class="headerlink" title="六、Spark Streaming与实时处理"></a>六、Spark Streaming与实时处理</h2><h3 id="6-1-两种流处理模型"><a href="#6-1-两种流处理模型" class="headerlink" title="6.1 两种流处理模型"></a>6.1 两种流处理模型</h3><h4 id="DStream（Spark-Streaming）"><a href="#DStream（Spark-Streaming）" class="headerlink" title="DStream（Spark Streaming）"></a>DStream（Spark Streaming）</h4><ul><li>基于微批处理的流处理模型</li><li>将流数据分割为小批量数据进行处理</li><li>延迟通常在秒级</li><li>API与RDD类似，易于使用</li></ul><h4 id="Structured-Streaming"><a href="#Structured-Streaming" class="headerlink" title="Structured Streaming"></a>Structured Streaming</h4><ul><li>基于DataFrame&#x2F;Dataset的流处理模型</li><li>提供”流即表”的抽象，处理无限数据流</li><li>支持事件时间（Event Time）和水印（Watermark）</li><li>支持Exactly-Once语义</li><li>延迟可低至毫秒级（Continuous Processing模式）</li></ul><h3 id="6-2-Structured-Streaming核心概念"><a href="#6-2-Structured-Streaming核心概念" class="headerlink" title="6.2 Structured Streaming核心概念"></a>6.2 Structured Streaming核心概念</h3><ul><li><strong>输入表</strong>：无限增长的输入数据</li><li><strong>结果表</strong>：查询结果不断更新的表</li><li><strong>输出模式</strong>：<ul><li>Append：仅输出新添加到结果表的行</li><li>Update：仅输出结果表中更新的行</li><li>Complete：输出结果表的所有行</li></ul></li><li><strong>水印</strong>：处理迟到数据的机制，定义数据的最大延迟时间</li></ul><h3 id="6-3-处理语义保证"><a href="#6-3-处理语义保证" class="headerlink" title="6.3 处理语义保证"></a>6.3 处理语义保证</h3><ul><li><strong>At-Least-Once</strong>：每条数据至少处理一次，可能重复</li><li><strong>Exactly-Once</strong>：每条数据精确处理一次，不重复不丢失<ul><li>实现依赖于检查点（Checkpoint）和事务性输出</li></ul></li></ul><h2 id="七、Spark内存管理"><a href="#七、Spark内存管理" class="headerlink" title="七、Spark内存管理"></a>七、Spark内存管理</h2><h3 id="7-1-内存区域划分"><a href="#7-1-内存区域划分" class="headerlink" title="7.1 内存区域划分"></a>7.1 内存区域划分</h3><p>Spark使用统一内存管理模型，将Executor内存划分为以下区域：</p><pre class="mermaid">%%{init: {"securityLevel": "loose"}}%%graph TD    subgraph JVM堆内存        subgraph 保留内存            RM[300MB固定保留]        end        subgraph 可用内存            subgraph 存储内存                SM[Storage Memory<br/>默认占可用内存60%]            end            subgraph 执行内存                EM[Execution Memory<br/>默认占可用内存60%]            end            Other[其他内存]        end    end    subgraph 堆外内存        OOM[Off-Heap Memory<br/>通过spark.memory.offHeap.size配置]    end</pre><ul><li><strong>存储内存</strong>：用于缓存RDD和广播变量</li><li><strong>执行内存</strong>：用于Shuffle、Join、Aggregation等计算</li><li><strong>堆外内存</strong>：绕过JVM直接管理的内存，避免GC开销</li></ul><h3 id="7-2-内存动态调整"><a href="#7-2-内存动态调整" class="headerlink" title="7.2 内存动态调整"></a>7.2 内存动态调整</h3><p>存储内存和执行内存之间可以动态调整：</p><ul><li>当一方内存不足时，可以借用另一方的空闲内存</li><li>执行内存优先，存储内存被借用后可被驱逐</li><li>可通过<code>spark.memory.storageFraction</code>调整基础比例</li></ul><h3 id="7-3-内存优化策略"><a href="#7-3-内存优化策略" class="headerlink" title="7.3 内存优化策略"></a>7.3 内存优化策略</h3><ul><li><strong>使用堆外内存</strong>：减少GC压力</li><li><strong>序列化缓存</strong>：<code>rdd.persist(StorageLevel.MEMORY_AND_DISK_SER)</code></li><li><strong>调整内存比例</strong>：根据应用类型调整存储和执行内存比例</li><li><strong>控制缓存大小</strong>：避免缓存过多数据导致GC</li><li><strong>使用Kryo序列化</strong>：比Java序列化更紧凑高效</li></ul><h2 id="八、Spark性能调优"><a href="#八、Spark性能调优" class="headerlink" title="八、Spark性能调优"></a>八、Spark性能调优</h2><h3 id="8-1-数据倾斜处理"><a href="#8-1-数据倾斜处理" class="headerlink" title="8.1 数据倾斜处理"></a>8.1 数据倾斜处理</h3><p>数据倾斜是Spark作业性能的常见瓶颈，表现为少数任务执行时间过长：</p><h4 id="检测数据倾斜"><a href="#检测数据倾斜" class="headerlink" title="检测数据倾斜"></a>检测数据倾斜</h4><ul><li>Spark UI的Stage页面查看任务执行时间分布</li><li>查看Shuffle Read Size分布</li><li>日志中的长尾任务警告</li></ul><h4 id="解决策略"><a href="#解决策略" class="headerlink" title="解决策略"></a>解决策略</h4><ol><li><p><strong>预处理数据</strong>：</p><ul><li>过滤异常值</li><li>拆分热点Key</li></ul></li><li><p><strong>调整并行度</strong>：</p><ul><li>增加Shuffle分区数：<code>spark.sql.shuffle.partitions</code></li><li>设置合理的默认并行度：<code>spark.default.parallelism</code></li></ul></li><li><p><strong>使用特殊算子</strong>：</p><ul><li><code>reduceByKey</code>替代<code>groupByKey</code></li><li><code>aggregateByKey</code>自定义聚合逻辑</li><li><code>repartitionAndSortWithinPartitions</code>替代<code>repartition</code>+<code>sort</code></li></ul></li><li><p><strong>加盐（Salting）</strong>：</p><ul><li>对热点Key添加随机前缀</li><li>两次聚合（局部聚合+全局聚合）</li></ul></li><li><p><strong>广播连接（Broadcast Join）</strong>：</p><ul><li>小表广播到所有节点，避免Shuffle</li><li><code>spark.sql.autoBroadcastJoinThreshold</code>控制自动广播阈值</li></ul></li></ol><h3 id="8-2-序列化优化"><a href="#8-2-序列化优化" class="headerlink" title="8.2 序列化优化"></a>8.2 序列化优化</h3><ul><li><strong>使用Kryo序列化</strong>：<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>()</span><br><span class="line">  .set(<span class="string">&quot;spark.serializer&quot;</span>, <span class="string">&quot;org.apache.spark.serializer.KryoSerializer&quot;</span>)</span><br><span class="line">  .registerKryoClasses(<span class="type">Array</span>(classOf[<span class="type">MyClass</span>]))</span><br></pre></td></tr></table></figure></li><li><strong>优化对象结构</strong>：避免使用复杂嵌套对象</li><li><strong>控制序列化缓冲区大小</strong>：<code>spark.kryoserializer.buffer.max</code></li></ul><h3 id="8-3-JVM调优"><a href="#8-3-JVM调优" class="headerlink" title="8.3 JVM调优"></a>8.3 JVM调优</h3><ul><li><strong>设置合理的内存大小</strong>：避免过大堆内存导致GC延迟</li><li><strong>调整新生代大小</strong>：<code>-Xmn</code>，通常为堆内存的1&#x2F;4到1&#x2F;3</li><li><strong>选择合适的GC算法</strong>：G1GC适合大内存场景<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark.executor.extraJavaOptions -XX:+UseG1GC -XX:MaxGCPauseMillis=200</span><br></pre></td></tr></table></figure></li><li><strong>监控GC情况</strong>：<code>-verbose:gc -XX:+PrintGCDetails -XX:+PrintGCTimeStamps</code></li></ul><h3 id="8-4-其他优化技巧"><a href="#8-4-其他优化技巧" class="headerlink" title="8.4 其他优化技巧"></a>8.4 其他优化技巧</h3><ul><li>**避免使用<code>collect()</code>**：将分布式数据拉取到本地</li><li>**使用<code>foreachPartition</code>替代<code>foreach</code>**：减少创建对象开销</li><li><strong>合理使用持久化</strong>：避免重复计算</li><li><strong>使用<code>repartition</code>和<code>coalesce</code>优化分区</strong>：<code>coalesce</code>避免全Shuffle</li><li><strong>广播大变量</strong>：<code>spark.broadcast()</code>减少数据传输</li></ul><h2 id="九、Spark集群部署与管理"><a href="#九、Spark集群部署与管理" class="headerlink" title="九、Spark集群部署与管理"></a>九、Spark集群部署与管理</h2><h3 id="9-1-部署模式"><a href="#9-1-部署模式" class="headerlink" title="9.1 部署模式"></a>9.1 部署模式</h3><p>Spark支持多种部署模式，适应不同的集群环境：</p><h4 id="Standalone模式"><a href="#Standalone模式" class="headerlink" title="Standalone模式"></a>Standalone模式</h4><ul><li>Spark自带的集群管理器</li><li>简单易用，无需依赖其他组件</li><li>支持自动故障转移（Spark 1.2+）</li></ul><h4 id="YARN模式"><a href="#YARN模式" class="headerlink" title="YARN模式"></a>YARN模式</h4><ul><li>集成Hadoop YARN资源管理器</li><li>共享集群资源，与MapReduce共存</li><li>支持两种模式：<ul><li>YARN Client：Driver在客户端运行</li><li>YARN Cluster：Driver在集群中运行</li></ul></li></ul><h4 id="Kubernetes模式"><a href="#Kubernetes模式" class="headerlink" title="Kubernetes模式"></a>Kubernetes模式</h4><ul><li>容器化部署，适合云环境</li><li>动态扩缩容，资源利用率高</li><li>支持Spark应用的容器化打包</li></ul><h3 id="9-2-集群配置最佳实践"><a href="#9-2-集群配置最佳实践" class="headerlink" title="9.2 集群配置最佳实践"></a>9.2 集群配置最佳实践</h3><ul><li><p><strong>Executor内存分配</strong>：</p><ul><li>避免设置过大内存（建议不超过32GB），减少GC压力</li><li>为操作系统和缓存预留10-20%内存</li></ul></li><li><p><strong>CPU核心配置</strong>：</p><ul><li>每个Executor核心数建议2-5个</li><li>考虑超线程，物理核心数的1-2倍</li></ul></li><li><p><strong>网络配置</strong>：</p><ul><li>使用高性能网络（10Gbps+）减少Shuffle开销</li><li>配置合理的网络缓冲区大小</li></ul></li><li><p><strong>存储配置</strong>：</p><ul><li>使用SSD存储Shuffle数据</li><li>多个磁盘分散IO压力</li></ul></li></ul><h3 id="9-3-监控与调试"><a href="#9-3-监控与调试" class="headerlink" title="9.3 监控与调试"></a>9.3 监控与调试</h3><ul><li><p><strong>Spark UI</strong>：提供应用执行的详细指标</p><ul><li>默认地址：http:&#x2F;&#x2F;<driver-node>:4040</li><li>历史服务器：Spark History Server</li></ul></li><li><p><strong>日志管理</strong>：</p><ul><li>配置日志聚合（YARN模式下<code>yarn.log-aggregation-enable</code>）</li><li>使用ELK栈集中管理日志</li></ul></li><li><p><strong>性能分析工具</strong>：</p><ul><li>Sparklens：Spark性能分析工具</li><li>Flame Graph：可视化CPU使用情况</li><li>GC日志分析：GCEasy、GCViewer</li></ul></li></ul><h2 id="十、Spark生态系统"><a href="#十、Spark生态系统" class="headerlink" title="十、Spark生态系统"></a>十、Spark生态系统</h2><p>Spark生态系统包含多个组件，提供端到端的大数据解决方案：</p><pre class="mermaid">%%{init: {"securityLevel": "loose"}}%%graph LR    SparkCore[Spark Core<br/>核心引擎] --> SparkSQL[Spark SQL<br/>结构化查询]    SparkCore --> SparkStreaming[Spark Streaming<br/>流处理]    SparkCore --> MLlib[MLlib<br/>机器学习]    SparkCore --> GraphX[GraphX<br/>图计算]    SparkSQL --> DeltaLake[Delta Lake<br/>数据湖]    SparkStreaming --> StructuredStreaming[Structured Streaming<br/>结构化流处理]    MLlib --> MLflow[MLflow<br/>机器学习生命周期管理]</pre><h3 id="10-1-核心组件"><a href="#10-1-核心组件" class="headerlink" title="10.1 核心组件"></a>10.1 核心组件</h3><ul><li><strong>Spark SQL</strong>：处理结构化数据，支持SQL和DataFrame API</li><li><strong>Spark Streaming</strong>：微批处理流数据</li><li><strong>Structured Streaming</strong>：基于DataFrame的流处理，支持事件时间</li><li><strong>MLlib</strong>：机器学习库，提供常用算法和工具</li><li><strong>GraphX</strong>：图计算库，支持图算法和图操作</li></ul><h3 id="10-2-生态扩展"><a href="#10-2-生态扩展" class="headerlink" title="10.2 生态扩展"></a>10.2 生态扩展</h3><ul><li><strong>Delta Lake</strong>：构建在Spark之上的数据湖解决方案，支持ACID事务</li><li><strong>Kafka</strong>：与Spark Streaming&#x2F;Structured Streaming集成的流数据平台</li><li><strong>Hudi</strong>：增量处理框架，支持数据更新和删除</li><li><strong>Iceberg</strong>：开放表格式，支持大型分析数据集</li><li><strong>MLflow</strong>：机器学习生命周期管理工具</li></ul><h2 id="十一、实际应用场景与最佳实践"><a href="#十一、实际应用场景与最佳实践" class="headerlink" title="十一、实际应用场景与最佳实践"></a>十一、实际应用场景与最佳实践</h2><h3 id="11-1-典型应用场景"><a href="#11-1-典型应用场景" class="headerlink" title="11.1 典型应用场景"></a>11.1 典型应用场景</h3><ul><li><strong>批处理ETL</strong>：数据清洗、转换和加载</li><li><strong>实时数据处理</strong>：日志分析、实时监控</li><li><strong>交互式数据分析</strong>：Ad-hoc查询、数据探索</li><li><strong>机器学习</strong>：模型训练、预测和评估</li><li><strong>图计算</strong>：社交网络分析、路径查找</li></ul><h3 id="11-2-最佳实践案例"><a href="#11-2-最佳实践案例" class="headerlink" title="11.2 最佳实践案例"></a>11.2 最佳实践案例</h3><h4 id="案例1：大数据ETL优化"><a href="#案例1：大数据ETL优化" class="headerlink" title="案例1：大数据ETL优化"></a>案例1：大数据ETL优化</h4><p>某电商平台使用Spark进行每日用户行为数据ETL：</p><ul><li><strong>问题</strong>：原始数据量大（TB级），包含大量小文件</li><li><strong>优化措施</strong>：<ol><li>使用<code>coalesce</code>合并小文件</li><li>采用Snappy压缩存储中间结果</li><li>缓存频繁访问的维度表</li><li>使用广播连接优化维度关联</li></ol></li><li><strong>效果</strong>：ETL作业执行时间从4小时减少到1.5小时</li></ul><h4 id="案例2：实时推荐系统"><a href="#案例2：实时推荐系统" class="headerlink" title="案例2：实时推荐系统"></a>案例2：实时推荐系统</h4><p>某视频平台使用Structured Streaming构建实时推荐系统：</p><ul><li><strong>架构</strong>：Kafka + Spark Structured Streaming + Redis</li><li><strong>关键技术</strong>：<ol><li>事件时间窗口计算用户兴趣</li><li>水印处理迟到数据</li><li>状态管理保存用户偏好</li><li>微批处理间隔设为5秒</li></ol></li><li><strong>效果</strong>：推荐延迟从分钟级降至秒级，用户点击率提升15%</li></ul><h4 id="案例3：机器学习模型训练"><a href="#案例3：机器学习模型训练" class="headerlink" title="案例3：机器学习模型训练"></a>案例3：机器学习模型训练</h4><p>某金融公司使用MLlib构建信用评分模型：</p><ul><li><strong>数据规模</strong>：千万级用户数据，数百个特征</li><li><strong>优化措施</strong>：<ol><li>使用DataFrame API进行特征工程</li><li>采用交叉验证选择最佳参数</li><li>使用管道（Pipeline）整合特征处理和模型训练</li><li>模型并行训练加速收敛</li></ol></li><li><strong>效果</strong>：模型训练时间减少40%，预测准确率提升3%</li></ul><h2 id="十二、总结与展望"><a href="#十二、总结与展望" class="headerlink" title="十二、总结与展望"></a>十二、总结与展望</h2><p>Spark作为新一代分布式计算引擎，通过内存计算、DAG执行和丰富的API，极大提升了大数据处理效率。其统一的编程模型和丰富的生态系统，使其成为大数据处理的首选平台。</p><h3 id="12-1-Spark发展趋势"><a href="#12-1-Spark发展趋势" class="headerlink" title="12.1 Spark发展趋势"></a>12.1 Spark发展趋势</h3><ul><li><strong>性能持续优化</strong>：进一步提升执行效率和资源利用率</li><li><strong>云原生支持</strong>：更好地适应云环境，支持Serverless架构</li><li><strong>流批一体</strong>：统一批处理和流处理模型</li><li><strong>AI集成</strong>：更紧密地与机器学习和深度学习集成</li><li><strong>易用性提升</strong>：简化API，降低使用门槛</li></ul><h3 id="12-2-结语"><a href="#12-2-结语" class="headerlink" title="12.2 结语"></a>12.2 结语</h3><p>Spark的设计理念体现了分布式计算的核心思想：通过抽象简化复杂性，通过优化提升性能，通过统一整合多样性。深入理解Spark的内部原理和优化技术，对于构建高效、可靠的大数据系统至关重要。随着大数据技术的不断发展，Spark将继续在数据处理领域发挥核心作用，推动数据驱动决策的广泛应用。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
          <category> 分布式计算 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> 分布式处理 </tag>
            
            <tag> 内存计算 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HDFS技术详解：架构、存储与数据安全机制</title>
      <link href="/2023/11/15/HDFS%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E6%9E%B6%E6%9E%84%E3%80%81%E5%AD%98%E5%82%A8%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/"/>
      <url>/2023/11/15/HDFS%E6%8A%80%E6%9C%AF%E8%AF%A6%E8%A7%A3%EF%BC%9A%E6%9E%B6%E6%9E%84%E3%80%81%E5%AD%98%E5%82%A8%E4%B8%8E%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="HDFS技术详解：架构、存储与数据安全机制"><a href="#HDFS技术详解：架构、存储与数据安全机制" class="headerlink" title="HDFS技术详解：架构、存储与数据安全机制"></a>HDFS技术详解：架构、存储与数据安全机制</h1><h2 id="一、整体架构"><a href="#一、整体架构" class="headerlink" title="一、整体架构"></a>一、整体架构</h2><p>HDFS采用主从（Master&#x2F;Slave）架构模式，由以下核心组件构成：</p><h3 id="1-1-核心组件"><a href="#1-1-核心组件" class="headerlink" title="1.1 核心组件"></a>1.1 核心组件</h3><ul><li><p><strong>NameNode</strong>：集群的管理者，负责：</p><ul><li>管理文件系统命名空间</li><li>维护文件与数据块的映射关系</li><li>记录数据块的副本信息</li><li>处理客户端的元数据操作请求</li></ul></li><li><p><strong>DataNode</strong>：数据存储节点，负责：</p><ul><li>存储实际的数据块</li><li>执行数据块的读写操作</li><li>定期向NameNode发送心跳和块报告</li></ul></li><li><p><strong>Secondary NameNode</strong>：辅助节点，负责：</p><ul><li>定期合并NameNode的编辑日志（EditLog）和镜像文件（FSImage）</li><li>减轻NameNode的负担，但不提供故障转移能力</li></ul></li></ul><h3 id="1-2-架构图"><a href="#1-2-架构图" class="headerlink" title="1.2 架构图"></a>1.2 架构图</h3><pre class="mermaid">graph TD    Client[客户端] -->|元数据操作| NameNode    Client -->|数据读写| DataNode1    Client -->|数据读写| DataNode2    Client -->|数据读写| DataNode3    NameNode -->|心跳检测| DataNode1    NameNode -->|心跳检测| DataNode2    NameNode -->|心跳检测| DataNode3    SecondaryNameNode -->|合并日志| NameNode    DataNode1 <-->|副本复制| DataNode2    DataNode2 <-->|副本复制| DataNode3</pre><h2 id="二、文件存储结构"><a href="#二、文件存储结构" class="headerlink" title="二、文件存储结构"></a>二、文件存储结构</h2><h3 id="2-1-数据块（Block）"><a href="#2-1-数据块（Block）" class="headerlink" title="2.1 数据块（Block）"></a>2.1 数据块（Block）</h3><ul><li>默认块大小：128MB（可通过<code>dfs.blocksize</code>配置）</li><li>大文件会被分割成多个块，小文件不会占用整个块空间</li><li>每个块会存储多个副本，默认3个（可通过<code>dfs.replication</code>配置）</li></ul><h3 id="2-2-副本放置策略"><a href="#2-2-副本放置策略" class="headerlink" title="2.2 副本放置策略"></a>2.2 副本放置策略</h3><ul><li>第一个副本：放置在客户端所在节点（如果客户端不在集群内，则随机选择）</li><li>第二个副本：放置在与第一个副本不同的机架上</li><li>第三个副本：放置在与第二个副本相同机架的不同节点上</li><li>更多副本：随机分配</li></ul><h3 id="2-3-存储结构图"><a href="#2-3-存储结构图" class="headerlink" title="2.3 存储结构图"></a>2.3 存储结构图</h3><pre class="mermaid">graph LR    File[大文件] --> Block1[数据块1128MB]    File --> Block2[数据块2128MB]    File --> Block3[数据块364MB]    Block1 --> DN1[副本1DataNode A]    Block1 --> DN2[副本2DataNode B不同机架]    Block1 --> DN3[副本3DataNode C同机架B]    Block2 --> DN4[副本1DataNode B]    Block2 --> DN5[副本2DataNode C不同机架]    Block2 --> DN6[副本3DataNode D同机架C]</pre><h2 id="三、数据模型"><a href="#三、数据模型" class="headerlink" title="三、数据模型"></a>三、数据模型</h2><h3 id="3-1-命名空间"><a href="#3-1-命名空间" class="headerlink" title="3.1 命名空间"></a>3.1 命名空间</h3><ul><li>层次化文件系统结构，与Linux文件系统类似</li><li>支持目录和文件的创建、删除、重命名等操作</li><li>通过URI标识文件：<code>hdfs://namenode:port/path/to/file</code></li></ul><h3 id="3-2-元数据"><a href="#3-2-元数据" class="headerlink" title="3.2 元数据"></a>3.2 元数据</h3><ul><li><strong>内存元数据</strong>：NameNode内存中维护的文件系统树及文件&#x2F;目录元数据</li><li><strong>持久化元数据</strong>：<ul><li>FSImage：文件系统元数据的快照</li><li>EditLog：记录文件系统的所有修改操作</li></ul></li></ul><h3 id="3-3-数据模型特点"><a href="#3-3-数据模型特点" class="headerlink" title="3.3 数据模型特点"></a>3.3 数据模型特点</h3><ul><li>一次写入，多次读取（不支持随机写入）</li><li>支持追加写入</li><li>文件一旦创建、写入并关闭后，不能修改</li></ul><h2 id="四、数据写入流程"><a href="#四、数据写入流程" class="headerlink" title="四、数据写入流程"></a>四、数据写入流程</h2><h3 id="4-1-详细步骤"><a href="#4-1-详细步骤" class="headerlink" title="4.1 详细步骤"></a>4.1 详细步骤</h3><ol><li><p><strong>客户端请求创建文件</strong></p><ul><li>客户端调用<code>DistributedFileSystem.create()</code>方法</li><li>NameNode检查权限、路径是否存在等</li><li>NameNode返回FSDataOutputStream对象</li></ul></li><li><p><strong>客户端写入数据</strong></p><ul><li>客户端将数据分成数据包（Packet，默认64KB）</li><li>客户端创建DataStreamer和ResponseProcessor</li><li>DataStreamer负责将数据包发送到DataNode</li></ul></li><li><p><strong>构建数据管道</strong></p><ul><li>NameNode选择合适的DataNode组成管道</li><li>例如：DataNode1 -&gt; DataNode2 -&gt; DataNode3</li></ul></li><li><p><strong>数据传输</strong></p><ul><li>客户端将数据包写入管道的第一个DataNode</li><li>每个DataNode接收数据包后存储，并转发给下一个DataNode</li><li>最后一个DataNode返回确认信息</li></ul></li><li><p><strong>完成写入</strong></p><ul><li>所有数据写入完成后，客户端调用<code>close()</code>方法</li><li>NameNode提交文件创建操作</li></ul></li></ol><h3 id="4-2-写入流程图"><a href="#4-2-写入流程图" class="headerlink" title="4.2 写入流程图"></a>4.2 写入流程图</h3><pre class="mermaid">sequenceDiagram    participant Client    participant NameNode    participant DN1    participant DN2    participant DN3    Client->>NameNode: 请求创建文件    NameNode-->>Client: 返回FSDataOutputStream    Client->>NameNode: 请求数据块存储位置    NameNode-->>Client: 返回DN1, DN2, DN3    Client->>DN1: 建立数据管道(DN1->DN2->DN3)    DN1->>DN2: 确认管道    DN2->>DN3: 确认管道    DN3-->>DN2: 管道确认    DN2-->>DN1: 管道确认    DN1-->>Client: 管道建立完成    loop 写入数据包        Client->>DN1: 发送数据包        DN1->>DN2: 转发数据包        DN2->>DN3: 转发数据包        DN3-->>DN2: ACK        DN2-->>DN1: ACK        DN1-->>Client: ACK    end    Client->>NameNode: 完成写入，关闭文件    NameNode-->>Client: 确认关闭</pre><h2 id="五、数据读取流程"><a href="#五、数据读取流程" class="headerlink" title="五、数据读取流程"></a>五、数据读取流程</h2><h3 id="5-1-详细步骤"><a href="#5-1-详细步骤" class="headerlink" title="5.1 详细步骤"></a>5.1 详细步骤</h3><ol><li><p><strong>客户端请求读取文件</strong></p><ul><li>客户端调用<code>DistributedFileSystem.open()</code>方法</li><li>NameNode返回文件的数据块信息及对应DataNode位置</li></ul></li><li><p><strong>选择最优DataNode</strong></p><ul><li>客户端根据网络拓扑选择最近的DataNode</li><li>优先读取本地节点数据，其次同机架节点，最后跨机架节点</li></ul></li><li><p><strong>读取数据</strong></p><ul><li>客户端创建FSDataInputStream对象</li><li>按顺序读取数据块</li><li>若某DataNode故障，自动切换到其他副本</li></ul></li><li><p><strong>数据校验</strong></p><ul><li>读取数据时验证校验和</li><li>若校验失败，读取其他副本并标记坏块</li></ul></li><li><p><strong>组装文件</strong></p><ul><li>客户端将读取的数据块组装成完整文件</li></ul></li></ol><h3 id="5-2-读取流程图"><a href="#5-2-读取流程图" class="headerlink" title="5.2 读取流程图"></a>5.2 读取流程图</h3><pre class="mermaid">sequenceDiagram    participant Client    participant NameNode    participant DN1    participant DN2    participant DN3    Client->>NameNode: 请求读取文件元数据    NameNode-->>Client: 返回数据块及副本位置    Client->>DN1: 请求读取数据块1(最近节点)    DN1-->>Client: 返回数据块1    Client->>DN2: 请求读取数据块2(最近节点)    DN2-->>Client: 返回数据块2    alt 数据块3读取失败        Client->>DN3: 请求读取数据块3        DN3-->>Client: 返回数据块3    end    Client->>Client: 组装数据块为完整文件</pre><h2 id="六、数据防丢失机制"><a href="#六、数据防丢失机制" class="headerlink" title="六、数据防丢失机制"></a>六、数据防丢失机制</h2><h3 id="6-1-副本机制"><a href="#6-1-副本机制" class="headerlink" title="6.1 副本机制"></a>6.1 副本机制</h3><ul><li>默认3副本策略，确保数据冗余</li><li>可针对重要文件设置更高的副本数</li><li>副本分布在不同机架，提高容错性</li></ul><h3 id="6-2-心跳检测"><a href="#6-2-心跳检测" class="headerlink" title="6.2 心跳检测"></a>6.2 心跳检测</h3><ul><li>DataNode每3秒向NameNode发送心跳</li><li>NameNode若10分钟未收到心跳，标记DataNode为死亡</li><li>自动复制死亡节点上的数据块到其他节点</li></ul><h3 id="6-3-数据完整性校验"><a href="#6-3-数据完整性校验" class="headerlink" title="6.3 数据完整性校验"></a>6.3 数据完整性校验</h3><ul><li>每个数据块都有对应的校验和（Checksum）</li><li>写入时计算校验和并存储</li><li>读取时重新计算并比对校验和</li><li>校验失败时读取其他副本，并标记坏块</li></ul><h3 id="6-4-安全模式"><a href="#6-4-安全模式" class="headerlink" title="6.4 安全模式"></a>6.4 安全模式</h3><ul><li>启动时自动进入安全模式</li><li>NameNode接收所有DataNode的块报告</li><li>当最小副本条件满足时，自动退出安全模式</li><li>可手动进入或退出安全模式</li></ul><h3 id="6-5-元数据备份"><a href="#6-5-元数据备份" class="headerlink" title="6.5 元数据备份"></a>6.5 元数据备份</h3><ul><li>FSImage和EditLog定期备份</li><li>支持配置多个元数据存储目录</li><li>可配置自动备份到远程存储</li></ul><h2 id="七、磁盘损坏应对措施"><a href="#七、磁盘损坏应对措施" class="headerlink" title="七、磁盘损坏应对措施"></a>七、磁盘损坏应对措施</h2><h3 id="7-1-坏块检测与处理"><a href="#7-1-坏块检测与处理" class="headerlink" title="7.1 坏块检测与处理"></a>7.1 坏块检测与处理</h3><ul><li>DataNode定期扫描磁盘上的数据块</li><li>发现坏块后向NameNode报告</li><li>NameNode安排从其他副本复制数据</li><li>达到最小副本数后，标记坏块为可删除</li></ul><h3 id="7-2-数据均衡"><a href="#7-2-数据均衡" class="headerlink" title="7.2 数据均衡"></a>7.2 数据均衡</h3><ul><li>HDFS Balancer工具自动平衡集群数据分布</li><li>避免个别节点存储压力过大</li><li>可手动触发或配置定期执行</li></ul><h3 id="7-3-节点退役"><a href="#7-3-节点退役" class="headerlink" title="7.3 节点退役"></a>7.3 节点退役</h3><ul><li>支持DataNode平滑退役</li><li>管理员可将节点加入退役列表</li><li>NameNode自动迁移数据到其他节点</li><li>数据迁移完成后，节点可安全下线</li></ul><h3 id="7-4-灾难恢复"><a href="#7-4-灾难恢复" class="headerlink" title="7.4 灾难恢复"></a>7.4 灾难恢复</h3><ul><li>利用Secondary NameNode的元数据备份</li><li>配置NameNode高可用（HA）</li><li>使用QJM（Quorum Journal Manager）共享编辑日志</li><li>配置自动故障转移</li></ul><h2 id="八、HDFS高级特性与优化"><a href="#八、HDFS高级特性与优化" class="headerlink" title="八、HDFS高级特性与优化"></a>八、HDFS高级特性与优化</h2><h3 id="8-1-HDFS联邦（Federation）"><a href="#8-1-HDFS联邦（Federation）" class="headerlink" title="8.1 HDFS联邦（Federation）"></a>8.1 HDFS联邦（Federation）</h3><p>HDFS联邦通过引入多个独立的NameNode&#x2F;Namespace解决了单NameNode的扩展性瓶颈，每个NameNode管理文件系统命名空间的一部分，彼此独立且不共享状态。</p><h4 id="核心组件"><a href="#核心组件" class="headerlink" title="核心组件"></a>核心组件</h4><ul><li><strong>NameNode&#x2F;Namespace</strong>：多个独立的命名空间，每个管理一部分文件系统</li><li><strong>Block Pool</strong>：每个命名空间关联一组数据块池，包含该命名空间下文件的所有数据块</li><li><strong>ClusterID</strong>：标识整个集群的唯一ID，所有NameNode共享此ID</li></ul><h4 id="架构优势"><a href="#架构优势" class="headerlink" title="架构优势"></a>架构优势</h4><ul><li>命名空间水平扩展，支持更多文件和更大存储容量</li><li>性能隔离，不同业务可使用不同命名空间</li><li>故障隔离，单个NameNode故障不影响其他命名空间</li><li>可独立升级各个NameNode</li></ul><pre class="mermaid">graph TD    Client[客户端] -->|挂载表| NS1[命名空间1NameNode A]    Client -->|挂载表| NS2[命名空间2NameNode B]    Client -->|挂载表| NS3[命名空间3NameNode C]    NS1 --> BP1[块池1DataNode集群]    NS2 --> BP2[块池2DataNode集群]    NS3 --> BP3[块池3DataNode集群]    BP1 & BP2 & BP3 --> CommonDataNodes[共享DataNode存储]</pre><h3 id="8-2-HDFS高可用（HA）实现"><a href="#8-2-HDFS高可用（HA）实现" class="headerlink" title="8.2 HDFS高可用（HA）实现"></a>8.2 HDFS高可用（HA）实现</h3><p>HDFS HA通过主备NameNode机制解决单点故障问题，避免了Secondary NameNode无法提供故障转移的局限。</p><h4 id="核心组件-1"><a href="#核心组件-1" class="headerlink" title="核心组件"></a>核心组件</h4><ul><li><strong>Active NameNode</strong>：处理所有客户端请求</li><li><strong>Standby NameNode</strong>：同步Active的元数据，随时准备接管</li><li><strong>JournalNodes</strong>：集群（通常3-5个节点），存储EditLog的共享存储</li><li><strong>ZKFC</strong>：ZooKeeper故障检测器，监控NameNode健康状态</li></ul><h4 id="故障转移流程"><a href="#故障转移流程" class="headerlink" title="故障转移流程"></a>故障转移流程</h4><ol><li>ZKFC定期向NameNode发送健康检查</li><li>Active节点故障时，ZKFC释放ZooKeeper锁</li><li>Standby节点的ZKFC获取锁，通过 fencing 机制确保Active节点完全下线</li><li>Standby节点升级为Active，开始处理客户端请求</li></ol><pre class="mermaid">graph TD    Client[客户端] -->|自动路由| AN[Active NameNode]    Client -->|故障时切换| SN[Standby NameNode]    AN -->|写入EditLog| JN[JournalNodes集群(>=3节点)]    SN -->|读取EditLog| JN    AN --> ZKFC1[ZKFC]    SN --> ZKFC2[ZKFC]    ZKFC1 & ZKFC2 --> ZK[ZooKeeper选举与健康监控]    AN -->|隔离机制| Fencing[Fencing防止脑裂]    SN -->|接管服务| Fencing</pre><h3 id="8-3-纠删码（Erasure-Coding）"><a href="#8-3-纠删码（Erasure-Coding）" class="headerlink" title="8.3 纠删码（Erasure Coding）"></a>8.3 纠删码（Erasure Coding）</h3><p>Hadoop 3.0引入纠删码机制，在提供同等容错能力的同时大幅降低存储开销，适用于冷数据存储。</p><h4 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h4><ul><li>使用Reed-Solomon码：将n个数据块编码为m个校验块，任意n个块可恢复原始数据</li><li>默认配置(6,3)：6个数据块+3个校验块，相比3副本节省50%存储空间</li><li>支持按目录配置：通过<code>dfs.namenode.ec.system.default.policy</code>设置默认策略</li></ul><h4 id="优缺点对比"><a href="#优缺点对比" class="headerlink" title="优缺点对比"></a>优缺点对比</h4><table><thead><tr><th>特性</th><th>纠删码(6,3)</th><th>3副本机制</th></tr></thead><tbody><tr><td>存储开销</td><td>150%</td><td>200%</td></tr><tr><td>容错能力</td><td>最多3个块丢失</td><td>最多2个副本丢失</td></tr><tr><td>读写性能</td><td>写性能较低，读性能接近</td><td>读写性能均衡</td></tr><tr><td>适用场景</td><td>冷数据、归档数据</td><td>热数据、频繁访问数据</td></tr></tbody></table><h3 id="8-4-HDFS缓存机制"><a href="#8-4-HDFS缓存机制" class="headerlink" title="8.4 HDFS缓存机制"></a>8.4 HDFS缓存机制</h3><p>HDFS提供集中式缓存管理，允许将频繁访问的数据块缓存在指定DataNode的内存中，提高读取性能。</p><h4 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h4><ul><li><strong>缓存池（Cache Pool）</strong>：管理员创建的资源分配单元，包含缓存空间配额和权限控制</li><li><strong>缓存指令（Cache Directive）</strong>：指定要缓存的路径和缓存副本数</li><li><strong>缓存块（Cached Block）</strong>：被缓存的数据块，保留在DataNode内存中</li></ul><h4 id="工作流程"><a href="#工作流程" class="headerlink" title="工作流程"></a>工作流程</h4><ol><li>管理员创建缓存池并分配资源</li><li>用户提交缓存指令指定要缓存的文件&#x2F;目录</li><li>NameNode选择合适的DataNode缓存数据块</li><li>DataNode将数据块加载到内存并向NameNode确认</li><li>客户端读取时优先选择缓存副本</li></ol><h3 id="8-5-HDFS安全机制"><a href="#8-5-HDFS安全机制" class="headerlink" title="8.5 HDFS安全机制"></a>8.5 HDFS安全机制</h3><h4 id="8-5-1-身份认证"><a href="#8-5-1-身份认证" class="headerlink" title="8.5.1 身份认证"></a>8.5.1 身份认证</h4><ul><li><strong>Kerberos认证</strong>：HDFS默认的强认证机制，通过票据验证用户身份</li><li><strong>简单认证</strong>：适用于测试环境，基于主机名或用户名的信任机制</li><li><strong>Delegation Tokens</strong>：允许应用程序代表用户访问HDFS，避免重复认证</li></ul><h4 id="8-5-2-授权控制"><a href="#8-5-2-授权控制" class="headerlink" title="8.5.2 授权控制"></a>8.5.2 授权控制</h4><ul><li><strong>POSIX风格权限</strong>：基于用户、组和其他用户的读&#x2F;写&#x2F;执行权限</li><li><strong>ACL（访问控制列表）</strong>：更细粒度的权限控制，支持为特定用户&#x2F;组设置权限</li><li><strong>NameNode权限检查</strong>：所有元数据操作需通过权限验证</li><li><strong>DataNode权限检查</strong>：数据块访问需验证块所有权</li></ul><h4 id="8-5-3-数据保护"><a href="#8-5-3-数据保护" class="headerlink" title="8.5.3 数据保护"></a>8.5.3 数据保护</h4><ul><li><strong>传输加密</strong>：使用SSL&#x2F;TLS加密节点间数据传输</li><li><strong>存储加密</strong>：透明数据加密（TDE）保护磁盘上的数据</li><li><strong>数据脱敏</strong>：通过HDFS加密区（Encryption Zones）实现敏感数据隔离</li></ul><h2 id="九、HDFS性能优化"><a href="#九、HDFS性能优化" class="headerlink" title="九、HDFS性能优化"></a>九、HDFS性能优化</h2><h3 id="9-1-关键配置优化"><a href="#9-1-关键配置优化" class="headerlink" title="9.1 关键配置优化"></a>9.1 关键配置优化</h3><h4 id="NameNode优化"><a href="#NameNode优化" class="headerlink" title="NameNode优化"></a>NameNode优化</h4><ul><li><code>dfs.namenode.handler.count</code>：处理RPC请求的线程数，建议设置为集群规模的2-4倍</li><li><code>dfs.namenode.fs-limits.max-directory-items</code>：单个目录最大文件数，默认1048576</li><li><code>dfs.namenode.name.dir</code>：配置多个存储目录（最好包含SSD）提高元数据可靠性</li></ul><h4 id="DataNode优化"><a href="#DataNode优化" class="headerlink" title="DataNode优化"></a>DataNode优化</h4><ul><li><code>dfs.datanode.handler.count</code>：DataNode处理RPC的线程数，建议10-20</li><li><code>dfs.datanode.max.transfer.threads</code>：数据传输线程数，建议4096</li><li><code>dfs.datanode.balance.bandwidthPerSec</code>：平衡数据时的带宽限制，默认1048576（1MB&#x2F;s）</li></ul><h4 id="客户端优化"><a href="#客户端优化" class="headerlink" title="客户端优化"></a>客户端优化</h4><ul><li><code>dfs.client.read.shortcircuit</code>：启用短路读取，绕过DataNode直接读取本地数据</li><li><code>dfs.client.block.write.replace-datanode-on-failure.policy</code>：写入失败时替换DataNode策略</li><li><code>io.file.buffer.size</code>：文件缓冲区大小，建议64KB-128KB</li></ul><h3 id="9-2-块大小与副本策略优化"><a href="#9-2-块大小与副本策略优化" class="headerlink" title="9.2 块大小与副本策略优化"></a>9.2 块大小与副本策略优化</h3><h4 id="块大小选择"><a href="#块大小选择" class="headerlink" title="块大小选择"></a>块大小选择</h4><ul><li>大文件（如日志、视频）：256MB-512MB，减少块数量和元数据开销</li><li>小文件（如文档、图片）：64MB，提高并行处理效率</li><li>计算密集型作业：较小块大小，增加并行度</li><li>IO密集型作业：较大块大小，减少寻址开销</li></ul><h4 id="副本策略调整"><a href="#副本策略调整" class="headerlink" title="副本策略调整"></a>副本策略调整</h4><ul><li>热数据：3-5个副本，提高可用性</li><li>温数据：2-3个副本，平衡可用性和存储成本</li><li>冷数据：1个副本+纠删码，降低存储成本</li><li>本地性优化：根据计算节点位置调整副本分布</li></ul><h3 id="9-3-小文件问题解决方案"><a href="#9-3-小文件问题解决方案" class="headerlink" title="9.3 小文件问题解决方案"></a>9.3 小文件问题解决方案</h3><p>HDFS对大量小文件处理效率低下，可通过以下方案优化：</p><h4 id="合并小文件"><a href="#合并小文件" class="headerlink" title="合并小文件"></a>合并小文件</h4><ul><li>使用Hadoop Archive（HAR）将多个小文件打包成一个归档文件</li><li>应用层预处理，合并小文件后写入HDFS</li></ul><h4 id="联邦与命名空间隔离"><a href="#联邦与命名空间隔离" class="headerlink" title="联邦与命名空间隔离"></a>联邦与命名空间隔离</h4><ul><li>将不同类型小文件分布到不同命名空间</li><li>减轻单个NameNode的内存压力</li></ul><h4 id="缓存小文件元数据"><a href="#缓存小文件元数据" class="headerlink" title="缓存小文件元数据"></a>缓存小文件元数据</h4><ul><li>配置<code>dfs.namenode.metacache.size</code>增加元数据缓存</li><li>减少NameNode磁盘IO</li></ul><h2 id="十、总结"><a href="#十、总结" class="headerlink" title="十、总结"></a>十、总结</h2><p>HDFS通过精心设计的分布式架构、副本机制和数据校验等技术，在大规模集群环境下提供了高吞吐量和高可靠性的数据存储服务。其核心设计思想是通过牺牲部分硬件成本和延迟，换取系统的可扩展性和容错性，非常适合存储海量数据并进行批处理分析。</p><p>理解HDFS的内部工作原理，对于优化大数据处理性能、保障数据安全以及解决实际生产环境中的问题具有重要意义。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
          <category> Hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分布式存储 </tag>
            
            <tag> HDFS </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
